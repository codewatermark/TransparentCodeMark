func,func_intent_summary,security_intent_summary
"def sina_xml_to_url_list(xml_data):
    """"""str->list
    Convert XML to URL List.
    From Biligrab.
    """"""
    rawurl = []
    dom = parseString(xml_data)
    for node in dom.getElementsByTagName('durl'):
        url = node.getElementsByTagName('url')[0]
        rawurl.append(url.childNodes[0].data)
    return rawurl","str->list
    Convert XML to URL List.
    From Biligrab.",
"def makeMimi(upid):
    """"""From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js
    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal
    L110""""""
    strSeed = ""gGddgPfeaf_gzyr""
    prehash = upid + ""_"" + strSeed
    return md5(prehash.encode('utf-8')).hexdigest()","From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js
    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal
    L110",
"def dictify(r,root=True):
    """"""http://stackoverflow.com/a/30923963/2946714""""""
    if root:
        return {r.tag : dictify(r, False)}
    d=copy(r.attrib)
    if r.text:
        d[""_text""]=r.text
    for x in r.findall(""./*""):
        if x.tag not in d:
            d[x.tag]=[]
        d[x.tag].append(dictify(x,False))
    return d",http://stackoverflow.com/a/30923963/2946714,
"def ucas_download_playlist(url, output_dir = '.', merge = False, info_only = False, **kwargs):
    '''course page'''
    html = get_content(url)

    parts = re.findall( r'(getplaytitle.do\?.+)""', html)
    assert parts, 'No part found!'

    for part_path in parts:
        ucas_download('http://v.ucas.ac.cn/course/' + part_path, output_dir=output_dir, merge=merge, info_only=info_only)",course page,
"def sprint(text, *colors):
    """"""Format text with color or other effects into ANSI escaped string.""""""
    return ""\33[{}m{content}\33[{}m"".format("";"".join([str(color) for color in colors]), RESET, content=text) if IS_ANSI_TERMINAL and colors else text",Format text with color or other effects into ANSI escaped string.,
"def print_log(text, *colors):
    """"""Print a log message to standard error.""""""
    sys.stderr.write(sprint(""{}: {}"".format(script_name, text), *colors) + ""\n"")",Print a log message to standard error.,
"def e(message, exit_code=None):
    """"""Print an error log message.""""""
    print_log(message, YELLOW, BOLD)
    if exit_code is not None:
        sys.exit(exit_code)",Print an error log message.,
"def wtf(message, exit_code=1):
    """"""What a Terrible Failure!""""""
    print_log(message, RED, BOLD)
    if exit_code is not None:
        sys.exit(exit_code)",What a Terrible Failure!,
"def vimeo_download_by_channel(url, output_dir='.', merge=False, info_only=False, **kwargs):
    """"""str->None""""""
    # https://vimeo.com/channels/464686
    channel_id = match1(url, r'http://vimeo.com/channels/(\w+)')
    vimeo_download_by_channel_id(channel_id, output_dir, merge, info_only, **kwargs)",str->None,
"def get_vid_from_url(url):
        """"""Extracts video ID from URL.
        """"""
        vid = match1(url, 'https?://www.mgtv.com/(?:b|l)/\d+/(\d+).html')
        if not vid:
            vid = match1(url, 'https?://www.mgtv.com/hz/bdpz/\d+/(\d+).html')
        return vid",Extracts video ID from URL.,
"def get_head(repo_path):
    """"""Get (branch, commit) from HEAD of a git repo.""""""
    try:
        ref = open(os.path.join(repo_path, '.git', 'HEAD'), 'r').read().strip()[5:].split('/')
        branch = ref[-1]
        commit = open(os.path.join(repo_path, '.git', *ref), 'r').read().strip()[:7]
        return branch, commit
    except:
        return None","Get (branch, commit) from HEAD of a git repo.",
"def get_terminal_size():
    """"""Get (width, height) of the current terminal.""""""
    try:
        import fcntl, termios, struct # fcntl module only available on Unix
        return struct.unpack('hh', fcntl.ioctl(1, termios.TIOCGWINSZ, '1234'))
    except:
        return (40, 80)","Get (width, height) of the current terminal.",
"def cbs_download(url, output_dir='.', merge=True, info_only=False, **kwargs):
    """"""Downloads CBS videos by URL.
    """"""

    html = get_content(url)
    pid = match1(html, r'video\.settings\.pid\s*=\s*\'([^\']+)\'')
    title = match1(html, r'video\.settings\.title\s*=\s*\""([^\""]+)\""')

    theplatform_download_by_pid(pid, title, output_dir=output_dir, merge=merge, info_only=info_only)",Downloads CBS videos by URL.,
"def matchall(text, patterns):
    """"""Scans through a string for substrings matched some patterns.

    Args:
        text: A string to be scanned.
        patterns: a list of regex pattern.

    Returns:
        a list if matched. empty if not.
    """"""

    ret = []
    for pattern in patterns:
        match = re.findall(pattern, text)
        ret += match

    return ret","Scans through a string for substrings matched some patterns.

    Args:
        text: A string to be scanned.
        patterns: a list of regex pattern.

    Returns:
        a list if matched. empty if not.",
"def parse_query_param(url, param):
    """"""Parses the query string of a URL and returns the value of a parameter.

    Args:
        url: A URL.
        param: A string representing the name of the parameter.

    Returns:
        The value of the parameter.
    """"""

    try:
        return parse.parse_qs(parse.urlparse(url).query)[param][0]
    except:
        return None","Parses the query string of a URL and returns the value of a parameter.

    Args:
        url: A URL.
        param: A string representing the name of the parameter.

    Returns:
        The value of the parameter.",
"def ungzip(data):
    """"""Decompresses data for Content-Encoding: gzip.
    """"""
    from io import BytesIO
    import gzip
    buffer = BytesIO(data)
    f = gzip.GzipFile(fileobj=buffer)
    return f.read()",Decompresses data for Content-Encoding: gzip.,
"def undeflate(data):
    """"""Decompresses data for Content-Encoding: deflate.
    (the zlib compression is used.)
    """"""
    import zlib
    decompressobj = zlib.decompressobj(-zlib.MAX_WBITS)
    return decompressobj.decompress(data)+decompressobj.flush()","Decompresses data for Content-Encoding: deflate.
    (the zlib compression is used.)",
"def parse_host(host):
    """"""Parses host name and port number from a string.
    """"""
    if re.match(r'^(\d+)$', host) is not None:
        return (""0.0.0.0"", int(host))
    if re.match(r'^(\w+)://', host) is None:
        host = ""//"" + host
    o = parse.urlparse(host)
    hostname = o.hostname or ""0.0.0.0""
    port = o.port or 0
    return (hostname, port)",Parses host name and port number from a string.,
"def _wanmen_get_title_by_json_topic_part(json_content, tIndex, pIndex):
    """"""JSON, int, int, int->str
    
    Get a proper title with courseid+topicID+partID.""""""

    return '_'.join([json_content[0]['name'],
                    json_content[0]['Topics'][tIndex]['name'],
                    json_content[0]['Topics'][tIndex]['Parts'][pIndex]['name']])","JSON, int, int, int->str
    
    Get a proper title with courseid+topicID+partID.",
"def has_task(self, task_instance):
        """"""
        Checks if a task is either queued or running in this executor

        :param task_instance: TaskInstance
        :return: True if the task is known to this executor
        """"""
        if task_instance.key in self.queued_tasks or task_instance.key in self.running:
            return True","Checks if a task is either queued or running in this executor

        :param task_instance: TaskInstance
        :return: True if the task is known to this executor",
"def get_uri(self):
        """"""
        override DbApiHook get_uri method for get_sqlalchemy_engine()
        """"""
        conn_config = self._get_conn_params()
        uri = 'snowflake://{user}:{password}@{account}/{database}/'
        uri += '{schema}?warehouse={warehouse}&role={role}'
        return uri.format(**conn_config)",override DbApiHook get_uri method for get_sqlalchemy_engine(),
"def get_conn(self):
        """"""
        Returns a snowflake.connection object
        """"""
        conn_config = self._get_conn_params()
        conn = snowflake.connector.connect(**conn_config)
        return conn",Returns a snowflake.connection object,
"def bulk_load(self, table, tmp_file):
        """"""
        Loads a tab-delimited file into a database table
        """"""
        self.copy_expert(""COPY {table} FROM STDIN"".format(table=table), tmp_file)",Loads a tab-delimited file into a database table,
"def bulk_dump(self, table, tmp_file):
        """"""
        Dumps a database table into a tab-delimited file
        """"""
        self.copy_expert(""COPY {table} TO STDOUT"".format(table=table), tmp_file)",Dumps a database table into a tab-delimited file,
"def bulk_load(self, table, tmp_file):
        """"""
        Loads a tab-delimited file into a database table
        """"""
        conn = self.get_conn()
        cur = conn.cursor()
        cur.execute(""""""
            LOAD DATA LOCAL INFILE '{tmp_file}'
            INTO TABLE {table}
            """""".format(tmp_file=tmp_file, table=table))
        conn.commit()",Loads a tab-delimited file into a database table,
"def task_state(args):
    """"""
    Returns the state of a TaskInstance at the command line.
    >>> airflow task_state tutorial sleep 2015-01-01
    success
    """"""
    dag = get_dag(args)
    task = dag.get_task(task_id=args.task_id)
    ti = TaskInstance(task, args.execution_date)
    print(ti.current_state())","Returns the state of a TaskInstance at the command line.
    >>> airflow task_state tutorial sleep 2015-01-01
    success",
"def dag_state(args):
    """"""
    Returns the state of a DagRun at the command line.
    >>> airflow dag_state tutorial 2015-01-01T00:00:00.000000
    running
    """"""
    dag = get_dag(args)
    dr = DagRun.find(dag.dag_id, execution_date=args.execution_date)
    print(dr[0].state if len(dr) > 0 else None)","Returns the state of a DagRun at the command line.
    >>> airflow dag_state tutorial 2015-01-01T00:00:00.000000
    running",
"def get_conn(self):
        """"""
        Retrieves connection to Cloud Translate

        :return: Google Cloud Translate client object.
        :rtype: Client
        """"""
        if not self._client:
            self._client = Client(credentials=self._get_credentials())
        return self._client","Retrieves connection to Cloud Translate

        :return: Google Cloud Translate client object.
        :rtype: Client",
"def cleanup_database_hook(self):
        """"""
        Clean up database hook after it was used.
        """"""
        if self.database_type == 'postgres':
            if hasattr(self.db_hook,
                       'conn') and self.db_hook.conn and self.db_hook.conn.notices:
                for output in self.db_hook.conn.notices:
                    self.log.info(output)",Clean up database hook after it was used.,
"def reserve_free_tcp_port(self):
        """"""
        Reserve free TCP port to be used by Cloud SQL Proxy
        """"""
        self.reserved_tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.reserved_tcp_socket.bind(('127.0.0.1', 0))
        self.sql_proxy_tcp_port = self.reserved_tcp_socket.getsockname()[1]",Reserve free TCP port to be used by Cloud SQL Proxy,
"def _get_error_code(self, e):
        """"""Extract error code from ftp exception""""""
        try:
            matches = self.error_code_pattern.match(str(e))
            code = int(matches.group(0))
            return code
        except ValueError:
            return e",Extract error code from ftp exception,
"def _integrate_plugins():
    """"""Integrate plugins to the context""""""
    import sys
    from airflow.plugins_manager import sensors_modules
    for sensors_module in sensors_modules:
        sys.modules[sensors_module.__name__] = sensors_module
        globals()[sensors_module._name] = sensors_module",Integrate plugins to the context,
"def clear_dag_runs():
    """"""
    Remove any existing DAG runs for the perf test DAGs.
    """"""
    session = settings.Session()
    drs = session.query(DagRun).filter(
        DagRun.dag_id.in_(DAG_IDS),
    ).all()
    for dr in drs:
        logging.info('Deleting DagRun :: {}'.format(dr))
        session.delete(dr)",Remove any existing DAG runs for the perf test DAGs.,
"def set_dags_paused_state(is_paused):
    """"""
    Toggle the pause state of the DAGs in the test.
    """"""
    session = settings.Session()
    dms = session.query(DagModel).filter(
        DagModel.dag_id.in_(DAG_IDS))
    for dm in dms:
        logging.info('Setting DAG :: {} is_paused={}'.format(dm, is_paused))
        dm.is_paused = is_paused
    session.commit()",Toggle the pause state of the DAGs in the test.,
"def _convert_to_float_if_possible(s):
    """"""
    A small helper function to convert a string to a numeric value
    if appropriate

    :param s: the string to be converted
    :type s: str
    """"""
    try:
        ret = float(s)
    except (ValueError, TypeError):
        ret = s
    return ret","A small helper function to convert a string to a numeric value
    if appropriate

    :param s: the string to be converted
    :type s: str",
"def utcnow():
    """"""
    Get the current date and time in UTC
    :return:
    """"""

    # pendulum utcnow() is not used as that sets a TimezoneInfo object
    # instead of a Timezone. This is not pickable and also creates issues
    # when using replace()
    d = dt.datetime.utcnow()
    d = d.replace(tzinfo=utc)

    return d","Get the current date and time in UTC
    :return:",
"def utc_epoch():
    """"""
    Gets the epoch in the users timezone
    :return:
    """"""

    # pendulum utcnow() is not used as that sets a TimezoneInfo object
    # instead of a Timezone. This is not pickable and also creates issues
    # when using replace()
    d = dt.datetime(1970, 1, 1)
    d = d.replace(tzinfo=utc)

    return d","Gets the epoch in the users timezone
    :return:",
"def convert_to_utc(value):
    """"""
    Returns the datetime with the default timezone added if timezone
    information was not associated
    :param value: datetime
    :return: datetime with tzinfo
    """"""
    if not value:
        return value

    if not is_localized(value):
        value = pendulum.instance(value, TIMEZONE)

    return value.astimezone(utc)","Returns the datetime with the default timezone added if timezone
    information was not associated
    :param value: datetime
    :return: datetime with tzinfo",
"def datetime(*args, **kwargs):
    """"""
    Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified

    :return: datetime.datetime
    """"""
    if 'tzinfo' not in kwargs:
        kwargs['tzinfo'] = TIMEZONE

    return dt.datetime(*args, **kwargs)","Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified

    :return: datetime.datetime",
"def create_session():
    """"""
    Contextmanager that will create and teardown a session.
    """"""
    session = settings.Session()
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()",Contextmanager that will create and teardown a session.,
"def get_records(self, hql, parameters=None):
        """"""
        Get a set of records from Presto
        """"""
        try:
            return super().get_records(
                self._strip_sql(hql), parameters)
        except DatabaseError as e:
            raise PrestoException(self._get_pretty_exception_message(e))",Get a set of records from Presto,
"def run(self, hql, parameters=None):
        """"""
        Execute the statement against Presto. Can be used to create views.
        """"""
        return super().run(self._strip_sql(hql), parameters)",Execute the statement against Presto. Can be used to create views.,
"def get_conn(self):
        """"""
        Return a cosmos db client.
        """"""
        if self.cosmos_client is not None:
            return self.cosmos_client

        # Initialize the Python Azure Cosmos DB client
        self.cosmos_client = cosmos_client.CosmosClient(self.endpoint_uri, {'masterKey': self.master_key})

        return self.cosmos_client",Return a cosmos db client.,
"def delete_database(self, database_name):
        """"""
        Deletes an existing database in CosmosDB.
        """"""
        if database_name is None:
            raise AirflowBadRequest(""Database name cannot be None."")

        self.get_conn().DeleteDatabase(get_database_link(database_name))",Deletes an existing database in CosmosDB.,
"def delete_collection(self, collection_name, database_name=None):
        """"""
        Deletes an existing collection in the CosmosDB database.
        """"""
        if collection_name is None:
            raise AirflowBadRequest(""Collection name cannot be None."")

        self.get_conn().DeleteContainer(
            get_collection_link(self.__get_database_name(database_name), collection_name))",Deletes an existing collection in the CosmosDB database.,
"def get_function(self, name):
        """"""
        Returns the Cloud Function with the given name.

        :param name: Name of the function.
        :type name: str
        :return: A Cloud Functions object representing the function.
        :rtype: dict
        """"""
        return self.get_conn().projects().locations().functions().get(
            name=name).execute(num_retries=self.num_retries)","Returns the Cloud Function with the given name.

        :param name: Name of the function.
        :type name: str
        :return: A Cloud Functions object representing the function.
        :rtype: dict",
"def write(self, message):
        """"""
        Do whatever it takes to actually log the specified logging record
        :param message: message to log
        """"""
        if not message.endswith(""\n""):
            self._buffer += message
        else:
            self._buffer += message
            self.logger.log(self.level, self._buffer.rstrip())
            self._buffer = str()","Do whatever it takes to actually log the specified logging record
        :param message: message to log",
"def flush(self):
        """"""
        Ensure all logging output has been flushed
        """"""
        if len(self._buffer) > 0:
            self.logger.log(self.level, self._buffer)
            self._buffer = str()",Ensure all logging output has been flushed,
"def correct_maybe_zipped(fileloc):
    """"""
    If the path contains a folder with a .zip suffix, then
    the folder is treated as a zip archive and path to zip is returned.
    """"""

    _, archive, filename = re.search(
        r'((.*\.zip){})?(.*)'.format(re.escape(os.sep)), fileloc).groups()
    if archive and zipfile.is_zipfile(archive):
        return archive
    else:
        return fileloc","If the path contains a folder with a .zip suffix, then
    the folder is treated as a zip archive and path to zip is returned.",
"def _heartbeat_manager(self):
        """"""
        Heartbeat DAG file processor and start it if it is not alive.
        :return:
        """"""
        if self._process and not self._process.is_alive() and not self.done:
            self.start()","Heartbeat DAG file processor and start it if it is not alive.
        :return:",
"def terminate(self):
        """"""
        Send termination signal to DAG parsing processor manager
        and expect it to terminate all DAG file processors.
        """"""
        self.log.info(""Sending termination message to manager."")
        self._child_signal_conn.send(DagParsingSignal.TERMINATE_MANAGER)","Send termination signal to DAG parsing processor manager
        and expect it to terminate all DAG file processors.",
"def _exit_gracefully(self, signum, frame):
        """"""
        Helper method to clean up DAG file processors to avoid leaving orphan processes.
        """"""
        self.log.info(""Exiting gracefully upon receiving signal %s"", signum)
        self.terminate()
        self.end()
        self.log.debug(""Finished terminating DAG processors."")
        sys.exit(os.EX_OK)",Helper method to clean up DAG file processors to avoid leaving orphan processes.,
"def wait_until_finished(self):
        """"""
        Sleeps until all the processors are done.
        """"""
        for file_path, processor in self._processors.items():
            while not processor.done:
                time.sleep(0.1)",Sleeps until all the processors are done.,
"def cancel_transfer_operation(self, operation_name):
        """"""
        Cancels an transfer operation in Google Storage Transfer Service.

        :param operation_name: Name of the transfer operation.
        :type operation_name: str
        :rtype: None
        """"""
        self.get_conn().transferOperations().cancel(name=operation_name).execute(num_retries=self.num_retries)","Cancels an transfer operation in Google Storage Transfer Service.

        :param operation_name: Name of the transfer operation.
        :type operation_name: str
        :rtype: None",
"def pause_transfer_operation(self, operation_name):
        """"""
        Pauses an transfer operation in Google Storage Transfer Service.

        :param operation_name: (Required) Name of the transfer operation.
        :type operation_name: str
        :rtype: None
        """"""
        self.get_conn().transferOperations().pause(name=operation_name).execute(num_retries=self.num_retries)","Pauses an transfer operation in Google Storage Transfer Service.

        :param operation_name: (Required) Name of the transfer operation.
        :type operation_name: str
        :rtype: None",
"def resume_transfer_operation(self, operation_name):
        """"""
        Resumes an transfer operation in Google Storage Transfer Service.

        :param operation_name: (Required) Name of the transfer operation.
        :type operation_name: str
        :rtype: None
        """"""
        self.get_conn().transferOperations().resume(name=operation_name).execute(num_retries=self.num_retries)","Resumes an transfer operation in Google Storage Transfer Service.

        :param operation_name: (Required) Name of the transfer operation.
        :type operation_name: str
        :rtype: None",
"def parameterized_config(template):
    """"""
    Generates a configuration from the provided template + variables defined in
    current scope
    :param template: a config content templated with {{variables}}
    """"""
    all_vars = {k: v for d in [globals(), locals()] for k, v in d.items()}
    return template.format(**all_vars)","Generates a configuration from the provided template + variables defined in
    current scope
    :param template: a config content templated with {{variables}}",
"def get_conn(self):
        """"""
        Retrieves connection to Cloud Natural Language service.

        :return: Cloud Natural Language service object
        :rtype: google.cloud.language_v1.LanguageServiceClient
        """"""
        if not self._conn:
            self._conn = LanguageServiceClient(credentials=self._get_credentials())
        return self._conn","Retrieves connection to Cloud Natural Language service.

        :return: Cloud Natural Language service object
        :rtype: google.cloud.language_v1.LanguageServiceClient",
"def dispose_orm():
    """""" Properly close pooled database connections """"""
    log.debug(""Disposing DB connection pool (PID %s)"", os.getpid())
    global engine
    global Session

    if Session:
        Session.remove()
        Session = None
    if engine:
        engine.dispose()
        engine = None",Properly close pooled database connections,
"def alchemy_to_dict(obj):
    """"""
    Transforms a SQLAlchemy model instance into a dictionary
    """"""
    if not obj:
        return None
    d = {}
    for c in obj.__table__.columns:
        value = getattr(obj, c.name)
        if type(value) == datetime:
            value = value.isoformat()
        d[c.name] = value
    return d",Transforms a SQLAlchemy model instance into a dictionary,
"def chunks(items, chunk_size):
    """"""
    Yield successive chunks of a given size from a list of items
    """"""
    if chunk_size <= 0:
        raise ValueError('Chunk size must be a positive integer')
    for i in range(0, len(items), chunk_size):
        yield items[i:i + chunk_size]",Yield successive chunks of a given size from a list of items,
"def reduce_in_chunks(fn, iterable, initializer, chunk_size=0):
    """"""
    Reduce the given list of items by splitting it into chunks
    of the given size and passing each chunk through the reducer
    """"""
    if len(iterable) == 0:
        return initializer
    if chunk_size == 0:
        chunk_size = len(iterable)
    return reduce(fn, chunks(iterable, chunk_size), initializer)","Reduce the given list of items by splitting it into chunks
    of the given size and passing each chunk through the reducer",
"def chain(*tasks):
    """"""
    Given a number of tasks, builds a dependency chain.

    chain(task_1, task_2, task_3, task_4)

    is equivalent to

    task_1.set_downstream(task_2)
    task_2.set_downstream(task_3)
    task_3.set_downstream(task_4)
    """"""
    for up_task, down_task in zip(tasks[:-1], tasks[1:]):
        up_task.set_downstream(down_task)","Given a number of tasks, builds a dependency chain.

    chain(task_1, task_2, task_3, task_4)

    is equivalent to

    task_1.set_downstream(task_2)
    task_2.set_downstream(task_3)
    task_3.set_downstream(task_4)",
"def _integrate_plugins():
    """"""Integrate plugins to the context""""""
    import sys
    from airflow.plugins_manager import operators_modules
    for operators_module in operators_modules:
        sys.modules[operators_module.__name__] = operators_module
        globals()[operators_module._name] = operators_module",Integrate plugins to the context,
"def get_conn(self):
        """"""Returns a Google Cloud Dataproc service object.""""""
        http_authorized = self._authorize()
        return build(
            'dataproc', self.api_version, http=http_authorized,
            cache_discovery=False)",Returns a Google Cloud Dataproc service object.,
"def wait(self, operation):
        """"""Awaits for Google Cloud Dataproc Operation to complete.""""""
        submitted = _DataProcOperation(self.get_conn(), operation,
                                       self.num_retries)
        submitted.wait_for_done()",Awaits for Google Cloud Dataproc Operation to complete.,
"def _num_tasks_per_send_process(self, to_send_count):
        """"""
        How many Celery tasks should each worker process send.

        :return: Number of tasks that should be sent per process
        :rtype: int
        """"""
        return max(1,
                   int(math.ceil(1.0 * to_send_count / self._sync_parallelism)))","How many Celery tasks should each worker process send.

        :return: Number of tasks that should be sent per process
        :rtype: int",
"def _num_tasks_per_fetch_process(self):
        """"""
        How many Celery tasks should be sent to each worker process.

        :return: Number of tasks that should be used per process
        :rtype: int
        """"""
        return max(1,
                   int(math.ceil(1.0 * len(self.tasks) / self._sync_parallelism)))","How many Celery tasks should be sent to each worker process.

        :return: Number of tasks that should be used per process
        :rtype: int",
"def get_conn(self):
        """"""
        Returns a Google MLEngine service object.
        """"""
        authed_http = self._authorize()
        return build('ml', 'v1', http=authed_http, cache_discovery=False)",Returns a Google MLEngine service object.,
"def _integrate_plugins():
    """"""Integrate plugins to the context.""""""
    from airflow.plugins_manager import executors_modules
    for executors_module in executors_modules:
        sys.modules[executors_module.__name__] = executors_module
        globals()[executors_module._name] = executors_module",Integrate plugins to the context.,
"def get_conn(self):
        """"""
        Returns a mssql connection object
        """"""
        conn = self.get_connection(self.mssql_conn_id)
        conn = pymssql.connect(
            server=conn.host,
            user=conn.login,
            password=conn.password,
            database=self.schema or conn.schema,
            port=conn.port)
        return conn",Returns a mssql connection object,
"def get_dag_code(dag_id):
    """"""Return python code of a given dag_id.""""""
    try:
        return get_code(dag_id)
    except AirflowException as err:
        _log.info(err)
        response = jsonify(error=""{}"".format(err))
        response.status_code = err.status_code
        return response",Return python code of a given dag_id.,
"def get_pools():
    """"""Get all pools.""""""
    try:
        pools = pool_api.get_pools()
    except AirflowException as err:
        _log.error(err)
        response = jsonify(error=""{}"".format(err))
        response.status_code = err.status_code
        return response
    else:
        return jsonify([p.to_json() for p in pools])",Get all pools.,
"def create_pool():
    """"""Create a pool.""""""
    params = request.get_json(force=True)
    try:
        pool = pool_api.create_pool(**params)
    except AirflowException as err:
        _log.error(err)
        response = jsonify(error=""{}"".format(err))
        response.status_code = err.status_code
        return response
    else:
        return jsonify(pool.to_json())",Create a pool.,
"def delete_pool(name):
    """"""Delete pool.""""""
    try:
        pool = pool_api.delete_pool(name=name)
    except AirflowException as err:
        _log.error(err)
        response = jsonify(error=""{}"".format(err))
        response.status_code = err.status_code
        return response
    else:
        return jsonify(pool.to_json())",Delete pool.,
"def delete(self, resource_group, name):
        """"""
        Delete a container group

        :param resource_group: the name of the resource group
        :type resource_group: str
        :param name: the name of the container group
        :type name: str
        """"""
        self.connection.container_groups.delete(resource_group, name)","Delete a container group

        :param resource_group: the name of the resource group
        :type resource_group: str
        :param name: the name of the container group
        :type name: str",
"def get_previous_dagrun(self, session=None):
        """"""The previous DagRun, if there is one""""""

        return session.query(DagRun).filter(
            DagRun.dag_id == self.dag_id,
            DagRun.execution_date < self.execution_date
        ).order_by(
            DagRun.execution_date.desc()
        ).first()","The previous DagRun, if there is one",
"def get_previous_scheduled_dagrun(self, session=None):
        """"""The previous, SCHEDULED DagRun, if there is one""""""
        dag = self.get_dag()

        return session.query(DagRun).filter(
            DagRun.dag_id == self.dag_id,
            DagRun.execution_date == dag.previous_schedule(self.execution_date)
        ).first()","The previous, SCHEDULED DagRun, if there is one",
"def _integrate_plugins():
    """"""Integrate plugins to the context""""""
    import sys
    from airflow.plugins_manager import macros_modules
    for macros_module in macros_modules:
        sys.modules[macros_module.__name__] = macros_module
        globals()[macros_module._name] = macros_module",Integrate plugins to the context,
"def error(self, session=None):
        """"""
        Forces the task instance's state to FAILED in the database.
        """"""
        self.log.error(""Recording the task instance as FAILED"")
        self.state = State.FAILED
        session.merge(self)
        session.commit()",Forces the task instance's state to FAILED in the database.,
"def clear_xcom_data(self, session=None):
        """"""
        Clears all XCom data from the database for the task instance
        """"""
        session.query(XCom).filter(
            XCom.dag_id == self.dag_id,
            XCom.task_id == self.task_id,
            XCom.execution_date == self.execution_date
        ).delete()
        session.commit()",Clears all XCom data from the database for the task instance,
"def key(self):
        """"""
        Returns a tuple that identifies the task instance uniquely
        """"""
        return self.dag_id, self.task_id, self.execution_date, self.try_number",Returns a tuple that identifies the task instance uniquely,
"def ready_for_retry(self):
        """"""
        Checks on whether the task instance is in the right state and timeframe
        to be retried.
        """"""
        return (self.state == State.UP_FOR_RETRY and
                self.next_retry_datetime() < timezone.utcnow())","Checks on whether the task instance is in the right state and timeframe
        to be retried.",
"def init_run_context(self, raw=False):
        """"""
        Sets the log context.
        """"""
        self.raw = raw
        self._set_context(self)",Sets the log context.,
"def check_for_bucket(self, bucket_name):
        """"""
        Check if bucket_name exists.

        :param bucket_name: the name of the bucket
        :type bucket_name: str
        """"""
        try:
            self.get_conn().head_bucket(Bucket=bucket_name)
            return True
        except ClientError as e:
            self.log.info(e.response[""Error""][""Message""])
            return False","Check if bucket_name exists.

        :param bucket_name: the name of the bucket
        :type bucket_name: str",
"def read_key(self, key, bucket_name=None):
        """"""
        Reads a key from S3

        :param key: S3 key that will point to the file
        :type key: str
        :param bucket_name: Name of the bucket in which the file is stored
        :type bucket_name: str
        """"""

        obj = self.get_key(key, bucket_name)
        return obj.get()['Body'].read().decode('utf-8')","Reads a key from S3

        :param key: S3 key that will point to the file
        :type key: str
        :param bucket_name: Name of the bucket in which the file is stored
        :type bucket_name: str",
"def _query_cassandra(self):
        """"""
        Queries cassandra and returns a cursor to the results.
        """"""
        self.hook = CassandraHook(cassandra_conn_id=self.cassandra_conn_id)
        session = self.hook.get_conn()
        cursor = session.execute(self.cql)
        return cursor",Queries cassandra and returns a cursor to the results.,
"def get_conn(self):
        """"""
        Retrieves connection to Cloud Speech.

        :return: Google Cloud Speech client object.
        :rtype: google.cloud.speech_v1.SpeechClient
        """"""
        if not self._client:
            self._client = SpeechClient(credentials=self._get_credentials())
        return self._client","Retrieves connection to Cloud Speech.

        :return: Google Cloud Speech client object.
        :rtype: google.cloud.speech_v1.SpeechClient",
"def set_context(self, ti):
        """"""
        Provide task_instance context to airflow task handler.
        :param ti: task instance object
        """"""
        local_loc = self._init_file(ti)
        self.handler = logging.FileHandler(local_loc)
        self.handler.setFormatter(self.formatter)
        self.handler.setLevel(self.level)","Provide task_instance context to airflow task handler.
        :param ti: task instance object",
"def list(self, path):
        """"""
        List files in Azure Data Lake Storage

        :param path: full path/globstring to use to list files in ADLS
        :type path: str
        """"""
        if ""*"" in path:
            return self.connection.glob(path)
        else:
            return self.connection.walk(path)","List files in Azure Data Lake Storage

        :param path: full path/globstring to use to list files in ADLS
        :type path: str",
"def _query_mssql(self):
        """"""
        Queries MSSQL and returns a cursor of results.

        :return: mssql cursor
        """"""
        mssql = MsSqlHook(mssql_conn_id=self.mssql_conn_id)
        conn = mssql.get_conn()
        cursor = conn.cursor()
        cursor.execute(self.sql)
        return cursor","Queries MSSQL and returns a cursor of results.

        :return: mssql cursor",
"def convert_types(cls, value):
        """"""
        Takes a value from MSSQL, and converts it to a value that's safe for
        JSON/Google Cloud Storage/BigQuery.
        """"""
        if isinstance(value, decimal.Decimal):
            return float(value)
        else:
            return value","Takes a value from MSSQL, and converts it to a value that's safe for
        JSON/Google Cloud Storage/BigQuery.",
"def gcs_read(self, remote_log_location):
        """"""
        Returns the log found at the remote_log_location.
        :param remote_log_location: the log's location in remote storage
        :type remote_log_location: str (path)
        """"""
        bkt, blob = self.parse_gcs_url(remote_log_location)
        return self.hook.download(bkt, blob).decode('utf-8')","Returns the log found at the remote_log_location.
        :param remote_log_location: the log's location in remote storage
        :type remote_log_location: str (path)",
"def get_collection(self, mongo_collection, mongo_db=None):
        """"""
        Fetches a mongo collection object for querying.

        Uses connection schema as DB unless specified.
        """"""
        mongo_db = mongo_db if mongo_db is not None else self.connection.schema
        mongo_conn = self.get_conn()

        return mongo_conn.get_database(mongo_db).get_collection(mongo_collection)","Fetches a mongo collection object for querying.

        Uses connection schema as DB unless specified.",
"def insert_one(self, mongo_collection, doc, mongo_db=None, **kwargs):
        """"""
        Inserts a single document into a mongo collection
        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.insert_one
        """"""
        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)

        return collection.insert_one(doc, **kwargs)","Inserts a single document into a mongo collection
        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.insert_one",
"def insert_many(self, mongo_collection, docs, mongo_db=None, **kwargs):
        """"""
        Inserts many docs into a mongo collection.
        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.insert_many
        """"""
        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)

        return collection.insert_many(docs, **kwargs)","Inserts many docs into a mongo collection.
        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.insert_many",
"def get_file(self):
        """"""
        Gets the file including name and payload.

        :returns: the part's name and payload.
        :rtype: tuple
        """"""
        return self.part.get_filename(), self.part.get_payload(decode=True)","Gets the file including name and payload.

        :returns: the part's name and payload.
        :rtype: tuple",
"def put_records(self, records):
        """"""
        Write batch records to Kinesis Firehose
        """"""

        firehose_conn = self.get_conn()

        response = firehose_conn.put_record_batch(
            DeliveryStreamName=self.delivery_stream,
            Records=records
        )

        return response",Write batch records to Kinesis Firehose,
"def get_conn(self):
        """"""
        Returns a FTP connection object
        """"""
        if self.conn is None:
            params = self.get_connection(self.ftp_conn_id)
            pasv = params.extra_dejson.get(""passive"", True)
            self.conn = ftplib.FTP(params.host, params.login, params.password)
            self.conn.set_pasv(pasv)

        return self.conn",Returns a FTP connection object,
"def list_directory(self, path, nlst=False):
        """"""
        Returns a list of files on the remote system.

        :param path: full path to the remote directory to list
        :type path: str
        """"""
        conn = self.get_conn()
        conn.cwd(path)

        files = conn.nlst()
        return files","Returns a list of files on the remote system.

        :param path: full path to the remote directory to list
        :type path: str",
"def rename(self, from_name, to_name):
        """"""
        Rename a file.

        :param from_name: rename file from name
        :param to_name: rename file to name
        """"""
        conn = self.get_conn()
        return conn.rename(from_name, to_name)","Rename a file.

        :param from_name: rename file from name
        :param to_name: rename file to name",
"def execute(self, context):
        """"""
        Call the DiscordWebhookHook to post message
        """"""
        self.hook = DiscordWebhookHook(
            self.http_conn_id,
            self.webhook_endpoint,
            self.message,
            self.username,
            self.avatar_url,
            self.tts,
            self.proxy
        )
        self.hook.execute()",Call the DiscordWebhookHook to post message,
"def get_conn(self):
        """"""Return the FileService object.""""""
        conn = self.get_connection(self.conn_id)
        service_options = conn.extra_dejson
        return FileService(account_name=conn.login,
                           account_key=conn.password, **service_options)",Return the FileService object.,
"def get_conn(self):
        """"""
        Returns a Google Cloud Storage service object.
        """"""
        if not self._conn:
            self._conn = storage.Client(credentials=self._get_credentials())

        return self._conn",Returns a Google Cloud Storage service object.,
"def argmin(arr, f):
    """"""Return the index, i, in arr that minimizes f(arr[i])""""""
    m = None
    i = None
    for idx, item in enumerate(arr):
        if item is not None:
            if m is None or f(item) < m:
                m = f(item)
                i = idx
    return i","Return the index, i, in arr that minimizes f(arr[i])",
"def get_log_conn(self):
        """"""
        Establish an AWS connection for retrieving logs during training

        :rtype: CloudWatchLogs.Client
        """"""
        config = botocore.config.Config(retries={'max_attempts': 15})
        return self.get_client_type('logs', config=config)","Establish an AWS connection for retrieving logs during training

        :rtype: CloudWatchLogs.Client",
"def get_tables(self, db, pattern='*'):
        """"""
        Get a metastore table object
        """"""
        with self.metastore as client:
            tables = client.get_tables(db_name=db, pattern=pattern)
            return client.get_table_objects_by_name(db, tables)",Get a metastore table object,
"def get_conn(self):
        """"""
        Retrieves connection to Cloud Vision.

        :return: Google Cloud Vision client object.
        :rtype: google.cloud.vision_v1.ProductSearchClient
        """"""
        if not self._client:
            self._client = ProductSearchClient(credentials=self._get_credentials())
        return self._client","Retrieves connection to Cloud Vision.

        :return: Google Cloud Vision client object.
        :rtype: google.cloud.vision_v1.ProductSearchClient",
"def _escape(s):
    """""" Helper method that escapes parameters to a SQL query. """"""
    e = s
    e = e.replace('\\', '\\\\')
    e = e.replace('\n', '\\n')
    e = e.replace('\r', '\\r')
    e = e.replace(""'"", ""\\'"")
    e = e.replace('""', '\\""')
    return e",Helper method that escapes parameters to a SQL query.,
"def _validate_value(key, value, expected_type):
    """""" function to check expected type and raise
    error if type is not correct """"""
    if not isinstance(value, expected_type):
        raise TypeError(""{} argument must have a type {} not {}"".format(
            key, expected_type, type(value)))","function to check expected type and raise
    error if type is not correct",
"def get_service(self):
        """"""
        Returns a BigQuery service object.
        """"""
        http_authorized = self._authorize()
        return build(
            'bigquery', 'v2', http=http_authorized, cache_discovery=False)",Returns a BigQuery service object.,
"def fetchall(self):
        """"""
        Fetch all (remaining) rows of a query result, returning them as a sequence of
        sequences (e.g. a list of tuples).
        """"""
        result = []
        while True:
            one = self.fetchone()
            if one is None:
                break
            else:
                result.append(one)
        return result","Fetch all (remaining) rows of a query result, returning them as a sequence of
        sequences (e.g. a list of tuples).",
"def _query_postgres(self):
        """"""
        Queries Postgres and returns a cursor to the results.
        """"""
        postgres = PostgresHook(postgres_conn_id=self.postgres_conn_id)
        conn = postgres.get_conn()
        cursor = conn.cursor()
        cursor.execute(self.sql, self.parameters)
        return cursor",Queries Postgres and returns a cursor to the results.,
"def _integrate_plugins():
    """"""Integrate plugins to the context""""""
    from airflow.plugins_manager import hooks_modules
    for hooks_module in hooks_modules:
        sys.modules[hooks_module.__name__] = hooks_module
        globals()[hooks_module._name] = hooks_module",Integrate plugins to the context,
"def on_finish(self):
        """"""
        A callback that should be called when this is done running.
        """"""
        if self._cfg_path and os.path.isfile(self._cfg_path):
            if self.run_as_user:
                subprocess.call(['sudo', 'rm', self._cfg_path], close_fds=True)
            else:
                os.remove(self._cfg_path)",A callback that should be called when this is done running.,
"def buildhtml(self):
        """"""Build the HTML page
        Create the htmlheader with css / js
        Create html page
        Add Js code for nvd3
        """"""
        self.buildcontent()
        self.content = self.htmlcontent
        self.htmlcontent = self.template_page_nvd3.render(chart=self)","Build the HTML page
        Create the htmlheader with css / js
        Create html page
        Add Js code for nvd3",
"def get_conn(self):
        """"""
        Returns a sqlite connection object
        """"""
        conn = self.get_connection(self.sqlite_conn_id)
        conn = sqlite3.connect(conn.host)
        return conn",Returns a sqlite connection object,
"def json_response(obj):
    """"""
    returns a json response from a json serializable python object
    """"""
    return Response(
        response=json.dumps(
            obj, indent=4, cls=AirflowJsonEncoder),
        status=200,
        mimetype=""application/json"")",returns a json response from a json serializable python object,
"def make_cache_key(*args, **kwargs):
    """"""
    Used by cache to get a unique key per URL
    """"""
    path = request.path
    args = str(hash(frozenset(request.args.items())))
    return (path + args).encode('ascii', 'ignore')",Used by cache to get a unique key per URL,
"def get_conn(self):
        """"""
        Returns Gcp Video Intelligence Service client

        :rtype: google.cloud.videointelligence_v1.VideoIntelligenceServiceClient
        """"""
        if not self._conn:
            self._conn = VideoIntelligenceServiceClient(credentials=self._get_credentials())
        return self._conn","Returns Gcp Video Intelligence Service client

        :rtype: google.cloud.videointelligence_v1.VideoIntelligenceServiceClient",
"def _get_api_key(self):
        """"""
        Get Opsgenie api_key for creating alert
        """"""
        conn = self.get_connection(self.http_conn_id)
        api_key = conn.password
        if not api_key:
            raise AirflowException('Opsgenie API Key is required for this hook, '
                                   'please check your conn_id configuration.')
        return api_key",Get Opsgenie api_key for creating alert,
"def execute(self, context):
        """"""
        Call the OpsgenieAlertHook to post message
        """"""
        self.hook = OpsgenieAlertHook(self.opsgenie_conn_id)
        self.hook.execute(self._build_opsgenie_payload())",Call the OpsgenieAlertHook to post message,
"def get_conn(self):
        """"""
        check if aws conn exists already or create one and return it

        :return: boto3 session
        """"""
        if not self.conn:
            self.conn = self.get_client_type('athena')
        return self.conn","check if aws conn exists already or create one and return it

        :return: boto3 session",
"def list_directory(self, path):
        """"""
        Returns a list of files on the remote system.
        :param path: full path to the remote directory to list
        :type path: str
        """"""
        conn = self.get_conn()
        files = conn.listdir(path)
        return files","Returns a list of files on the remote system.
        :param path: full path to the remote directory to list
        :type path: str",
"def create_directory(self, path, mode=777):
        """"""
        Creates a directory on the remote system.
        :param path: full path to the remote directory to create
        :type path: str
        :param mode: int representation of octal mode for directory
        """"""
        conn = self.get_conn()
        conn.mkdir(path, mode)","Creates a directory on the remote system.
        :param path: full path to the remote directory to create
        :type path: str
        :param mode: int representation of octal mode for directory",
"def add_volume(self, volume):
        """"""
        Args:
            volume (Volume):
        """"""

        self._add_volume(name=volume.name, configs=volume.configs)","Args:
            volume (Volume):",
"def add_mount(self,
                  volume_mount):
        """"""
        Args:
            volume_mount (VolumeMount):
        """"""
        self._add_mount(
            name=volume_mount.name,
            mount_path=volume_mount.mount_path,
            sub_path=volume_mount.sub_path,
            read_only=volume_mount.read_only
        )","Args:
            volume_mount (VolumeMount):",
"def _stringify(iterable, joinable='\n'):
        """"""
        Takes an iterable (pymongo Cursor or Array) containing dictionaries and
        returns a stringified version using python join
        """"""
        return joinable.join(
            [json.dumps(doc, default=json_util.default) for doc in iterable]
        )","Takes an iterable (pymongo Cursor or Array) containing dictionaries and
        returns a stringified version using python join",
"def get_pool(name, session=None):
    """"""Get pool by a given name.""""""
    if not (name and name.strip()):
        raise AirflowBadRequest(""Pool name shouldn't be empty"")

    pool = session.query(Pool).filter_by(pool=name).first()
    if pool is None:
        raise PoolNotFound(""Pool '%s' doesn't exist"" % name)

    return pool",Get pool by a given name.,
"def delete_pool(name, session=None):
    """"""Delete pool by a given name.""""""
    if not (name and name.strip()):
        raise AirflowBadRequest(""Pool name shouldn't be empty"")

    pool = session.query(Pool).filter_by(pool=name).first()
    if pool is None:
        raise PoolNotFound(""Pool '%s' doesn't exist"" % name)

    session.delete(pool)
    session.commit()

    return pool",Delete pool by a given name.,
"def get_conn(self):
        """"""
        Retrieves connection to Cloud Text to Speech.

        :return: Google Cloud Text to Speech client object.
        :rtype: google.cloud.texttospeech_v1.TextToSpeechClient
        """"""
        if not self._client:
            self._client = TextToSpeechClient(credentials=self._get_credentials())
        return self._client","Retrieves connection to Cloud Text to Speech.

        :return: Google Cloud Text to Speech client object.
        :rtype: google.cloud.texttospeech_v1.TextToSpeechClient",
"def get_log(self, ti):
        """"""
        Get Logs of a command from Qubole
        :param ti: Task Instance of the dag, used to determine the Quboles command id
        :return: command log as text
        """"""
        if self.cmd is None:
            cmd_id = ti.xcom_pull(key=""qbol_cmd_id"", task_ids=self.task_id)
        Command.get_log_id(self.cls, cmd_id)","Get Logs of a command from Qubole
        :param ti: Task Instance of the dag, used to determine the Quboles command id
        :return: command log as text",
"def get_jobs_id(self, ti):
        """"""
        Get jobs associated with a Qubole commands
        :param ti: Task Instance of the dag, used to determine the Quboles command id
        :return: Job information associated with command
        """"""
        if self.cmd is None:
            cmd_id = ti.xcom_pull(key=""qbol_cmd_id"", task_ids=self.task_id)
        Command.get_jobs_id(self.cls, cmd_id)","Get jobs associated with a Qubole commands
        :param ti: Task Instance of the dag, used to determine the Quboles command id
        :return: Job information associated with command",
"def _exit_gracefully(self, signum, frame):
        """"""
        Helper method to clean up processor_agent to avoid leaving orphan processes.
        """"""
        self.log.info(""Exiting gracefully upon receiving signal %s"", signum)
        if self.processor_agent:
            self.processor_agent.end()
        sys.exit(os.EX_OK)",Helper method to clean up processor_agent to avoid leaving orphan processes.,
"def get_conn(self):
        """"""
        Returns a cassandra Session object
        """"""
        if self.session and not self.session.is_shutdown:
            return self.session
        self.session = self.cluster.connect(self.keyspace)
        return self.session",Returns a cassandra Session object,
"def _query_mysql(self):
        """"""
        Queries mysql and returns a cursor to the results.
        """"""
        mysql = MySqlHook(mysql_conn_id=self.mysql_conn_id)
        conn = mysql.get_conn()
        cursor = conn.cursor()
        cursor.execute(self.sql)
        return cursor",Queries mysql and returns a cursor to the results.,
"def _configure_csv_file(self, file_handle, schema):
        """"""Configure a csv writer with the file_handle and write schema
        as headers for the new file.
        """"""
        csv_writer = csv.writer(file_handle, encoding='utf-8',
                                delimiter=self.field_delimiter)
        csv_writer.writerow(schema)
        return csv_writer","Configure a csv writer with the file_handle and write schema
        as headers for the new file.",
"def extra_dejson(self):
        """"""Returns the extra property by deserializing json.""""""
        obj = {}
        if self.extra:
            try:
                obj = json.loads(self.extra)
            except Exception as e:
                self.log.exception(e)
                self.log.error(""Failed parsing the json for conn_id %s"", self.conn_id)

        return obj",Returns the extra property by deserializing json.,
"def days_ago(n, hour=0, minute=0, second=0, microsecond=0):
    """"""
    Get a datetime object representing `n` days ago. By default the time is
    set to midnight.
    """"""
    today = timezone.utcnow().replace(
        hour=hour,
        minute=minute,
        second=second,
        microsecond=microsecond)
    return today - timedelta(days=n)","Get a datetime object representing `n` days ago. By default the time is
    set to midnight.",
"def get_all_permissions_views(self):
        """"""
        Returns a set of tuples with the perm name and view menu name
        """"""
        perms_views = set()
        for role in self.get_user_roles():
            perms_views.update({(perm_view.permission.name, perm_view.view_menu.name)
                                for perm_view in role.permissions})
        return perms_views",Returns a set of tuples with the perm name and view menu name,
"def _has_role(self, role_name_or_list):
        """"""
        Whether the user has this role name
        """"""
        if not isinstance(role_name_or_list, list):
            role_name_or_list = [role_name_or_list]
        return any(
            [r.name in role_name_or_list for r in self.get_user_roles()])",Whether the user has this role name,
"def _has_perm(self, permission_name, view_menu_name):
        """"""
        Whether the user has this perm
        """"""
        if hasattr(self, 'perms'):
            if (permission_name, view_menu_name) in self.perms:
                return True
        # rebuild the permissions set
        self._get_and_cache_perms()
        return (permission_name, view_menu_name) in self.perms",Whether the user has this perm,
"def create_perm_vm_for_all_dag(self):
        """"""
        Create perm-vm if not exist and insert into FAB security model for all-dags.
        """"""
        # create perm for global logical dag
        for dag_vm in self.DAG_VMS:
            for perm in self.DAG_PERMS:
                self._merge_perm(permission_name=perm,
                                 view_menu_name=dag_vm)",Create perm-vm if not exist and insert into FAB security model for all-dags.,
"def get_hook(self):
        """"""
        Gets the AwsGlueCatalogHook
        """"""
        if not hasattr(self, 'hook'):
            from airflow.contrib.hooks.aws_glue_catalog_hook import AwsGlueCatalogHook
            self.hook = AwsGlueCatalogHook(
                aws_conn_id=self.aws_conn_id,
                region_name=self.region_name)

        return self.hook",Gets the AwsGlueCatalogHook,
"def get_records(self, sql):
        """"""
        Executes the sql and returns a set of records.

        :param sql: the sql statement to be executed (str) or a list of
            sql statements to execute
        :type sql: str
        """"""
        with self.get_conn() as cur:
            cur.execute(sql)
            return cur.fetchall()","Executes the sql and returns a set of records.

        :param sql: the sql statement to be executed (str) or a list of
            sql statements to execute
        :type sql: str",
"def get_first(self, sql):
        """"""
        Executes the sql and returns the first resulting row.

        :param sql: the sql statement to be executed (str) or a list of
            sql statements to execute
        :type sql: str or list
        """"""
        with self.get_conn() as cur:
            cur.execute(sql)
            return cur.fetchone()","Executes the sql and returns the first resulting row.

        :param sql: the sql statement to be executed (str) or a list of
            sql statements to execute
        :type sql: str or list",
"def _convert_date_to_dict(field_date):
        """"""
        Convert native python ``datetime.date`` object  to a format supported by the API
        """"""
        return {DAY: field_date.day, MONTH: field_date.month, YEAR: field_date.year}",Convert native python ``datetime.date`` object  to a format supported by the API,
"def _convert_time_to_dict(time):
        """"""
        Convert native python ``datetime.time`` object  to a format supported by the API
        """"""
        return {HOURS: time.hour, MINUTES: time.minute, SECONDS: time.second}",Convert native python ``datetime.time`` object  to a format supported by the API,
"def get_conn(self):
        """"""Returns a connection object
        """"""
        db = self.get_connection(getattr(self, self.conn_name_attr))
        return self.connector.connect(
            host=db.host,
            port=db.port,
            username=db.login,
            schema=db.schema)",Returns a connection object,
"def set_autocommit(self, conn, autocommit):
        """"""
        Sets the autocommit flag on the connection
        """"""
        if not self.supports_autocommit and autocommit:
            self.log.warn(
                (""%s connection doesn't support ""
                 ""autocommit but autocommit activated.""),
                getattr(self, self.conn_name_attr))
        conn.autocommit = autocommit",Sets the autocommit flag on the connection,
"def get_query(self):
        """"""
        Default filters for model
        """"""
        return (
            super().get_query()
            .filter(or_(models.DagModel.is_active,
                        models.DagModel.is_paused))
            .filter(~models.DagModel.is_subdag)
        )",Default filters for model,
"def get_count_query(self):
        """"""
        Default filters for model
        """"""
        return (
            super().get_count_query()
            .filter(models.DagModel.is_active)
            .filter(~models.DagModel.is_subdag)
        )",Default filters for model,
"def _authorize(self):
        """"""
        Returns an authorized HTTP object to be used to build a Google cloud
        service hook connection.
        """"""
        credentials = self._get_credentials()
        http = httplib2.Http()
        authed_http = google_auth_httplib2.AuthorizedHttp(
            credentials, http=http)
        return authed_http","Returns an authorized HTTP object to be used to build a Google cloud
        service hook connection.",
"def unfinished(cls):
        """"""
        A list of states indicating that a task either has not completed
        a run or has not even started.
        """"""
        return [
            cls.NONE,
            cls.SCHEDULED,
            cls.QUEUED,
            cls.RUNNING,
            cls.SHUTDOWN,
            cls.UP_FOR_RETRY,
            cls.UP_FOR_RESCHEDULE
        ]","A list of states indicating that a task either has not completed
        a run or has not even started.",
"def vgg13(pretrained=False, **kwargs):
    """"""VGG 13-layer model (configuration ""B"")

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """"""
    if pretrained:
        kwargs['init_weights'] = False
    model = VGG(make_layers(cfg['B']), **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))
    return model","VGG 13-layer model (configuration ""B"")

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet",
"def alexnet(pretrained=False, **kwargs):
    r""""""AlexNet model architecture from the
    `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """"""
    model = AlexNet(**kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['alexnet']))
    return model","r""""""AlexNet model architecture from the
    `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet",
"def hflip(img):
    """"""Horizontally flip the given PIL Image.

    Args:
        img (PIL Image): Image to be flipped.

    Returns:
        PIL Image:  Horizontall flipped image.
    """"""
    if not _is_pil_image(img):
        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))

    return img.transpose(Image.FLIP_LEFT_RIGHT)","Horizontally flip the given PIL Image.

    Args:
        img (PIL Image): Image to be flipped.

    Returns:
        PIL Image:  Horizontall flipped image.",
"def vflip(img):
    """"""Vertically flip the given PIL Image.

    Args:
        img (PIL Image): Image to be flipped.

    Returns:
        PIL Image:  Vertically flipped image.
    """"""
    if not _is_pil_image(img):
        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))

    return img.transpose(Image.FLIP_TOP_BOTTOM)","Vertically flip the given PIL Image.

    Args:
        img (PIL Image): Image to be flipped.

    Returns:
        PIL Image:  Vertically flipped image.",
"def read_info_file(data_dir, info_file):
    """"""Return a Tensor containing the list of labels
       Read the file and keep only the ID of the 3D point.
    """"""
    labels = []
    with open(os.path.join(data_dir, info_file), 'r') as f:
        labels = [int(line.split()[0]) for line in f]
    return torch.LongTensor(labels)","Return a Tensor containing the list of labels
       Read the file and keep only the ID of the 3D point.",
"def conv1x1(in_planes, out_planes, stride=1):
    """"""1x1 convolution""""""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)",1x1 convolution,
"def setup_for_distributed(is_master):
    """"""
    This function disables printing when not in master process
    """"""
    import builtins as __builtin__
    builtin_print = __builtin__.print

    def print(*args, **kwargs):
        force = kwargs.pop('force', False)
        if is_master or force:
            builtin_print(*args, **kwargs)

    __builtin__.print = print",This function disables printing when not in master process,
"def synchronize_between_processes(self):
        """"""
        Warning: does not synchronize the deque!
        """"""
        if not is_dist_avail_and_initialized():
            return
        t = torch.tensor([self.count, self.total], dtype=torch.float64, device='cuda')
        dist.barrier()
        dist.all_reduce(t)
        t = t.tolist()
        self.count = int(t[0])
        self.total = t[1]",Warning: does not synchronize the deque!,
"def makedir_exist_ok(dirpath):
    """"""
    Python2 support for os.makedirs(.., exist_ok=True)
    """"""
    try:
        os.makedirs(dirpath)
    except OSError as e:
        if e.errno == errno.EEXIST:
            pass
        else:
            raise","Python2 support for os.makedirs(.., exist_ok=True)",
"def request(query, params):
    '''pre-request callback
    params<dict>:
      method  : POST/GET
      headers : {}
      data    : {} # if method == POST
      url     : ''
      category: 'search category'
      pageno  : 1 # number of the requested page
    '''

    offset = (params['pageno'] - 1)
    params['url'] = search_url.format(offset=offset, query=quote(query))
    return params","pre-request callback
    params<dict>:
      method  : POST/GET
      headers : {}
      data    : {} # if method == POST
      url     : ''
      category: 'search category'
      pageno  : 1 # number of the requested page",
"def get_themes(templates_path):
    """"""Returns available themes list.""""""
    themes = os.listdir(templates_path)
    if '__common__' in themes:
        themes.remove('__common__')
    return themes",Returns available themes list.,
"def mvn(*args, **kwargs):
  """"""Convenience function to efficiently construct a MultivariateNormalDiag.""""""
  # Faster than using `tfd.MultivariateNormalDiag`.
  return tfd.Independent(tfd.Normal(*args, **kwargs),
                         reinterpreted_batch_ndims=1)",Convenience function to efficiently construct a MultivariateNormalDiag.,
"def _mode_mean_shape(self):
    """"""Shape for the mode/mean Tensors.""""""
    shape = tensorshape_util.concatenate(self.batch_shape, self.event_shape)
    has_static_shape = tensorshape_util.is_fully_defined(shape)
    if not has_static_shape:
      shape = tf.concat([
          self.batch_shape_tensor(),
          self.event_shape_tensor(),
      ], 0)
    return shape",Shape for the mode/mean Tensors.,
"def _max_mask_non_finite(x, axis=-1, keepdims=False, mask=0):
  """"""Returns `max` or `mask` if `max` is not finite.""""""
  m = np.max(x, axis=_astuple(axis), keepdims=keepdims)
  needs_masking = ~np.isfinite(m)
  if needs_masking.ndim > 0:
    m[needs_masking] = mask
  elif needs_masking:
    m = mask
  return m",Returns `max` or `mask` if `max` is not finite.,
"def params_size(event_size, name=None):
    """"""The number of `params` needed to create a single distribution.""""""
    with tf.compat.v1.name_scope(name, 'MultivariateNormalTriL_params_size',
                                 [event_size]):
      return event_size + event_size * (event_size + 1) // 2",The number of `params` needed to create a single distribution.,
"def params_size(num_components, event_shape=(), name=None):
    """"""The number of `params` needed to create a single distribution.""""""
    return MixtureSameFamily.params_size(
        num_components,
        IndependentNormal.params_size(event_shape, name=name),
        name=name)",The number of `params` needed to create a single distribution.,
"def new(params, num_components, event_shape=(),
          validate_args=False, name=None):
    """"""Create the distribution instance from a `params` vector.""""""
    return MixtureSameFamily.new(
        params,
        num_components,
        IndependentLogistic(
            event_shape, validate_args=validate_args, name=name),
        validate_args=validate_args,
        name=name)",Create the distribution instance from a `params` vector.,
"def params_size(num_components, event_shape=(), name=None):
    """"""The number of `params` needed to create a single distribution.""""""
    return MixtureSameFamily.params_size(
        num_components,
        IndependentLogistic.params_size(event_shape, name=name),
        name=name)",The number of `params` needed to create a single distribution.,
"def _as_tensor(x, name, dtype):
  """"""Convenience to convert to `Tensor` or leave as `None`.""""""
  return None if x is None else tf.convert_to_tensor(
      value=x, name=name, dtype=dtype)",Convenience to convert to `Tensor` or leave as `None`.,
"def _get_default_reinterpreted_batch_ndims(self, distribution):
    """"""Computes the default value for reinterpreted_batch_ndim __init__ arg.""""""
    ndims = prefer_static.rank_from_shape(
        distribution.batch_shape_tensor, distribution.batch_shape)
    return prefer_static.maximum(0, ndims - 1)",Computes the default value for reinterpreted_batch_ndim __init__ arg.,
"def _cat_probs(self, log_probs):
    """"""Get a list of num_components batchwise probabilities.""""""
    which_softmax = tf.nn.log_softmax if log_probs else tf.nn.softmax
    cat_probs = which_softmax(self.cat.logits)
    cat_probs = tf.unstack(cat_probs, num=self.num_components, axis=-1)
    return cat_probs",Get a list of num_components batchwise probabilities.,
"def logistic_regression(features):
  """"""Bayesian logistic regression, which returns labels given features.""""""
  coeffs = ed.MultivariateNormalDiag(
      loc=tf.zeros(features.shape[1]), name=""coeffs"")
  labels = ed.Bernoulli(
      logits=tf.tensordot(features, coeffs, [[1], [0]]), name=""labels"")
  return labels","Bayesian logistic regression, which returns labels given features.",
"def _z(self, x):
    """"""Standardize input `x` to a unit normal.""""""
    with tf.name_scope(""standardize""):
      return (x - self.loc) / self.scale",Standardize input `x` to a unit normal.,
"def _inv_z(self, z):
    """"""Reconstruct input `x` from a its normalized version.""""""
    with tf.name_scope(""reconstruct""):
      return z * self.scale + self.loc",Reconstruct input `x` from a its normalized version.,
"def _machine_eps(dtype):
  """"""Returns the machine epsilon for the supplied dtype.""""""
  if isinstance(dtype, tf.DType):
    dtype = dtype.as_numpy_dtype()
  return np.finfo(dtype).eps",Returns the machine epsilon for the supplied dtype.,
"def _to_str(x):
  """"""Converts a bool tensor to a string with True/False values.""""""
  x = tf.convert_to_tensor(value=x)
  if x.dtype == tf.bool:
    return tf.where(x, tf.fill(x.shape, 'True'), tf.fill(x.shape, 'False'))
  return x",Converts a bool tensor to a string with True/False values.,
"def concat_vectors(*args):
  """"""Concatenates input vectors, statically if possible.""""""
  args_ = [tf.get_static_value(x) for x in args]
  if any(vec is None for vec in args_):
    return tf.concat(args, axis=0)
  return [val for vec in args_ for val in vec]","Concatenates input vectors, statically if possible.",
"def _log_vector_matrix(vs, ms):
  """"""Multiply tensor of vectors by matrices assuming values stored are logs.""""""

  return tf.reduce_logsumexp(input_tensor=vs[..., tf.newaxis] + ms, axis=-2)",Multiply tensor of vectors by matrices assuming values stored are logs.,
"def _log_matrix_vector(ms, vs):
  """"""Multiply tensor of matrices by vectors assuming values stored are logs.""""""

  return tf.reduce_logsumexp(input_tensor=ms + vs[..., tf.newaxis, :], axis=-1)",Multiply tensor of matrices by vectors assuming values stored are logs.,
"def _vector_matrix(vs, ms):
  """"""Multiply tensor of vectors by matrices.""""""

  return tf.reduce_sum(input_tensor=vs[..., tf.newaxis] * ms, axis=-2)",Multiply tensor of vectors by matrices.,
"def _extract_log_probs(num_states, dist):
  """"""Tabulate log probabilities from a batch of distributions.""""""

  states = tf.reshape(tf.range(num_states),
                      tf.concat([[num_states],
                                 tf.ones_like(dist.batch_shape_tensor())],
                                axis=0))
  return distribution_util.move_dimension(dist.log_prob(states), 0, -1)",Tabulate log probabilities from a batch of distributions.,
"def range(self, name=""range""):
    """"""`high - low`.""""""
    with self._name_scope(name):
      return self.high - self.low",`high - low`.,
"def _entropy(self):
    """"""Shannon entropy in nats.""""""
    if any(self._dist_fn_args):
      raise ValueError(
          'Can only compute entropy when all distributions are independent.')
    return sum(joint_distribution_lib.maybe_check_wont_broadcast(
        (d().entropy() for d in self._dist_fn_wrapped),
        self.validate_args))",Shannon entropy in nats.,
"def _ndtr(x):
  """"""Implements ndtr core logic.""""""
  half_sqrt_2 = tf.constant(
      0.5 * np.sqrt(2.), dtype=x.dtype, name=""half_sqrt_2"")
  w = x * half_sqrt_2
  z = tf.abs(w)
  y = tf.where(
      tf.less(z, half_sqrt_2), 1. + tf.math.erf(w),
      tf.where(tf.greater(w, 0.), 2. - tf.math.erfc(z), tf.math.erfc(z)))
  return 0.5 * y",Implements ndtr core logic.,
"def _log_ndtr_lower(x, series_order):
  """"""Asymptotic expansion version of `Log[cdf(x)]`, appropriate for `x<<-1`.""""""
  x_2 = tf.square(x)
  # Log of the term multiplying (1 + sum)
  log_scale = -0.5 * x_2 - tf.math.log(-x) - 0.5 * np.log(2. * np.pi)
  return log_scale + tf.math.log(_log_ndtr_asymptotic_series(x, series_order))","Asymptotic expansion version of `Log[cdf(x)]`, appropriate for `x<<-1`.",
"def mean_log_det(self, name=""mean_log_det""):
    """"""Computes E[log(det(X))] under this Wishart distribution.""""""
    with self._name_scope(name):
      return (self._multi_digamma(0.5 * self.df, self.dimension) +
              self.dimension * math.log(2.) +
              2 * self.scale_operator.log_abs_determinant())",Computes E[log(det(X))] under this Wishart distribution.,
"def log_normalization(self, name=""log_normalization""):
    """"""Computes the log normalizing constant, log(Z).""""""
    with self._name_scope(name):
      return (self.df * self.scale_operator.log_abs_determinant() +
              0.5 * self.df * self.dimension * math.log(2.) +
              self._multi_lgamma(0.5 * self.df, self.dimension))","Computes the log normalizing constant, log(Z).",
"def _multi_lgamma(self, a, p, name=""multi_lgamma""):
    """"""Computes the log multivariate gamma function; log(Gamma_p(a)).""""""
    with self._name_scope(name):
      seq = self._multi_gamma_sequence(a, p)
      return (0.25 * p * (p - 1.) * math.log(math.pi) +
              tf.reduce_sum(input_tensor=tf.math.lgamma(seq), axis=[-1]))",Computes the log multivariate gamma function; log(Gamma_p(a)).,
"def _multi_digamma(self, a, p, name=""multi_digamma""):
    """"""Computes the multivariate digamma function; Psi_p(a).""""""
    with self._name_scope(name):
      seq = self._multi_gamma_sequence(a, p)
      return tf.reduce_sum(input_tensor=tf.math.digamma(seq), axis=[-1])",Computes the multivariate digamma function; Psi_p(a).,
"def _outer_squared_difference(x, y):
  """"""Convenience function analogous to tf.squared_difference.""""""
  z = x - y
  return z[..., tf.newaxis, :] * z[..., tf.newaxis]",Convenience function analogous to tf.squared_difference.,
"def _split_covariance_into_marginals(covariance, block_sizes):
  """"""Split a covariance matrix into block-diagonal marginals of given sizes.""""""
  start_dim = 0
  marginals = []
  for size in block_sizes:
    end_dim = start_dim + size
    marginals.append(covariance[..., start_dim:end_dim, start_dim:end_dim])
    start_dim = end_dim
  return marginals",Split a covariance matrix into block-diagonal marginals of given sizes.,
"def _operator(attr):
  """"""Defers an operator overload to `attr`.

  Args:
    attr: Operator attribute to use.

  Returns:
    Function calling operator attribute.
  """"""
  @functools.wraps(attr)
  def func(a, *args):
    return attr(a.value, *args)
  return func","Defers an operator overload to `attr`.

  Args:
    attr: Operator attribute to use.

  Returns:
    Function calling operator attribute.",
"def _numpy_text(tensor, is_repr=False):
  """"""Human-readable representation of a tensor's numpy value.""""""
  if tensor.dtype.is_numpy_compatible:
    text = repr(tensor.numpy()) if is_repr else str(tensor.numpy())
  else:
    text = ""<unprintable>""
  if ""\n"" in text:
    text = ""\n"" + text
  return text",Human-readable representation of a tensor's numpy value.,
"def sample_shape(self):
    """"""Sample shape of random variable as a `TensorShape`.""""""
    if isinstance(self._sample_shape, tf.Tensor):
      return tf.TensorShape(tf.get_static_value(self._sample_shape))
    return tf.TensorShape(self._sample_shape)",Sample shape of random variable as a `TensorShape`.,
"def numpy(self):
    """"""Value as NumPy array, only available for TF Eager.""""""
    if not isinstance(self.value, ops.EagerTensor):
      raise NotImplementedError(""value argument must be a EagerTensor."")

    return self.value.numpy()","Value as NumPy array, only available for TF Eager.",
"def _replicate(n, tensor):
  """"""Replicate the input tensor n times along a new (major) dimension.""""""
  # TODO(axch) Does this already exist somewhere?  Should it get contributed?
  multiples = tf.concat([[n], tf.ones_like(tensor.shape)], axis=0)
  return tf.tile(tf.expand_dims(tensor, axis=0), multiples)",Replicate the input tensor n times along a new (major) dimension.,
"def _broadcast_to(tensor_to_broadcast, target_tensors):
  """"""Helper to broadcast a tensor using a list of target tensors.""""""
  output = tensor_to_broadcast
  for tensor in target_tensors:
    output += tf.zeros_like(tensor)
  return output",Helper to broadcast a tensor using a list of target tensors.,
"def _pdf_at_peak(self):
    """"""Pdf evaluated at the peak.""""""
    return (self.peak - self.low) / (self.high - self.low)",Pdf evaluated at the peak.,
"def _axis_size(x, axis=None):
  """"""Get number of elements of `x` in `axis`, as type `x.dtype`.""""""
  if axis is None:
    return tf.cast(tf.size(input=x), x.dtype)
  return tf.cast(
      tf.reduce_prod(input_tensor=tf.gather(tf.shape(input=x), axis)), x.dtype)","Get number of elements of `x` in `axis`, as type `x.dtype`.",
"def remove(self, field):
    """"""To support weak referencing, removes cache key from the cache value.""""""
    return _Mapping(
        x=None if field == ""x"" else self.x,
        y=None if field == ""y"" else self.y,
        ildj=self.ildj,
        kwargs=self.kwargs)","To support weak referencing, removes cache key from the cache value.",
"def _merge(self, old, new, use_equals=False):
    """"""Helper to merge which handles merging one value.""""""
    if old is None:
      return new
    if new is None:
      return old
    if (old == new) if use_equals else (old is new):
      return old
    raise ValueError(""Incompatible values: %s != %s"" % (old, new))",Helper to merge which handles merging one value.,
"def _deep_tuple(self, x):
    """"""Converts nested `tuple`, `list`, or `dict` to nested `tuple`.""""""
    if isinstance(x, dict):
      return self._deep_tuple(tuple(sorted(x.items())))
    elif isinstance(x, (list, tuple)):
      return tuple(map(self._deep_tuple, x))

    return x","Converts nested `tuple`, `list`, or `dict` to nested `tuple`.",
"def _has_no_u_turn(state_one, state_two, momentum):
  """"""If two given states and momentum do not exhibit a U-turn pattern.""""""
  dot_product = sum([
      tf.reduce_sum(input_tensor=(s1 - s2) * m)
      for s1, s2, m in zip(state_one, state_two, momentum)
  ])
  return dot_product > 0",If two given states and momentum do not exhibit a U-turn pattern.,
"def _log_joint(current_target_log_prob, current_momentum):
  """"""Log-joint probability given a state's log-probability and momentum.""""""
  momentum_log_prob = -sum(
      [tf.reduce_sum(input_tensor=0.5 * (m**2.)) for m in current_momentum])
  return current_target_log_prob + momentum_log_prob",Log-joint probability given a state's log-probability and momentum.,
"def _random_bernoulli(shape, probs, dtype=tf.int32, seed=None, name=None):
  """"""Returns samples from a Bernoulli distribution.""""""
  with tf.compat.v1.name_scope(name, ""random_bernoulli"", [shape, probs]):
    probs = tf.convert_to_tensor(value=probs)
    random_uniform = tf.random.uniform(shape, dtype=probs.dtype, seed=seed)
    return tf.cast(tf.less(random_uniform, probs), dtype)",Returns samples from a Bernoulli distribution.,
"def expand_as_args(args):
  """"""Returns `True` if `args` should be expanded as `*args`.""""""
  return (isinstance(args, collections.Sequence) and
          not _is_namedtuple(args) and not _force_leaf(args))",Returns `True` if `args` should be expanded as `*args`.,
"def download(directory, filename):
  """"""Downloads a file.""""""
  filepath = os.path.join(directory, filename)
  if tf.io.gfile.exists(filepath):
    return filepath
  if not tf.io.gfile.exists(directory):
    tf.io.gfile.makedirs(directory)
  url = os.path.join(ROOT_PATH, filename)
  print(""Downloading %s to %s"" % (url, filepath))
  urllib.request.urlretrieve(url, filepath)
  return filepath",Downloads a file.,
"def _maybe_broadcast_volatility(volatility_parts,
                                state_parts):
  """"""Helper to broadcast `volatility_parts` to the shape of `state_parts`.""""""
  return [v + tf.zeros_like(sp, dtype=sp.dtype.base_dtype)
          for v, sp in zip(volatility_parts, state_parts)]",Helper to broadcast `volatility_parts` to the shape of `state_parts`.,
"def as_numpy_dtype(dtype):
  """"""Returns a `np.dtype` based on this `dtype`.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'as_numpy_dtype'):
    return dtype.as_numpy_dtype
  return dtype",Returns a `np.dtype` based on this `dtype`.,
"def base_dtype(dtype):
  """"""Returns a non-reference `dtype` based on this `dtype`.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'base_dtype'):
    return dtype.base_dtype
  return dtype",Returns a non-reference `dtype` based on this `dtype`.,
"def is_bool(dtype):
  """"""Returns whether this is a boolean data type.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'is_bool'):
    return dtype.is_bool
  # We use `kind` because:
  # np.issubdtype(np.uint8, np.bool) == True.
  return np.dtype(dtype).kind == 'b'",Returns whether this is a boolean data type.,
"def is_complex(dtype):
  """"""Returns whether this is a complex floating point type.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'is_complex'):
    return dtype.is_complex
  return np.issubdtype(np.dtype(dtype), np.complex)",Returns whether this is a complex floating point type.,
"def is_floating(dtype):
  """"""Returns whether this is a (non-quantized, real) floating point type.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'is_floating'):
    return dtype.is_floating
  return np.issubdtype(np.dtype(dtype), np.float)","Returns whether this is a (non-quantized, real) floating point type.",
"def is_integer(dtype):
  """"""Returns whether this is a (non-quantized) integer type.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'is_integer'):
    return dtype.is_integer
  return np.issubdtype(np.dtype(dtype), np.integer)",Returns whether this is a (non-quantized) integer type.,
"def max(dtype):  # pylint: disable=redefined-builtin
  """"""Returns the maximum representable value in this data type.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'max'):
    return dtype.max
  use_finfo = is_floating(dtype) or is_complex(dtype)
  return np.finfo(dtype).max if use_finfo else np.iinfo(dtype).max",Returns the maximum representable value in this data type.,
"def name(dtype):
  """"""Returns the string name for this `dtype`.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'name'):
    return dtype.name
  if hasattr(dtype, '__name__'):
    return dtype.__name__
  return str(dtype)",Returns the string name for this `dtype`.,
"def size(dtype):
  """"""Returns the number of bytes to represent this `dtype`.""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'size'):
    return dtype.size
  return np.dtype(dtype).itemsize",Returns the number of bytes to represent this `dtype`.,
"def _replace_at_index(x, index, replacement):
  """"""Replaces an element at supplied index.""""""
  x_new = tf.concat([x[:index], tf.expand_dims(replacement, axis=0),
                     x[(index + 1):]], axis=0)
  return x_new",Replaces an element at supplied index.,
"def get_config(self):
    """"""Returns initializer configuration as a JSON-serializable dict.""""""
    return {
        'initializers': [
            tf.compat.v2.initializers.serialize(
                tf.keras.initializers.get(init))
            for init in self.initializers
        ],
        'sizes': self.sizes,
        'validate_args': self.validate_args,
    }",Returns initializer configuration as a JSON-serializable dict.,
"def from_config(cls, config):
    """"""Instantiates an initializer from a configuration dictionary.""""""
    return cls(**{
        'initializers': [tf.compat.v2.initializers.deserialize(init)
                         for init in config.get('initializers', [])],
        'sizes': config.get('sizes', []),
        'validate_args': config.get('validate_args', False),
    })",Instantiates an initializer from a configuration dictionary.,
"def _apply_slice_sequence(dist, params_event_ndims, slice_overrides_seq):
  """"""Applies a sequence of slice or copy-with-overrides operations to `dist`.""""""
  for slices, overrides in slice_overrides_seq:
    dist = _apply_single_step(dist, params_event_ndims, slices, overrides)
  return dist",Applies a sequence of slice or copy-with-overrides operations to `dist`.,
"def num_cols(x):
  """"""Returns number of cols in a given `Tensor`.""""""
  if tf.compat.dimension_value(x.shape[-1]) is not None:
    return tf.compat.dimension_value(x.shape[-1])
  return tf.shape(input=x)[-1]",Returns number of cols in a given `Tensor`.,
"def _name_scope(self, name=None, default_name=None, values=None):
    """"""Helper function to standardize op scope.""""""
    with tf.compat.v1.name_scope(self.name):
      with tf.compat.v1.name_scope(
          name, default_name, values=values or []) as scope:
        yield scope",Helper function to standardize op scope.,
"def _is_known_unsigned_by_dtype(dt):
  """"""Helper returning True if dtype is known to be unsigned.""""""
  return {
      tf.bool: True,
      tf.uint8: True,
      tf.uint16: True,
  }.get(dt.base_dtype, False)",Helper returning True if dtype is known to be unsigned.,
"def _is_known_signed_by_dtype(dt):
  """"""Helper returning True if dtype is known to be signed.""""""
  return {
      tf.float16: True,
      tf.float32: True,
      tf.float64: True,
      tf.int8: True,
      tf.int16: True,
      tf.int32: True,
      tf.int64: True,
  }.get(dt.base_dtype, False)",Helper returning True if dtype is known to be signed.,
"def _smallest_integer_by_dtype(dt):
  """"""Helper returning the smallest integer exactly representable by dtype.""""""
  if not _is_known_dtype(dt):
    raise TypeError(""Unrecognized dtype: {}"".format(dt.name))
  if _is_known_unsigned_by_dtype(dt):
    return 0
  return -1 * _largest_integer_by_dtype(dt)",Helper returning the smallest integer exactly representable by dtype.,
"def _is_integer_like_by_dtype(dt):
  """"""Helper returning True if dtype.is_integer or is `bool`.""""""
  if not _is_known_dtype(dt):
    raise TypeError(""Unrecognized dtype: {}"".format(dt.name))
  return dt.is_integer or dt.base_dtype == tf.bool",Helper returning True if dtype.is_integer or is `bool`.,
"def gen_new_seed(seed, salt):
  """"""Generate a new seed, from the given seed and salt.""""""
  if seed is None:
    return None
  string = (str(seed) + salt).encode(""utf-8"")
  return int(hashlib.md5(string).hexdigest()[:8], 16) & 0x7FFFFFFF","Generate a new seed, from the given seed and salt.",
"def dimension_size(x, axis):
  """"""Returns the size of a specific dimension.""""""
  # Since tf.gather isn't ""constant-in, constant-out"", we must first check the
  # static shape or fallback to dynamic shape.
  s = tf.compat.dimension_value(
      tensorshape_util.with_rank_at_least(x.shape, np.abs(axis))[axis])
  if s is not None:
    return s
  return tf.shape(input=x)[axis]",Returns the size of a specific dimension.,
"def _propagate_mean(mean, linop, dist):
  """"""Propagate a mean through linear Gaussian transformation.""""""
  return linop.matmul(mean) + dist.mean()[..., tf.newaxis]",Propagate a mean through linear Gaussian transformation.,
"def _propagate_cov(cov, linop, dist):
  """"""Propagate covariance through linear Gaussian transformation.""""""
  # For linop A and input cov P, returns `A P A' + dist.cov()`
  return linop.matmul(linop.matmul(cov), adjoint_arg=True) + dist.covariance()",Propagate covariance through linear Gaussian transformation.,
"def _mode(self):
    """"""The mode of the von Mises-Fisher distribution is the mean direction.""""""
    return (self.mean_direction +
            tf.zeros_like(self.concentration)[..., tf.newaxis])",The mode of the von Mises-Fisher distribution is the mean direction.,
"def _remove_dict_keys_with_value(dict_, val):
  """"""Removes `dict` keys which have have `self` as value.""""""
  return {k: v for k, v in dict_.items() if v is not val}",Removes `dict` keys which have have `self` as value.,
"def is_namedtuple_like(x):
  """"""Helper which returns `True` if input is `collections.namedtuple`-like.""""""
  try:
    for fn in x._fields:
      _ = getattr(x, fn)
    return True
  except AttributeError:
    return False",Helper which returns `True` if input is `collections.namedtuple`-like.,
"def make_name(super_name, default_super_name, sub_name):
  """"""Helper which makes a `str` name; useful for tf.compat.v1.name_scope.""""""
  name = super_name if super_name is not None else default_super_name
  if sub_name is not None:
    name += '_' + sub_name
  return name",Helper which makes a `str` name; useful for tf.compat.v1.name_scope.,
"def _maybe_assert_valid_sample(self, x):
    """"""Checks the validity of a sample.""""""
    if not self.validate_args:
      return x
    return distribution_util.with_dependencies([
        assert_util.assert_positive(x, message=""sample must be positive""),
        assert_util.assert_less(x, 1., message=""sample must be less than `1`.""),
    ], x)",Checks the validity of a sample.,
"def converged_any(converged, failed):
  """"""Condition to stop when any batch member converges, or all have failed.""""""
  return (tf.reduce_any(input_tensor=converged) |
          tf.reduce_all(input_tensor=failed))","Condition to stop when any batch member converges, or all have failed.",
"def _get_field(kernel_results, field_name):
  """"""field_name from kernel_results or kernel_results.accepted_results.""""""
  if hasattr(kernel_results, field_name):
    return getattr(kernel_results, field_name)
  if hasattr(kernel_results, 'accepted_results'):
    return getattr(kernel_results.accepted_results, field_name)
  raise TypeError('Cannot extract %s from %s' % (field_name, kernel_results))",field_name from kernel_results or kernel_results.accepted_results.,
"def _variance_scale_term(self):
    """"""Helper to `_covariance` and `_variance` which computes a shared scale.""""""
    # Expand back the last dim so the shape of _variance_scale_term matches the
    # shape of self.concentration.
    c0 = self.total_concentration[..., tf.newaxis]
    return tf.sqrt((1. + c0 / self.total_count[..., tf.newaxis]) / (1. + c0))",Helper to `_covariance` and `_variance` which computes a shared scale.,
"def forward_transform_fn(bijector):
  """"""Makes a function which applies a list of Bijectors' `forward`s.""""""
  if not mcmc_util.is_list_like(bijector):
    bijector = [bijector]

  def fn(transformed_state_parts):
    return [b.forward(sp) for b, sp in zip(bijector, transformed_state_parts)]

  return fn",Makes a function which applies a list of Bijectors' `forward`s.,
"def inverse_transform_fn(bijector):
  """"""Makes a function which applies a list of Bijectors' `inverse`s.""""""
  if not mcmc_util.is_list_like(bijector):
    bijector = [bijector]
  def fn(state_parts):
    return [b.inverse(sp)
            for b, sp in zip(bijector, state_parts)]
  return fn",Makes a function which applies a list of Bijectors' `inverse`s.,
"def val_where(cond, tval, fval):
  """"""Like tf.where but works on namedtuples.""""""
  if isinstance(tval, tf.Tensor):
    return tf.where(cond, tval, fval)
  elif isinstance(tval, tuple):
    cls = type(tval)
    return cls(*(val_where(cond, t, f) for t, f in zip(tval, fval)))
  else:
    raise Exception(TypeError)",Like tf.where but works on namedtuples.,
"def _log_sum_sq(x, axis=None):
  """"""Computes log(sum(x**2)).""""""
  return tf.reduce_logsumexp(
      input_tensor=2. * tf.math.log(tf.abs(x)), axis=axis)",Computes log(sum(x**2)).,
"def read_image(filepath):
  """"""Returns an image tensor.""""""
  im_bytes = tf.io.read_file(filepath)
  im = tf.image.decode_image(im_bytes, channels=CHANNELS)
  im = tf.image.convert_image_dtype(im, tf.float32)
  return im",Returns an image tensor.,
"def create_random_seq(character, action_metadata, direction, length=8):
  """"""Creates a random sequence.""""""
  start = tf.random.uniform([], maxval=action_metadata[1], dtype=tf.int32)
  return create_seq(character, action_metadata, direction, length, start)",Creates a random sequence.,
"def _insert_back_keep_dims(x, axis):
  """"""Insert the dims in `axis` back as singletons after being removed.

  Args:
    x:  `Tensor`.
    axis:  Python list of integers.

  Returns:
    `Tensor` with same values as `x`, but additional singleton dimensions.
  """"""
  for i in sorted(axis):
    x = tf.expand_dims(x, axis=i)
  return x","Insert the dims in `axis` back as singletons after being removed.

  Args:
    x:  `Tensor`.
    axis:  Python list of integers.

  Returns:
    `Tensor` with same values as `x`, but additional singleton dimensions.",
"def _sort_tensor(tensor):
  """"""Use `top_k` to sort a `Tensor` along the last dimension.""""""
  sorted_, _ = tf.nn.top_k(tensor, k=tf.shape(input=tensor)[-1])
  sorted_.set_shape(tensor.shape)
  return sorted_",Use `top_k` to sort a `Tensor` along the last dimension.,
"def _batch_transpose(mat):
  """"""Transpose a possibly batched matrix.

  Args:
    mat: A `tf.Tensor` of shape `[..., n, m]`.

  Returns:
    A tensor of shape `[..., m, n]` with matching batch dimensions.
  """"""
  n = distribution_util.prefer_static_rank(mat)
  perm = tf.range(n)
  perm = tf.concat([perm[:-2], [perm[-1], perm[-2]]], axis=0)
  return tf.transpose(a=mat, perm=perm)","Transpose a possibly batched matrix.

  Args:
    mat: A `tf.Tensor` of shape `[..., n, m]`.

  Returns:
    A tensor of shape `[..., m, n]` with matching batch dimensions.",
"def _check_failure(population_values):
  """"""Checks if all the population values are NaN/infinite.""""""
  return tf.math.reduce_all(input_tensor=tf.math.is_inf(population_values))",Checks if all the population values are NaN/infinite.,
"def _find_best_in_population(population, values):
  """"""Finds the population member with the lowest value.""""""
  best_value = tf.math.reduce_min(input_tensor=values)
  best_index = tf.where(tf.math.equal(values, best_value))[0, 0]

  return ([population_part[best_index] for population_part in population],
          best_value)",Finds the population member with the lowest value.,
"def _hat_integral_inverse(self, x):
    """"""Inverse function of _hat_integral.""""""
    x = tf.cast(x, self.power.dtype)
    t = self.power - 1.
    return tf.math.expm1(-(tf.math.log(t) + tf.math.log(x)) / t)",Inverse function of _hat_integral.,
"def _create_masks(degrees):
  """"""Returns a list of binary mask matrices enforcing autoregressivity.""""""
  return [
      # Create input->hidden and hidden->hidden masks.
      inp[:, np.newaxis] <= out
      for inp, out in zip(degrees[:-1], degrees[1:])
  ] + [
      # Create hidden->output mask.
      degrees[-1][:, np.newaxis] < degrees[0]
  ]",Returns a list of binary mask matrices enforcing autoregressivity.,
"def _zero_dimensional_mvndiag(dtype):
  """"""Build a zero-dimensional MVNDiag object.""""""
  dummy_mvndiag = tfd.MultivariateNormalDiag(
      scale_diag=tf.ones([0], dtype=dtype))
  dummy_mvndiag.covariance = lambda: dummy_mvndiag.variance()[..., tf.newaxis]
  return dummy_mvndiag",Build a zero-dimensional MVNDiag object.,
"def _observe_timeseries_fn(timeseries):
  """"""Build an observation_noise_fn that observes a Tensor timeseries.""""""
  def observation_noise_fn(t):
    current_slice = timeseries[..., t, :]
    return tfd.MultivariateNormalDiag(
        loc=current_slice,
        scale_diag=tf.zeros_like(current_slice))
  return observation_noise_fn",Build an observation_noise_fn that observes a Tensor timeseries.,
"def add(self, scheduler, max_iteration, bigdl_type=""float""):
        """"""
        Add a learning rate scheduler to the contained `schedules`

        :param scheduler: learning rate scheduler to be add
        :param max_iteration: iteration numbers this scheduler will run
        """"""
        return callBigDlFunc(bigdl_type, ""addScheduler"", self.value, scheduler, max_iteration)","Add a learning rate scheduler to the contained `schedules`

        :param scheduler: learning rate scheduler to be add
        :param max_iteration: iteration numbers this scheduler will run",
"def save(self, path, overWrite):
        """"""
        save OptimMethod
        :param path      path
        :param overWrite whether to overwrite
        """"""
        method=self.value
        return callBigDlFunc(self.bigdl_type, ""saveOptimMethod"", method, path, overWrite)","save OptimMethod
        :param path      path
        :param overWrite whether to overwrite",
"def set_gradclip_const(self, min_value, max_value):
        """"""
        Configure constant clipping settings.


        :param min_value: the minimum value to clip by
        :param max_value: the maxmimum value to clip by
        """"""
        callBigDlFunc(self.bigdl_type, ""setConstantClip"", self.value, min_value, max_value)","Configure constant clipping settings.


        :param min_value: the minimum value to clip by
        :param max_value: the maxmimum value to clip by",
"def optimize(self):
        """"""
        Do an optimization.
        """"""
        jmodel = callJavaFunc(self.value.optimize)
        from bigdl.nn.layer import Layer
        return Layer.of(jmodel)",Do an optimization.,
"def set_traindata(self, training_rdd, batch_size):
        """"""
        Set new training dataset, for optimizer reuse

        :param training_rdd: the training dataset
        :param batch_size: training batch size
        :return:
        """"""
        callBigDlFunc(self.bigdl_type, ""setTrainData"", self.value,
                     training_rdd, batch_size)","Set new training dataset, for optimizer reuse

        :param training_rdd: the training dataset
        :param batch_size: training batch size
        :return:",
"def from_jvalue(jvalue, bigdl_type=""float""):
        """"""
        Create a Python Model base on the given java value
        :param jvalue: Java object create by Py4j
        :return: A Python Model
        """"""
        model = Sequential(jvalue=jvalue)
        model.value = jvalue
        return model","Create a Python Model base on the given java value
        :param jvalue: Java object create by Py4j
        :return: A Python Model",
"def from_jvalue(jvalue, bigdl_type=""float""):
        """"""
        Create a Python Model base on the given java value
        :param jvalue: Java object create by Py4j
        :return: A Python Model
        """"""
        model = Model([], [], jvalue=jvalue)
        model.value = jvalue
        return model","Create a Python Model base on the given java value
        :param jvalue: Java object create by Py4j
        :return: A Python Model",
"def get_end_trigger(options):
    """"""
    When to end the optimization based on input option.
    """"""
    if options.endTriggerType.lower() == ""epoch"":
        return MaxEpoch(options.endTriggerNum)
    else:
        return MaxIteration(options.endTriggerNum)",When to end the optimization based on input option.,
"def validate_optimizer(optimizer, test_data, options):
    """"""
    Set validation and checkpoint for distributed optimizer.
    """"""
    optimizer.set_validation(
        batch_size=options.batchSize,
        val_rdd=test_data,
        trigger=EveryEpoch(),
        val_method=[Top1Accuracy()]
    )
    optimizer.set_checkpoint(EveryEpoch(), options.checkpointPath)",Set validation and checkpoint for distributed optimizer.,
"def setBatchSize(self, val):
        """"""
        Sets the value of :py:attr:`batchSize`.
        """"""
        self._paramMap[self.batchSize] = val
        pythonBigDL_method_name = ""setBatchSize"" + self.__class__.__name__
        callBigDlFunc(self.bigdl_type, pythonBigDL_method_name, self.value, val)
        return self",Sets the value of :py:attr:`batchSize`.,
"def value(self):
        """""" Return the broadcasted value
        """"""
        if not hasattr(self, ""_value"") and self._path is not None:
            self._value = self._load(self._path)
        return self._value",Return the broadcasted value,
"def callJavaFunc(func, *args):
    """""" Call Java Function """"""
    gateway = _get_gateway()
    args = [_py2java(gateway, a) for a in args]
    result = func(*args)
    return _java2py(gateway, result)",Call Java Function,
"def to_ndarray(self):
        """"""
        Transfer JTensor to ndarray.
        As SparseTensor may generate an very big ndarray, so we don't support this function for SparseTensor.
        :return: a ndarray
        """"""
        assert self.indices is None, ""sparseTensor to ndarray is not supported""
        return np.array(self.storage, dtype=get_dtype(self.bigdl_type)).reshape(self.shape)","Transfer JTensor to ndarray.
        As SparseTensor may generate an very big ndarray, so we don't support this function for SparseTensor.
        :return: a ndarray",
"def transform(self, image_feature, bigdl_type=""float""):
        """"""
        transform ImageFeature
        """"""
        callBigDlFunc(bigdl_type, ""transformImageFeature"", self.value, image_feature)
        return image_feature",transform ImageFeature,
"def get_label(self):
        """"""
        get label as ndarray from ImageFeature
        """"""
        label = callBigDlFunc(self.bigdl_type, ""imageFeatureToLabelTensor"", self.value)
        return label.to_ndarray()",get label as ndarray from ImageFeature,
"def read_parquet(cls, path, sc, bigdl_type=""float""):
        """"""
        Read parquet file as DistributedImageFrame
        """"""
        return DistributedImageFrame(jvalue=callBigDlFunc(bigdl_type, ""readParquet"", path, sc))",Read parquet file as DistributedImageFrame,
"def write_parquet(cls, path, output, sc, partition_num = 1, bigdl_type=""float""):
        """"""
        write ImageFrame as parquet file
        """"""
        return callBigDlFunc(bigdl_type, ""writeParquet"", path, output, sc, partition_num)",write ImageFrame as parquet file,
"def transform(self, transformer, bigdl_type=""float""):
        """"""
        transformImageFrame
        """"""
        self.value = callBigDlFunc(bigdl_type,
                                 ""transformImageFrame"", transformer, self.value)
        return self",transformImageFrame,
"def get_image(self, float_key=""floats"", to_chw=True):
        """"""
        get image from ImageFrame
        """"""
        return self.image_frame.get_image(float_key, to_chw)",get image from ImageFrame,
"def random_split(self, weights):
        """"""
        Random split imageframes according to weights
        :param weights: weights for each ImageFrame
        :return: 
        """"""
        jvalues =  self.image_frame.random_split(weights)
        return [ImageFrame(jvalue) for jvalue in jvalues]","Random split imageframes according to weights
        :param weights: weights for each ImageFrame
        :return:",
"def get_image(self, float_key=""floats"", to_chw=True):
        """"""
        get image list from ImageFrame
        """"""
        tensors = callBigDlFunc(self.bigdl_type,
                                   ""localImageFrameToImageTensor"", self.value, float_key, to_chw)
        return map(lambda tensor: tensor.to_ndarray(), tensors)",get image list from ImageFrame,
"def get_label(self):
        """"""
        get label rdd from ImageFrame
        """"""
        tensor_rdd = callBigDlFunc(self.bigdl_type, ""distributedImageFrameToLabelTensorRdd"", self.value)
        return tensor_rdd.map(lambda tensor: tensor.to_ndarray())",get label rdd from ImageFrame,
"def get_predict(self, key=""predict""):
        """"""
        get prediction rdd from ImageFrame
        """"""
        predicts = callBigDlFunc(self.bigdl_type, ""distributedImageFrameToPredict"", self.value, key)
        return predicts.map(lambda predict: (predict[0], predict[1].to_ndarray()) if predict[1] else (predict[0], None))",get prediction rdd from ImageFrame,
"def transform(self, dataset):
        """"""
        Apply the transformer to the images in ""inputCol"" and store the transformed result
        into ""outputCols""
        """"""
        self._transfer_params_to_java()
        return callBigDlFunc(self.bigdl_type, ""dlImageTransform"", self.value, dataset)","Apply the transformer to the images in ""inputCol"" and store the transformed result
        into ""outputCols""",
"def save_keras_definition(keras_model, path):
    """"""
    Save a Keras model definition to JSON with given path
    """"""
    model_json = keras_model.to_json()
    with open(path, ""w"") as json_file:
        json_file.write(model_json)",Save a Keras model definition to JSON with given path,
"def load(path, bigdl_type=""float""):
        """"""
        Load a pre-trained Bigdl model.

        :param path: The path containing the pre-trained model.
        :return: A pre-trained model.
        """"""
        jmodel = callBigDlFunc(bigdl_type, ""loadBigDL"", path)
        return Layer.of(jmodel)","Load a pre-trained Bigdl model.

        :param path: The path containing the pre-trained model.
        :return: A pre-trained model.",
"def set_running_mean(self, running_mean):
        """"""
        Set the running mean of the layer.
        Only use this method for a BatchNormalization layer.
        :param running_mean: a Numpy array.
        """"""
        callBigDlFunc(self.bigdl_type, ""setRunningMean"",
                      self.value, JTensor.from_ndarray(running_mean))
        return self","Set the running mean of the layer.
        Only use this method for a BatchNormalization layer.
        :param running_mean: a Numpy array.",
"def set_running_std(self, running_std):
        """"""
        Set the running variance of the layer.
        Only use this method for a BatchNormalization layer.
        :param running_std: a Numpy array.
        """"""
        callBigDlFunc(self.bigdl_type, ""setRunningStd"",
                      self.value, JTensor.from_ndarray(running_std))
        return self","Set the running variance of the layer.
        Only use this method for a BatchNormalization layer.
        :param running_std: a Numpy array.",
"def from_jvalue(jvalue, bigdl_type=""float""):
        """"""
        Create a Python Model base on the given java value
        :param jvalue: Java object create by Py4j
        :return: A Python Model
        """"""
        model = Layer(jvalue=jvalue, bigdl_type=bigdl_type)
        model.value = jvalue
        return model","Create a Python Model base on the given java value
        :param jvalue: Java object create by Py4j
        :return: A Python Model",
"def predict_class_distributed(self, data_rdd):
        """"""
        module predict, return the predict label

        :param data_rdd: the data to be predict.
        :return: An RDD represent the predict label.
        """"""
        result = callBigDlFunc(self.bigdl_type,
                               ""modelPredictClass"", self.value, data_rdd)
        return result","module predict, return the predict label

        :param data_rdd: the data to be predict.
        :return: An RDD represent the predict label.",
"def freeze(self, names=None):
        """"""
        freeze module, if names is not None, set an array of layers that match given names
        to be freezed
        :param names: an array of layer names
        :return:
        """"""
        callBigDlFunc(self.bigdl_type, ""freeze"", self.value, names)
        return self","freeze module, if names is not None, set an array of layers that match given names
        to be freezed
        :param names: an array of layer names
        :return:",
"def unfreeze(self, names=None):
        """"""
        unfreeze module, if names is not None, unfreeze layers that match given names
        :param names: an array of layer names
        :return:
        """"""
        callBigDlFunc(self.bigdl_type, ""unFreeze"", self.value, names)
        return self","unfreeze module, if names is not None, unfreeze layers that match given names
        :param names: an array of layer names
        :return:",
"def training(self, is_training=True):
        '''
        Set this layer in the training mode or in predition mode if is_training=False
        '''
        if is_training:
            callJavaFunc(self.value.training)
        else:
            callJavaFunc(self.value.evaluate)
        return self",Set this layer in the training mode or in predition mode if is_training=False,
"def loadModel(modelPath, weightPath =None, bigdl_type=""float""):
        """"""
        Load a pre-trained Bigdl model.

        :param path: The path containing the pre-trained model.
        :return: A pre-trained model.
        """"""
        jmodel = callBigDlFunc(bigdl_type, ""loadBigDLModule"", modelPath, weightPath)
        return Layer.of(jmodel)","Load a pre-trained Bigdl model.

        :param path: The path containing the pre-trained model.
        :return: A pre-trained model.",
"def load_torch(path, bigdl_type=""float""):
        """"""
        Load a pre-trained Torch model.

        :param path: The path containing the pre-trained model.
        :return: A pre-trained model.
        """"""
        jmodel = callBigDlFunc(bigdl_type, ""loadTorch"", path)
        return Layer.of(jmodel)","Load a pre-trained Torch model.

        :param path: The path containing the pre-trained model.
        :return: A pre-trained model.",
"def node(self, name, bigdl_type=""float""):
        """"""
        Return the corresponding node has the given name. If the given name doesn't match any node,
        an exception will be thrown
        :param name: node name
        :param bigdl_type: 
        :return: 
        """"""
        jnode = callBigDlFunc(bigdl_type, ""findGraphNode"", self.value, name)
        return Node.of(jnode)","Return the corresponding node has the given name. If the given name doesn't match any node,
        an exception will be thrown
        :param name: node name
        :param bigdl_type: 
        :return:",
"def of(cls, jcriterion, bigdl_type=""float""):
        """"""
        Create a python Criterion by a java criterion object

        :param jcriterion: A java criterion object which created by Py4j
        :return: a criterion.
        """"""
        criterion = Criterion(bigdl_type, jcriterion)
        criterion.value = jcriterion
        criterion.bigdl_type = bigdl_type
        return criterion","Create a python Criterion by a java criterion object

        :param jcriterion: A java criterion object which created by Py4j
        :return: a criterion.",
"def from_json_path(cls, json_path):
        """"""
        :param json_path: definition path which can be stored in a local file system, HDFS, S3, or any Hadoop-supported file system.
        :return: BigDL Model
        """"""
        json_str = BCommon.text_from_path(json_path)
        return DefinitionLoader.from_json_str(json_str)",":param json_path: definition path which can be stored in a local file system, HDFS, S3, or any Hadoop-supported file system.
        :return: BigDL Model",
"def get_input_shape(self):
        """"""
        Return a list of shape tuples if there are multiple inputs.
        Return one shape tuple otherwise.
        """"""
        input = callBigDlFunc(self.bigdl_type, ""getInputShape"",
                              self.value)
        return self.__process_shape(input)","Return a list of shape tuples if there are multiple inputs.
        Return one shape tuple otherwise.",
"def get_output_shape(self):
        """"""
        Return a list of shape tuples if there are multiple outputs.
        Return one shape tuple otherwise.
        """"""
        output = callBigDlFunc(self.bigdl_type, ""getOutputShape"",
                               self.value)
        return self.__process_shape(output)","Return a list of shape tuples if there are multiple outputs.
        Return one shape tuple otherwise.",
"def make_cashed(self):
        """"""
            descend
        """"""
        self._descendance_cash = [dict() for _ in self.graph]
        self.descend = self._descend_cashed",    descend,
"def _add_empty_child(self, parent, code, final=False):
        """"""
            parent     code
        """"""
        self.graph[parent][code] = self.nodes_number
        self.graph.append(self._make_default_node())
        self.data.append(None)
        self.final.append(final)
        self.nodes_number += 1
        return (self.nodes_number - 1)",    parent     code,
"def _descend_simple(self, curr, s):
        """"""
           curr   s
        """"""
        for a in s:
            curr = self.graph[curr][self.alphabet_codes[a]]
            if curr == Trie.NO_NODE:
                break
        return curr",   curr   s,
"def _get_children(self, index):
        """"""
              index
        """"""
        if self.dict_storage:
            return list(self.graph[index].values())
        else:
            return [elem for elem in self.graph[index] if elem != Trie.NO_NODE]",      index,
"def log_in(self, utterance: Any, dialog_id: Optional[Hashable] = None) -> None:
        """"""Wraps _log method for all input utterances.
        Args:
            utterance: Dialog utterance.
            dialog_id: Dialog ID.
        """"""
        if self.enabled:
            self._log(utterance, 'in', dialog_id)","Wraps _log method for all input utterances.
        Args:
            utterance: Dialog utterance.
            dialog_id: Dialog ID.",
"def get_iterator_from_config(config: dict, data: dict):
    """"""Create iterator (from config) for specified data.""""""
    iterator_config = config['dataset_iterator']
    iterator: Union[DataLearningIterator, DataFittingIterator] = from_params(iterator_config,
                                                                             data=data)
    return iterator",Create iterator (from config) for specified data.,
"def _config_session():
        """"""
        Configure session for particular device

        Returns:
            tensorflow.Session
        """"""
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        config.gpu_options.visible_device_list = '0'
        return tf.Session(config=config)","Configure session for particular device

        Returns:
            tensorflow.Session",
"def load(self) -> None:
        """"""Checks existence of the model file, loads the model if the file exists""""""

        # Checks presence of the model files
        if self.load_path.exists():
            path = str(self.load_path.resolve())
            log.info('[loading model from {}]'.format(path))
            self._net.load(path)","Checks existence of the model file, loads the model if the file exists",
"def save(self) -> None:
        """"""Saves model to the save_path, provided in config. The directory is
        already created by super().__init__, which is called in __init__ of this class""""""
        path = str(self.save_path.absolute())
        log.info('[saving model to {}]'.format(path))
        self._net.save(path)","Saves model to the save_path, provided in config. The directory is
        already created by super().__init__, which is called in __init__ of this class",
"def train_on_batch(self, *args) -> None:
        """"""Trains the model on a single batch.

        Args:
            *args: the list of network inputs.
            Last element of `args` is the batch of targets,
            all previous elements are training data batches
        """"""
        *data, labels = args
        self._net.train_on_batch(data, labels)","Trains the model on a single batch.

        Args:
            *args: the list of network inputs.
            Last element of `args` is the batch of targets,
            all previous elements are training data batches",
"def get_momentum_variable(self):
        """"""
        Extract values of momentum variables from optimizer

        Returns:
            optimizer's `rho` or `beta_1`
        """"""
        optimizer = self.get_optimizer()
        if hasattr(optimizer, 'rho'):
            return optimizer.rho
        elif hasattr(optimizer, 'beta_1'):
            return optimizer.beta_1
        return None","Extract values of momentum variables from optimizer

        Returns:
            optimizer's `rho` or `beta_1`",
"def round_f1(y_true, y_predicted):
    """"""
    Calculates F1 (binary) measure.

    Args:
        y_true: list of true values
        y_predicted: list of predicted values

    Returns:
        F1 score
    """"""
    try:
        predictions = [np.round(x) for x in y_predicted]
    except TypeError:
        predictions = y_predicted

    return f1_score(y_true, predictions)","Calculates F1 (binary) measure.

    Args:
        y_true: list of true values
        y_predicted: list of predicted values

    Returns:
        F1 score",
"def train_on_batch(self, data: List[Iterable], labels: Iterable[list]) -> None:
        """"""Trains model on a single batch

        Args:
            data: a batch of word sequences
            labels: a batch of correct tag sequences
        Returns:
            the trained model
        """"""
        X, Y = self._transform_batch(data, labels)
        self.model_.train_on_batch(X, Y)","Trains model on a single batch

        Args:
            data: a batch of word sequences
            labels: a batch of correct tag sequences
        Returns:
            the trained model",
"def json(self) -> list:
        """"""Returns list of json compatible states of the RichMessage instance
        nested controls.

        Returns:
            json_controls: Json representation of RichMessage instance
                nested controls.
        """"""
        json_controls = [control.json() for control in self.controls]
        return json_controls","Returns list of json compatible states of the RichMessage instance
        nested controls.

        Returns:
            json_controls: Json representation of RichMessage instance
                nested controls.",
"def telegram(self) -> list:
        """"""Returns list of Telegram compatible states of the RichMessage
        instance nested controls.

        Returns:
            telegram_controls: Telegram representation of RichMessage instance nested
                controls.
        """"""
        telegram_controls = [control.telegram() for control in self.controls]
        return telegram_controls","Returns list of Telegram compatible states of the RichMessage
        instance nested controls.

        Returns:
            telegram_controls: Telegram representation of RichMessage instance nested
                controls.",
"def alexa(self) -> list:
        """"""Returns list of Amazon Alexa compatible states of the RichMessage
        instance nested controls.

        Returns:
            alexa_controls: Amazon Alexa representation of RichMessage instance nested
                controls.
        """"""
        alexa_controls = [control.alexa() for control in self.controls]
        return alexa_controls","Returns list of Amazon Alexa compatible states of the RichMessage
        instance nested controls.

        Returns:
            alexa_controls: Amazon Alexa representation of RichMessage instance nested
                controls.",
"def _graph_wrap(func, graph):
    """"""Constructs function encapsulated in the graph.""""""
    @wraps(func)
    def _wrapped(*args, **kwargs):
        with graph.as_default():
            return func(*args, **kwargs)
    return _wrapped",Constructs function encapsulated in the graph.,
"def _keras_wrap(func, graph, session):
    """"""Constructs function encapsulated in the graph and the session.""""""
    import keras.backend as K

    @wraps(func)
    def _wrapped(*args, **kwargs):
        with graph.as_default():
            K.set_session(session)
            return func(*args, **kwargs)
    return _wrapped",Constructs function encapsulated in the graph and the session.,
"def hash_(token: str, hash_size: int) -> int:
    """"""Convert a token to a hash of given size.
    Args:
        token: a word
        hash_size: hash size

    Returns:
        int, hashed token

    """"""
    return murmurhash3_32(token, positive=True) % hash_size","Convert a token to a hash of given size.
    Args:
        token: a word
        hash_size: hash size

    Returns:
        int, hashed token",
"def read(self, data_path: str, *args, **kwargs) -> Dict[str, List[Tuple[Any, Any]]]:
        """"""Reads a file from a path and returns data as a list of tuples of inputs and correct outputs
         for every data type in ``train``, ``valid`` and ``test``.
        """"""
        raise NotImplementedError","Reads a file from a path and returns data as a list of tuples of inputs and correct outputs
         for every data type in ``train``, ``valid`` and ``test``.",
"def to_one_hot(x, k):
    """"""
    Takes an array of integers and transforms it
    to an array of one-hot encoded vectors
    """"""
    unit = np.eye(k, dtype=int)
    return unit[x]","Takes an array of integers and transforms it
    to an array of one-hot encoded vectors",
"def prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:
    """"""Prettifies the dictionary of metrics.""""""
    prettified_metrics = OrderedDict()
    for key, value in metrics:
        value = round(value, precision)
        prettified_metrics[key] = value
    return prettified_metrics",Prettifies the dictionary of metrics.,
"def update_state(self,
                     slots: Union[List[Tuple[str, Any]], Dict[str, Any]]) -> 'Tracker':
        """"""
        Updates dialogue state with new ``slots``, calculates features.
        
        Returns:
            Tracker: .""""""
        pass","Updates dialogue state with new ``slots``, calculates features.
        
        Returns:
            Tracker: .",
"def _start_timer(self) -> None:
        """"""Initiates self-destruct timer.""""""
        self.timer = Timer(self.config['conversation_lifetime'], self.self_destruct_callback)
        self.timer.start()",Initiates self-destruct timer.,
"def elmo_loss2ppl(losses: List[np.ndarray]) -> float:
    """""" Calculates perplexity by loss

    Args:
        losses: list of numpy arrays of model losses

    Returns:
        perplexity : float
    """"""
    avg_loss = np.mean(losses)
    return float(np.exp(avg_loss))","Calculates perplexity by loss

    Args:
        losses: list of numpy arrays of model losses

    Returns:
        perplexity : float",
"def get_metric_by_name(name: str) -> Callable[..., Any]:
    """"""Returns a metric callable with a corresponding name.""""""
    if name not in _REGISTRY:
        raise ConfigError(f'""{name}"" is not registered as a metric')
    return fn_from_str(_REGISTRY[name])",Returns a metric callable with a corresponding name.,
"def sk_log_loss(y_true: Union[List[List[float]], List[List[int]], np.ndarray],
                y_predicted: Union[List[List[float]], List[List[int]], np.ndarray]) -> float:
    """"""
    Calculates log loss.

    Args:
        y_true: list or array of true values
        y_predicted: list or array of predicted values

    Returns:
        Log loss
    """"""
    return log_loss(y_true, y_predicted)","Calculates log loss.

    Args:
        y_true: list or array of true values
        y_predicted: list or array of predicted values

    Returns:
        Log loss",
"def show_details(item_data: Dict[Any, Any]) -> str:
    """"""Format catalog item output

    Parameters:
        item_data: item's attributes values

    Returns:
        [rich_message]: list of formatted rich message
    """"""

    txt = """"

    for key, value in item_data.items():
        txt += ""**"" + str(key) + ""**"" + ': ' + str(value) + ""  \n""

    return txt","Format catalog item output

    Parameters:
        item_data: item's attributes values

    Returns:
        [rich_message]: list of formatted rich message",
"def make_agent() -> EcommerceAgent:
    """"""Make an agent

    Returns:
        agent: created Ecommerce agent
    """"""

    config_path = find_config('tfidf_retrieve')
    skill = build_model(config_path)
    agent = EcommerceAgent(skills=[skill])
    return agent","Make an agent

    Returns:
        agent: created Ecommerce agent",
"def main():
    """"""Parse parameters and run ms bot framework""""""

    args = parser.parse_args()
    run_ms_bot_framework_server(agent_generator=make_agent,
                                app_id=args.ms_id,
                                app_secret=args.ms_secret,
                                stateful=True)",Parse parameters and run ms bot framework,
"def positions_func(inputs, pad=0):
    """"""
    A layer filling i-th column of a 2D tensor with
    1+ln(1+i) when it contains a meaningful symbol
    and with 0 when it contains PAD
    """"""
    position_inputs = kb.cumsum(kb.ones_like(inputs, dtype=""float32""), axis=1)
    position_inputs *= kb.cast(kb.not_equal(inputs, pad), ""float32"")
    return kb.log(1.0 + position_inputs)","A layer filling i-th column of a 2D tensor with
    1+ln(1+i) when it contains a meaningful symbol
    and with 0 when it contains PAD",
"def path_set_md5(url):
    """"""Given a file URL, return a md5 query of the file

    Args:
        url: a given URL
    Returns:
        URL of the md5 file
    """"""
    scheme, netloc, path, query_string, fragment = urlsplit(url)
    path += '.md5'

    return urlunsplit((scheme, netloc, path, query_string, fragment))","Given a file URL, return a md5 query of the file

    Args:
        url: a given URL
    Returns:
        URL of the md5 file",
"def json(self) -> dict:
        """"""Returns json compatible state of the Button instance.

        Returns:
            control_json: Json representation of Button state.
        """"""
        content = {}
        content['name'] = self.name
        content['callback'] = self.callback
        self.control_json['content'] = content
        return self.control_json","Returns json compatible state of the Button instance.

        Returns:
            control_json: Json representation of Button state.",
"def expand_path(path: Union[str, Path]) -> Path:
    """"""Convert relative paths to absolute with resolving user directory.""""""
    return Path(path).expanduser().resolve()",Convert relative paths to absolute with resolving user directory.,
"def run(self) -> None:
        """"""Thread run method implementation.""""""
        while True:
            request = self.input_queue.get()
            response = self._handle_request(request)
            self.output_queue.put(response)",Thread run method implementation.,
"def _del_conversation(self, conversation_key: str) -> None:
        """"""Deletes Conversation instance.

        Args:
            conversation_key: Conversation key.
        """"""
        if conversation_key in self.conversations.keys():
            del self.conversations[conversation_key]
            log.info(f'Deleted conversation, key: {conversation_key}')","Deletes Conversation instance.

        Args:
            conversation_key: Conversation key.",
"def cls_from_str(name: str) -> type:
    """"""Returns a class object with the name given as a string.""""""
    try:
        module_name, cls_name = name.split(':')
    except ValueError:
        raise ConfigError('Expected class description in a `module.submodules:ClassName` form, but got `{}`'
                          .format(name))

    return getattr(importlib.import_module(module_name), cls_name)",Returns a class object with the name given as a string.,
"def get_model(name: str) -> type:
    """"""Returns a registered class object with the name given in the string.""""""
    if name not in _REGISTRY:
        if ':' not in name:
            raise ConfigError(""Model {} is not registered."".format(name))
        return cls_from_str(name)
    return cls_from_str(_REGISTRY[name])",Returns a registered class object with the name given in the string.,
"def list_timezones(self):
        """"""Return the list of all known timezones.""""""
        from h2o.expr import ExprNode
        return h2o.H2OFrame._expr(expr=ExprNode(""listTimeZones""))._frame()",Return the list of all known timezones.,
"def _fill_from_h2ocluster(self, other):
        """"""
        Update information in this object from another H2OCluster instance.

        :param H2OCluster other: source of the new information for this object.
        """"""
        self._props = other._props
        self._retrieved_at = other._retrieved_at
        other._props = {}
        other._retrieved_at = None","Update information in this object from another H2OCluster instance.

        :param H2OCluster other: source of the new information for this object.",
"def jobs(self, job_key=None, timeoutSecs=10, **kwargs):
    '''
    Fetch all the jobs or a single job from the /Jobs endpoint.
    '''
    params_dict = {
        # 'job_key': job_key
    }
    h2o_methods.check_params_update_kwargs(params_dict, kwargs, 'jobs', True)
    result = self.do_json_request('3/Jobs.json', timeout=timeoutSecs, params=params_dict)
    return result",Fetch all the jobs or a single job from the /Jobs endpoint.,
"def model_metrics(self, timeoutSecs=60, **kwargs):
    '''
    ModelMetrics list. 
    '''
    result = self.do_json_request('/3/ModelMetrics.json', cmd='get', timeout=timeoutSecs)
    h2o_sandbox.check_sandbox_for_errors()
    return result",ModelMetrics list.,
"def terminate_instances(instances, region):
    '''terminate all the instances given by its ids'''
    if not instances: return
    conn = ec2_connect(region)
    log(""Terminating instances {0}."".format(instances))
    conn.terminate_instances(instances)
    log(""Done"")",terminate all the instances given by its ids,
"def stop_instances(instances, region):
    '''stop all the instances given by its ids'''
    if not instances: return
    conn = ec2_connect(region)
    log(""Stopping instances {0}."".format(instances))
    conn.stop_instances(instances)
    log(""Done"")",stop all the instances given by its ids,
"def start_instances(instances, region):
    '''Start all the instances given by its ids'''
    if not instances: return
    conn = ec2_connect(region)
    log(""Starting instances {0}."".format(instances))
    conn.start_instances(instances)
    log(""Done"")",Start all the instances given by its ids,
"def reboot_instances(instances, region):
    '''Reboot all the instances given by its ids'''
    if not instances: return
    conn = ec2_connect(region)
    log(""Rebooting instances {0}."".format(instances))
    conn.reboot_instances(instances)
    log(""Done"")",Reboot all the instances given by its ids,
"def join(self):
        """"""Wait until job's completion.""""""
        self._future = False
        self._job.poll()
        model_key = self._job.dest_key
        self._job = None
        model_json = h2o.api(""GET /%d/Models/%s"" % (self._rest_version, model_key))[""models""][0]
        self._resolve_model(model_key, model_json)",Wait until job's completion.,
"def is_ipython_notebook(file_name):
    """"""
    Return True if file_name matches a regexp for an ipython notebook.  False otherwise.
    :param file_name: file to test
    """"""
    if (not re.match(""^.*checkpoint\.ipynb$"", file_name)) and re.match(""^.*\.ipynb$"", file_name): return True
    return False","Return True if file_name matches a regexp for an ipython notebook.  False otherwise.
    :param file_name: file to test",
"def stop(self):
        """"""
        Normal node shutdown.
        Ignore failures for now.

        :return none
        """"""
        if self.pid > 0:
            print(""Killing JVM with PID {}"".format(self.pid))
            try:
                self.child.terminate()
                self.child.wait()
            except OSError:
                pass
            self.pid = -1","Normal node shutdown.
        Ignore failures for now.

        :return none",
"def start(self):
        """"""
        Start H2O cluster.
        The cluster is not up until wait_for_cloud_to_be_up() is called and returns.

        :return none
        """"""
        for node in self.nodes:
            node.start()

        for node in self.client_nodes:
            node.start()","Start H2O cluster.
        The cluster is not up until wait_for_cloud_to_be_up() is called and returns.

        :return none",
"def stop(self):
        """"""
        Normal cluster shutdown.

        :return none
        """"""
        for node in self.nodes:
            node.stop()

        for node in self.client_nodes:
            node.stop()","Normal cluster shutdown.

        :return none",
"def terminate(self):
        """"""
        Terminate a running cluster.  (Due to a signal.)

        :return none
        """"""
        for node in self.client_nodes:
            node.terminate()

        for node in self.nodes:
            node.terminate()","Terminate a running cluster.  (Due to a signal.)

        :return none",
"def get_ip(self):
        """""" Return an ip to use to talk to this cluster. """"""
        if len(self.client_nodes) > 0:
            node = self.client_nodes[0]
        else:
            node = self.nodes[0]
        return node.get_ip()",Return an ip to use to talk to this cluster.,
"def get_port(self):
        """""" Return a port to use to talk to this cluster. """"""
        if len(self.client_nodes) > 0:
            node = self.client_nodes[0]
        else:
            node = self.nodes[0]
        return node.get_port()",Return a port to use to talk to this cluster.,
"def from_external(external=H2OFrame):
        """"""
        Creates new H2OWord2vecEstimator based on an external model.
        :param external: H2OFrame with an external model
        :return: H2OWord2vecEstimator instance representing the external model
        """"""
        w2v_model = H2OWord2vecEstimator(pre_trained=external)
        w2v_model.train()
        return w2v_model","Creates new H2OWord2vecEstimator based on an external model.
        :param external: H2OFrame with an external model
        :return: H2OWord2vecEstimator instance representing the external model",
"def h2o_median_absolute_error(y_actual, y_predicted):
    """"""
    Median absolute error regression loss

    :param y_actual: H2OFrame of actual response.
    :param y_predicted: H2OFrame of predicted response.
    :returns: median absolute error loss (best is 0.0)
    """"""
    ModelBase._check_targets(y_actual, y_predicted)
    return (y_predicted - y_actual).abs().median()","Median absolute error regression loss

    :param y_actual: H2OFrame of actual response.
    :param y_predicted: H2OFrame of predicted response.
    :returns: median absolute error loss (best is 0.0)",
"def name(self, src=None):
        """"""Return string representing the name of this type.""""""
        res = [_get_type_name(tt, src) for tt in self._types]
        if len(res) == 2 and ""None"" in res:
            res.remove(""None"")
            return ""?"" + res[0]
        else:
            return "" | "".join(res)",Return string representing the name of this type.,
"def check(self, var):
        """"""Return True if the variable matches this type, and False otherwise.""""""
        return all(_check_type(var, tt) for tt in self._types)","Return True if the variable matches this type, and False otherwise.",
"def name(self, src=None):
        """"""Return string representing the name of this type.""""""
        return "" & "".join(_get_type_name(tt, src) for tt in self._types)",Return string representing the name of this type.,
"def check(self, var):
        """"""Return True if the variable does not match any of the types, and False otherwise.""""""
        return not any(_check_type(var, tt) for tt in self._types)","Return True if the variable does not match any of the types, and False otherwise.",
"def name(self, src=None):
        """"""Return string representing the name of this type.""""""
        if len(self._types) > 1:
            return ""!(%s)"" % str(""|"".join(_get_type_name(tt, src) for tt in self._types))
        else:
            return ""!"" + _get_type_name(self._types[0], src)",Return string representing the name of this type.,
"def check(self, var):
        """"""Return True if the variable matches this type, and False otherwise.""""""
        return isinstance(var, tuple) and all(_check_type(t, self._element_type) for t in var)","Return True if the variable matches this type, and False otherwise.",
"def name(self, src=None):
        """"""Return string representing the name of this type.""""""
        return ""{%s}"" % "", "".join(""%s: %s"" % (key, _get_type_name(ktype, src))
                                  for key, ktype in viewitems(self._types))",Return string representing the name of this type.,
"def check(self, var):
        """"""Return True if the variable matches the specified type.""""""
        return (isinstance(var, _int_type) and
                (self._lower_bound is None or var >= self._lower_bound) and
                (self._upper_bound is None or var <= self._upper_bound))",Return True if the variable matches the specified type.,
"def check(self, var):
        """"""Return True if the variable matches the specified type.""""""
        return (isinstance(var, _num_type) and
                (self._lower_bound is None or var >= self._lower_bound) and
                (self._upper_bound is None or var <= self._upper_bound))",Return True if the variable matches the specified type.,
"def check(self, var):
        """"""Return True if the variable matches this type, and False otherwise.""""""
        if self._class is None: self._init()
        return self._class and self._checker(var, self._class)","Return True if the variable matches this type, and False otherwise.",
"def check(self, var):
        """"""Check whether the provided value is a valid enum constant.""""""
        if not isinstance(var, _str_type): return False
        return _enum_mangle(var) in self._consts",Check whether the provided value is a valid enum constant.,
"def get_config():
        """"""Retrieve the config as a dictionary of key-value pairs.""""""
        self = H2OConfigReader._get_instance()
        if not self._config_loaded:
            self._read_config()
        return self._config",Retrieve the config as a dictionary of key-value pairs.,
"def render(self, progress, width=None, status=None):
        """"""Render the widget.""""""
        current_pct = int(progress * 100 + 0.1)
        return RenderResult(rendered=""%3d%%"" % current_pct, next_progress=(current_pct + 1) / 100)",Render the widget.,
"def refresh(self):
        """"""Reload frame information from the backend H2O server.""""""
        self._ex._cache.flush()
        self._frame(fill_cache=True)",Reload frame information from the backend H2O server.,
"def names(self):
        """"""The list of column names (List[str]).""""""
        if not self._ex._cache.names_valid():
            self._ex._cache.flush()
            self._frame(fill_cache=True)
        return list(self._ex._cache.names)",The list of column names (List[str]).,
"def nrows(self):
        """"""Number of rows in the dataframe (int).""""""
        if not self._ex._cache.nrows_valid():
            self._ex._cache.flush()
            self._frame(fill_cache=True)
        return self._ex._cache.nrows",Number of rows in the dataframe (int).,
"def ncols(self):
        """"""Number of columns in the dataframe (int).""""""
        if not self._ex._cache.ncols_valid():
            self._ex._cache.flush()
            self._frame(fill_cache=True)
        return self._ex._cache.ncols",Number of columns in the dataframe (int).,
"def types(self):
        """"""The dictionary of column name/type pairs.""""""
        if not self._ex._cache.types_valid():
            self._ex._cache.flush()
            self._frame(fill_cache=True)
        return dict(self._ex._cache.types)",The dictionary of column name/type pairs.,
"def levels(self):
        """"""
        Get the factor levels.

        :returns: A list of lists, one list per column, of levels.
        """"""
        lol = H2OFrame._expr(expr=ExprNode(""levels"", self)).as_data_frame(False)
        lol.pop(0)  # Remove column headers
        lol = list(zip(*lol))
        return [[ll for ll in l if ll != ''] for l in lol]","Get the factor levels.

        :returns: A list of lists, one list per column, of levels.",
"def nlevels(self):
        """"""
        Get the number of factor levels for each categorical column.

        :returns: A list of the number of levels per column.
        """"""
        levels = self.levels()
        return [len(l) for l in levels] if levels else 0","Get the number of factor levels for each categorical column.

        :returns: A list of the number of levels per column.",
"def set_level(self, level):
        """"""
        A method to set all column values to one of the levels.

        :param str level: The level at which the column will be set (a string)

        :returns: H2OFrame with entries set to the desired level.
        """"""
        return H2OFrame._expr(expr=ExprNode(""setLevel"", self, level), cache=self._ex._cache)","A method to set all column values to one of the levels.

        :param str level: The level at which the column will be set (a string)

        :returns: H2OFrame with entries set to the desired level.",
"def cumsum(self,  axis=0):
        """"""
        Compute cumulative sum over rows / columns of the frame.

        :param int axis: 0 for column-wise, 1 for row-wise
        :returns: new H2OFrame with cumulative sums of the original frame.
        """"""
        return H2OFrame._expr(expr=ExprNode(""cumsum"", self, axis), cache=self._ex._cache)","Compute cumulative sum over rows / columns of the frame.

        :param int axis: 0 for column-wise, 1 for row-wise
        :returns: new H2OFrame with cumulative sums of the original frame.",
"def strsplit(self, pattern):
        """"""
        Split the strings in the target column on the given regular expression pattern.

        :param str pattern: The split pattern.
        :returns: H2OFrame containing columns of the split strings.
        """"""
        fr = H2OFrame._expr(expr=ExprNode(""strsplit"", self, pattern))
        fr._ex._cache.nrows = self.nrow
        return fr","Split the strings in the target column on the given regular expression pattern.

        :param str pattern: The split pattern.
        :returns: H2OFrame containing columns of the split strings.",
"def entropy(self):
        """"""
        For each string compute its Shannon entropy, if the string is empty the entropy is 0.

        :returns: an H2OFrame of Shannon entropies.
        """"""
        fr = H2OFrame._expr(expr=ExprNode(""entropy"", self))
        fr._ex._cache.nrows = self.nrow
        fr._ex._cache.ncol = self.ncol
        return fr","For each string compute its Shannon entropy, if the string is empty the entropy is 0.

        :returns: an H2OFrame of Shannon entropies.",
"def toupper(self):
        """"""
        Translate characters from lower to upper case for a particular column.

        :returns: new H2OFrame with all strings in the current frame converted to the uppercase.
        """"""
        return H2OFrame._expr(expr=ExprNode(""toupper"", self), cache=self._ex._cache)","Translate characters from lower to upper case for a particular column.

        :returns: new H2OFrame with all strings in the current frame converted to the uppercase.",
"def signif(self, digits=6):
        """"""
        Round doubles/floats to the given number of significant digits.

        :param int digits: Number of significant digits to retain.
        :returns: new H2OFrame with rounded values from the original frame.
        """"""
        return H2OFrame._expr(expr=ExprNode(""signif"", self, digits), cache=self._ex._cache)","Round doubles/floats to the given number of significant digits.

        :param int digits: Number of significant digits to retain.
        :returns: new H2OFrame with rounded values from the original frame.",
"def na_omit(self):
        """"""
        Remove rows with NAs from the H2OFrame.

        :returns: new H2OFrame with all rows from the original frame containing any NAs removed.
        """"""
        fr = H2OFrame._expr(expr=ExprNode(""na.omit"", self), cache=self._ex._cache)
        fr._ex._cache.nrows = -1
        return fr","Remove rows with NAs from the H2OFrame.

        :returns: new H2OFrame with all rows from the original frame containing any NAs removed.",
"def from_python(python_obj, destination_frame=None, header=0, separator="","", column_names=None,
                    column_types=None, na_strings=None):
        """"""[DEPRECATED] Use constructor ``H2OFrame()`` instead.""""""
        return H2OFrame(python_obj, destination_frame, header, separator, column_names, column_types,
                        na_strings)",[DEPRECATED] Use constructor ``H2OFrame()`` instead.,
"def parse_text(text):
    """"""Parse code from a string of text.""""""
    assert isinstance(text, _str_type), ""`text` parameter should be a string, got %r"" % type(text)
    gen = iter(text.splitlines(True))  # True = keep newlines
    readline = gen.next if hasattr(gen, ""next"") else gen.__next__
    return Code(_tokenize(readline))",Parse code from a string of text.,
"def parse_file(filename):
    """"""Parse the provided file, and return Code object.""""""
    assert isinstance(filename, _str_type), ""`filename` parameter should be a string, got %r"" % type(filename)
    with open(filename, ""rt"", encoding=""utf-8"") as f:
        return Code(_tokenize(f.readline))","Parse the provided file, and return Code object.",
"def move(self, drow, dcol=0):
        """"""Move the token by `drow` rows and `dcol` columns.""""""
        self._start_row += drow
        self._start_col += dcol
        self._end_row += drow
        self._end_col += dcol",Move the token by `drow` rows and `dcol` columns.,
"def unparse(self):
        """"""Convert the parsed representation back into the source code.""""""
        ut = Untokenizer(start_row=self._tokens[0].start_row)
        self._unparse(ut)
        return ut.result()",Convert the parsed representation back into the source code.,
"def centers(self):
        """"""The centers for the KMeans model.""""""
        o = self._model_json[""output""]
        cvals = o[""centers""].cell_values
        centers = [list(cval[1:]) for cval in cvals]
        return centers",The centers for the KMeans model.,
"def centers_std(self):
        """"""The standardized centers for the kmeans model.""""""
        o = self._model_json[""output""]
        cvals = o[""centers_std""].cell_values
        centers_std = [list(cval[1:]) for cval in cvals]
        centers_std = [list(x) for x in zip(*centers_std)]
        return centers_std",The standardized centers for the kmeans model.,
"def get_frame(frame_id, **kwargs):
    """"""
    Obtain a handle to the frame in H2O with the frame_id key.

    :param str frame_id: id of the frame to retrieve.
    :returns: an :class:`H2OFrame` object
    """"""
    assert_is_type(frame_id, str)
    return H2OFrame.get_frame(frame_id, **kwargs)","Obtain a handle to the frame in H2O with the frame_id key.

    :param str frame_id: id of the frame to retrieve.
    :returns: an :class:`H2OFrame` object",
"def print2(msg, flush=False, end=""\n""):
    """"""
    This function exists here ONLY because Sphinx.ext.autodoc gets into a bad state when seeing the print()
    function. When in that state, autodoc doesn't display any errors or warnings, but instead completely
    ignores the ""bysource"" member-order option.
    """"""
    print(msg, end=end)
    if flush: sys.stdout.flush()","This function exists here ONLY because Sphinx.ext.autodoc gets into a bad state when seeing the print()
    function. When in that state, autodoc doesn't display any errors or warnings, but instead completely
    ignores the ""bysource"" member-order option.",
"def slice_is_normalized(s):
    """"""Return True if slice ``s`` in ""normalized"" form.""""""
    return (s.start is not None and s.stop is not None and s.step is not None and s.start <= s.stop)","Return True if slice ``s`` in ""normalized"" form.",
"def join(self):
        """"""Wait until grid finishes computing.""""""
        self._future = False
        self._job.poll()
        self._job = None",Wait until grid finishes computing.,
"def predict(self, test_data):
        """"""
        Predict on a dataset.

        :param H2OFrame test_data: Data to be predicted on.
        :returns: H2OFrame filled with predictions.
        """"""
        return {model.model_id: model.predict(test_data) for model in self.models}","Predict on a dataset.

        :param H2OFrame test_data: Data to be predicted on.
        :returns: H2OFrame filled with predictions.",
"def get_xval_models(self, key=None):
        """"""
        Return a Model object.

        :param str key: If None, return all cross-validated models; otherwise return the model
            specified by the key.
        :returns: A model or a list of models.
        """"""
        return {model.model_id: model.get_xval_models(key) for model in self.models}","Return a Model object.

        :param str key: If None, return all cross-validated models; otherwise return the model
            specified by the key.
        :returns: A model or a list of models.",
"def deepfeatures(self, test_data, layer):
        """"""
        Obtain a hidden layer's details on a dataset.

        :param test_data: Data to create a feature space on.
        :param int layer: Index of the hidden layer.
        :returns: A dictionary of hidden layer details for each model.
        """"""
        return {model.model_id: model.deepfeatures(test_data, layer) for model in self.models}","Obtain a hidden layer's details on a dataset.

        :param test_data: Data to create a feature space on.
        :param int layer: Index of the hidden layer.
        :returns: A dictionary of hidden layer details for each model.",
"def biases(self, vector_id=0):
        """"""
        Return the frame for the respective bias vector.

        :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.
        :returns: an H2OFrame which represents the bias vector identified by vector_id
        """"""
        return {model.model_id: model.biases(vector_id) for model in self.models}","Return the frame for the respective bias vector.

        :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.
        :returns: an H2OFrame which represents the bias vector identified by vector_id",
"def pprint_coef(self):
        """"""Pretty print the coefficents table (includes normalized coefficients).""""""
        for i, model in enumerate(self.models):
            print('Model', i)
            model.pprint_coef()
            print()",Pretty print the coefficents table (includes normalized coefficients).,
"def confusion_matrix(self, data):
        """"""
        Returns a confusion matrix based of H2O's default prediction threshold for a dataset.

        :param data: metric for which the confusion matrix will be calculated.
        """"""
        return {model.model_id: model.confusion_matrix(data) for model in self.models}","Returns a confusion matrix based of H2O's default prediction threshold for a dataset.

        :param data: metric for which the confusion matrix will be calculated.",
"def archetypes(self):
        """"""The archetypes (Y) of the GLRM model.""""""
        o = self._model_json[""output""]
        yvals = o[""archetypes""].cell_values
        archetypes = []
        for yidx, yval in enumerate(yvals):
            archetypes.append(list(yvals[yidx])[1:])
        return archetypes",The archetypes (Y) of the GLRM model.,
"def parse(self):
        """"""
        Parse file specified by constructor.
        """"""
        f = open(self.parse_log_path, ""r"")
        self.parse2(f)
        f.close()",Parse file specified by constructor.,
"def _print(self, msg, flush=False, end=""\n""):
        """"""Helper function to print connection status messages when in verbose mode.""""""
        if self._verbose:
            print2(msg, end=end, flush=flush)",Helper function to print connection status messages when in verbose mode.,
"def transform(self, X, y=None, **params):
        """"""
        Scale an H2OFrame with the fitted means and standard deviations.

        :param X: An H2OFrame; may contain NAs and/or categoricals.
        :param y: None (Ignored)
        :param params: (Ignored)
        :returns: A scaled H2OFrame.
        """"""
        return X.scale(self.means, self.stds)","Scale an H2OFrame with the fitted means and standard deviations.

        :param X: An H2OFrame; may contain NAs and/or categoricals.
        :param y: None (Ignored)
        :param params: (Ignored)
        :returns: A scaled H2OFrame.",
"def inverse_transform(self, X, y=None, **params):
        """"""
        Undo the scale transformation.

        :param X: An H2OFrame; may contain NAs and/or categoricals.
        :param y: None (Ignored)
        :param params: (Ignored)
        :returns: An H2OFrame
        """"""
        for i in range(X.ncol):
            X[i] = self.means[i] + self.stds[i] * X[i]
        return X","Undo the scale transformation.

        :param X: An H2OFrame; may contain NAs and/or categoricals.
        :param y: None (Ignored)
        :param params: (Ignored)
        :returns: An H2OFrame",
"def normalize_enum_constant(s):
    """"""Return enum constant `s` converted to a canonical snake-case.""""""
    if s.islower(): return s
    if s.isupper(): return s.lower()
    return """".join(ch if ch.islower() else ""_"" + ch.lower() for ch in s).strip(""_"")",Return enum constant `s` converted to a canonical snake-case.,
"def params(self):
        """"""
        Get the parameters and the actual/default values only.

        :returns: A dictionary of parameters used to build this model.
        """"""
        params = {}
        for p in self.parms:
            params[p] = {""default"": self.parms[p][""default_value""],
                         ""actual"": self.parms[p][""actual_value""]}
        return params","Get the parameters and the actual/default values only.

        :returns: A dictionary of parameters used to build this model.",
"def default_params(self):
        """"""Dictionary of the default parameters of the model.""""""
        params = {}
        for p in self.parms:
            params[p] = self.parms[p][""default_value""]
        return params",Dictionary of the default parameters of the model.,
"def get_xval_models(self, key=None):
        """"""
        Return a Model object.

        :param key: If None, return all cross-validated models; otherwise return the model that key points to.

        :returns: A model or list of models.
        """"""
        return h2o.get_model(key) if key is not None else [h2o.get_model(k) for k in self._xval_keys]","Return a Model object.

        :param key: If None, return all cross-validated models; otherwise return the model that key points to.

        :returns: A model or list of models.",
"def _check_targets(y_actual, y_predicted):
        """"""Check that y_actual and y_predicted have the same length.

        :param H2OFrame y_actual:
        :param H2OFrame y_predicted:

        :returns: None
        """"""
        if len(y_actual) != len(y_predicted):
            raise ValueError(""Row mismatch: [{},{}]"".format(len(y_actual), len(y_predicted)))","Check that y_actual and y_predicted have the same length.

        :param H2OFrame y_actual:
        :param H2OFrame y_predicted:

        :returns: None",
"def cross_validation_models(self):
        """"""
        Obtain a list of cross-validation models.

        :returns: list of H2OModel objects.
        """"""
        cvmodels = self._model_json[""output""][""cross_validation_models""]
        if cvmodels is None: return None
        m = []
        for p in cvmodels: m.append(h2o.get_model(p[""name""]))
        return m","Obtain a list of cross-validation models.

        :returns: list of H2OModel objects.",
"def as_data_frame(self):
        """"""Convert to a python 'data frame'.""""""
        if can_use_pandas():
            import pandas
            pandas.options.display.max_colwidth = 70
            return pandas.DataFrame(self._cell_values, columns=self._col_header)
        return self",Convert to a python 'data frame'.,
"def csv_dict_writer(f, fieldnames, **kwargs):
    """"""Equivalent of csv.DictWriter, but allows `delimiter` to be a unicode string on Py2.""""""
    import csv
    if ""delimiter"" in kwargs:
        kwargs[""delimiter""] = str(kwargs[""delimiter""])
    return csv.DictWriter(f, fieldnames, **kwargs)","Equivalent of csv.DictWriter, but allows `delimiter` to be a unicode string on Py2.",
"def bytes_iterator(s):
    """"""Given a string, return an iterator over this string's bytes (as ints).""""""
    if s is None: return
    if PY2 or PY3 and isinstance(s, str):
        for ch in s:
            yield ord(ch)
    elif PY3 and isinstance(s, bytes):
        for ch in s:
            yield ch
    else:
        raise TypeError(""String argument expected, got %s"" % type(s))","Given a string, return an iterator over this string's bytes (as ints).",
"def repr2(x):
    """"""Analogous to repr(), but will suppress 'u' prefix when repr-ing a unicode string.""""""
    s = repr(x)
    if len(s) >= 2 and s[0] == ""u"" and (s[1] == ""'"" or s[1] == '""'):
        s = s[1:]
    return s","Analogous to repr(), but will suppress 'u' prefix when repr-ing a unicode string.",
"def _path2uri(self, dirpath):
        ''' Convert directory path to uri '''
        relpath = dirpath.replace(self.root_path, self.package_name)
        if relpath.startswith(os.path.sep):
            relpath = relpath[1:]
        return relpath.replace(os.path.sep, '.')",Convert directory path to uri,
"def _parse_module(self, uri):
        ''' Parse module defined in *uri* '''
        filename = self._uri2path(uri)
        if filename is None:
            # nothing that we could handle here.
            return ([],[])
        f = open(filename, 'rt')
        functions, classes = self._parse_lines(f)
        f.close()
        return functions, classes",Parse module defined in *uri*,
"def to_list(self):
        """"""Convert this confusion matrix into a 2x2 plain list of values.""""""
        return [[int(self.table.cell_values[0][1]), int(self.table.cell_values[0][2])],
                [int(self.table.cell_values[1][1]), int(self.table.cell_values[1][2])]]",Convert this confusion matrix into a 2x2 plain list of values.,
"def read_cms(cms=None, domains=None):
        """"""Read confusion matrices from the list of sources (?).""""""
        assert_is_type(cms, [list])
        return [ConfusionMatrix(cm, domains) for cm in cms]",Read confusion matrices from the list of sources (?).,
"def save_dict():
    """"""
    Save the ignored java message dict stored in g_ok_java_messages into a pickle file for future use.

    :return: none
    """"""
    global g_ok_java_messages
    global g_save_java_message_filename
    global g_dict_changed

    if g_dict_changed:
        with open(g_save_java_message_filename,'wb') as ofile:
            pickle.dump(g_ok_java_messages,ofile)","Save the ignored java message dict stored in g_ok_java_messages into a pickle file for future use.

    :return: none",
"def locate_files(root_dir):
    """"""Find all python files in the given directory and all subfolders.""""""
    all_files = []
    root_dir = os.path.abspath(root_dir)
    for dir_name, subdirs, files in os.walk(root_dir):
        for f in files:
            if f.endswith("".py""):
                all_files.append(os.path.join(dir_name, f))
    return all_files",Find all python files in the given directory and all subfolders.,
"def parse_python_file(filename):
    """"""Parse file into chunks / objects.""""""



    with open(filename, ""rt"", encoding=""utf-8"") as f:
        tokens = list(tokenize.generate_tokens(f.readline))
        tokens = normalize_tokens(tokens)
        module = ChunkCode(tokens, 0, len(tokens))
        module.parse()
        print(module)",Parse file into chunks / objects.,
"def mean_per_class_error(self, thresholds=None):
        """"""
        :param thresholds: thresholds parameter must be a list (i.e. [0.01, 0.5, 0.99]). If None, then the
            thresholds in this set of metrics will be used.
        :returns: mean per class error.
        """"""
        return [[x[0], 1 - x[1]] for x in self.metric(""mean_per_class_accuracy"", thresholds=thresholds)]",":param thresholds: thresholds parameter must be a list (i.e. [0.01, 0.5, 0.99]). If None, then the
            thresholds in this set of metrics will be used.
        :returns: mean per class error.",
"def vprint(msg, pretty=False):
    """"""
    Print the provided string {msg}, but only when the --verbose option is on.
      :param msg     String to print.
      :param pretty  If on, then pprint() will be used instead of the regular print function.
    """"""
    if not config[""verbose""]:
        return
    if pretty:
        pp(msg)
    else:
        print(msg)","Print the provided string {msg}, but only when the --verbose option is on.
      :param msg     String to print.
      :param pretty  If on, then pprint() will be used instead of the regular print function.",
"def endpoint_groups():
    """"""Return endpoints, grouped by the class which handles them.""""""
    groups = defaultdict(list)
    for e in endpoints():
        groups[e[""class_name""]].append(e)
    return groups","Return endpoints, grouped by the class which handles them.",
"def update_site_forward(apps, schema_editor):
    """"""Set site domain and name.""""""
    Site = apps.get_model(""sites"", ""Site"")
    Site.objects.update_or_create(
        id=settings.SITE_ID,
        defaults={
            ""domain"": ""{{cookiecutter.domain_name}}"",
            ""name"": ""{{cookiecutter.project_name}}"",
        },
    )",Set site domain and name.,
"def json_data(self, data=None):
        """"""Adds the default_data to data and dumps it to a json.""""""
        if data is None:
            data = {}
        data.update(self.default_data)
        return json.dumps(data)",Adds the default_data to data and dumps it to a json.,
"def like_hashtag(self, hashtag, amount=None):
    """""" Likes last medias from hashtag """"""
    self.logger.info(""Going to like media with hashtag #%s."" % hashtag)
    medias = self.get_total_hashtag_medias(hashtag, amount)
    return self.like_medias(medias)",Likes last medias from hashtag,
"def get_uri(self, request):
        ''' Return the target uri for the request.'''
        protocol = request.protocol_override \
            if request.protocol_override else self.protocol
        protocol = protocol.lower()
        port = HTTP_PORT if protocol == 'http' else HTTPS_PORT
        return protocol + '://' + request.host + ':' + str(port) + request.path",Return the target uri for the request.,
"def get_authorization_server(self):
        """""" Returns the URI for the authorization server if present, otherwise empty string. """"""
        value = ''
        for key in ['authorization_uri', 'authorization']:
            value = self.get_value(key) or ''
            if value:
                break
        return value","Returns the URI for the authorization server if present, otherwise empty string.",
"def open(self, method, url):
        '''
        Opens the request.

        method:
            the request VERB 'GET', 'POST', etc.
        url:
            the url to connect
        '''
        flag = VARIANT.create_bool_false()
        _method = BSTR(method)
        _url = BSTR(url)
        _WinHttpRequest._Open(self, _method, _url, flag)","Opens the request.

        method:
            the request VERB 'GET', 'POST', etc.
        url:
            the url to connect",
"def set_timeout(self, timeout_in_seconds):
        ''' Sets up the timeout for the request. '''
        timeout_in_ms = int(timeout_in_seconds * 1000)
        _WinHttpRequest._SetTimeouts(
            self, 0, timeout_in_ms, timeout_in_ms, timeout_in_ms)",Sets up the timeout for the request.,
"def set_request_header(self, name, value):
        ''' Sets the request header. '''

        _name = BSTR(name)
        _value = BSTR(value)
        _WinHttpRequest._SetRequestHeader(self, _name, _value)",Sets the request header.,
"def get_all_response_headers(self):
        ''' Gets back all response headers. '''

        bstr_headers = c_void_p()
        _WinHttpRequest._GetAllResponseHeaders(self, byref(bstr_headers))
        bstr_headers = ctypes.cast(bstr_headers, c_wchar_p)
        headers = bstr_headers.value
        _SysFreeString(bstr_headers)
        return headers",Gets back all response headers.,
"def status(self):
        ''' Gets status of response. '''

        status = c_long()
        _WinHttpRequest._Status(self, byref(status))
        return int(status.value)",Gets status of response.,
"def status_text(self):
        ''' Gets status text of response. '''

        bstr_status_text = c_void_p()
        _WinHttpRequest._StatusText(self, byref(bstr_status_text))
        bstr_status_text = ctypes.cast(bstr_status_text, c_wchar_p)
        status_text = bstr_status_text.value
        _SysFreeString(bstr_status_text)
        return status_text",Gets status text of response.,
"def response_body(self):
        '''
        Gets response body as a SAFEARRAY and converts the SAFEARRAY to str.
        '''
        var_respbody = VARIANT()
        _WinHttpRequest._ResponseBody(self, byref(var_respbody))
        if var_respbody.is_safearray_of_bytes():
            respbody = var_respbody.str_from_safearray()
            return respbody
        else:
            return ''",Gets response body as a SAFEARRAY and converts the SAFEARRAY to str.,
"def set_client_certificate(self, certificate):
        '''Sets client certificate for the request. '''
        _certificate = BSTR(certificate)
        _WinHttpRequest._SetClientCertificate(self, _certificate)",Sets client certificate for the request.,
"def set_tunnel(self, host, port):
        ''' Sets up the host and the port for the HTTP CONNECT Tunnelling.'''
        url = host
        if port:
            url = url + u':' + port

        var_host = VARIANT.create_bstr_from_str(url)
        var_empty = VARIANT.create_empty()

        _WinHttpRequest._SetProxy(
            self, HTTPREQUEST_PROXYSETTING_PROXY, var_host, var_empty)",Sets up the host and the port for the HTTP CONNECT Tunnelling.,
"def set_tunnel(self, host, port=None, headers=None):
        ''' Sets up the host and the port for the HTTP CONNECT Tunnelling. '''
        self._httprequest.set_tunnel(unicode(host), unicode(str(port)))",Sets up the host and the port for the HTTP CONNECT Tunnelling.,
"def putheader(self, name, value):
        ''' Sends the headers of request. '''
        if sys.version_info < (3,):
            name = str(name).decode('utf-8')
            value = str(value).decode('utf-8')
        self._httprequest.set_request_header(name, value)",Sends the headers of request.,
"def send(self, request_body):
        ''' Sends request body. '''
        if not request_body:
            self._httprequest.send()
        else:
            self._httprequest.send(request_body)",Sends request body.,
"def _bstr_to_b64url(bstr, **kwargs):
    """"""Serialize bytes into base-64 string.
    :param str: Object to be serialized.
    :rtype: str
    """"""
    encoded = b64encode(bstr).decode()
    return encoded.strip('=').replace('+', '-').replace('/', '_')","Serialize bytes into base-64 string.
    :param str: Object to be serialized.
    :rtype: str",
"def _b64_to_bstr(b64str):
    """"""Deserialize base64 encoded string into string.
    :param str b64str: response string to be deserialized.
    :rtype: bytearray
    :raises: TypeError if string format invalid.
    """"""
    padding = '=' * (3 - (len(b64str) + 3) % 4)
    b64str = b64str + padding
    encoded = b64str.replace('-', '+').replace('_', '/')
    return b64decode(encoded)","Deserialize base64 encoded string into string.
    :param str b64str: response string to be deserialized.
    :rtype: bytearray
    :raises: TypeError if string format invalid.",
"def get_challenge_for_url(url):
    """""" Gets the challenge for the cached URL.
    :param url: the URL the challenge is cached for.
    :rtype: HttpBearerChallenge """"""
    if not url:
        raise ValueError('URL cannot be None')

    url = parse.urlparse(url)

    _lock.acquire()

    val = _cache.get(url.netloc)

    _lock.release()

    return val","Gets the challenge for the cached URL.
    :param url: the URL the challenge is cached for.
    :rtype: HttpBearerChallenge",
"def remove_challenge_for_url(url):
    """""" Removes the cached challenge for the specified URL.
    :param url: the URL for which to remove the cached challenge """"""
    if not url:
        raise ValueError('URL cannot be empty')

    url = parse.urlparse(url)

    _lock.acquire()

    del _cache[url.netloc]

    _lock.release()","Removes the cached challenge for the specified URL.
    :param url: the URL for which to remove the cached challenge",
"def _parse_response_body_from_xml_node(node, return_type):
        '''
        parse the xml and fill all the data into a class of return_type
        '''
        return_obj = return_type()
        _MinidomXmlToObject._fill_data_to_return_object(node, return_obj)

        return return_obj",parse the xml and fill all the data into a class of return_type,
"def parse_object_id(collection, id):
        """"""
        :param collection: The resource collection type.
        :type collection: str
        :param id: The resource uri.
        :type id: str
        :rtype: KeyVaultId
        """"""
        collection = _validate_string_argument(collection, 'collection')
        return KeyVaultIdentifier(uri=id, collection=collection)",":param collection: The resource collection type.
        :type collection: str
        :param id: The resource uri.
        :type id: str
        :rtype: KeyVaultId",
"def create_key_id(vault, name, version=None):
        """"""
        :param vault: The vault uri.
        :type vault: str
        :param name: The key name.
        :type name: str
        :param version: The key version.
        :type version: str
        :rtype: KeyVaultId
        """"""
        return KeyId(vault=vault, name=name, version=version)",":param vault: The vault uri.
        :type vault: str
        :param name: The key name.
        :type name: str
        :param version: The key version.
        :type version: str
        :rtype: KeyVaultId",
"def create_secret_id(vault, name, version=None):
        """"""
        :param vault: The vault uri.
        :type vault: str
        :param name: The secret name.
        :type name: str
        :param version: The secret version.
        :type version: str
        :rtype: KeyVaultId
        """"""
        return SecretId(vault=vault, name=name, version=version)",":param vault: The vault uri.
        :type vault: str
        :param name: The secret name.
        :type name: str
        :param version: The secret version.
        :type version: str
        :rtype: KeyVaultId",
"def create_certificate_id(vault, name, version=None):
        """"""
        :param vault: The vault uri.
        :type vault: str
        :param name: The certificate name.
        :type name: str
        :param version: The certificate version.
        :type version: str
        :rtype: KeyVaultId
        """"""
        return CertificateId(vault=vault, name=name, version=version)",":param vault: The vault uri.
        :type vault: str
        :param name: The certificate name.
        :type name: str
        :param version: The certificate version.
        :type version: str
        :rtype: KeyVaultId",
"def delete_storage_account(self, service_name):
        '''
        Deletes the specified storage account from Windows Azure.

        service_name:
            Name of the storage service account.
        '''
        _validate_not_none('service_name', service_name)
        return self._perform_delete(
            self._get_storage_service_path(service_name),
            as_async=True)","Deletes the specified storage account from Windows Azure.

        service_name:
            Name of the storage service account.",
"def delete_reserved_ip_address(self, name):
        '''
        Deletes a reserved IP address from the specified subscription.

        name:
            Required. Name of the reserved IP address.
        '''
        _validate_not_none('name', name)
        return self._perform_delete(self._get_reserved_ip_path(name),
                                    as_async=True)","Deletes a reserved IP address from the specified subscription.

        name:
            Required. Name of the reserved IP address.",
"def get_reserved_ip_address(self, name):
        '''
        Retrieves information about the specified reserved IP address.

        name:
            Required. Name of the reserved IP address.
        '''
        _validate_not_none('name', name)
        return self._perform_get(self._get_reserved_ip_path(name), ReservedIP)","Retrieves information about the specified reserved IP address.

        name:
            Required. Name of the reserved IP address.",
"def parse_response_for_async_op(response):
    ''' Extracts request id from response header. '''

    if response is None:
        return None

    result = AsynchronousOperationResult()
    if response.headers:
        for name, value in response.headers:
            if name.lower() == 'x-ms-request-id':
                result.request_id = value

    return result",Extracts request id from response header.,
"def get_regions(self):
        '''
        Get list of available service bus regions.
        '''
        response = self._perform_get(
            self._get_path('services/serviceBus/Regions/', None),
            None)

        return _MinidomXmlToObject.convert_response_to_feeds(
            response,
            _ServiceBusManagementXmlSerializer.xml_to_region)",Get list of available service bus regions.,
"def list_namespaces(self):
        '''
        List the service bus namespaces defined on the account.
        '''
        response = self._perform_get(
            self._get_path('services/serviceBus/Namespaces/', None),
            None)

        return _MinidomXmlToObject.convert_response_to_feeds(
            response,
            _ServiceBusManagementXmlSerializer.xml_to_namespace)",List the service bus namespaces defined on the account.,
"def get_namespace(self, name):
        '''
        Get details about a specific namespace.

        name:
            Name of the service bus namespace.
        '''
        response = self._perform_get(
            self._get_path('services/serviceBus/Namespaces', name),
            None)

        return _ServiceBusManagementXmlSerializer.xml_to_namespace(
            response.body)","Get details about a specific namespace.

        name:
            Name of the service bus namespace.",
"def delete_namespace(self, name):
        '''
        Delete a service bus namespace.

        name:
            Name of the service bus namespace to delete.
        '''
        _validate_not_none('name', name)

        return self._perform_delete(
            self._get_path('services/serviceBus/Namespaces', name),
            None)","Delete a service bus namespace.

        name:
            Name of the service bus namespace to delete.",
"def delete_server(self, server_name):
        '''
        Deletes an Azure SQL Database server (including all its databases).

        server_name:
            Name of the server you want to delete.
        '''
        _validate_not_none('server_name', server_name)
        return self._perform_delete(
            self._get_servers_path(server_name))","Deletes an Azure SQL Database server (including all its databases).

        server_name:
            Name of the server you want to delete.",
"def delete_database(self, server_name, name):
        '''
        Deletes an Azure SQL Database.

        server_name:
            Name of the server where the database is located.
        name:
            Name of the database to delete.
        '''
        return self._perform_delete(self._get_databases_path(server_name, name))","Deletes an Azure SQL Database.

        server_name:
            Name of the server where the database is located.
        name:
            Name of the database to delete.",
"def list_databases(self, name):
        '''
        List the SQL databases defined on the specified server name
        '''
        response = self._perform_get(self._get_list_databases_path(name),
                                     None)
        return _MinidomXmlToObject.parse_service_resources_response(
            response, Database)",List the SQL databases defined on the specified server name,
"def _get_authorization(self, request, httpclient):
        ''' return the signed string with token. '''
        return 'WRAP access_token=""' + \
                self._get_token(request.host, request.path, httpclient) + '""'",return the signed string with token.,
"def _general_error_handler(http_error):
    ''' Simple error handler for azure.'''
    message = str(http_error)
    if http_error.respbody is not None:
        message += '\n' + http_error.respbody.decode('utf-8-sig')
    raise AzureHttpError(message, http_error.status)",Simple error handler for azure.,
"def _handle_redirect(self, r, **kwargs):
        """"""Reset auth_attempted on redirects.""""""
        if r.is_redirect:
            self._thread_local.auth_attempted = False",Reset auth_attempted on redirects.,
"def use(self, profile):
        """"""Define a new default profile.""""""
        if not isinstance(profile, (KnownProfiles, ProfileDefinition)):
            raise ValueError(""Can only set as default a ProfileDefinition or a KnownProfiles"")
        type(self).profile = profile",Define a new default profile.,
"def expired(self):
        """"""Whether the receivers lock on a particular session has expired.

        :rtype: bool
        """"""
        if self.locked_until and self.locked_until <= datetime.datetime.now():
            return True
        return False","Whether the receivers lock on a particular session has expired.

        :rtype: bool",
"def _parse_response_body_from_xml_node(node, return_type):
        '''
        parse the xml and fill all the data into a class of return_type
        '''
        return_obj = return_type()
        _ETreeXmlToObject._fill_data_to_return_object(node, return_obj)

        return return_obj",parse the xml and fill all the data into a class of return_type,
"def restart_site(self, webspace_name, website_name):
        '''
        Restart a web site.

        webspace_name:
            The name of the webspace.
        website_name:
            The name of the website.
        '''
        return self._perform_post(
            self._get_restart_path(webspace_name, website_name),
            None, as_async=True)","Restart a web site.

        webspace_name:
            The name of the webspace.
        website_name:
            The name of the website.",
"def get_publish_profile(self, webspace_name, website_name):
        '''
        Get a site's publish profile as an object

        webspace_name:
            The name of the webspace.
        website_name:
            The name of the website.
        '''
        return self._perform_get(self._get_publishxml_path(webspace_name, website_name),
                                 PublishData)","Get a site's publish profile as an object

        webspace_name:
            The name of the webspace.
        website_name:
            The name of the website.",
"def _get_client_impl(self):
        """"""
        Get the versioned client implementation corresponding to the current profile.
        :return:  The versioned client implementation.
        """"""
        api_version = self._get_api_version(None)
        if api_version not in self._client_impls:
            self._create_client_impl(api_version)
        return self._client_impls[api_version]","Get the versioned client implementation corresponding to the current profile.
        :return:  The versioned client implementation.",
"def terminal_width(value):
    """"""Returns the width of the string it would be when displayed.""""""
    if isinstance(value, bytes):
        value = value.decode(""utf8"", ""ignore"")
    return sum(map(get_width, map(ord, value)))",Returns the width of the string it would be when displayed.,
"def get_cut_prefix(value, max_len):
    """"""Drops Characters by unicode not by bytes.""""""
    should_convert = isinstance(value, bytes)
    if should_convert:
        value = value.decode(""utf8"", ""ignore"")
    for i in range(len(value)):
        if terminal_width(value[i:]) <= max_len:
            break
    return value[i:].encode(""utf8"", ""ignore"") if should_convert else value[i:]",Drops Characters by unicode not by bytes.,
"def format_filesize(size):
    """"""Formats the file size into a human readable format.""""""
    for suffix in (""bytes"", ""KB"", ""MB"", ""GB"", ""TB""):
        if size < 1024.0:
            if suffix in (""GB"", ""TB""):
                return ""{0:3.2f} {1}"".format(size, suffix)
            else:
                return ""{0:3.1f} {1}"".format(size, suffix)

        size /= 1024.0",Formats the file size into a human readable format.,
"def format_time(elapsed):
    """"""Formats elapsed seconds into a human readable format.""""""
    hours = int(elapsed / (60 * 60))
    minutes = int((elapsed % (60 * 60)) / 60)
    seconds = int(elapsed % 60)

    rval = """"
    if hours:
        rval += ""{0}h"".format(hours)

    if elapsed > 60:
        rval += ""{0}m"".format(minutes)

    rval += ""{0}s"".format(seconds)
    return rval",Formats elapsed seconds into a human readable format.,
"def create_status_line(**params):
    """"""Creates a status line with appropriate size.""""""
    max_size = get_terminal_size().columns - 1

    for fmt in PROGRESS_FORMATS:
        status = fmt.format(**params)

        if len(status) <= max_size:
            break

    return status",Creates a status line with appropriate size.,
"def clear(self):
        'od.clear() -> None.  Remove all items from od.'
        try:
            for node in self.__map.itervalues():
                del node[:]
            root = self.__root
            root[:] = [root, root, None]
            self.__map.clear()
        except AttributeError:
            pass
        dict.clear(self)",od.clear() -> None.  Remove all items from od.,
"def fromkeys(cls, iterable, value=None):
        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
        and values equal to v (which defaults to None).

        '''
        d = cls()
        for key in iterable:
            d[key] = value
        return d","OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
        and values equal to v (which defaults to None).",
"def close(self):
        """"""Shuts down the thread.""""""
        if not self.closed:
            log.debug(""Closing worker thread"")

        self.closed = True
        if self._wait:
            self._wait.set()",Shuts down the thread.,
"def wait(self, time):
        """"""Pauses the thread for a specified time.

        Returns False if interrupted by another thread and True if the
        time runs out normally.
        """"""
        self._wait = Event()
        return not self._wait.wait(time)","Pauses the thread for a specified time.

        Returns False if interrupted by another thread and True if the
        time runs out normally.",
"def close(self):
        """"""Shuts down the thread.""""""
        if not self.closed:
            log.debug(""Closing writer thread"")

        self.closed = True
        self.reader.buffer.close()
        self.executor.shutdown(wait=False)
        if concurrent.futures.thread._threads_queues:
            concurrent.futures.thread._threads_queues.clear()",Shuts down the thread.,
"def put(self, segment):
        """"""Adds a segment to the download pool and write queue.""""""
        if self.closed:
            return

        if segment is not None:
            future = self.executor.submit(self.fetch, segment,
                                          retries=self.retries)
        else:
            future = None

        self.queue(self.futures, (segment, future))",Adds a segment to the download pool and write queue.,
"def queue(self, queue_, value):
        """"""Puts a value into a queue but aborts if this thread is closed.""""""
        while not self.closed:
            try:
                queue_.put(value, block=True, timeout=1)
                return
            except queue.Full:
                continue",Puts a value into a queue but aborts if this thread is closed.,
"def pkcs7_decode(paddedData, keySize=16):
    '''
    Remove the PKCS#7 padding
    '''
    # Use ord + [-1:] to support both python 2 and 3
    val = ord(paddedData[-1:])
    if val > keySize:
        raise StreamError(""Input is not padded or padding is corrupt, got padding size of {0}"".format(val))

    return paddedData[:-val]",Remove the PKCS#7 padding,
"def prepend_www(url):
    """"""Changes google.com to www.google.com""""""
    parsed = urlparse(url)
    if parsed.netloc.split(""."")[0] != ""www"":
        return parsed.scheme + ""://www."" + parsed.netloc + parsed.path
    else:
        return url",Changes google.com to www.google.com,
"def parse_qsd(data, name=""query string"", exception=PluginError, schema=None, **params):
    """"""Parses a query string into a dict.

    Unlike parse_qs and parse_qsl, duplicate keys are not preserved in
    favor of a simpler return value.
    """"""

    value = dict(parse_qsl(data, **params))
    if schema:
        value = schema.validate(value, name=name, exception=exception)

    return value","Parses a query string into a dict.

    Unlike parse_qs and parse_qsl, duplicate keys are not preserved in
    favor of a simpler return value.",
"def json(cls, res, *args, **kwargs):
        """"""Parses JSON from a response.""""""
        # if an encoding is already set then use the provided encoding
        if res.encoding is None:
            res.encoding = cls.determine_json_encoding(res.content[:4])
        return parse_json(res.text, *args, **kwargs)",Parses JSON from a response.,
"def xml(cls, res, *args, **kwargs):
        """"""Parses XML from a response.""""""
        return parse_xml(res.text, *args, **kwargs)",Parses XML from a response.,
"def parse_cookies(self, cookies, **kwargs):
        """"""Parses a semi-colon delimited list of cookies.

        Example: foo=bar;baz=qux
        """"""
        for name, value in _parse_keyvalue_list(cookies):
            self.cookies.set(name, value, **kwargs)","Parses a semi-colon delimited list of cookies.

        Example: foo=bar;baz=qux",
"def parse_headers(self, headers):
        """"""Parses a semi-colon delimited list of headers.

        Example: foo=bar;baz=qux
        """"""
        for name, value in _parse_keyvalue_list(headers):
            self.headers[name] = value","Parses a semi-colon delimited list of headers.

        Example: foo=bar;baz=qux",
"def parse_query_params(self, cookies, **kwargs):
        """"""Parses a semi-colon delimited list of query parameters.

        Example: foo=bar;baz=qux
        """"""
        for name, value in _parse_keyvalue_list(cookies):
            self.params[name] = value","Parses a semi-colon delimited list of query parameters.

        Example: foo=bar;baz=qux",
"def device_id(self):
        """"""
        Randomly generated deviceId.
        :return:
        """"""
        if self._device_id is None:
            self._device_id = """".join(
                random.choice(""0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"") for _ in range(50))
        return self._device_id","Randomly generated deviceId.
        :return:",
"def getMessage(self):
        """"""
        Return the message for this LogRecord.

        Return the message for this LogRecord after merging any user-supplied
        arguments with the message.
        """"""
        msg = self.msg
        if self.args:
            msg = msg.format(*self.args)
        return maybe_encode(msg)","Return the message for this LogRecord.

        Return the message for this LogRecord after merging any user-supplied
        arguments with the message.",
"def iter_http_requests(server, player):
    """"""Repeatedly accept HTTP connections on a server.

    Forever if the serving externally, or while a player is running if it is not
    empty.
    """"""

    while not player or player.running:
        try:
            yield server.open(timeout=2.5)
        except OSError:
            continue","Repeatedly accept HTTP connections on a server.

    Forever if the serving externally, or while a player is running if it is not
    empty.",
"def fetch_streams(plugin):
    """"""Fetches streams using correct parameters.""""""

    return plugin.streams(stream_types=args.stream_types,
                          sorting_excludes=args.stream_sorting_excludes)",Fetches streams using correct parameters.,
"def resolve_stream_name(streams, stream_name):
    """"""Returns the real stream name of a synonym.""""""

    if stream_name in STREAM_SYNONYMS and stream_name in streams:
        for name, stream in streams.items():
            if stream is streams[stream_name] and name not in STREAM_SYNONYMS:
                return name

    return stream_name",Returns the real stream name of a synonym.,
"def print_plugins():
    """"""Outputs a list of all plugins Streamlink has loaded.""""""

    pluginlist = list(streamlink.get_plugins().keys())
    pluginlist_formatted = "", "".join(sorted(pluginlist))

    if console.json:
        console.msg_json(pluginlist)
    else:
        console.msg(""Loaded plugins: {0}"", pluginlist_formatted)",Outputs a list of all plugins Streamlink has loaded.,
"def load_plugins(dirs):
    """"""Attempts to load plugins from a list of directories.""""""

    dirs = [os.path.expanduser(d) for d in dirs]

    for directory in dirs:
        if os.path.isdir(directory):
            streamlink.load_plugins(directory)
        else:
            log.warning(""Plugin path {0} does not exist or is not ""
                        ""a directory!"", directory)",Attempts to load plugins from a list of directories.,
"def setup_console(output):
    """"""Console setup.""""""
    global console

    # All console related operations is handled via the ConsoleOutput class
    console = ConsoleOutput(output, streamlink)
    console.json = args.json

    # Handle SIGTERM just like SIGINT
    signal.signal(signal.SIGTERM, signal.default_int_handler)",Console setup.,
"def setup_plugins(extra_plugin_dir=None):
    """"""Loads any additional plugins.""""""
    if os.path.isdir(PLUGINS_DIR):
        load_plugins([PLUGINS_DIR])

    if extra_plugin_dir:
        load_plugins(extra_plugin_dir)",Loads any additional plugins.,
"def _get_stream_id(self, text):
        """"""Try to find a stream_id""""""
        m = self._image_re.search(text)
        if m:
            return m.group(""stream_id"")",Try to find a stream_id,
"def _get_iframe(self, text):
        """"""Fallback if no stream_id was found before""""""
        m = self._iframe_re.search(text)
        if m:
            return self.session.streams(m.group(""url""))",Fallback if no stream_id was found before,
"def get_plugin_option(self, plugin, key):
        """"""Returns current value of plugin specific option.

        :param plugin: name of the plugin
        :param key: key of the option

        """"""

        if plugin in self.plugins:
            plugin = self.plugins[plugin]
            return plugin.get_option(key)","Returns current value of plugin specific option.

        :param plugin: name of the plugin
        :param key: key of the option",
"def streams(self, url, **params):
        """"""Attempts to find a plugin and extract streams from the *url*.

        *params* are passed to :func:`Plugin.streams`.

        Raises :exc:`NoPluginError` if no plugin is found.
        """"""

        plugin = self.resolve_url(url)
        return plugin.streams(**params)","Attempts to find a plugin and extract streams from the *url*.

        *params* are passed to :func:`Plugin.streams`.

        Raises :exc:`NoPluginError` if no plugin is found.",
"def length(length):
    """"""Checks value for minimum length using len().""""""
    def min_len(value):
        if not len(value) >= length:
            raise ValueError(
                ""Minimum length is {0} but value is {1}"".format(length, len(value))
            )
        return True

    return min_len",Checks value for minimum length using len().,
"def startswith(string):
    """"""Checks if the string value starts with another string.""""""
    def starts_with(value):
        validate(text, value)
        if not value.startswith(string):
            raise ValueError(""'{0}' does not start with '{1}'"".format(value, string))
        return True

    return starts_with",Checks if the string value starts with another string.,
"def endswith(string):
    """"""Checks if the string value ends with another string.""""""
    def ends_with(value):
        validate(text, value)
        if not value.endswith(string):
            raise ValueError(""'{0}' does not end with '{1}'"".format(value, string))
        return True

    return ends_with",Checks if the string value ends with another string.,
"def contains(string):
    """"""Checks if the string value contains another string.""""""
    def contains_str(value):
        validate(text, value)
        if string not in value:
            raise ValueError(""'{0}' does not contain '{1}'"".format(value, string))
        return True

    return contains_str",Checks if the string value contains another string.,
"def getattr(attr, default=None):
    """"""Get a named attribute from an object.

    When a default argument is given, it is returned when the attribute
    doesn't exist.
    """"""
    def getter(value):
        return _getattr(value, attr, default)

    return transform(getter)","Get a named attribute from an object.

    When a default argument is given, it is returned when the attribute
    doesn't exist.",
"def xml_find(xpath):
    """"""Find a XML element via xpath.""""""
    def xpath_find(value):
        validate(ET.iselement, value)
        value = value.find(xpath)
        if value is None:
            raise ValueError(""XPath '{0}' did not return an element"".format(xpath))

        return validate(ET.iselement, value)

    return transform(xpath_find)",Find a XML element via xpath.,
"def xml_findall(xpath):
    """"""Find a list of XML elements via xpath.""""""
    def xpath_findall(value):
        validate(ET.iselement, value)
        return value.findall(xpath)

    return transform(xpath_findall)",Find a list of XML elements via xpath.,
"def _find_playlist_info(response):
    """"""
    Finds playlist info (type, id) in HTTP response.

    :param response: Response object.
    :returns: Dictionary with type and id.
    """"""
    values = {}
    matches = _playlist_info_re.search(response.text)
    if matches:
        values['type'] = matches.group(1)
        values['id'] = matches.group(2)

    return values","Finds playlist info (type, id) in HTTP response.

    :param response: Response object.
    :returns: Dictionary with type and id.",
"def _get_vod_stream(self):
        """"""
        Find the VOD video url
        :return: video url
        """"""
        res = self.session.http.get(self.url)
        video_urls = self._re_vod.findall(res.text)
        if len(video_urls):
            return dict(vod=HTTPStream(self.session, video_urls[0]))","Find the VOD video url
        :return: video url",
"def _get_streams(self):
        """"""
        Find the streams for euronews
        :return:
        """"""
        match = self._url_re.match(self.url).groupdict()

        if match.get(""path"") == ""live"":
            return self._get_live_streams(match)
        else:
            return self._get_vod_stream()","Find the streams for euronews
        :return:",
"def get_stream_id(self, html):
        """"""Returns the stream_id contained in the HTML.""""""
        stream_id = stream_id_pattern.search(html)

        if not stream_id:
            self.logger.error(""Failed to extract stream_id."")

        return stream_id.group(""stream_id"")",Returns the stream_id contained in the HTML.,
"def map(self, key, func, *args, **kwargs):
        """"""Creates a key-function mapping.

        The return value from the function should be either
          - A tuple containing a name and stream
          - A iterator of tuples containing a name and stream

        Any extra arguments will be passed to the function.
        """"""
        self._map.append((key, partial(func, *args, **kwargs)))","Creates a key-function mapping.

        The return value from the function should be either
          - A tuple containing a name and stream
          - A iterator of tuples containing a name and stream

        Any extra arguments will be passed to the function.",
"def parse_timestamp(ts):
    """"""Takes ISO 8601 format(string) and converts into a utc datetime(naive)""""""
    return (
        datetime.datetime.strptime(ts[:-7], ""%Y-%m-%dT%H:%M:%S"") +
        datetime.timedelta(hours=int(ts[-5:-3]), minutes=int(ts[-2:])) *
        int(ts[-6:-5] + ""1"")
    )",Takes ISO 8601 format(string) and converts into a utc datetime(naive),
"def outputCharFormatter(c):
    """"""Show character in readable format
    """"""
    #TODO 2: allow hex only output
    if 32<c<127: return chr(c)
    elif c==10: return '\\n'
    elif c==13: return '\\r'
    elif c==32: return '"" ""'
    else: return '\\x{:02x}'.format(c)",Show character in readable format,
"def outputFormatter(s):
    """"""Show string or char.
    """"""
    result = ''
    def formatSubString(s):
        for c in s:
            if c==32: yield ' '
            else: yield outputCharFormatter(c)
    if len(result)<200: return ''.join(formatSubString(s))
    else:
        return ''.join(formatSubString(s[:100]))+'...'+ \
               ''.join(formatSubString(s[-100:]))",Show string or char.,
"def readBytes(self, n):
        """"""Read n bytes from the stream on a byte boundary.
        """"""
        if self.pos&7: raise ValueError('readBytes: need byte boundary')
        result = self.data[self.pos>>3:(self.pos>>3)+n]
        self.pos += 8*n
        return result",Read n bytes from the stream on a byte boundary.,
"def explanation(self, extra=None):
        """"""Long explanation of the value from the numeric value
        with optional extra bits
        Used by Layout.verboseRead when printing the value
        """"""
        if isinstance(self.code, WithExtra):
            return self.code.callback(self, extra)
        return self.code.callback(self)","Long explanation of the value from the numeric value
        with optional extra bits
        Used by Layout.verboseRead when printing the value",
"def decodePeek(self, data):
        """"""Find which symbol index matches the given data (from peek, as a number)
        and return the number of bits decoded.
        Can also be used to figure out length of a symbol.
        """"""
        return self.maxLength, Symbol(self, data&(1<<self.maxLength)-1)","Find which symbol index matches the given data (from peek, as a number)
        and return the number of bits decoded.
        Can also be used to figure out length of a symbol.",
"def readTuple(self, stream):
        """"""Read symbol from stream. Returns symbol, length.
        """"""
        length, symbol = self.decodePeek(stream.peek(self.maxLength))
        stream.pos += length
        return length, symbol","Read symbol from stream. Returns symbol, length.",
"def value(self, index, extra):
        """"""Override if you don't define value0 and extraTable
        """"""
        lower, upper = self.span(index)
        value = lower+(extra or 0)
        if value>upper:
            raise ValueError('value: extra out of range')
        return value",Override if you don't define value0 and extraTable,
"def span(self, index):
        """"""Give the range of possible values in a tuple
        Useful for mnemonic and explanation
        """"""
        lower = self.value0+sum(1<<x for x in self.extraTable[:index])
        upper = lower+(1<<self.extraTable[index])
        return lower, upper-1","Give the range of possible values in a tuple
        Useful for mnemonic and explanation",
"def value(self, index, extra):
        """"""Returns ('Simple', #codewords) or ('Complex', HSKIP)
        """"""
        if index==1:
            if extra>3:
                raise ValueError('value: extra out of range')
            return 'Simple', extra+1
        if extra:
            raise ValueError('value: extra out of range')
        return 'Complex', index","Returns ('Simple', #codewords) or ('Complex', HSKIP)",
"def value(self, index, extra):
        """"""Give count and value.""""""
        index = index
        if index==0: return 1, 0
        if index<=self.RLEMAX: return (1<<index)+extra, 0
        return 1, index-self.RLEMAX",Give count and value.,
"def doAction(self, w, action):
        """"""Perform the proper action
        """"""
        #set environment for the UpperCaseFirst
        U = self.upperCase1
        return eval(self.actionList[action], locals())",Perform the proper action,
"def makeHexData(self, pos):
        """"""Produce hex dump of all data containing the bits
        from pos to stream.pos
        """"""
        firstAddress = pos+7>>3
        lastAddress = self.stream.pos+7>>3
        return ''.join(map('{:02x} '.format,
            self.stream.data[firstAddress:lastAddress]))","Produce hex dump of all data containing the bits
        from pos to stream.pos",
"def patch(f):
    '''Adds method f to the Dataset class'''
    name = f.__name__
    Dataset.__hidden__[name] = f
    return f",Adds method f to the Dataset class,
"def min(self, binby=[], limits=None, shape=default_shape, selection=False, delay=False, progress=None):
        '''Shortcut for ds.min(expression, ...), see `Dataset.min`'''
        kwargs = dict(locals())
        del kwargs['self']
        kwargs['expression'] = self.expression
        return self.ds.min(**kwargs)","Shortcut for ds.min(expression, ...), see `Dataset.min`",
"def from_astropy_table(table):
    """"""Create a vaex DataFrame from an Astropy Table.""""""
    import vaex.file.other
    return vaex.file.other.DatasetAstropyTable(table=table)",Create a vaex DataFrame from an Astropy Table.,
"def from_scalars(**kwargs):
    """"""Similar to from_arrays, but convenient for a DataFrame of length 1.

    Example:

    >>> import vaex
    >>> df = vaex.from_scalars(x=1, y=2)

    :rtype: DataFrame
    """"""
    import numpy as np
    return from_arrays(**{k: np.array([v]) for k, v in kwargs.items()})","Similar to from_arrays, but convenient for a DataFrame of length 1.

    Example:

    >>> import vaex
    >>> df = vaex.from_scalars(x=1, y=2)

    :rtype: DataFrame",
"def from_csv(filename_or_buffer, copy_index=True, **kwargs):
    """"""Shortcut to read a csv file using pandas and convert to a DataFrame directly.

    :rtype: DataFrame
    """"""
    import pandas as pd
    return from_pandas(pd.read_csv(filename_or_buffer, **kwargs), copy_index=copy_index)","Shortcut to read a csv file using pandas and convert to a DataFrame directly.

    :rtype: DataFrame",
"def example(download=True):
    """"""Returns an example DataFrame which comes with vaex for testing/learning purposes.

    :rtype: DataFrame
    """"""
    from . import utils
    path = utils.get_data_file(""helmi-dezeeuw-2000-10p.hdf5"")
    if path is None and download:
        return vaex.datasets.helmi_de_zeeuw_10percent.fetch()
    return open(path) if path else None","Returns an example DataFrame which comes with vaex for testing/learning purposes.

    :rtype: DataFrame",
"def zeldovich(dim=2, N=256, n=-2.5, t=None, scale=1, seed=None):
    """"""Creates a zeldovich DataFrame.
    """"""
    import vaex.file
    return vaex.file.other.Zeldovich(dim=dim, N=N, n=n, t=t, scale=scale)",Creates a zeldovich DataFrame.,
"def concat(dfs):
    '''Concatenate a list of DataFrames.

    :rtype: DataFrame
    '''
    ds = reduce((lambda x, y: x.concat(y)), dfs)
    return ds","Concatenate a list of DataFrames.

    :rtype: DataFrame",
"def vrange(start, stop, step=1, dtype='f8'):
    """"""Creates a virtual column which is the equivalent of numpy.arange, but uses 0 memory""""""
    from .column import ColumnVirtualRange
    return ColumnVirtualRange(start, stop, step, dtype)","Creates a virtual column which is the equivalent of numpy.arange, but uses 0 memory",
"def bounded_by_sigmas(self, sigmas=3, square=False):
        """"""Returns a bounded subspace (SubspaceBounded) with limits given by Subspace.limits_sigma()

        :rtype: SubspaceBounded
        """"""
        bounds = self.limits_sigma(sigmas=sigmas, square=square)
        return SubspaceBounded(self, bounds)","Returns a bounded subspace (SubspaceBounded) with limits given by Subspace.limits_sigma()

        :rtype: SubspaceBounded",
"def clear(self, event):
        """"""clear the cursor""""""
        if self.useblit:
            self.background = (
                self.canvas.copy_from_bbox(self.canvas.figure.bbox))
        for line in self.vlines + self.hlines:
            line.set_visible(False)
        self.ellipse.set_visible(False)",clear the cursor,
"def write_to(f, mode):
    """"""Flexible writing, where f can be a filename or f object, if filename, closed after writing""""""
    if hasattr(f, 'write'):
        yield f
    else:
        f = open(f, mode)
        yield f
        f.close()","Flexible writing, where f can be a filename or f object, if filename, closed after writing",
"def dtypes(self):
        """"""Gives a Pandas series object containing all numpy dtypes of all columns (except hidden).""""""
        from pandas import Series
        return Series({column_name:self.dtype(column_name) for column_name in self.get_column_names()})",Gives a Pandas series object containing all numpy dtypes of all columns (except hidden).,
"def is_masked(self, column):
        '''Return if a column is a masked (numpy.ma) column.'''
        column = _ensure_string_from_expression(column)
        if column in self.columns:
            return np.ma.isMaskedArray(self.columns[column])
        return False",Return if a column is a masked (numpy.ma) column.,
"def state_load(self, f, use_active_range=False):
        """"""Load a state previously stored by :meth:`DataFrame.state_store`, see also :meth:`DataFrame.state_set`.""""""
        state = vaex.utils.read_json_or_yaml(f)
        self.state_set(state, use_active_range=use_active_range)","Load a state previously stored by :meth:`DataFrame.state_store`, see also :meth:`DataFrame.state_set`.",
"def _evaluate_selection_mask(self, name=""default"", i1=None, i2=None, selection=None, cache=False):
        """"""Internal use, ignores the filter""""""
        i1 = i1 or 0
        i2 = i2 or len(self)
        scope = scopes._BlockScopeSelection(self, i1, i2, selection, cache=cache)
        return scope.evaluate(name)","Internal use, ignores the filter",
"def validate_expression(self, expression):
        """"""Validate an expression (may throw Exceptions)""""""
        # return self.evaluate(expression, 0, 2)
        vars = set(self.get_column_names()) | set(self.variables.keys())
        funcs = set(expression_namespace.keys())
        return vaex.expresso.validate_expression(expression, vars, funcs)",Validate an expression (may throw Exceptions),
"def delete_virtual_column(self, name):
        """"""Deletes a virtual column from a DataFrame.""""""
        del self.virtual_columns[name]
        self.signal_column_changed.emit(self, name, ""delete"")",Deletes a virtual column from a DataFrame.,
"def delete_variable(self, name):
        """"""Deletes a variable from a DataFrame.""""""
        del self.variables[name]
        self.signal_variable_changed.emit(self, name, ""delete"")",Deletes a variable from a DataFrame.,
"def tail(self, n=10):
        """"""Return a shallow copy a DataFrame with the last n rows.""""""
        N = len(self)
        # self.cat(i1=max(0, N-n), i2=min(len(self), N))
        return self[max(0, N - n):min(len(self), N)]",Return a shallow copy a DataFrame with the last n rows.,
"def head_and_tail_print(self, n=5):
        """"""Display the first and last n elements of a DataFrame.""""""
        from IPython import display
        display.display(display.HTML(self._head_and_tail_table(n)))",Display the first and last n elements of a DataFrame.,
"def set_current_row(self, value):
        """"""Set the current row, and emit the signal signal_pick.""""""
        if (value is not None) and ((value < 0) or (value >= len(self))):
            raise IndexError(""index %d out of range [0,%d]"" % (value, len(self)))
        self._current_row = value
        self.signal_pick.emit(self, value)","Set the current row, and emit the signal signal_pick.",
"def get_selection(self, name=""default""):
        """"""Get the current selection object (mostly for internal use atm).""""""
        name = _normalize_selection_name(name)
        selection_history = self.selection_histories[name]
        index = self.selection_history_indices[name]
        if index == -1:
            return None
        else:
            return selection_history[index]",Get the current selection object (mostly for internal use atm).,
"def selection_can_redo(self, name=""default""):
        """"""Can selection name be redone?""""""
        return (self.selection_history_indices[name] + 1) < len(self.selection_histories[name])",Can selection name be redone?,
"def select_inverse(self, name=""default"", executor=None):
        """"""Invert the selection, i.e. what is selected will not be, and vice versa

        :param str name:
        :param executor:
        :return:
        """"""

        def create(current):
            return selections.SelectionInvert(current)
        self._selection(create, name, executor=executor)","Invert the selection, i.e. what is selected will not be, and vice versa

        :param str name:
        :param executor:
        :return:",
"def set_selection(self, selection, name=""default"", executor=None):
        """"""Sets the selection object

        :param selection: Selection object
        :param name: selection 'slot'
        :param executor:
        :return:
        """"""
        def create(current):
            return selection
        self._selection(create, name, executor=executor, execute_fully=True)","Sets the selection object

        :param selection: Selection object
        :param name: selection 'slot'
        :param executor:
        :return:",
"def _hide_column(self, column):
        '''Hides a column by prefixing the name with \'__\''''
        column = _ensure_string_from_expression(column)
        new_name = self._find_valid_name('__' + column)
        self._rename(column, new_name)",Hides a column by prefixing the name with \'__\,
"def _find_valid_name(self, initial_name):
        '''Finds a non-colliding name by optional postfixing'''
        return vaex.utils.find_valid_name(initial_name, used=self.get_column_names(hidden=True))",Finds a non-colliding name by optional postfixing,
"def _graphviz(self, dot=None):
        """"""Return a graphviz.Digraph object with a graph of all virtual columns""""""
        from graphviz import Digraph
        dot = dot or Digraph(comment='whole dataframe')
        root_nodes = self._root_nodes()
        for column in root_nodes:
            self[column]._graphviz(dot=dot)
        return dot",Return a graphviz.Digraph object with a graph of all virtual columns,
"def patch(f):
    '''Adds method f to the DataFrame class'''
    name = f.__name__
    setattr(DataFrame, name, f)
    return f",Adds method f to the DataFrame class,
"def str_join(x, sep):
    """"""Same as find (difference with pandas is that it does not raise a ValueError)""""""
    sl = _to_string_list_sequence(x).join(sep)
    return column.ColumnStringArrow(sl.bytes, sl.indices, sl.length, sl.offset, string_sequence=sl)",Same as find (difference with pandas is that it does not raise a ValueError),
"def format(x, format):
    """"""Uses http://www.cplusplus.com/reference/string/to_string/ for formatting""""""
    # don't change the dtype, otherwise for each block the dtype may be different (string length)
    sl = vaex.strings.format(x, format)
    return column.ColumnStringArrow(sl.bytes, sl.indices, sl.length, sl.offset, string_sequence=sl)",Uses http://www.cplusplus.com/reference/string/to_string/ for formatting,
"def readff(s,format):
    """"""
    Fixed-format reader
    Pass in a single line string (s) and a format list, 
    which needs to be a python list of string lengths 
    """"""

    F = numpy.array([0]+format).cumsum()
    bothF = zip(F[:-1],F[1:])
    strarr = [s[l:u] for l,u in bothF]

    return strarr","Fixed-format reader
    Pass in a single line string (s) and a format list, 
    which needs to be a python list of string lengths",
"def as_recarray(self):
        """""" Convert into numpy recordarray """"""
        dtype = [(k,v.dtype) for k,v in self.__dict__.iteritems()]
        R = numpy.recarray(len(self.__dict__[k]),dtype=dtype)
        for key in self.__dict__:
            R[key] = self.__dict__[key]
        return R",Convert into numpy recordarray,
"def __cqt_response(y, n_fft, hop_length, fft_basis, mode):
    '''Compute the filter response with a target STFT hop.'''

    # Compute the STFT matrix
    D = stft(y, n_fft=n_fft, hop_length=hop_length,
             window='ones',
             pad_mode=mode)

    # And filter response energy
    return fft_basis.dot(D)",Compute the filter response with a target STFT hop.,
"def __envelope(x, hop):
    '''Compute the max-envelope of x at a stride/frame length of h'''
    return util.frame(x, hop_length=hop, frame_length=hop).max(axis=0)",Compute the max-envelope of x at a stride/frame length of h,
"def __set_current_image(ax, img):
    '''Helper to set the current image in pyplot mode.

    If the provided `ax` is not `None`, then we assume that the user is using the object API.
    In this case, the pyplot current image is not set.
    '''

    if ax is None:
        import matplotlib.pyplot as plt
        plt.sci(img)","Helper to set the current image in pyplot mode.

    If the provided `ax` is not `None`, then we assume that the user is using the object API.
    In this case, the pyplot current image is not set.",
"def __check_axes(axes):
    '''Check if ""axes"" is an instance of an axis object. If not, use `gca`.'''
    if axes is None:
        import matplotlib.pyplot as plt
        axes = plt.gca()
    elif not isinstance(axes, Axes):
        raise ValueError(""`axes` must be an instance of matplotlib.axes.Axes. ""
                         ""Found type(axes)={}"".format(type(axes)))
    return axes","Check if ""axes"" is an instance of an axis object. If not, use `gca`.",
"def __coord_mel_hz(n, fmin=0, fmax=11025.0, **_kwargs):
    '''Get the frequencies for Mel bins'''

    if fmin is None:
        fmin = 0
    if fmax is None:
        fmax = 11025.0

    basis = core.mel_frequencies(n, fmin=fmin, fmax=fmax)
    basis[1:] -= 0.5 * np.diff(basis)
    basis = np.append(np.maximum(0, basis), [fmax])
    return basis",Get the frequencies for Mel bins,
"def __coord_cqt_hz(n, fmin=None, bins_per_octave=12, **_kwargs):
    '''Get CQT bin frequencies'''
    if fmin is None:
        fmin = core.note_to_hz('C1')

    # we drop by half a bin so that CQT bins are centered vertically
    return core.cqt_frequencies(n+1,
                                fmin=fmin / 2.0**(0.5/bins_per_octave),
                                bins_per_octave=bins_per_octave)",Get CQT bin frequencies,
"def __coord_chroma(n, bins_per_octave=12, **_kwargs):
    '''Get chroma bin numbers'''
    return np.linspace(0, (12.0 * n) / bins_per_octave, num=n+1, endpoint=True)",Get chroma bin numbers,
"def __coord_tempo(n, sr=22050, hop_length=512, **_kwargs):
    '''Tempo coordinates'''
    basis = core.tempo_frequencies(n+2, sr=sr, hop_length=hop_length)[1:]
    edges = np.arange(1, n+2)
    return basis * (edges + 0.5) / edges",Tempo coordinates,
"def __coord_time(n, sr=22050, hop_length=512, **_kwargs):
    '''Get time coordinates from frames'''
    return core.frames_to_time(np.arange(n+1), sr=sr, hop_length=hop_length)",Get time coordinates from frames,
"def __window_ss_fill(x, win_sq, n_frames, hop_length):  # pragma: no cover
    '''Helper function for window sum-square calculation.'''

    n = len(x)
    n_fft = len(win_sq)
    for i in range(n_frames):
        sample = i * hop_length
        x[sample:min(n, sample + n_fft)] += win_sq[:max(0, min(n_fft, n - sample))]",Helper function for window sum-square calculation.,
"def __match_interval_overlaps(query, intervals_to, candidates):  # pragma: no cover
    '''Find the best Jaccard match from query to candidates'''

    best_score = -1
    best_idx = -1
    for idx in candidates:
        score = __jaccard(query, intervals_to[idx])

        if score > best_score:
            best_score, best_idx = score, idx
    return best_idx",Find the best Jaccard match from query to candidates,
"def __get_files(dir_name, extensions):
    '''Helper function to get files in a single directory'''

    # Expand out the directory
    dir_name = os.path.abspath(os.path.expanduser(dir_name))

    myfiles = set()

    for sub_ext in extensions:
        globstr = os.path.join(dir_name, '*' + os.path.extsep + sub_ext)
        myfiles |= set(glob.glob(globstr))

    return myfiles",Helper function to get files in a single directory,
"def __normalize_onsets(onsets):
    '''Maps onset strength function into the range [0, 1]'''

    norm = onsets.std(ddof=1)
    if norm > 0:
        onsets = onsets / norm
    return onsets","Maps onset strength function into the range [0, 1]",
"def __beat_local_score(onset_envelope, period):
    '''Construct the local score for an onset envlope and given period'''

    window = np.exp(-0.5 * (np.arange(-period, period+1)*32.0/period)**2)
    return scipy.signal.convolve(__normalize_onsets(onset_envelope),
                                 window,
                                 'same')",Construct the local score for an onset envlope and given period,
"def __last_beat(cumscore):
    """"""Get the last beat from the cumulative score array""""""

    maxes = util.localmax(cumscore)
    med_score = np.median(cumscore[np.argwhere(maxes)])

    # The last of these is the last beat (since score generally increases)
    return np.argwhere((cumscore * maxes * 2 > med_score)).max()",Get the last beat from the cumulative score array,
"def _scale_size(size, scale):
    """"""Rescale a size by a ratio.

    Args:
        size (tuple): w, h.
        scale (float): Scaling factor.

    Returns:
        tuple[int]: scaled size.
    """"""
    w, h = size
    return int(w * float(scale) + 0.5), int(h * float(scale) + 0.5)","Rescale a size by a ratio.

    Args:
        size (tuple): w, h.
        scale (float): Scaling factor.

    Returns:
        tuple[int]: scaled size.",
"def imshow(img, win_name='', wait_time=0):
    """"""Show an image.

    Args:
        img (str or ndarray): The image to be displayed.
        win_name (str): The window name.
        wait_time (int): Value of waitKey param.
    """"""
    cv2.imshow(win_name, imread(img))
    cv2.waitKey(wait_time)","Show an image.

    Args:
        img (str or ndarray): The image to be displayed.
        win_name (str): The window name.
        wait_time (int): Value of waitKey param.",
"def weights_to_cpu(state_dict):
    """"""Copy a model state_dict to cpu.

    Args:
        state_dict (OrderedDict): Model weights on GPU.

    Returns:
        OrderedDict: Model weights on GPU.
    """"""
    state_dict_cpu = OrderedDict()
    for key, val in state_dict.items():
        state_dict_cpu[key] = val.cpu()
    return state_dict_cpu","Copy a model state_dict to cpu.

    Args:
        state_dict (OrderedDict): Model weights on GPU.

    Returns:
        OrderedDict: Model weights on GPU.",
"def current_lr(self):
        """"""Get current learning rates.

        Returns:
            list: Current learning rate of all param groups.
        """"""
        if self.optimizer is None:
            raise RuntimeError(
                'lr is not applicable because optimizer does not exist.')
        return [group['lr'] for group in self.optimizer.param_groups]","Get current learning rates.

        Returns:
            list: Current learning rate of all param groups.",
"def conv3x3(in_planes, out_planes, dilation=1):
    ""3x3 convolution with padding""
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        padding=dilation,
        dilation=dilation)",3x3 convolution with padding,
"def gray2bgr(img):
    """"""Convert a grayscale image to BGR image.

    Args:
        img (ndarray or str): The input image.

    Returns:
        ndarray: The converted BGR image.
    """"""
    img = img[..., None] if img.ndim == 2 else img
    out_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    return out_img","Convert a grayscale image to BGR image.

    Args:
        img (ndarray or str): The input image.

    Returns:
        ndarray: The converted BGR image.",
"def average(self, n=0):
        """"""Average latest n values or all values""""""
        assert n >= 0
        for key in self.val_history:
            values = np.array(self.val_history[key][-n:])
            nums = np.array(self.n_history[key][-n:])
            avg = np.sum(values * nums) / np.sum(nums)
            self.output[key] = avg
        self.ready = True",Average latest n values or all values,
"def start(self):
        """"""Start the timer.""""""
        if not self._is_running:
            self._t_start = time()
            self._is_running = True
        self._t_last = time()",Start the timer.,
"def since_start(self):
        """"""Total time since the timer is started.

        Returns (float): Time in seconds.
        """"""
        if not self._is_running:
            raise TimerError('timer is not running')
        self._t_last = time()
        return self._t_last - self._t_start","Total time since the timer is started.

        Returns (float): Time in seconds.",
"def since_last_check(self):
        """"""Time since the last checking.

        Either :func:`since_start` or :func:`since_last_check` is a checking
        operation.

        Returns (float): Time in seconds.
        """"""
        if not self._is_running:
            raise TimerError('timer is not running')
        dur = time() - self._t_last
        self._t_last = time()
        return dur","Time since the last checking.

        Either :func:`since_start` or :func:`since_last_check` is a checking
        operation.

        Returns (float): Time in seconds.",
"def flowshow(flow, win_name='', wait_time=0):
    """"""Show optical flow.

    Args:
        flow (ndarray or str): The optical flow to be displayed.
        win_name (str): The window name.
        wait_time (int): Value of waitKey param.
    """"""
    flow = flowread(flow)
    flow_img = flow2rgb(flow)
    imshow(rgb2bgr(flow_img), win_name, wait_time)","Show optical flow.

    Args:
        flow (ndarray or str): The optical flow to be displayed.
        win_name (str): The window name.
        wait_time (int): Value of waitKey param.",
"def request(self, *args, **kwargs):
        """"""
        Define a Decorate to be called before a request.
        eg: @middleware.request
        """"""
        middleware = args[0]

        @wraps(middleware)
        def register_middleware(*args, **kwargs):
            self.request_middleware.append(middleware)
            return middleware

        return register_middleware()","Define a Decorate to be called before a request.
        eg: @middleware.request",
"def response(self, *args, **kwargs):
        """"""
        Define a Decorate to be called after a response.
        eg: @middleware.response
        """"""
        middleware = args[0]

        @wraps(middleware)
        def register_middleware(*args, **kwargs):
            self.response_middleware.appendleft(middleware)
            return middleware

        return register_middleware()","Define a Decorate to be called after a response.
        eg: @middleware.response",
"async def json(self,
                   *,
                   encoding: str = None,
                   loads: JSONDecoder = DEFAULT_JSON_DECODER,
                   content_type: Optional[str] = 'application/json') -> Any:
        """"""Read and decodes JSON response.""""""
        return await self._aws_json(
            encoding=encoding, loads=loads, content_type=content_type)",Read and decodes JSON response.,
"async def text(self,
                   *,
                   encoding: Optional[str] = None,
                   errors: str = 'strict') -> str:
        """"""Read response payload and decode.""""""
        return await self._aws_text(encoding=encoding, errors=errors)",Read response payload and decode.,
"async def stop(self, _signal):
        """"""
        Finish all running tasks, cancel remaining tasks, then stop loop.
        :param _signal:
        :return:
        """"""
        self.logger.info(f'Stopping spider: {self.name}')
        await self._cancel_tasks()
        self.loop.stop()","Finish all running tasks, cancel remaining tasks, then stop loop.
        :param _signal:
        :return:",
"def get_db(self, db='test'):
        """"""
        Get a db instance
        :param db: database name
        :return: the motor db instance
        """"""
        if db not in self._db:
            self._db[db] = self.client(db)[db]

        return self._db[db]","Get a db instance
        :param db: database name
        :return: the motor db instance",
"async def authenticate_request(self, request: Activity, auth_header: str):
        """"""
        Allows for the overriding of authentication in unit tests.
        :param request:
        :param auth_header:
        :return:
        """"""
        await JwtTokenValidation.authenticate_request(request, auth_header, self._credential_provider)","Allows for the overriding of authentication in unit tests.
        :param request:
        :param auth_header:
        :return:",
"def create_connector_client(self, service_url: str) -> ConnectorClient:
        """"""
        Allows for mocking of the connector client in unit tests.
        :param service_url:
        :return:
        """"""
        client = ConnectorClient(self._credentials, base_url=service_url)
        client.config.add_user_agent(USER_AGENT)
        return client","Allows for mocking of the connector client in unit tests.
        :param service_url:
        :return:",
"def wheel_dist_name(self):
        """"""Return distribution full name with - replaced with _""""""
        return '-'.join((safer_name(self.distribution.get_name()),
                         safer_version(self.distribution.get_version())))",Return distribution full name with - replaced with _,
"def get_archive_basename(self):
        """"""Return archive name without extension""""""

        impl_tag, abi_tag, plat_tag = self.get_tag()

        archive_basename = ""%s-%s-%s-%s"" % (
            self.wheel_dist_name,
            impl_tag,
            abi_tag,
            plat_tag)
        return archive_basename",Return archive name without extension,
"def telemetry_client(self, value: BotTelemetryClient) -> None:
        """"""
        Sets the telemetry client for logging events.
        """"""
        if value is None:
            self._telemetry_client = NullTelemetryClient()
        else:
            self._telemetry_client = value",Sets the telemetry client for logging events.,
"def stream_download_async(self, response, user_callback):
        """"""Async Generator for streaming request body data.
        :param response: The initial response
        :param user_callback: Custom callback for monitoring progress.
        """"""
        block = self.config.connection.data_block_size
        return StreamDownloadGenerator(response, user_callback, block)","Async Generator for streaming request body data.
        :param response: The initial response
        :param user_callback: Custom callback for monitoring progress.",
"def __create_db_and_container(self):
        """"""Call the get or create methods.""""""
        db_id = self.config.database
        container_name = self.config.container
        self.db = self.__get_or_create_database(self.client, db_id)
        self.container = self.__get_or_create_container(
            self.client, container_name
            )",Call the get or create methods.,
"def activity(self, value):
        """"""
        Used to set TurnContext._activity when a context object is created. Only takes instances of Activities.
        :param value:
        :return:
        """"""
        if not isinstance(value, Activity):
            raise TypeError('TurnContext: cannot set `activity` to a type other than Activity.')
        else:
            self._activity = value","Used to set TurnContext._activity when a context object is created. Only takes instances of Activities.
        :param value:
        :return:",
"def has(self, key: str) -> bool:
        """"""
        Returns True is set() has been called for a key. The cached value may be of type 'None'.
        :param key:
        :return:
        """"""
        if key in self._services:
            return True
        return False","Returns True is set() has been called for a key. The cached value may be of type 'None'.
        :param key:
        :return:",
"def set(self, key: str, value: object) -> None:
        """"""
        Caches a value for the lifetime of the current turn.
        :param key:
        :param value:
        :return:
        """"""
        if not key or not isinstance(key, str):
            raise KeyError('""key"" must be a valid string.')

        self._services[key] = value","Caches a value for the lifetime of the current turn.
        :param key:
        :param value:
        :return:",
"async def update_activity(self, activity: Activity):
        """"""
        Replaces an existing activity.
        :param activity:
        :return:
        """"""
        return await self._emit(self._on_update_activity, activity, self.adapter.update_activity(self, activity))","Replaces an existing activity.
        :param activity:
        :return:",
"def add_step(self, step):
        """"""
        Adds a new step to the waterfall.
        :param step: Step to add
           
        :return: Waterfall dialog for fluent calls to `add_step()`.
        """"""
        if not step:
            raise TypeError('WaterfallDialog.add_step(): step cannot be None.')

        self._steps.append(step)
        return self","Adds a new step to the waterfall.
        :param step: Step to add
           
        :return: Waterfall dialog for fluent calls to `add_step()`.",
"def get_step_name(self, index: int) -> str:
        """"""
        Give the waterfall step a unique name
        """"""
        step_name = self._steps[index].__qualname__

        if not step_name or "">"" in step_name :
            step_name = f""Step{index + 1}of{len(self._steps)}""

        return step_name",Give the waterfall step a unique name,
"def calculate_change_hash(item: StoreItem) -> str:
    """"""
    Utility function to calculate a change hash for a `StoreItem`.
    :param item:
    :return:
    """"""
    cpy = copy(item)
    if cpy.e_tag is not None:
        del cpy.e_tag
    return str(cpy)","Utility function to calculate a change hash for a `StoreItem`.
    :param item:
    :return:",
"def c_if(self, classical, val):
        """"""Add classical control on register classical and value val.""""""
        if not isinstance(classical, ClassicalRegister):
            raise QiskitError(""c_if must be used with a classical register"")
        if val < 0:
            raise QiskitError(""control value should be non-negative"")
        self.control = (classical, val)
        return self",Add classical control on register classical and value val.,
"def _qasmif(self, string):
        """"""Print an if statement if needed.""""""
        if self.control is None:
            return string
        return ""if(%s==%d) "" % (self.control[0].name, self.control[1]) + string",Print an if statement if needed.,
"def passes(self):
        """"""
        Returns a list structure of the appended passes and its options.

        Returns (list): The appended passes.
        """"""
        ret = []
        for pass_ in self.working_list:
            ret.append(pass_.dump_passes())
        return ret","Returns a list structure of the appended passes and its options.

        Returns (list): The appended passes.",
"def u_base(self, theta, phi, lam, q):
    """"""Apply U to q.""""""
    return self.append(UBase(theta, phi, lam), [q], [])",Apply U to q.,
"def exp_fit_fun(x, a, tau, c):
    """"""Function used to fit the exponential decay.""""""
    # pylint: disable=invalid-name
    return a * np.exp(-x / tau) + c",Function used to fit the exponential decay.,
"def osc_fit_fun(x, a, tau, f, phi, c):
    """"""Function used to fit the decay cosine.""""""
    # pylint: disable=invalid-name
    return a * np.exp(-x / tau) * np.cos(2 * np.pi * f * x + phi) + c",Function used to fit the decay cosine.,
"def _trim(image):
    """"""Trim a PIL image and remove white space.""""""
    background = PIL.Image.new(image.mode, image.size, image.getpixel((0, 0)))
    diff = PIL.ImageChops.difference(image, background)
    diff = PIL.ImageChops.add(diff, diff, 2.0, -100)
    bbox = diff.getbbox()
    if bbox:
        image = image.crop(bbox)
    return image",Trim a PIL image and remove white space.,
"def conjugate(self):
        """"""Return the conjugate of the QuantumChannel.""""""
        kraus_l, kraus_r = self._data
        kraus_l = [k.conj() for k in kraus_l]
        if kraus_r is not None:
            kraus_r = [k.conj() for k in kraus_r]
        return Kraus((kraus_l, kraus_r), self.input_dims(), self.output_dims())",Return the conjugate of the QuantumChannel.,
"def transpose(self):
        """"""Return the transpose of the QuantumChannel.""""""
        kraus_l, kraus_r = self._data
        kraus_l = [k.T for k in kraus_l]
        if kraus_r is not None:
            kraus_r = [k.T for k in kraus_r]
        return Kraus((kraus_l, kraus_r),
                     input_dims=self.output_dims(),
                     output_dims=self.input_dims())",Return the transpose of the QuantumChannel.,
"def real(self, nested_scope=None):
        """"""Return the correspond floating point number.""""""
        operation = self.children[0].operation()
        lhs = self.children[1].real(nested_scope)
        rhs = self.children[2].real(nested_scope)
        return operation(lhs, rhs)",Return the correspond floating point number.,
"def sym(self, nested_scope=None):
        """"""Return the correspond symbolic number.""""""
        operation = self.children[0].operation()
        lhs = self.children[1].sym(nested_scope)
        rhs = self.children[2].sym(nested_scope)
        return operation(lhs, rhs)",Return the correspond symbolic number.,
"def _process_if(self, node):
        """"""Process an if node.""""""
        creg_name = node.children[0].name
        creg = self.dag.cregs[creg_name]
        cval = node.children[1].value
        self.condition = (creg, cval)
        self._process_node(node.children[2])
        self.condition = None",Process an if node.,
"def qasm(self, prec=15):
        """"""Return the corresponding OPENQASM string.""""""
        return ""measure "" + self.children[0].qasm(prec) + "" -> "" + \
               self.children[1].qasm(prec) + "";""",Return the corresponding OPENQASM string.,
"def ch_duration(self, *channels: List[Channel]) -> int:
        """"""Return duration of supplied channels.

        Args:
            *channels: Supplied channels
        """"""
        return self.timeslots.ch_duration(*channels)","Return duration of supplied channels.

        Args:
            *channels: Supplied channels",
"def ch_start_time(self, *channels: List[Channel]) -> int:
        """"""Return minimum start time for supplied channels.

        Args:
            *channels: Supplied channels
        """"""
        return self.timeslots.ch_start_time(*channels)","Return minimum start time for supplied channels.

        Args:
            *channels: Supplied channels",
"def ch_stop_time(self, *channels: List[Channel]) -> int:
        """"""Return maximum start time for supplied channels.

        Args:
            *channels: Supplied channels
        """"""
        return self.timeslots.ch_stop_time(*channels)","Return maximum start time for supplied channels.

        Args:
            *channels: Supplied channels",
"def to_string(self, indent):
        """"""Print with indent.""""""
        ind = indent * ' '
        print(ind, 'indexed_id', self.name, self.index)",Print with indent.,
"def _validate(instance):
        """"""Validate the internal representation of the instance.""""""
        try:
            _ = instance.schema.validate(instance.to_dict())
        except ValidationError as ex:
            raise ModelValidationError(
                ex.messages, ex.field_names, ex.fields, ex.data, **ex.kwargs)",Validate the internal representation of the instance.,
"def qft(circ, q, n):
    """"""n-qubit QFT on q in circ.""""""
    for j in range(n):
        for k in range(j):
            circ.cu1(math.pi / float(2**(j - k)), q[j], q[k])
        circ.h(q[j])",n-qubit QFT on q in circ.,
"def random_unitary_matrix(dim, seed=None):
    """"""Deprecated in 0.8+
    """"""
    warnings.warn('The random_unitary_matrix() function in qiskit.tools.qi has been '
                  'deprecated and will be removed in the future. Instead use '
                  'the function in qiskit.quantum_info.random',
                  DeprecationWarning)
    return random.random_unitary(dim, seed).data",Deprecated in 0.8+,
"def entropy(state):
    """"""
    Compute the von-Neumann entropy of a quantum state.

    Args:
        state (array_like): a density matrix or state vector.

    Returns:
        float: The von-Neumann entropy S(rho).
    """"""

    rho = np.array(state)
    if rho.ndim == 1:
        return 0
    evals = np.maximum(np.linalg.eigvalsh(state), 0.)
    return shannon_entropy(evals, base=np.e)","Compute the von-Neumann entropy of a quantum state.

    Args:
        state (array_like): a density matrix or state vector.

    Returns:
        float: The von-Neumann entropy S(rho).",
"def __eof_qubit(rho):
    """"""
    Compute the Entanglement of Formation of a 2-qubit density matrix.

    Args:
        rho ((array_like): (4,4) array_like, input density matrix.

    Returns:
        float: The entanglement of formation.
    """"""
    c = concurrence(rho)
    c = 0.5 + 0.5 * np.sqrt(1 - c * c)
    return shannon_entropy([c, 1 - c])","Compute the Entanglement of Formation of a 2-qubit density matrix.

    Args:
        rho ((array_like): (4,4) array_like, input density matrix.

    Returns:
        float: The entanglement of formation.",
"def flatten(schedule: ScheduleComponent, name: str = None) -> Schedule:
    """"""Create a flattened schedule.

    Args:
        schedule: Schedules to flatten
        name: Name of the new schedule. Defaults to first element of `schedules`
    """"""
    if name is None:
        name = schedule.name

    return Schedule(*schedule.instructions, name=name)","Create a flattened schedule.

    Args:
        schedule: Schedules to flatten
        name: Name of the new schedule. Defaults to first element of `schedules`",
"def shift(schedule: ScheduleComponent, time: int, name: str = None) -> Schedule:
    """"""Return schedule shifted by `time`.

    Args:
        schedule: The schedule to shift
        time: The time to shift by
        name: Name of shifted schedule. Defaults to name of `schedule`
    """"""
    if name is None:
        name = schedule.name
    return union((time, schedule), name=name)","Return schedule shifted by `time`.

    Args:
        schedule: The schedule to shift
        time: The time to shift by
        name: Name of shifted schedule. Defaults to name of `schedule`",
"def u3(self, theta, phi, lam, q):
    """"""Apply u3 to q.""""""
    return self.append(U3Gate(theta, phi, lam), [q], [])",Apply u3 to q.,
"def status(self):
        """"""Return backend status.

        Returns:
            BackendStatus: the status of the backend.
        """"""
        return BackendStatus(backend_name=self.name(),
                             backend_version=__version__,
                             operational=True,
                             pending_jobs=0,
                             status_msg='')","Return backend status.

        Returns:
            BackendStatus: the status of the backend.",
"def start(self, iterations):
        """"""Start the progress bar.

        Parameters:
            iterations (int): Number of iterations.
        """"""
        self.touched = True
        self.iter = int(iterations)
        self.t_start = time.time()","Start the progress bar.

        Parameters:
            iterations (int): Number of iterations.",
"def assemble(self):
        """"""Assemble a QasmQobjInstruction""""""
        instruction = super().assemble()
        if self.label:
            instruction.label = self.label
        return instruction",Assemble a QasmQobjInstruction,
"def is_square_matrix(mat):
    """"""Test if an array is a square matrix.""""""
    mat = np.array(mat)
    if mat.ndim != 2:
        return False
    shape = mat.shape
    return shape[0] == shape[1]",Test if an array is a square matrix.,
"def is_diagonal_matrix(mat, rtol=RTOL_DEFAULT, atol=ATOL_DEFAULT):
    """"""Test if an array is a diagonal matrix""""""
    if atol is None:
        atol = ATOL_DEFAULT
    if rtol is None:
        rtol = RTOL_DEFAULT
    mat = np.array(mat)
    if mat.ndim != 2:
        return False
    return np.allclose(mat, np.diag(np.diagonal(mat)), rtol=rtol, atol=atol)",Test if an array is a diagonal matrix,
"def is_symmetric_matrix(op, rtol=RTOL_DEFAULT, atol=ATOL_DEFAULT):
    """"""Test if an array is a symmetrix matrix""""""
    if atol is None:
        atol = ATOL_DEFAULT
    if rtol is None:
        rtol = RTOL_DEFAULT
    mat = np.array(op)
    if mat.ndim != 2:
        return False
    return np.allclose(mat, mat.T, rtol=rtol, atol=atol)",Test if an array is a symmetrix matrix,
"def is_hermitian_matrix(mat, rtol=RTOL_DEFAULT, atol=ATOL_DEFAULT):
    """"""Test if an array is a Hermitian matrix""""""
    if atol is None:
        atol = ATOL_DEFAULT
    if rtol is None:
        rtol = RTOL_DEFAULT
    mat = np.array(mat)
    if mat.ndim != 2:
        return False
    return np.allclose(mat, np.conj(mat.T), rtol=rtol, atol=atol)",Test if an array is a Hermitian matrix,
"def _stinespring_to_operator(data, input_dim, output_dim):
    """"""Transform Stinespring representation to Operator representation.""""""
    trace_dim = data[0].shape[0] // output_dim
    if data[1] is not None or trace_dim != 1:
        raise QiskitError(
            'Channel cannot be converted to Operator representation')
    return data[0]",Transform Stinespring representation to Operator representation.,
"def _superop_to_choi(data, input_dim, output_dim):
    """"""Transform SuperOp representation to Choi representation.""""""
    shape = (output_dim, output_dim, input_dim, input_dim)
    return _reshuffle(data, shape)",Transform SuperOp representation to Choi representation.,
"def _choi_to_superop(data, input_dim, output_dim):
    """"""Transform Choi to SuperOp representation.""""""
    shape = (input_dim, output_dim, input_dim, output_dim)
    return _reshuffle(data, shape)",Transform Choi to SuperOp representation.,
"def _kraus_to_superop(data, input_dim, output_dim):
    """"""Transform Kraus representation to SuperOp representation.""""""
    kraus_l, kraus_r = data
    superop = 0
    if kraus_r is None:
        for i in kraus_l:
            superop += np.kron(np.conj(i), i)
    else:
        for i, j in zip(kraus_l, kraus_r):
            superop += np.kron(np.conj(j), i)
    return superop",Transform Kraus representation to SuperOp representation.,
"def _chi_to_choi(data, input_dim, output_dim):
    """"""Transform Chi representation to a Choi representation.""""""
    num_qubits = int(np.log2(input_dim))
    return _transform_from_pauli(data, num_qubits)",Transform Chi representation to a Choi representation.,
"def _choi_to_chi(data, input_dim, output_dim):
    """"""Transform Choi representation to the Chi representation.""""""
    num_qubits = int(np.log2(input_dim))
    return _transform_to_pauli(data, num_qubits)",Transform Choi representation to the Chi representation.,
"def _reshuffle(mat, shape):
    """"""Reshuffle the indicies of a bipartite matrix A[ij,kl] -> A[lj,ki].""""""
    return np.reshape(
        np.transpose(np.reshape(mat, shape), (3, 1, 2, 0)),
        (shape[3] * shape[1], shape[0] * shape[2]))","Reshuffle the indicies of a bipartite matrix A[ij,kl] -> A[lj,ki].",
"def _hide_tick_lines_and_labels(axis):
    """"""
    Set visible property of ticklines and ticklabels of an axis to False
    """"""
    for item in axis.get_ticklines() + axis.get_ticklabels():
        item.set_visible(False)",Set visible property of ticklines and ticklabels of an axis to False,
"def clear(self):
        """"""Resets Bloch sphere data sets to empty.
        """"""
        self.points = []
        self.vectors = []
        self.point_style = []
        self.annotations = []",Resets Bloch sphere data sets to empty.,
"def add_vectors(self, vectors):
        """"""Add a list of vectors to Bloch sphere.

        Args:
            vectors (array_like):
                Array with vectors of unit length or smaller.
        """"""
        if isinstance(vectors[0], (list, np.ndarray)):
            for vec in vectors:
                self.vectors.append(vec)
        else:
            self.vectors.append(vectors)","Add a list of vectors to Bloch sphere.

        Args:
            vectors (array_like):
                Array with vectors of unit length or smaller.",
"def show(self, title=''):
        """"""
        Display Bloch sphere and corresponding data sets.
        """"""
        self.render(title=title)
        if self.fig:
            plt.show(self.fig)",Display Bloch sphere and corresponding data sets.,
"def two_qubit_kak(unitary_matrix, verify_gate_sequence=False):
    """"""Deprecated after 0.8
    """"""
    warnings.warn(""two_qubit_kak function is now accessible under ""
                  ""qiskit.quantum_info.synthesis"", DeprecationWarning)
    return synthesis.two_qubit_kak(unitary_matrix)",Deprecated after 0.8,
"def length(self):
        """""" Returns the length of the element, including the box around.""""""
        return max(len(self.top), len(self.mid), len(self.bot))","Returns the length of the element, including the box around.",
"def dump(self, filename, encoding=""utf8""):
        """"""
        Dumps the ascii art in the file.
        Args:
            filename (str): File to dump the ascii art.
            encoding (str): Optional. Default ""utf-8"".
        """"""
        with open(filename, mode='w', encoding=encoding) as text_file:
            text_file.write(self.single_string())","Dumps the ascii art in the file.
        Args:
            filename (str): File to dump the ascii art.
            encoding (str): Optional. Default ""utf-8"".",
"def label_for_box(instruction):
        """""" Creates the label for a box.""""""
        label = instruction.name.capitalize()
        params = TextDrawing.params_for_label(instruction)
        if params:
            label += ""(%s)"" % ','.join(params)
        return label",Creates the label for a box.,
"def set_qubit(self, qubit, element):
        """"""
        Sets the qubit to the element
        Args:
            qubit (qbit): Element of self.qregs.
            element (DrawElement): Element to set in the qubit
        """"""
        self.qubit_layer[self.qregs.index(qubit)] = element","Sets the qubit to the element
        Args:
            qubit (qbit): Element of self.qregs.
            element (DrawElement): Element to set in the qubit",
"def set_clbit(self, clbit, element):
        """"""
        Sets the clbit to the element
        Args:
            clbit (cbit): Element of self.cregs.
            element (DrawElement): Element to set in the clbit
        """"""
        self.clbit_layer[self.cregs.index(clbit)] = element","Sets the clbit to the element
        Args:
            clbit (cbit): Element of self.cregs.
            element (DrawElement): Element to set in the clbit",
"def constant(times: np.ndarray, amp: complex) -> np.ndarray:
    """"""Continuous constant pulse.

    Args:
        times: Times to output pulse for.
        amp: Complex pulse amplitude.
    """"""
    return np.full(len(times), amp, dtype=np.complex_)","Continuous constant pulse.

    Args:
        times: Times to output pulse for.
        amp: Complex pulse amplitude.",
"def cos(times: np.ndarray, amp: complex, freq: float, phase: float = 0) -> np.ndarray:
    """"""Continuous cosine wave.

    Args:
        times: Times to output wave for.
        amp: Pulse amplitude.
        freq: Pulse frequency, units of 1/dt.
        phase: Pulse phase.
    """"""
    return amp*np.cos(2*np.pi*freq*times+phase).astype(np.complex_)","Continuous cosine wave.

    Args:
        times: Times to output wave for.
        amp: Pulse amplitude.
        freq: Pulse frequency, units of 1/dt.
        phase: Pulse phase.",
"def _attach(self, instruction, qargs, cargs):
        """"""DEPRECATED after 0.8""""""
        self.append(instruction, qargs, cargs)",DEPRECATED after 0.8,
"def _check_dups(self, qubits):
        """"""Raise exception if list of qubits contains duplicates.""""""
        squbits = set(qubits)
        if len(squbits) != len(qubits):
            raise QiskitError(""duplicate qubit arguments"")",Raise exception if list of qubits contains duplicates.,
"def size(self):
        """"""Returns total number of gate operations in circuit.

        Returns:
            int: Total number of gate operations.
        """"""
        gate_ops = 0
        for instr, _, _ in self.data:
            if instr.name not in ['barrier', 'snapshot']:
                gate_ops += 1
        return gate_ops","Returns total number of gate operations in circuit.

        Returns:
            int: Total number of gate operations.",
"def width(self):
        """"""Return number of qubits plus clbits in circuit.

        Returns:
            int: Width of circuit.

        """"""
        return sum(reg.size for reg in self.qregs+self.cregs)","Return number of qubits plus clbits in circuit.

        Returns:
            int: Width of circuit.",
"def _bind_parameter(self, parameter, value):
        """"""Assigns a parameter value to matching instructions in-place.""""""
        for (instr, param_index) in self._parameter_table[parameter]:
            instr.params[param_index] = value",Assigns a parameter value to matching instructions in-place.,
"def _score_step(step):

    """"""Count the mapped two-qubit gates, less the number of added SWAPs.""""""
    # Each added swap will add 3 ops to gates_mapped, so subtract 3.
    return len([g for g in step['gates_mapped']
                if len(g.qargs) == 2]) - 3 * step['swaps_added']","Count the mapped two-qubit gates, less the number of added SWAPs.",
"def physical_qubits(self):
        """"""Returns a sorted list of physical_qubits""""""
        if self._qubit_list is None:
            self._qubit_list = sorted([pqubit for pqubit in self.graph.nodes])
        return self._qubit_list",Returns a sorted list of physical_qubits,
"def is_connected(self):
        """"""
        Test if the graph is connected.

        Return True if connected, False otherwise
        """"""
        try:
            return nx.is_weakly_connected(self.graph)
        except nx.exception.NetworkXException:
            return False","Test if the graph is connected.

        Return True if connected, False otherwise",
"def cu1(self, theta, ctl, tgt):
    """"""Apply cu1 from ctl to tgt with angle theta.""""""
    return self.append(Cu1Gate(theta), [ctl, tgt], [])",Apply cu1 from ctl to tgt with angle theta.,
"def add(self, gate, qargs, cargs):
        """"""Add an instruction and its context (where it's attached).""""""
        if not isinstance(gate, Instruction):
            raise QiskitError(""attempt to add non-Instruction"" +
                              "" to InstructionSet"")
        self.instructions.append(gate)
        self.qargs.append(qargs)
        self.cargs.append(cargs)",Add an instruction and its context (where it's attached).,
"def inverse(self):
        """"""Invert all instructions.""""""
        for index, instruction in enumerate(self.instructions):
            self.instructions[index] = instruction.inverse()
        return self",Invert all instructions.,
"def q_if(self, *qregs):
        """"""Add controls to all instructions.""""""
        for gate in self.instructions:
            gate.q_if(*qregs)
        return self",Add controls to all instructions.,
"def c_if(self, classical, val):
        """"""Add classical control register to all instructions.""""""
        for gate in self.instructions:
            gate.c_if(classical, val)
        return self",Add classical control register to all instructions.,
"def publish(self, event, *args, **kwargs):
        """""" Triggers an event, and associates some data to it, so if there are any
        subscribers, their callback will be called synchronously. """"""
        return self._broker.dispatch(event, *args, **kwargs)","Triggers an event, and associates some data to it, so if there are any
        subscribers, their callback will be called synchronously.",
"def initialize(self, params, qubits):
    """"""Apply initialize to circuit.""""""
    if isinstance(qubits, QuantumRegister):
        qubits = qubits[:]
    else:
        qubits = _convert_to_bits([qubits], [qbit for qreg in self.qregs for qbit in qreg])[0]
    return self.append(Initialize(params), qubits)",Apply initialize to circuit.,
"def is_virtual(value):
        """"""Checks if value has the format of a virtual qubit """"""
        return value is None or isinstance(value, tuple) and len(value) == 2 and isinstance(
            value[0], Register) and isinstance(value[1], int)",Checks if value has the format of a virtual qubit,
"def copy(self):
        """"""Returns a copy of a Layout instance.""""""
        layout_copy = type(self)()

        layout_copy._p2v = self._p2v.copy()
        layout_copy._v2p = self._v2p.copy()

        return layout_copy",Returns a copy of a Layout instance.,
"def ccx(self, ctl1, ctl2, tgt):
    """"""Apply Toffoli to from ctl1 and ctl2 to tgt.""""""
    return self.append(ToffoliGate(), [ctl1, ctl2, tgt], [])",Apply Toffoli to from ctl1 and ctl2 to tgt.,
"def u2(self, phi, lam, q):
    """"""Apply u2 to q.""""""
    return self.append(U2Gate(phi, lam), [q], [])",Apply u2 to q.,
"def insert(self, start_time: int, schedule: ScheduleComponent) -> 'ScheduleComponent':
        """"""Return a new schedule with `schedule` inserted within `self` at `start_time`.

        Args:
            start_time: time to be inserted
            schedule: schedule to be inserted
        """"""
        return ops.insert(self, start_time, schedule)","Return a new schedule with `schedule` inserted within `self` at `start_time`.

        Args:
            start_time: time to be inserted
            schedule: schedule to be inserted",
"def conjugate(self):
        """"""Return the conjugate of the QuantumChannel.""""""
        # pylint: disable=assignment-from-no-return
        stine_l = np.conjugate(self._data[0])
        stine_r = None
        if self._data[1] is not None:
            stine_r = np.conjugate(self._data[1])
        return Stinespring((stine_l, stine_r), self.input_dims(),
                           self.output_dims())",Return the conjugate of the QuantumChannel.,
"def to_operator(self):
        """"""Convert to Operator object.""""""
        # Place import here to avoid cyclic import from circuit visualization
        from qiskit.quantum_info.operators.operator import Operator
        return Operator(self.to_matrix())",Convert to Operator object.,
"def append_paulis(self, paulis=None, pauli_labels=None):
        """"""
        Append pauli at the end.

        Args:
            paulis (Pauli): the to-be-inserted or appended pauli
            pauli_labels (list[str]): the to-be-inserted or appended pauli label

        Returns:
            Pauli: self
        """"""
        return self.insert_paulis(None, paulis=paulis, pauli_labels=pauli_labels)","Append pauli at the end.

        Args:
            paulis (Pauli): the to-be-inserted or appended pauli
            pauli_labels (list[str]): the to-be-inserted or appended pauli label

        Returns:
            Pauli: self",
"def _get_statevector(self):
        """"""Return the current statevector in JSON Result spec format""""""
        vec = np.reshape(self._statevector, 2 ** self._number_of_qubits)
        # Expand complex numbers
        vec = np.stack([vec.real, vec.imag], axis=1)
        # Truncate small values
        vec[abs(vec) < self._chop_threshold] = 0.0
        return vec",Return the current statevector in JSON Result spec format,
"def _get_unitary(self):
        """"""Return the current unitary in JSON Result spec format""""""
        unitary = np.reshape(self._unitary, 2 * [2 ** self._number_of_qubits])
        # Expand complex numbers
        unitary = np.stack((unitary.real, unitary.imag), axis=-1)
        # Truncate small values
        unitary[abs(unitary) < self._chop_threshold] = 0.0
        return unitary",Return the current unitary in JSON Result spec format,
"def _is_bit(obj):
    """"""Determine if obj is a bit""""""
    # If there is a bit type this could be replaced by isinstance.
    if isinstance(obj, tuple) and len(obj) == 2:
        if isinstance(obj[0], Register) and isinstance(obj[1], int) and obj[1] < len(obj[0]):
            return True
    return False",Determine if obj is a bit,
"def to_matrix(self):
        """"""Return a Numpy.array for the U3 gate.""""""
        lam = self.params[0]
        lam = float(lam)
        return numpy.array([[1, 0], [0, numpy.exp(1j * lam)]], dtype=complex)",Return a Numpy.array for the U3 gate.,
"def has_overlap(self, interval: 'Interval') -> bool:
        """"""Check if self has overlap with `interval`.

        Args:
            interval: interval to be examined

        Returns:
            bool: True if self has overlap with `interval` otherwise False
        """"""
        if self.begin < interval.end and interval.begin < self.end:
            return True
        return False","Check if self has overlap with `interval`.

        Args:
            interval: interval to be examined

        Returns:
            bool: True if self has overlap with `interval` otherwise False",
"def shift(self, time: int) -> 'Interval':
        """"""Return a new interval shifted by `time` from self

        Args:
            time: time to be shifted

        Returns:
            Interval: interval shifted by `time`
        """"""
        return Interval(self._begin + time, self._end + time)","Return a new interval shifted by `time` from self

        Args:
            time: time to be shifted

        Returns:
            Interval: interval shifted by `time`",
"def shift(self, time: int) -> 'Timeslot':
        """"""Return a new Timeslot shifted by `time`.

        Args:
            time: time to be shifted
        """"""
        return Timeslot(self.interval.shift(time), self.channel)","Return a new Timeslot shifted by `time`.

        Args:
            time: time to be shifted",
"def shift(self, time: int) -> 'TimeslotCollection':
        """"""Return a new TimeslotCollection shifted by `time`.

        Args:
            time: time to be shifted by
        """"""
        slots = [Timeslot(slot.interval.shift(time), slot.channel) for slot in self.timeslots]
        return TimeslotCollection(*slots)","Return a new TimeslotCollection shifted by `time`.

        Args:
            time: time to be shifted by",
"def process_data(rho):
    """""" Sort rho data """"""
    result = dict()

    num = int(np.log2(len(rho)))
    labels = list(map(lambda x: x.to_label(), pauli_group(num)))
    values = list(map(lambda x: np.real(np.trace(np.dot(x.to_matrix(), rho))),
                      pauli_group(num)))

    for position, label in enumerate(labels):
        result[label] = values[position]
    return result",Sort rho data,
"def rzz(self, theta, qubit1, qubit2):
    """"""Apply RZZ to circuit.""""""
    return self.append(RZZGate(theta), [qubit1, qubit2], [])",Apply RZZ to circuit.,
"def cswap(self, ctl, tgt1, tgt2):
    """"""Apply Fredkin to circuit.""""""
    return self.append(FredkinGate(), [ctl, tgt1, tgt2], [])",Apply Fredkin to circuit.,
"def inverse(self):
        """"""Invert this gate.""""""
        self.data = [gate.inverse() for gate in reversed(self.data)]
        self.inverse_flag = not self.inverse_flag
        return self",Invert this gate.,
"def q_if(self, *qregs):
        """"""Add controls to this gate.""""""
        self.data = [gate.q_if(qregs) for gate in self.data]
        return self",Add controls to this gate.,
"def c_if(self, classical, val):
        """"""Add classical control register.""""""
        self.data = [gate.c_if(classical, val) for gate in self.data]
        return self",Add classical control register.,
"def is_unitary(self, atol=None, rtol=None):
        """"""Return True if operator is a unitary matrix.""""""
        if atol is None:
            atol = self._atol
        if rtol is None:
            rtol = self._rtol
        return is_unitary_matrix(self._data, rtol=rtol, atol=atol)",Return True if operator is a unitary matrix.,
"def conjugate(self):
        """"""Return the conjugate of the operator.""""""
        return Operator(
            np.conj(self.data), self.input_dims(), self.output_dims())",Return the conjugate of the operator.,
"def transpose(self):
        """"""Return the transpose of the operator.""""""
        return Operator(
            np.transpose(self.data), self.input_dims(), self.output_dims())",Return the transpose of the operator.,
"def _shape(self):
        """"""Return the tensor shape of the matrix operator""""""
        return tuple(reversed(self.output_dims())) + tuple(
            reversed(self.input_dims()))",Return the tensor shape of the matrix operator,
"def real(self, nested_scope=None):
        """"""Return the correspond floating point number.""""""
        operation = self.children[0].operation()
        expr = self.children[1].real(nested_scope)
        return operation(expr)",Return the correspond floating point number.,
"def sym(self, nested_scope=None):
        """"""Return the correspond symbolic number.""""""
        operation = self.children[0].operation()
        expr = self.children[1].sym(nested_scope)
        return operation(expr)",Return the correspond symbolic number.,
"def _separate_bitstring(bitstring, creg_sizes):
    """"""Separate a bitstring according to the registers defined in the result header.""""""
    substrings = []
    running_index = 0
    for _, size in reversed(creg_sizes):
        substrings.append(bitstring[running_index: running_index + size])
        running_index += size
    return ' '.join(substrings)",Separate a bitstring according to the registers defined in the result header.,
"def includes(self, lo_freq: float) -> bool:
        """"""Whether `lo_freq` is within the `LoRange`.

        Args:
            lo_freq: LO frequency to be checked

        Returns:
            bool: True if lo_freq is included in this range, otherwise False
        """"""
        if self._lb <= lo_freq <= self._ub:
            return True
        return False","Whether `lo_freq` is within the `LoRange`.

        Args:
            lo_freq: LO frequency to be checked

        Returns:
            bool: True if lo_freq is included in this range, otherwise False",
"def bit_string_index(text):
    """"""Return the index of a string of 0s and 1s.""""""
    n = len(text)
    k = text.count(""1"")
    if text.count(""0"") != n - k:
        raise VisualizationError(""s must be a string of 0 and 1"")
    ones = [pos for pos, char in enumerate(text) if char == ""1""]
    return lex_index(n, k, ones)",Return the index of a string of 0s and 1s.,
"def bit_string_index(s):
    """"""Return the index of a string of 0s and 1s.""""""
    n = len(s)
    k = s.count(""1"")
    if s.count(""0"") != n - k:
        raise VisualizationError(""s must be a string of 0 and 1"")
    ones = [pos for pos, char in enumerate(s) if char == ""1""]
    return lex_index(n, k, ones)",Return the index of a string of 0s and 1s.,
"def op(self):
        """"""Returns the Instruction object corresponding to the op for the node else None""""""
        if 'type' not in self.data_dict or self.data_dict['type'] != 'op':
            raise QiskitError(""The node %s is not an op node"" % (str(self)))
        return self.data_dict.get('op')",Returns the Instruction object corresponding to the op for the node else None,
"def wire(self):
        """"""
        Returns (Register, int) tuple where the int is the index of
        the wire else None
        """"""
        if self.data_dict['type'] not in ['in', 'out']:
            raise QiskitError('The node %s is not an input/output node' % str(self))
        return self.data_dict.get('wire')","Returns (Register, int) tuple where the int is the index of
        the wire else None",
"def zero(duration: int, name: str = None) -> SamplePulse:
    """"""Generates zero-sampled `SamplePulse`.

    Args:
        duration: Duration of pulse. Must be greater than zero.
        name: Name of pulse.
    """"""
    return _sampled_zero_pulse(duration, name=name)","Generates zero-sampled `SamplePulse`.

    Args:
        duration: Duration of pulse. Must be greater than zero.
        name: Name of pulse.",
"def dist_real(self):
        """"""Compute distance.
        """"""
        x0, y0 = self.ax.transAxes.transform(  # pylint: disable=invalid-name
            (0, 0))
        x1, y1 = self.ax.transAxes.transform(  # pylint: disable=invalid-name
            (1, 1))
        value = x1 - x0 if self.x else y1 - y0
        return value",Compute distance.,
"def dist_abs(self):
        """"""Distance abs
        """"""
        bounds = self.ax.get_xlim() if self.x else self.ax.get_ylim()
        return bounds[0] - bounds[1]",Distance abs,
"def to_string(self, indent):
        """"""Print the node data, with indent.""""""
        ind = indent * ' '
        print(ind, 'qreg')
        self.children[0].to_string(indent + 3)","Print the node data, with indent.",
"def qubits(self):
        """"""Return a list of qubits as (QuantumRegister, index) pairs.""""""
        return [(v, i) for k, v in self.qregs.items() for i in range(v.size)]","Return a list of qubits as (QuantumRegister, index) pairs.",
"def clbits(self):
        """"""Return a list of bits as (ClassicalRegister, index) pairs.""""""
        return [(v, i) for k, v in self.cregs.items() for i in range(v.size)]","Return a list of bits as (ClassicalRegister, index) pairs.",
"def remove_all_ops_named(self, opname):
        """"""Remove all operation nodes with the given name.""""""
        for n in self.named_nodes(opname):
            self.remove_op_node(n)",Remove all operation nodes with the given name.,
"def topological_nodes(self):
        """"""
        Yield nodes in topological order.

        Returns:
            generator(DAGNode): node in topological order
        """"""
        return nx.lexicographical_topological_sort(self._multi_graph,
                                                   key=lambda x: str(x.qargs))","Yield nodes in topological order.

        Returns:
            generator(DAGNode): node in topological order",
"def edges(self, nodes=None):
        """"""Iterator for node values.

        Yield:
            node: the node.
        """"""
        for source_node, dest_node, edge_data in self._multi_graph.edges(nodes, data=True):
            yield source_node, dest_node, edge_data","Iterator for node values.

        Yield:
            node: the node.",
"def gate_nodes(self):
        """"""Get the list of gate nodes in the dag.

        Returns:
            list: the list of node ids that represent gates.
        """"""
        nodes = []
        for node in self.op_nodes():
            if isinstance(node.op, Gate):
                nodes.append(node)
        return nodes","Get the list of gate nodes in the dag.

        Returns:
            list: the list of node ids that represent gates.",
"def named_nodes(self, *names):
        """"""Get the set of ""op"" nodes with the given name.""""""
        named_nodes = []
        for node in self._multi_graph.nodes():
            if node.type == 'op' and node.op.name in names:
                named_nodes.append(node)
        return named_nodes","Get the set of ""op"" nodes with the given name.",
"def twoQ_gates(self):
        """"""Get list of 2-qubit gates. Ignore snapshot, barriers, and the like.""""""
        two_q_gates = []
        for node in self.gate_nodes():
            if len(node.qargs) == 2:
                two_q_gates.append(node)
        return two_q_gates","Get list of 2-qubit gates. Ignore snapshot, barriers, and the like.",
"def threeQ_or_more_gates(self):
        """"""Get list of 3-or-more-qubit gates: (id, data).""""""
        three_q_gates = []
        for node in self.gate_nodes():
            if len(node.qargs) >= 3:
                three_q_gates.append(node)
        return three_q_gates","Get list of 3-or-more-qubit gates: (id, data).",
"def count_ops(self):
        """"""Count the occurrences of operation names.

        Returns a dictionary of counts keyed on the operation name.
        """"""
        op_dict = {}
        for node in self.topological_op_nodes():
            name = node.name
            if name not in op_dict:
                op_dict[name] = 1
            else:
                op_dict[name] += 1
        return op_dict","Count the occurrences of operation names.

        Returns a dictionary of counts keyed on the operation name.",
"def properties(self):
        """"""Return a dictionary of circuit properties.""""""
        summary = {""size"": self.size(),
                   ""depth"": self.depth(),
                   ""width"": self.width(),
                   ""bits"": self.num_cbits(),
                   ""factors"": self.num_tensor_factors(),
                   ""operations"": self.count_ops()}
        return summary",Return a dictionary of circuit properties.,
"def __pauli_meas_gates(circuit, qreg, op):
    """"""
    Add state measurement gates to a circuit.
    """"""
    if op not in ['X', 'Y', 'Z']:
        raise QiskitError(""There's no X, Y or Z basis for this Pauli ""
                          ""measurement"")

    if op == ""X"":
        circuit.u2(0., np.pi, qreg)  # H
    elif op == ""Y"":
        circuit.u2(0., 0.5 * np.pi, qreg)",Add state measurement gates to a circuit.,
"def __projector(op_list, basis):
    """"""Returns a projectors.
    """"""
    ret = 1
    # list is from qubit 0 to 1
    for op in op_list:
        label, eigenstate = op
        ret = np.kron(basis[label][eigenstate], ret)
    return ret",Returns a projectors.,
"def run(self, dag):
        """"""Return a new circuit that has been optimized.""""""
        resets = dag.op_nodes(Reset)
        for reset in resets:
            predecessor = next(dag.predecessors(reset))
            if predecessor.type == 'in':
                dag.remove_op_node(reset)
        return dag",Return a new circuit that has been optimized.,
"def cu3(self, theta, phi, lam, ctl, tgt):
    """"""Apply cu3 from ctl to tgt with angle theta, phi, lam.""""""
    return self.append(Cu3Gate(theta, phi, lam), [ctl, tgt], [])","Apply cu3 from ctl to tgt with angle theta, phi, lam.",
"def build_bell_circuit():
    """"""Returns a circuit putting 2 qubits in the Bell state.""""""
    q = QuantumRegister(2)
    c = ClassicalRegister(2)
    qc = QuantumCircuit(q, c)
    qc.h(q[0])
    qc.cx(q[0], q[1])
    qc.measure(q, c)
    return qc",Returns a circuit putting 2 qubits in the Bell state.,
"def drive(self) -> DriveChannel:
        """"""Return the primary drive channel of this qubit.""""""
        if self._drives:
            return self._drives[0]
        else:
            raise PulseError(""No drive channels in q[%d]"" % self._index)",Return the primary drive channel of this qubit.,
"def control(self) -> ControlChannel:
        """"""Return the primary control channel of this qubit.""""""
        if self._controls:
            return self._controls[0]
        else:
            raise PulseError(""No control channels in q[%d]"" % self._index)",Return the primary control channel of this qubit.,
"def measure(self) -> MeasureChannel:
        """"""Return the primary measure channel of this qubit.""""""
        if self._measures:
            return self._measures[0]
        else:
            raise PulseError(""No measurement channels in q[%d]"" % self._index)",Return the primary measure channel of this qubit.,
"def acquire(self) -> AcquireChannel:
        """"""Return the primary acquire channel of this qubit.""""""
        if self._acquires:
            return self._acquires[0]
        else:
            raise PulseError(""No acquire channels in q[%d]"" % self._index)",Return the primary acquire channel of this qubit.,
"def input_state(circ, q, n):
    """"""n-qubit input state for QFT that produces output 1.""""""
    for j in range(n):
        circ.h(q[j])
        circ.u1(math.pi/float(2**(j)), q[j]).inverse()",n-qubit input state for QFT that produces output 1.,
"def unset_qiskit_logger():
    """"""Remove the handlers for the 'qiskit' logger.""""""
    qiskit_logger = logging.getLogger('qiskit')
    for handler in qiskit_logger.handlers:
        qiskit_logger.removeHandler(handler)",Remove the handlers for the 'qiskit' logger.,
"def input(self, data):
        """"""Set the input text data.""""""
        self.data = data
        self.lexer.input(data)",Set the input text data.,
"def pop(self):
        """"""Pop a PLY lexer off the stack.""""""
        self.lexer = self.stack.pop()
        self.filename = self.lexer.qasm_file
        self.lineno = self.lexer.qasm_line",Pop a PLY lexer off the stack.,
"def push(self, filename):
        """"""Push a PLY lexer on the stack to parse filename.""""""
        self.lexer.qasm_file = self.filename
        self.lexer.qasm_line = self.lineno
        self.stack.append(self.lexer)
        self.__mklexer__(filename)",Push a PLY lexer on the stack to parse filename.,
"def t_ID(self, t):
        r'[a-z][a-zA-Z0-9_]*'

        t.type = self.reserved.get(t.value, 'ID')
        if t.type == 'ID':
            t.value = node.Id(t.value, self.lineno, self.filename)
        return t",r'[a-z][a-zA-Z0-9_]*,
"def t_newline(self, t):
        r'\n+'
        self.lineno += len(t.value)
        t.lexer.lineno = self.lineno",r'\n+,
"def get_bound_method(self, instruction):
        """"""Get conversion method for instruction.""""""
        try:
            return self._bound_instructions[type(instruction)]
        except KeyError:
            raise PulseError('Qobj conversion method for %s is not found.' % instruction)",Get conversion method for instruction.,
"def verify_reg_list(self, obj, object_type):
        """"""Verify a list of registers.""""""
        # We expect the object to be a bitlist or an idlist, we don't care.
        # We will iterate it and ensure everything in it is declared as a bit,
        # and throw if not.
        for children in obj.children:
            self.verify_reg(children, object_type)",Verify a list of registers.,
"def p_gate_id_list_0(self, program):
        """"""
           gate_id_list : id
        """"""
        program[0] = node.IdList([program[1]])
        self.update_symtab(program[1])",gate_id_list : id,
"def p_gate_id_list_1(self, program):
        """"""
           gate_id_list : gate_id_list ',' id
        """"""
        program[0] = program[1]
        program[0].add_child(program[3])
        self.update_symtab(program[3])","gate_id_list : gate_id_list ',' id",
"def p_bit_list_0(self, program):
        """"""
           bit_list : id
        """"""
        program[0] = node.IdList([program[1]])
        program[1].is_bit = True
        self.update_symtab(program[1])",bit_list : id,
"def p_bit_list_1(self, program):
        """"""
           bit_list : bit_list ',' id
        """"""
        program[0] = program[1]
        program[0].add_child(program[3])
        program[3].is_bit = True
        self.update_symtab(program[3])","bit_list : bit_list ',' id",
"def p_gate_body_0(self, program):
        """"""
           gate_body : '{' '}'
        """"""
        if program[2] != '}':
            raise QasmError(""Missing '}' in gate definition; received'""
                            + str(program[2].value) + ""'"")
        program[0] = node.GateBody(None)",gate_body : '{' '}',
"def p_unitary_op_0(self, program):
        """"""
          unitary_op : U '(' exp_list ')' primary
        """"""
        program[0] = node.UniversalUnitary([program[3], program[5]])
        self.verify_reg(program[5], 'qreg')
        self.verify_exp_list(program[3])",unitary_op : U '(' exp_list ')' primary,
"def p_unitary_op_1(self, program):
        """"""
        unitary_op : CX primary ',' primary
        """"""
        program[0] = node.Cnot([program[2], program[4]])
        self.verify_reg(program[2], 'qreg')
        self.verify_reg(program[4], 'qreg')
        self.verify_distinct([program[2], program[4]])","unitary_op : CX primary ',' primary",
"def p_unitary_op_2(self, program):
        """"""
        unitary_op : id primary_list
        """"""
        program[0] = node.CustomUnitary([program[1], program[2]])
        self.verify_as_gate(program[1], program[2])
        self.verify_reg_list(program[2], 'qreg')
        self.verify_distinct([program[2]])",unitary_op : id primary_list,
"def p_unitary_op_3(self, program):
        """"""
        unitary_op : id '(' ')' primary_list
        """"""
        program[0] = node.CustomUnitary([program[1], program[4]])
        self.verify_as_gate(program[1], program[4])
        self.verify_reg_list(program[4], 'qreg')
        self.verify_distinct([program[4]])",unitary_op : id '(' ')' primary_list,
"def p_unitary_op_4(self, program):
        """"""
        unitary_op : id '(' exp_list ')' primary_list
        """"""
        program[0] = node.CustomUnitary([program[1], program[3], program[5]])
        self.verify_as_gate(program[1], program[5], arglist=program[3])
        self.verify_reg_list(program[5], 'qreg')
        self.verify_exp_list(program[3])
        self.verify_distinct([program[5]])",unitary_op : id '(' exp_list ')' primary_list,
"def p_gate_op_0(self, program):
        """"""
        gate_op : U '(' exp_list ')' id ';'
        """"""
        program[0] = node.UniversalUnitary([program[3], program[5]])
        self.verify_declared_bit(program[5])
        self.verify_exp_list(program[3])",gate_op : U '(' exp_list ')' id ';',
"def p_gate_op_1(self, program):
        """"""
        gate_op : CX id ',' id ';'
        """"""
        program[0] = node.Cnot([program[2], program[4]])
        self.verify_declared_bit(program[2])
        self.verify_declared_bit(program[4])
        self.verify_distinct([program[2], program[4]])","gate_op : CX id ',' id ';'",
"def p_gate_op_3(self, program):
        """"""
        gate_op : id '(' ')' id_list ';'
        """"""
        program[0] = node.CustomUnitary([program[1], program[4]])
        self.verify_as_gate(program[1], program[4])
        self.verify_bit_list(program[4])
        self.verify_distinct([program[4]])",gate_op : id '(' ')' id_list ';',
"def p_gate_op_4(self, program):
        """"""
        gate_op : id '(' exp_list ')' id_list ';'
        """"""
        program[0] = node.CustomUnitary([program[1], program[3], program[5]])
        self.verify_as_gate(program[1], program[5], arglist=program[3])
        self.verify_bit_list(program[5])
        self.verify_exp_list(program[3])
        self.verify_distinct([program[5]])",gate_op : id '(' exp_list ')' id_list ';',
"def p_gate_op_5(self, program):
        """"""
        gate_op : BARRIER id_list ';'
        """"""
        program[0] = node.Barrier([program[2]])
        self.verify_bit_list(program[2])
        self.verify_distinct([program[2]])",gate_op : BARRIER id_list ';',
"def p_opaque_1(self, program):
        """"""
           opaque : OPAQUE id gate_scope '(' ')' bit_list
        """"""
        program[0] = node.Opaque([program[2], program[6]])
        self.pop_scope()
        self.update_symtab(program[0])",opaque : OPAQUE id gate_scope '(' ')' bit_list,
"def p_measure(self, program):
        """"""
           measure : MEASURE primary ASSIGN primary
        """"""
        program[0] = node.Measure([program[2], program[4]])
        self.verify_reg(program[2], 'qreg')
        self.verify_reg(program[4], 'creg')",measure : MEASURE primary ASSIGN primary,
"def p_barrier(self, program):
        """"""
        barrier : BARRIER primary_list
        """"""
        program[0] = node.Barrier([program[2]])
        self.verify_reg_list(program[2], 'qreg')
        self.verify_distinct([program[2]])",barrier : BARRIER primary_list,
"def p_reset(self, program):
        """"""
        reset : RESET primary
        """"""
        program[0] = node.Reset([program[2]])
        self.verify_reg(program[2], 'qreg')",reset : RESET primary,
"def p_unary_6(self, program):
        """"""
           unary : id '(' expression ')'
        """"""
        # note this is a semantic check, not syntactic
        if program[1].name not in self.external_functions:
            raise QasmError(""Illegal external function call: "",
                            str(program[1].name))
        program[0] = node.External([program[1], program[3]])",unary : id '(' expression ')',
"def p_expression_1(self, program):
        """"""
            expression : '-' expression %prec negative
                        | '+' expression %prec positive
        """"""
        program[0] = node.Prefix([node.UnaryOperator(program[1]), program[2]])","expression : '-' expression %prec negative
                        | '+' expression %prec positive",
"def find_column(self, input_, token):
        """"""Compute the column.

        Input is the input text string.
        token is a token instance.
        """"""
        if token is None:
            return 0
        last_cr = input_.rfind('\n', 0, token.lexpos)
        if last_cr < 0:
            last_cr = 0
        column = (token.lexpos - last_cr) + 1
        return column","Compute the column.

        Input is the input text string.
        token is a token instance.",
"def get_tokens(self):
        """"""Returns a generator of the tokens.""""""
        try:
            while True:
                token = self.lexer.token()

                if not token:
                    break

                yield token
        except QasmError as e:
            print('Exception tokenizing qasm file:', e.msg)",Returns a generator of the tokens.,
"def parse_debug(self, val):
        """"""Set the parse_deb field.""""""
        if val is True:
            self.parse_deb = True
        elif val is False:
            self.parse_deb = False
        else:
            raise QasmError(""Illegal debug value '"" + str(val)
                            + ""' must be True or False."")",Set the parse_deb field.,
"def parse(self, data):
        """"""Parse some data.""""""
        self.parser.parse(data, lexer=self.lexer, debug=self.parse_deb)
        if self.qasm is None:
            raise QasmError(""Uncaught exception in parser; ""
                            + ""see previous messages for details."")
        return self.qasm",Parse some data.,
"def run(self, data):
        """"""Parser runner.

        To use this module stand-alone.
        """"""
        ast = self.parser.parse(data, debug=True)
        self.parser.parse(data, debug=True)
        ast.to_string(0)","Parser runner.

        To use this module stand-alone.",
"def get_tokens(self):
        """"""Returns a generator of the tokens.""""""
        if self._filename:
            with open(self._filename) as ifile:
                self._data = ifile.read()

        with QasmParser(self._filename) as qasm_p:
            return qasm_p.get_tokens()",Returns a generator of the tokens.,
"def parse(self):
        """"""Parse the data.""""""
        if self._filename:
            with open(self._filename) as ifile:
                self._data = ifile.read()

        with QasmParser(self._filename) as qasm_p:
            qasm_p.parse_debug(False)
            return qasm_p.parse(self._data)",Parse the data.,
"def crz(self, theta, ctl, tgt):
    """"""Apply crz from ctl to tgt with angle theta.""""""
    return self.append(CrzGate(theta), [ctl, tgt], [])",Apply crz from ctl to tgt with angle theta.,
"def purity(state):
    """"""Calculate the purity of a quantum state.

    Args:
        state (ndarray): a quantum state
    Returns:
        float: purity.
    """"""
    rho = np.array(state)
    if rho.ndim == 1:
        return 1.0
    return np.real(np.trace(rho.dot(rho)))","Calculate the purity of a quantum state.

    Args:
        state (ndarray): a quantum state
    Returns:
        float: purity.",
"def qasm(self, prec=15):
        """"""Return the corresponding OPENQASM string.""""""
        string = ""gate "" + self.name
        if self.arguments is not None:
            string += ""("" + self.arguments.qasm(prec) + "")""
        string += "" "" + self.bitlist.qasm(prec) + ""\n""
        string += ""{\n"" + self.body.qasm(prec) + ""}""
        return string",Return the corresponding OPENQASM string.,
"def _bipartite_shape(self):
        """"""Return the shape for bipartite matrix""""""
        return (self._input_dim, self._output_dim, self._input_dim,
                self._output_dim)",Return the shape for bipartite matrix,
"def conjugate(self):
        """"""Return the conjugate of the QuantumChannel.""""""
        return Choi(np.conj(self._data), self.input_dims(), self.output_dims())",Return the conjugate of the QuantumChannel.,
"def _truncate_float(matchobj, format_str='0.2g'):
    """"""Truncate long floats

    Args:
        matchobj (re.Match): contains original float
        format_str (str): format specifier
    Returns:
       str: returns truncated float
    """"""
    if matchobj.group(0):
        return format(float(matchobj.group(0)), format_str)
    return ''","Truncate long floats

    Args:
        matchobj (re.Match): contains original float
        format_str (str): format specifier
    Returns:
       str: returns truncated float",
"def _load_schemas_and_validators():
    """"""Load all default schemas into `_SCHEMAS`.""""""
    schema_base_path = os.path.join(os.path.dirname(__file__), '../..')
    for name, path in _DEFAULT_SCHEMA_PATHS.items():
        _load_schema(os.path.join(schema_base_path, path), name)
        _get_validator(name)",Load all default schemas into `_SCHEMAS`.,
"def qasm(self, prec=15):
        """"""Return the corresponding OPENQASM string.""""""
        return "","".join([self.children[j].qasm(prec)
                         for j in range(self.size())])",Return the corresponding OPENQASM string.,
"def majority(p, a, b, c):
    """"""Majority gate.""""""
    p.cx(c, b)
    p.cx(c, a)
    p.ccx(a, b, c)",Majority gate.,
"def unmajority(p, a, b, c):
    """"""Unmajority gate.""""""
    p.ccx(a, b, c)
    p.cx(c, a)
    p.cx(a, b)",Unmajority gate.,
"def qasm(self, prec=15):
        """"""Return the corresponding OPENQASM string.""""""
        string = """"
        for children in self.children:
            string += ""  "" + children.qasm(prec) + ""\n""
        return string",Return the corresponding OPENQASM string.,
"def calls(self):
        """"""Return a list of custom gate names in this gate body.""""""
        lst = []
        for children in self.children:
            if children.type == ""custom_unitary"":
                lst.append(children.name)
        return lst",Return a list of custom gate names in this gate body.,
"def qasm(self, prec=15):
        """"""Return the corresponding OPENQASM string.""""""
        if self.value == pi:
            return ""pi""

        return ccode(self.value, precision=prec)",Return the corresponding OPENQASM string.,
"def _define(self):
        """"""
        gate sdg a { u1(-pi/2) a; }
        """"""
        definition = []
        q = QuantumRegister(1, ""q"")
        rule = [
            (U1Gate(-pi/2), [q[0]], [])
        ]
        for inst in rule:
            definition.append(inst)
        self.definition = definition",gate sdg a { u1(-pi/2) a; },
"def conjugate(self):
        """"""Return the conjugate of the QuantumChannel.""""""
        return SuperOp(
            np.conj(self._data), self.input_dims(), self.output_dims())",Return the conjugate of the QuantumChannel.,
"def transpose(self):
        """"""Return the transpose of the QuantumChannel.""""""
        return SuperOp(
            np.transpose(self._data),
            input_dims=self.output_dims(),
            output_dims=self.input_dims())",Return the transpose of the QuantumChannel.,
"def unitary(self, obj, qubits, label=None):
    """"""Apply u2 to q.""""""
    if isinstance(qubits, QuantumRegister):
        qubits = qubits[:]
    return self.append(UnitaryGate(obj, label=label), qubits, [])",Apply u2 to q.,
"def _define(self):
        """"""Calculate a subcircuit that implements this unitary.""""""
        if self.num_qubits == 1:
            q = QuantumRegister(1, ""q"")
            angles = euler_angles_1q(self.to_matrix())
            self.definition = [(U3Gate(*angles), [q[0]], [])]
        if self.num_qubits == 2:
            self.definition = two_qubit_kak(self.to_matrix())",Calculate a subcircuit that implements this unitary.,
"def input_dims(self, qargs=None):
        """"""Return tuple of input dimension for specified subsystems.""""""
        if qargs is None:
            return self._input_dims
        return tuple(self._input_dims[i] for i in qargs)",Return tuple of input dimension for specified subsystems.,
"def output_dims(self, qargs=None):
        """"""Return tuple of output dimension for specified subsystems.""""""
        if qargs is None:
            return self._output_dims
        return tuple(self._output_dims[i] for i in qargs)",Return tuple of output dimension for specified subsystems.,
"def copy(self):
        """"""Make a copy of current operator.""""""
        # pylint: disable=no-value-for-parameter
        # The constructor of subclasses from raw data should be a copy
        return self.__class__(self.data, self.input_dims(), self.output_dims())",Make a copy of current operator.,
"def _deserialize(self, value, attr, data):
        """"""Override ``_deserialize`` for customizing the exception raised.""""""
        try:
            return super()._deserialize(value, attr, data)
        except ValidationError as ex:
            if 'deserialization_schema_selector' in ex.messages[0]:
                ex.messages[0] = 'Cannot find a valid schema among the choices'
            raise",Override ``_deserialize`` for customizing the exception raised.,
"def _serialize(self, value, key, obj):
        """"""Override ``_serialize`` for customizing the exception raised.""""""
        try:
            return super()._serialize(value, key, obj)
        except TypeError as ex:
            if 'serialization_schema_selector' in str(ex):
                raise ValidationError('Data from an invalid schema')
            raise",Override ``_serialize`` for customizing the exception raised.,
"def assemble(self):
        """"""Assemble a QasmQobjInstruction""""""
        instruction = super().assemble()
        instruction.label = self._label
        instruction.snapshot_type = self._snapshot_type
        return instruction",Assemble a QasmQobjInstruction,
"def inverse(self):
        """"""Special case. Return self.""""""
        return Snapshot(self.num_qubits, self.num_clbits, self.params[0],
                        self.params[1])",Special case. Return self.,
"def label(self, name):
        """"""Set snapshot label to name

        Args:
            name (str or None): label to assign unitary

        Raises:
            TypeError: name is not string or None.
        """"""
        if isinstance(name, str):
            self._label = name
        else:
            raise TypeError('label expects a string')","Set snapshot label to name

        Args:
            name (str or None): label to assign unitary

        Raises:
            TypeError: name is not string or None.",
"def is_cptp(self, atol=None, rtol=None):
        """"""Return True if completely-positive trace-preserving (CPTP).""""""
        choi = _to_choi(self.rep, self._data, *self.dim)
        return self._is_cp_helper(choi, atol, rtol) and self._is_tp_helper(
            choi, atol, rtol)",Return True if completely-positive trace-preserving (CPTP).,
"def is_tp(self, atol=None, rtol=None):
        """"""Test if a channel is completely-positive (CP)""""""
        choi = _to_choi(self.rep, self._data, *self.dim)
        return self._is_tp_helper(choi, atol, rtol)",Test if a channel is completely-positive (CP),
"def is_cp(self, atol=None, rtol=None):
        """"""Test if Choi-matrix is completely-positive (CP)""""""
        choi = _to_choi(self.rep, self._data, *self.dim)
        return self._is_cp_helper(choi, atol, rtol)",Test if Choi-matrix is completely-positive (CP),
"def is_unitary(self, atol=None, rtol=None):
        """"""Return True if QuantumChannel is a unitary channel.""""""
        try:
            op = self.to_operator()
            return op.is_unitary(atol=atol, rtol=rtol)
        except QiskitError:
            return False",Return True if QuantumChannel is a unitary channel.,
"def to_operator(self):
        """"""Try to convert channel to a unitary representation Operator.""""""
        mat = _to_operator(self.rep, self._data, *self.dim)
        return Operator(mat, self.input_dims(), self.output_dims())",Try to convert channel to a unitary representation Operator.,
"def _is_cp_helper(self, choi, atol, rtol):
        """"""Test if a channel is completely-positive (CP)""""""
        if atol is None:
            atol = self._atol
        if rtol is None:
            rtol = self._rtol
        return is_positive_semidefinite_matrix(choi, rtol=rtol, atol=atol)",Test if a channel is completely-positive (CP),
"def _parse_time(self, date_string, settings):
        """"""Attemps to parse time part of date strings like '1 day ago, 2 PM' """"""
        date_string = PATTERN.sub('', date_string)
        date_string = re.sub(r'\b(?:ago|in)\b', '', date_string)
        try:
            return time_parser(date_string)
        except:
            pass","Attemps to parse time part of date strings like '1 day ago, 2 PM'",
"def validate_duration(self, field, duration):
        '''
        2h
        2h5m
        5m
        180
        1h4m3
        :param duration:
        :return:
        '''
        DURATION_RE = r'^(\d+d)?(\d+h)?(\d+m)?(\d+s?)?$'
        if not re.match(DURATION_RE, duration):
            self._error(field, 'Load duration examples: 2h30m; 5m15; 180')","2h
        2h5m
        5m
        180
        1h4m3
        :param duration:
        :return:",
"def pid_exists(pid):
    """"""Check whether pid exists in the current process table.""""""
    if pid < 0:
        return False
    try:
        os.kill(pid, 0)
    except OSError as exc:
        logging.debug(""No process[%s]: %s"", exc.errno, exc)
        return exc.errno == errno.EPERM
    else:
        p = psutil.Process(pid)
        return p.status != psutil.STATUS_ZOMBIE",Check whether pid exists in the current process table.,
"def get_option(self, option, param2=None):
        ''' get_option wrapper'''
        result = self.cfg[option]
        self.log.debug(
            ""Option %s = %s"", option, result)
        return result",get_option wrapper,
"def __read_cached_options(self):
        '''
        Read stepper info from json
        '''
        self.log.debug(""Reading cached stepper info: %s"", self.__si_filename())
        with open(self.__si_filename(), 'r') as si_file:
            si = info.StepperInfo(**json.load(si_file))
        return si",Read stepper info from json,
"def __write_cached_options(self, si):
        '''
        Write stepper info to json
        '''
        self.log.debug(""Saving stepper info: %s"", self.__si_filename())
        with open(self.__si_filename(), 'w') as si_file:
            json.dump(si._asdict(), si_file, indent=4)",Write stepper info to json,
"def ts(self, n):
        """"""
        :param n: number of charge
        :return: when to shoot nth charge, milliseconds
        """"""
        try:
            root1, root2 = solve_quadratic(self.slope / 2.0, self.minrps, -n)
        except ZeroDivisionError:
            root2 = float(n) / self.minrps
        return int(root2 * 1000)",":param n: number of charge
        :return: when to shoot nth charge, milliseconds",
"def rps_at(self, t):
        '''Return rps for second t'''
        if 0 <= t <= self.duration:
            return self.minrps + \
                float(self.maxrps - self.minrps) * t / self.duration
        else:
            return 0",Return rps for second t,
"def execute(self, cmd):
        """"""
        Execute and check exit code
        """"""
        self.log.info(""Executing: %s"", cmd)
        retcode = execute(
            cmd, shell=True, poll_period=0.1, catch_out=self.catch_out)[0]
        if retcode:
            raise RuntimeError(""Subprocess returned %s"" % retcode)
        return retcode",Execute and check exit code,
"def publish(self, key, value):
        """"""publish value to status""""""
        self.log.debug(
            ""Publishing status: %s/%s: %s"", self.__class__.__name__, key, value)
        self.core.publish(self.__class__.__name__, key, value)",publish value to status,
"def count_matched_codes(codes_regex, codes_dict):
        """""" helper to aggregate codes by mask """"""
        total = 0
        for code, count in codes_dict.items():
            if codes_regex.match(str(code)):
                total += count
        return total",helper to aggregate codes by mask,
"def __add_user_options(self):
        """""" override config options with user specified options""""""
        if self.options.get('user_options', None):
            self.core.apply_shorthand_options(self.options['user_options'])",override config options with user specified options,
"def __graceful_shutdown(self):
        """""" call shutdown routines """"""
        retcode = 1
        self.log.info(""Trying to shutdown gracefully..."")
        retcode = self.core.plugins_end_test(retcode)
        retcode = self.core.plugins_post_process(retcode)
        self.log.info(""Done graceful shutdown"")
        return retcode",call shutdown routines,
"def __notify_listeners(self, data, stats):
        """""" notify all listeners about aggregate data and stats """"""
        for listener in self.listeners:
            listener.on_aggregated_data(data, stats)",notify all listeners about aggregate data and stats,
"def cfg_folder_loader(path):
    """"""
    :type path: str
    """"""
    CFG_WILDCARD = '*.yaml'
    return [load_cfg(filename) for filename in sorted(glob.glob(os.path.join(path, CFG_WILDCARD)))]",:type path: str,
"def parse_options(options):
    """"""
    :type options: list of str
    :rtype: list of dict
    """"""
    if options is None:
        return []
    else:
        return [
            convert_single_option(key.strip(), value.strip())
            for key, value
            in [option.split('=', 1) for option in options]
        ]",":type options: list of str
    :rtype: list of dict",
"def clean_markup(self, orig_str):
        ''' clean markup from string '''
        for val in [
            self.YELLOW, self.RED, self.RESET, self.CYAN, self.BG_MAGENTA,
            self.WHITE, self.BG_GREEN, self.GREEN, self.BG_BROWN,
            self.RED_DARK, self.MAGENTA, self.BG_CYAN
        ]:
            orig_str = orig_str.replace(val, '')
        return orig_str",clean markup from string,
"def solve_quadratic(a, b, c):
    '''
    >>> solve_quadratic(1.0, 2.0, 1.0)
    (-1.0, -1.0)
    '''
    discRoot = math.sqrt((b * b) - 4 * a * c)
    root1 = (-b - discRoot) / (2 * a)
    root2 = (-b + discRoot) / (2 * a)
    return (root1, root2)",">>> solve_quadratic(1.0, 2.0, 1.0)
    (-1.0, -1.0)",
"def proper_round(n):
    """"""
    rounds float to closest int
    :rtype: int
    :param n: float
    """"""
    return int(n) + (n / abs(n)) * int(abs(n - int(n)) >= 0.5) if n != 0 else 0","rounds float to closest int
    :rtype: int
    :param n: float",
"def parse_sections(cfg_ini):
    """"""
    :type cfg_ini: ConfigParser
    """"""
    return [Section(section.lower(),
                    guess_plugin(section.lower()),
                    without_defaults(cfg_ini, section))
            for section in cfg_ini.sections()
            if not re.match(CORE_SECTION_PATTERN, section.lower()) and section.lower() not in DEPRECATED_SECTIONS]",:type cfg_ini: ConfigParser,
"def converted(self):
        """"""
        :rtype: {str: object}
        """"""
        if self._converted is None:
            self._converted = self.converter(self.name, self.value)
        return self._converted",:rtype: {str: object},
"def as_tuple(self):
        """"""
        :rtype: (str, object)
        """"""
        if self._as_tuple is None:
            self._as_tuple = self.converted.items()[0]
        return self._as_tuple",":rtype: (str, object)",
"def __check_mem(self):
        ''' raise exception on RAM exceeded '''
        mem_free = psutil.virtual_memory().available / 2**20
        self.log.debug(""Memory free: %s/%s"", mem_free, self.mem_limit)
        if mem_free < self.mem_limit:
            raise RuntimeError(
                ""Not enough resources: free memory less ""
                ""than %sMB: %sMB"" % (self.mem_limit, mem_free))",raise exception on RAM exceeded,
"def add_info_widget(self, widget):
        '''
        Add widget string to right panel of the screen
        '''
        index = widget.get_index()
        while index in self.info_widgets.keys():
            index += 1
        self.info_widgets[widget.get_index()] = widget",Add widget string to right panel of the screen,
"def fill_rectangle(self, prepared):
        '''  Right-pad lines of block to equal width  '''
        result = []
        width = max([self.clean_len(line) for line in prepared])
        for line in prepared:
            spacer = ' ' * (width - self.clean_len(line))
            result.append(line + (self.screen.markup.RESET, spacer))
        return (width, result)",Right-pad lines of block to equal width,
"def get_level_str(self):
        ''' format level str '''
        if self.is_relative:
            level_str = str(self.level) + ""%""
        else:
            level_str = self.level
        return level_str",format level str,
"def add_info_widget(self, widget):
        ''' add right panel widget '''
        if not self.screen:
            self.log.debug(""No screen instance to add widget"")
        else:
            self.screen.add_info_widget(widget)",add right panel widget,
"def clean_markup(self, orig_str):
        ''' clean markup from string '''
        for val in self.get_markup_vars():
            orig_str = orig_str.replace(val, '')
        return orig_str",clean markup from string,
"def plugins(self):
        """"""
        :returns: {plugin_name: plugin_class, ...}
        :rtype: dict
        """"""
        if self._plugins is None:
            self.load_plugins()
            if self._plugins is None:
                self._plugins = {}
        return self._plugins",":returns: {plugin_name: plugin_class, ...}
        :rtype: dict",
"def add_artifact_file(self, filename, keep_original=False):
        """"""
        Add file to be stored as result artifact on post-process phase
        """"""
        if filename:
            logger.debug(
                ""Adding artifact file to collect (keep=%s): %s"", keep_original,
                filename)
            self.artifact_files[filename] = keep_original",Add file to be stored as result artifact on post-process phase,
"def load_files(self, configs):
        """"""         Read configs set into storage        """"""
        logger.debug(""Reading configs: %s"", configs)
        config_filenames = [resource.resource_filename(config) for config in configs]
        try:
            self.config.read(config_filenames)
        except Exception as ex:
            logger.error(""Can't load configs: %s"", ex)
            raise ex",Read configs set into storage,
"def flush(self, filename=None):
        """"""        Flush current stat to file        """"""
        if not filename:
            filename = self.file

        if filename:
            with open(filename, 'w') as handle:
                self.config.write(handle)",Flush current stat to file,
"def find_sections(self, prefix):
        """""" return sections with specified prefix """"""
        res = []
        for section in self.config.sections():
            if section.startswith(prefix):
                res.append(section)
        return res",return sections with specified prefix,
"def phantom(self):
        """"""
        :rtype: PhantomConfig
        """"""
        if not self._phantom:
            self._phantom = PhantomConfig(self.core, self.cfg, self.stat_log)
            self._phantom.read_config()
        return self._phantom",:rtype: PhantomConfig,
"def get_info(self):
        """""" returns info object """"""
        if not self.cached_info:
            if not self.phantom:
                return None
            self.cached_info = self.phantom.get_info()
        return self.cached_info",returns info object,
"def start(self):
        """""" Start agents

        execute popen of agent.py on target and start output reader thread.
        """"""
        [agent.start() for agent in self.agents]
        [agent.reader_thread.start() for agent in self.agents]","Start agents

        execute popen of agent.py on target and start output reader thread.",
"def send_collected_data(self):
        """"""sends pending data set to listeners""""""
        data = self.__collected_data
        self.__collected_data = []
        for listener in self.listeners:
            # deep copy to ensure each listener gets it's own copy
            listener.monitoring_data(copy.deepcopy(data))",sends pending data set to listeners,
"def run(self, initial_channels=[]):
        '''Run forever and block until exception is rasised.
        initial_channels is the channels to start with.
        '''
        loop = asyncio.get_event_loop()
        try:
            loop.run_until_complete(self.subscribe(initial_channels))
            loop.run_forever()
        finally:
            loop.run_until_complete(self.close())","Run forever and block until exception is rasised.
        initial_channels is the channels to start with.",
"async def close(self):
        '''Close any of open connections'''
        if self._ws is not None:
            await self._ws.close()
        if self.polygon is not None:
            await self.polygon.close()",Close any of open connections,
"def get_order(self, order_id):
        '''Get an order'''
        resp = self.get('/orders/{}'.format(order_id))
        return Order(resp)",Get an order,
"def get_position(self, symbol):
        '''Get an open position'''
        resp = self.get('/positions/{}'.format(symbol))
        return Position(resp)",Get an open position,
"def list_assets(self, status=None, asset_class=None):
        '''Get a list of assets'''
        params = {
            'status': status,
            'assert_class': asset_class,
        }
        resp = self.get('/assets', params)
        return [Asset(o) for o in resp]",Get a list of assets,
"def get_asset(self, symbol):
        '''Get an asset'''
        resp = self.get('/assets/{}'.format(symbol))
        return Asset(resp)",Get an asset,
"def get_all_pipelines(self):
        '''Return all pipelines as a list

        Returns:
            List[PipelineDefinition]:

        '''
        pipelines = list(map(self.get_pipeline, self.pipeline_dict.keys()))
        # This does uniqueness check
        self._construct_solid_defs(pipelines)
        return pipelines","Return all pipelines as a list

        Returns:
            List[PipelineDefinition]:",
"def join(self):
        '''Waits until all there are no processes enqueued.'''
        while True:
            with self._processes_lock:
                if not self._processes and self._processing_semaphore.locked():
                    return True
            gevent.sleep(0.1)",Waits until all there are no processes enqueued.,
"def download_from_s3(context):
    '''Download an object from s3.

    Args:
        info (ExpectationExecutionInfo): Must expose a boto3 S3 client as its `s3` resource.

    Returns:
        str:
            The path to the downloaded object.
    '''
    target_file = context.solid_config['target_file']
    return context.resources.download_manager.download_file_contents(context, target_file)","Download an object from s3.

    Args:
        info (ExpectationExecutionInfo): Must expose a boto3 S3 client as its `s3` resource.

    Returns:
        str:
            The path to the downloaded object.",
"def mkdir_p(newdir, mode=0o777):
    """"""The missing mkdir -p functionality in os.""""""
    try:
        os.makedirs(newdir, mode)
    except OSError as err:
        # Reraise the error unless it's about an already existing directory
        if err.errno != errno.EEXIST or not os.path.isdir(newdir):
            raise",The missing mkdir -p functionality in os.,
"def skipped(self):
        '''Whether the solid execution was skipped'''
        return all(
            [
                step_event.event_type == DagsterEventType.STEP_SKIPPED
                for step_event in itertools.chain(
                    self.input_expectations, self.output_expectations, self.transforms
                )
            ]
        )",Whether the solid execution was skipped,
"def failure_data(self):
        '''Returns the failing step's data that happened during this solid's execution, if any'''
        for result in itertools.chain(
            self.input_expectations, self.output_expectations, self.transforms
        ):
            if result.event_type == DagsterEventType.STEP_FAILURE:
                return result.step_failure_data","Returns the failing step's data that happened during this solid's execution, if any",
"def _is_valid_dataset(config_value):
    '''Datasets must be of form ""project.dataset"" or ""dataset""
    '''
    return re.match(
        # regex matches: project.table -- OR -- table
        r'^' + RE_PROJECT + r'\.' + RE_DS_TABLE + r'$|^' + RE_DS_TABLE + r'$',
        config_value,
    )","Datasets must be of form ""project.dataset"" or ""dataset""",
"def parse_spark_config(spark_conf):
    '''For each key-value pair in spark conf, we need to pass to CLI in format:

        --conf ""key=value""
    '''

    spark_conf_list = flatten_dict(spark_conf)
    return list(
        itertools.chain.from_iterable([('--conf', '{}={}'.format(*c)) for c in spark_conf_list])
    )","For each key-value pair in spark conf, we need to pass to CLI in format:

        --conf ""key=value""",
"def SystemNamedDict(name, fields, description=None):
    '''A SystemNamedDict object is simply a NamedDict intended for internal (dagster) use.
    '''
    return NamedDict(name, fields, description, ConfigTypeAttributes(is_system_config=True))",A SystemNamedDict object is simply a NamedDict intended for internal (dagster) use.,
"def create_cursor(self, name=None):
        """"""
        Returns an active connection cursor to the database.
        """"""
        return Cursor(self.client_connection, self.connection, self.djongo_connection)",Returns an active connection cursor to the database.,
"def _close(self):
        """"""
        Closes the client connection to the database.
        """"""
        if self.connection:
            with self.wrap_database_errors:
                self.connection.client.close()",Closes the client connection to the database.,
"def make_mdl(model, model_dict):
    """"""
    Builds an instance of model from the model_dict.
    """"""
    for field_name in model_dict:
        field = model._meta.get_field(field_name)
        model_dict[field_name] = field.to_python(model_dict[field_name])

    return model(**model_dict)",Builds an instance of model from the model_dict.,
"def to_python(self, value):
        """"""
        Overrides Django's default to_python to allow correct
        translation to instance.
        """"""
        if value is None or isinstance(value, self.model_container):
            return value
        assert isinstance(value, dict)

        instance = make_mdl(self.model_container, value)
        return instance","Overrides Django's default to_python to allow correct
        translation to instance.",
"def _apply_rel_filters(self, queryset):
        """"""
        Filter the queryset for the instance this manager is bound to.
        """"""
        queryset._add_hints(instance=self.instance)
        if self._db:
            queryset = queryset.using(self._db)
        queryset = queryset.filter(**self.core_filters)

        return queryset",Filter the queryset for the instance this manager is bound to.,
"def _calc_a(self, r, b):
        '''
        Compute the function A(r, b)
        '''
        if r == 0.0:
            # Find the limit of A(r, b) as r -> 0.
            return 1.0 / (1 << b)
        return r * (1 - r) ** (2 ** b - 1) / (1 - (1 - r) ** (2 * b))","Compute the function A(r, b)",
"def count(self):
        '''Estimate the cardinality count based on the technique described in
        `this paper <http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=365694>`_.

        Returns:
            int: The estimated cardinality of the set represented by this MinHash.
        '''
        k = len(self)
        return np.float(k) / np.sum(self.hashvalues / np.float(_max_hash)) - 1.0","Estimate the cardinality count based on the technique described in
        `this paper <http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=365694>`_.

        Returns:
            int: The estimated cardinality of the set represented by this MinHash.",
"def copy(self):
        '''
        :returns: datasketch.MinHash -- A copy of this MinHash by exporting its state.
        '''
        return MinHash(seed=self.seed, hashfunc=self.hashfunc,
                hashvalues=self.digest(),
                permutations=self.permutations)",:returns: datasketch.MinHash -- A copy of this MinHash by exporting its state.,
"def is_empty(self):
        '''
        Returns:
            bool: Check if the index is empty.
        '''
        return all(all(index[r].is_empty() for r in index)
                   for index in self.indexes)","Returns:
            bool: Check if the index is empty.",
"def clear(self):
        '''
        Reset the current HyperLogLog to empty.
        '''
        self.reg = np.zeros((self.m,), dtype=np.int8)",Reset the current HyperLogLog to empty.,
"def index(self):
        '''
        Index all the keys added so far and make them searchable.
        '''
        for i, hashtable in enumerate(self.hashtables):
            self.sorted_hashtables[i] = [H for H in hashtable.keys()]
            self.sorted_hashtables[i].sort()",Index all the keys added so far and make them searchable.,
"def _binary_search(self, n, func):
        '''
        https://golang.org/src/sort/search.go?s=2247:2287#L49
        '''
        i, j = 0, n
        while i < j:
            h = int(i + (j - i) / 2)
            if not func(h):
                i = h + 1
            else:
                j = h
        return i",https://golang.org/src/sort/search.go?s=2247:2287#L49,
"async def close(self):
        """"""
        Cleanup client resources and disconnect from AsyncMinHashLSH storage.
        """"""
        async with self._lock:
            for t in self.hashtables:
                await t.close()

            if self.keys is not None:
                await self.keys.close()

            self._initialized = False",Cleanup client resources and disconnect from AsyncMinHashLSH storage.,
"async def get_counts(self):
        """"""
        see :class:`datasketch.MinHashLSH`.
        """"""
        fs = (hashtable.itemcounts() for hashtable in self.hashtables)
        return await asyncio.gather(*fs)",see :class:`datasketch.MinHashLSH`.,
"def itemcounts(self, **kwargs):
        '''Returns a dict where the keys are the keys of the container.
        The values are the *lengths* of the value sequences stored
        in this container.
        '''
        return {k: len(v) for k, v in self._dict.items()}","Returns a dict where the keys are the keys of the container.
        The values are the *lengths* of the value sequences stored
        in this container.",
"def advance_one_line(self):
    """"""Advances to next line.""""""

    current_line = self._current_token.line_number
    while current_line == self._current_token.line_number:
      self._current_token = ConfigParser.Token(*next(self._token_generator))",Advances to next line.,
"def _maybe_parse_macro(self):
    """"""Try to parse an macro (%scope/name).""""""
    if self._current_token.value != '%':
      return False, None

    location = self._current_location()
    self._advance_one_token()
    scoped_name = self._parse_selector(allow_periods_in_scope=True)

    with utils.try_with_location(location):
      macro = self._delegate.macro(scoped_name)

    return True, macro",Try to parse an macro (%scope/name).,
"def _find_class_construction_fn(cls):
  """"""Find the first __init__ or __new__ method in the given class's MRO.""""""
  for base in type.mro(cls):
    if '__init__' in base.__dict__:
      return base.__init__
    if '__new__' in base.__dict__:
      return base.__new__",Find the first __init__ or __new__ method in the given class's MRO.,
"def _should_skip(selector, skip_unknown):
  """"""Checks whether `selector` should be skipped (if unknown).""""""
  _validate_skip_unknown(skip_unknown)
  if _REGISTRY.matching_selectors(selector):
    return False  # Never skip known configurables.
  if isinstance(skip_unknown, (list, tuple, set)):
    return selector in skip_unknown
  return skip_unknown",Checks whether `selector` should be skipped (if unknown).,
"def _get_supplied_positional_parameter_names(fn, args):
  """"""Returns the names of the supplied arguments to the given function.""""""
  arg_spec = _get_cached_arg_spec(fn)
  # May be shorter than len(args) if args contains vararg (*args) arguments.
  return arg_spec.args[:len(args)]",Returns the names of the supplied arguments to the given function.,
"def _get_all_positional_parameter_names(fn):
  """"""Returns the names of all positional arguments to the given function.""""""
  arg_spec = _get_cached_arg_spec(fn)
  args = arg_spec.args
  if arg_spec.defaults:
    args = args[:-len(arg_spec.defaults)]
  return args",Returns the names of all positional arguments to the given function.,
"def parse_value(value):
  """"""Parse and return a single Gin value.""""""
  if not isinstance(value, six.string_types):
    raise ValueError('value ({}) should be a string type.'.format(value))
  return config_parser.ConfigParser(value, ParserDelegate()).parse_value()",Parse and return a single Gin value.,
"def get_all_matches(self, partial_selector):
    """"""Returns all values matching `partial_selector` as a list.""""""
    matching_selectors = self.matching_selectors(partial_selector)
    return [self._selector_map[selector] for selector in matching_selectors]",Returns all values matching `partial_selector` as a list.,
"def set_value(self, value):
        """"""
        Set the current value of the property.

        value -- the value to set
        """"""
        self.validate_value(value)
        self.value.set(value)","Set the current value of the property.

        value -- the value to set",
"def get_thing(self, idx):
        """"""
        Get the thing at the given index.

        idx -- the index
        """"""
        try:
            idx = int(idx)
        except ValueError:
            return None

        if idx < 0 or idx >= len(self.things):
            return None

        return self.things[idx]","Get the thing at the given index.

        idx -- the index",
"def initialize(self, things, hosts):
        """"""
        Initialize the handler.

        things -- list of Things managed by this server
        hosts -- list of allowed hostnames
        """"""
        self.things = things
        self.hosts = hosts","Initialize the handler.

        things -- list of Things managed by this server
        hosts -- list of allowed hostnames",
"def prepare(self):
        """"""Validate Host header.""""""
        host = self.request.headers.get('Host', None)
        if host is not None and host in self.hosts:
            return

        raise tornado.web.HTTPError(403)",Validate Host header.,
"def get(self, thing_id='0'):
        """"""
        Handle a GET request.

        thing_id -- ID of the thing this request is for
        """"""
        thing = self.get_thing(thing_id)
        if thing is None:
            self.set_status(404)
            return

        self.set_header('Content-Type', 'application/json')
        self.write(json.dumps(thing.get_event_descriptions()))","Handle a GET request.

        thing_id -- ID of the thing this request is for",
"def stop(self):
        """"""Stop listening.""""""
        self.zeroconf.unregister_service(self.service_info)
        self.zeroconf.close()
        self.server.stop()",Stop listening.,
"def start(self):
        """"""Start performing the action.""""""
        self.status = 'pending'
        self.thing.action_notify(self)
        self.perform_action()
        self.finish()",Start performing the action.,
"def finish(self):
        """"""Finish performing the action.""""""
        self.status = 'completed'
        self.time_completed = timestamp()
        self.thing.action_notify(self)",Finish performing the action.,
"def as_event_description(self):
        """"""
        Get the event description.

        Returns a dictionary describing the event.
        """"""
        description = {
            self.name: {
                'timestamp': self.time,
            },
        }

        if self.data is not None:
            description[self.name]['data'] = self.data

        return description","Get the event description.

        Returns a dictionary describing the event.",
"def get_ip():
    """"""
    Get the default local IP address.

    From: https://stackoverflow.com/a/28950776
    """"""
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        s.connect(('10.255.255.255', 1))
        ip = s.getsockname()[0]
    except (socket.error, IndexError):
        ip = '127.0.0.1'
    finally:
        s.close()

    return ip","Get the default local IP address.

    From: https://stackoverflow.com/a/28950776",
"def set(self, value):
        """"""
        Set a new value for this thing.

        value -- value to set
        """"""
        if self.value_forwarder is not None:
            self.value_forwarder(value)

        self.notify_of_external_update(value)","Set a new value for this thing.

        value -- value to set",
"def notify_of_external_update(self, value):
        """"""
        Notify observers of a new value.

        value -- new value
        """"""
        if value is not None and value != self.last_value:
            self.last_value = value
            self.emit('update', value)","Notify observers of a new value.

        value -- new value",
"def get_property_descriptions(self):
        """"""
        Get the thing's properties as a dictionary.

        Returns the properties as a dictionary, i.e. name -> description.
        """"""
        return {k: v.as_property_description()
                for k, v in self.properties.items()}","Get the thing's properties as a dictionary.

        Returns the properties as a dictionary, i.e. name -> description.",
"def add_property(self, property_):
        """"""
        Add a property to this thing.

        property_ -- property to add
        """"""
        property_.set_href_prefix(self.href_prefix)
        self.properties[property_.name] = property_","Add a property to this thing.

        property_ -- property to add",
"def remove_property(self, property_):
        """"""
        Remove a property from this thing.

        property_ -- property to remove
        """"""
        if property_.name in self.properties:
            del self.properties[property_.name]","Remove a property from this thing.

        property_ -- property to remove",
"def get_property(self, property_name):
        """"""
        Get a property's value.

        property_name -- the property to get the value of

        Returns the properties value, if found, else None.
        """"""
        prop = self.find_property(property_name)
        if prop:
            return prop.get_value()

        return None","Get a property's value.

        property_name -- the property to get the value of

        Returns the properties value, if found, else None.",
"def get_properties(self):
        """"""
        Get a mapping of all properties and their values.

        Returns a dictionary of property_name -> value.
        """"""
        return {prop.get_name(): prop.get_value()
                for prop in self.properties.values()}","Get a mapping of all properties and their values.

        Returns a dictionary of property_name -> value.",
"def set_property(self, property_name, value):
        """"""
        Set a property value.

        property_name -- name of the property to set
        value -- value to set
        """"""
        prop = self.find_property(property_name)
        if not prop:
            return

        prop.set_value(value)","Set a property value.

        property_name -- name of the property to set
        value -- value to set",
"def add_event(self, event):
        """"""
        Add a new event and notify subscribers.

        event -- the event that occurred
        """"""
        self.events.append(event)
        self.event_notify(event)","Add a new event and notify subscribers.

        event -- the event that occurred",
"def add_available_event(self, name, metadata):
        """"""
        Add an available event.

        name -- name of the event
        metadata -- event metadata, i.e. type, description, etc., as a dict
        """"""
        if metadata is None:
            metadata = {}

        self.available_events[name] = {
            'metadata': metadata,
            'subscribers': set(),
        }","Add an available event.

        name -- name of the event
        metadata -- event metadata, i.e. type, description, etc., as a dict",
"def remove_subscriber(self, ws):
        """"""
        Remove a websocket subscriber.

        ws -- the websocket
        """"""
        if ws in self.subscribers:
            self.subscribers.remove(ws)

        for name in self.available_events:
            self.remove_event_subscriber(name, ws)","Remove a websocket subscriber.

        ws -- the websocket",
"def add_event_subscriber(self, name, ws):
        """"""
        Add a new websocket subscriber to an event.

        name -- name of the event
        ws -- the websocket
        """"""
        if name in self.available_events:
            self.available_events[name]['subscribers'].add(ws)","Add a new websocket subscriber to an event.

        name -- name of the event
        ws -- the websocket",
"def remove_event_subscriber(self, name, ws):
        """"""
        Remove a websocket subscriber from an event.

        name -- name of the event
        ws -- the websocket
        """"""
        if name in self.available_events and \
                ws in self.available_events[name]['subscribers']:
            self.available_events[name]['subscribers'].remove(ws)","Remove a websocket subscriber from an event.

        name -- name of the event
        ws -- the websocket",
"def _on_model_save(sender, **kwargs):
        """"""When a model gets created or updated.""""""

        created, instance = kwargs['created'], kwargs['instance']

        if created:
            signals.create.send(sender, pk=instance.pk)
        else:
            signals.update.send(sender, pk=instance.pk)",When a model gets created or updated.,
"def _on_model_delete(sender, **kwargs):
        """"""When a model gets deleted.""""""

        instance = kwargs['instance']
        signals.delete.send(sender, pk=instance.pk)",When a model gets deleted.,
"def as_sql(self, compiler, connection):
        """"""Compiles this expression into SQL.""""""

        qn = compiler.quote_name_unless_alias
        return ""%s.%s->'%s'"" % (qn(self.alias), qn(self.target.column), self.hstore_key), []",Compiles this expression into SQL.,
"def relabeled_clone(self, relabels):
        """"""Gets a re-labeled clone of this expression.""""""

        return self.__class__(
            relabels.get(self.alias, self.alias),
            self.target,
            self.hstore_key,
            self.output_field
        )",Gets a re-labeled clone of this expression.,
"def resolve_expression(self, *args, **kwargs) -> HStoreColumn:
        """"""Resolves the expression into a :see:HStoreColumn expression.""""""

        original_expression = super().resolve_expression(*args, **kwargs)
        expression = HStoreColumn(
            original_expression.alias,
            original_expression.target,
            self.key
        )
        return expression",Resolves the expression into a :see:HStoreColumn expression.,
"def as_sql(self, compiler, connection):
        """"""Compiles this expression into SQL.""""""

        sql, params = super().as_sql(compiler, connection)
        return 'EXTRACT(epoch FROM {})'.format(sql), params",Compiles this expression into SQL.,
"def create_model(self, model):
        """"""Ran when a new model is created.""""""

        for field in model._meta.local_fields:
            if not isinstance(field, HStoreField):
                continue

            self.add_field(model, field)",Ran when a new model is created.,
"def delete_model(self, model):
        """"""Ran when a model is being deleted.""""""

        for field in model._meta.local_fields:
            if not isinstance(field, HStoreField):
                continue

            self.remove_field(model, field)",Ran when a model is being deleted.,
"def add_field(self, model, field):
        """"""Ran when a field is added to a model.""""""

        for key in self._iterate_required_keys(field):
            self._create_hstore_required(
                model._meta.db_table,
                field,
                key
            )",Ran when a field is added to a model.,
"def remove_field(self, model, field):
        """"""Ran when a field is removed from a model.""""""

        for key in self._iterate_required_keys(field):
            self._drop_hstore_required(
                model._meta.db_table,
                field,
                key
            )",Ran when a field is removed from a model.,
"def _drop_hstore_required(self, table_name, field, key):
        """"""Drops a REQUIRED CONSTRAINT for the specified hstore key.""""""

        name = self._required_constraint_name(
            table_name, field, key)

        sql = self.sql_hstore_required_drop.format(
            table=self.quote_name(table_name),
            name=self.quote_name(name)
        )
        self.execute(sql)",Drops a REQUIRED CONSTRAINT for the specified hstore key.,
"def deconstruct(self):
        """"""Serializes the :see:ConditionalUniqueIndex for the migrations file.""""""
        path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__)
        path = path.replace('django.db.models.indexes', 'django.db.models')
        return path, (), {'fields': self.fields, 'name': self.name, 'condition': self.condition}",Serializes the :see:ConditionalUniqueIndex for the migrations file.,
"def create_command(text, commands):
    """"""Creates a custom setup.py command.""""""

    class CustomCommand(BaseCommand):
        description = text

        def run(self):
            for cmd in commands:
                subprocess.check_call(cmd)

    return CustomCommand",Creates a custom setup.py command.,
"def create_model(self, model):
        """"""Ran when a new model is created.""""""

        super().create_model(model)

        for mixin in self.post_processing_mixins:
            mixin.create_model(model)",Ran when a new model is created.,
"def delete_model(self, model):
        """"""Ran when a model is being deleted.""""""

        for mixin in self.post_processing_mixins:
            mixin.delete_model(model)

        super().delete_model(model)",Ran when a model is being deleted.,
"def add_field(self, model, field):
        """"""Ran when a field is added to a model.""""""

        super(SchemaEditor, self).add_field(model, field)

        for mixin in self.post_processing_mixins:
            mixin.add_field(model, field)",Ran when a field is added to a model.,
"def remove_field(self, model, field):
        """"""Ran when a field is removed from a model.""""""

        for mixin in self.post_processing_mixins:
            mixin.remove_field(model, field)

        super(SchemaEditor, self).remove_field(model, field)",Ran when a field is removed from a model.,
"def alter_field(self, model, old_field, new_field, strict=False):
        """"""Ran when the configuration on a field changed.""""""

        super(SchemaEditor, self).alter_field(
            model, old_field, new_field, strict
        )

        for mixin in self.post_processing_mixins:
            mixin.alter_field(
                model, old_field, new_field, strict
            )",Ran when the configuration on a field changed.,
"def _form_returning(self):
        """"""Builds the RETURNING part of the query.""""""

        qn = self.connection.ops.quote_name
        return ' RETURNING %s' % qn(self.query.model._meta.pk.attname)",Builds the RETURNING part of the query.,
"def as_sql(self, return_id=False):
        """"""Builds the SQL INSERT statement.""""""

        queries = [
            self._rewrite_insert(sql, params, return_id)
            for sql, params in super().as_sql()
        ]

        return queries",Builds the SQL INSERT statement.,
"def _format_field_name(self, field_name) -> str:
        """"""Formats a field's name for usage in SQL.

        Arguments:
            field_name:
                The field name to format.

        Returns:
            The specified field name formatted for
            usage in SQL.
        """"""

        field = self._get_model_field(field_name)
        return self.qn(field.column)","Formats a field's name for usage in SQL.

        Arguments:
            field_name:
                The field name to format.

        Returns:
            The specified field name formatted for
            usage in SQL.",
"def add_field(self, model, field):
        """"""Ran when a field is added to a model.""""""

        for keys in self._iterate_uniqueness_keys(field):
            self._create_hstore_unique(
                model,
                field,
                keys
            )",Ran when a field is added to a model.,
"def remove_field(self, model, field):
        """"""Ran when a field is removed from a model.""""""

        for keys in self._iterate_uniqueness_keys(field):
            self._drop_hstore_unique(
                model,
                field,
                keys
            )",Ran when a field is removed from a model.,
"def _drop_hstore_unique(self, model, field, keys):
        """"""Drops a UNIQUE constraint for the specified hstore keys.""""""

        name = self._unique_constraint_name(
            model._meta.db_table, field, keys)
        sql = self.sql_hstore_unique_drop.format(name=self.quote_name(name))
        self.execute(sql)",Drops a UNIQUE constraint for the specified hstore keys.,
"def add_condition(self, field, value: Any) -> None:
        """"""Adds an extra condition to this join.

        Arguments:
            field:
                The field that the condition will apply to.

            value:
                The value to compare.
        """"""

        self.extra_conditions.append((field, value))","Adds an extra condition to this join.

        Arguments:
            field:
                The field that the condition will apply to.

            value:
                The value to compare.",
"def random_playout(self, board):
        """""" random play until both players pass """"""
        for x in range(MAXMOVES):  # XXX while not self.finished?
            if board.finished:
                break
            board.move(board.random_move())",random play until both players pass,
"def combinations(l):
    """"""Pure-Python implementation of itertools.combinations(l, 2).""""""
    result = []
    for x in xrange(len(l) - 1):
        ls = l[x + 1:]
        for y in ls:
            result.append((l[x], y))
    return result","Pure-Python implementation of itertools.combinations(l, 2).",
"def GetDomain(self):
        """"""Returns the domain of the B-Spline""""""
        return (self.knots[self.degree - 1],
                self.knots[len(self.knots) - self.degree])",Returns the domain of the B-Spline,
"def _parse_posts(self, raw_posts):
        """"""Parse posts and returns in order.""""""

        parsed_posts = self.parse_json(raw_posts)

        # Posts are not sorted. The order is provided by
        # 'order' key.
        for post_id in parsed_posts['order']:
            yield parsed_posts['posts'][post_id]",Parse posts and returns in order.,
"def posts(self, channel, page=None):
        """"""Fetch the history of a channel.""""""

        entrypoint = self.RCHANNELS + '/' + channel + '/' + self.RPOSTS

        params = {
            self.PPER_PAGE: self.max_items
        }

        if page is not None:
            params[self.PPAGE] = page

        response = self._fetch(entrypoint, params)

        return response",Fetch the history of a channel.,
"def user(self, user):
        """"""Fetch user data.""""""

        entrypoint = self.RUSERS + '/' + user
        response = self._fetch(entrypoint, None)

        return response",Fetch user data.,
"def _pre_init(self):
        """"""Initialize mailing lists directory path""""""

        if not self.parsed_args.mboxes_path:
            base_path = os.path.expanduser('~/.perceval/mailinglists/')
            dirpath = os.path.join(base_path, self.parsed_args.url)
        else:
            dirpath = self.parsed_args.mboxes_path

        setattr(self.parsed_args, 'dirpath', dirpath)",Initialize mailing lists directory path,
"def fetch(self, category=CATEGORY_ENTRY):
        """"""Fetch the entries from the url.

        The method retrieves all entries from a RSS url

        :param category: the category of items to fetch

        :returns: a generator of entries
        """"""
        kwargs = {}
        items = super().fetch(category, **kwargs)

        return items","Fetch the entries from the url.

        The method retrieves all entries from a RSS url

        :param category: the category of items to fetch

        :returns: a generator of entries",
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return RSSClient(self.url, self.archive, from_archive)",Init client,
"def setup_cmd_parser(cls):
        """"""Returns the RSS argument parser.""""""

        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,
                                              archive=True)

        # Required arguments
        parser.parser.add_argument('url',
                                   help=""URL of the RSS feed"")

        return parser",Returns the RSS argument parser.,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return BugzillaRESTClient(self.url, user=self.user, password=self.password, api_token=self.api_token,
                                  archive=self.archive, from_archive=from_archive)",Init client,
"def comments(self, *bug_ids):
        """"""Get the comments of the given bugs.

        :param bug_ids: list of bug identifiers
        """"""
        # Hack. The first value must be a valid bug id
        resource = urijoin(self.RBUG, bug_ids[0], self.RCOMMENT)

        params = {
            self.PIDS: bug_ids
        }

        response = self.call(resource, params)

        return response","Get the comments of the given bugs.

        :param bug_ids: list of bug identifiers",
"def history(self, *bug_ids):
        """"""Get the history of the given bugs.

        :param bug_ids: list of bug identifiers
        """"""
        resource = urijoin(self.RBUG, bug_ids[0], self.RHISTORY)

        params = {
            self.PIDS: bug_ids
        }

        response = self.call(resource, params)

        return response","Get the history of the given bugs.

        :param bug_ids: list of bug identifiers",
"def __get_award_emoji(self, item_type, item_id):
        """"""Get award emojis for issue/merge request""""""

        emojis = []

        group_emojis = self.client.emojis(item_type, item_id)
        for raw_emojis in group_emojis:

            for emoji in json.loads(raw_emojis):
                emojis.append(emoji)

        return emojis",Get award emojis for issue/merge request,
"def issues(self, from_date=None):
        """"""Get the issues from pagination""""""

        payload = {
            'state': 'all',
            'order_by': 'updated_at',
            'sort': 'asc',
            'per_page': PER_PAGE
        }

        if from_date:
            payload['updated_after'] = from_date.isoformat()

        return self.fetch_items(GitLabClient.ISSUES, payload)",Get the issues from pagination,
"def merge(self, merge_id):
        """"""Get the merge full data""""""

        path = urijoin(self.base_url,
                       GitLabClient.PROJECTS, self.owner + '%2F' + self.repository,
                       GitLabClient.MERGES, merge_id)

        response = self.fetch(path)

        return response.text",Get the merge full data,
"def merge_versions(self, merge_id):
        """"""Get the merge versions from pagination""""""

        payload = {
            'order_by': 'updated_at',
            'sort': 'asc',
            'per_page': PER_PAGE
        }

        path = urijoin(GitLabClient.MERGES, str(merge_id), GitLabClient.VERSIONS)
        return self.fetch_items(path, payload)",Get the merge versions from pagination,
"def merge_version(self, merge_id, version_id):
        """"""Get merge version detail""""""

        path = urijoin(self.base_url,
                       GitLabClient.PROJECTS, self.owner + '%2F' + self.repository,
                       GitLabClient.MERGES, merge_id, GitLabClient.VERSIONS, version_id)

        response = self.fetch(path)

        return response.text",Get merge version detail,
"def notes(self, item_type, item_id):
        """"""Get the notes from pagination""""""

        payload = {
            'order_by': 'updated_at',
            'sort': 'asc',
            'per_page': PER_PAGE
        }

        path = urijoin(item_type, str(item_id), GitLabClient.NOTES)

        return self.fetch_items(path, payload)",Get the notes from pagination,
"def emojis(self, item_type, item_id):
        """"""Get emojis from pagination""""""

        payload = {
            'order_by': 'updated_at',
            'sort': 'asc',
            'per_page': PER_PAGE
        }

        path = urijoin(item_type, str(item_id), GitLabClient.EMOJI)

        return self.fetch_items(path, payload)",Get emojis from pagination,
"def note_emojis(self, item_type, item_id, note_id):
        """"""Get emojis of a note""""""

        payload = {
            'order_by': 'updated_at',
            'sort': 'asc',
            'per_page': PER_PAGE
        }

        path = urijoin(item_type, str(item_id), GitLabClient.NOTES,
                       str(note_id), GitLabClient.EMOJI)

        return self.fetch_items(path, payload)",Get emojis of a note,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return SlackClient(self.api_token, self.max_items, self.archive, from_archive)",Init client,
"def channel_info(self, channel):
        """"""Fetch information about a channel.""""""

        resource = self.RCHANNEL_INFO

        params = {
            self.PCHANNEL: channel,
        }

        response = self._fetch(resource, params)

        return response",Fetch information about a channel.,
"def user(self, user_id):
        """"""Fetch user info.""""""

        resource = self.RUSER_INFO

        params = {
            self.PUSER: user_id
        }

        response = self._fetch(resource, params)

        return response",Fetch user info.,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return BugzillaClient(self.url, user=self.user, password=self.password,
                              max_bugs_csv=self.max_bugs_csv,
                              archive=self.archive, from_archive=from_archive)",Init client,
"def logout(self):
        """"""Logout from the server.""""""

        params = {
            self.PLOGOUT: '1'
        }

        self.call(self.CGI_LOGIN, params)
        self._close_http_session()

        logger.debug(""Bugzilla user logged out from %s"",
                     self.base_url)",Logout from the server.,
"def metadata(self):
        """"""Get metadata information in XML format.""""""

        params = {
            self.PCTYPE: self.CTYPE_XML
        }

        response = self.call(self.CGI_BUG, params)

        return response",Get metadata information in XML format.,
"def bugs(self, *bug_ids):
        """"""Get the information of a list of bugs in XML format.

        :param bug_ids: list of bug identifiers
        """"""
        params = {
            self.PBUG_ID: bug_ids,
            self.PCTYPE: self.CTYPE_XML,
            self.PEXCLUDE_FIELD: 'attachmentdata'
        }

        response = self.call(self.CGI_BUG, params)

        return response","Get the information of a list of bugs in XML format.

        :param bug_ids: list of bug identifiers",
"def bug_activity(self, bug_id):
        """"""Get the activity of a bug in HTML format.

        :param bug_id: bug identifier
        """"""
        params = {
            self.PBUG_ID: bug_id
        }

        response = self.call(self.CGI_BUG_ACTIVITY, params)

        return response","Get the activity of a bug in HTML format.

        :param bug_id: bug identifier",
"def comments(self, group, event_id):
        """"""Fetch the comments of a given event.""""""

        resource = urijoin(group, self.REVENTS, event_id, self.RCOMMENTS)

        params = {
            self.PPAGE: self.max_items
        }

        for page in self._fetch(resource, params):
            yield page",Fetch the comments of a given event.,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return AskbotClient(self.url, self.archive, from_archive)",Init client,
"def reviews(self, last_item, filter_=None):
        """"""Get the reviews starting from last_item.""""""

        cmd = self._get_gerrit_cmd(last_item, filter_)

        logger.debug(""Getting reviews with command: %s"", cmd)
        raw_data = self.__execute(cmd)
        raw_data = str(raw_data, ""UTF-8"")

        return raw_data",Get the reviews starting from last_item.,
"def __execute(self, cmd):
        """"""Execute gerrit command""""""

        if self.from_archive:
            response = self.__execute_from_archive(cmd)
        else:
            response = self.__execute_from_remote(cmd)

        return response",Execute gerrit command,
"def __execute_from_archive(self, cmd):
        """"""Execute gerrit command against the archive""""""

        cmd = self.sanitize_for_archive(cmd)
        response = self.archive.retrieve(cmd, None, None)

        if isinstance(response, RuntimeError):
            raise response

        return response",Execute gerrit command against the archive,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return LaunchpadClient(self.distribution, self.package, self.items_per_page,
                               self.sleep_time, self.archive, from_archive)",Init client,
"def __fetch_issue_data(self, issue_id):
        """"""Get data associated to an issue""""""

        raw_issue = self.client.issue(issue_id)
        issue = json.loads(raw_issue)

        return issue",Get data associated to an issue,
"def __fetch_issue_attachments(self, issue_id):
        """"""Get attachments of an issue""""""

        for attachments_raw in self.client.issue_collection(issue_id, ""attachments""):
            attachments = json.loads(attachments_raw)

            for attachment in attachments['entries']:
                yield attachment",Get attachments of an issue,
"def __fetch_issue_messages(self, issue_id):
        """"""Get messages of an issue""""""

        for messages_raw in self.client.issue_collection(issue_id, ""messages""):
            messages = json.loads(messages_raw)

            for msg in messages['entries']:
                msg['owner_data'] = self.__fetch_user_data('{OWNER}', msg['owner_link'])
                yield msg",Get messages of an issue,
"def __fetch_issue_activities(self, issue_id):
        """"""Get activities on an issue""""""

        for activities_raw in self.client.issue_collection(issue_id, ""activity""):
            activities = json.loads(activities_raw)

            for act in activities['entries']:
                act['person_data'] = self.__fetch_user_data('{PERSON}', act['person_link'])
                yield act",Get activities on an issue,
"def __fetch_user_data(self, tag_type, user_link):
        """"""Get data associated to an user""""""

        user_name = self.client.user_name(user_link)

        user = {}

        if not user_name:
            return user

        user_raw = self.client.user(user_name)
        user = json.loads(user_raw)

        return user",Get data associated to an user,
"def issues(self, start=None):
        """"""Get the issues from pagination""""""

        payload = self.__build_payload(size=self.items_per_page, operation=True, startdate=start)
        path = self.__get_url_project()
        return self.__fetch_items(path=path, payload=payload)",Get the issues from pagination,
"def issue(self, issue_id):
        """"""Get the issue data by its ID""""""

        path = urijoin(""bugs"", str(issue_id))
        url_issue = self.__get_url(path)
        raw_text = self.__send_request(url_issue)

        return raw_text",Get the issue data by its ID,
"def __get_url_project(self):
        """"""Build URL project""""""

        if self.package:
            url = self.__get_url_distribution_package()
        else:
            url = self.__get_url_distribution()

        return url",Build URL project,
"def __send_request(self, url, params=None):
        """"""Send request""""""

        r = self.fetch(url, payload=params)
        return r.text",Send request,
"def __fetch(self, url, payload):
        """"""Fetch requests from groupsio API""""""

        r = requests.get(url, params=payload, auth=self.auth, verify=self.verify)
        try:
            r.raise_for_status()
        except requests.exceptions.HTTPError as e:
            raise e

        return r",Fetch requests from groupsio API,
"def _copy_mbox(self, mbox):
        """"""Copy the contents of a mbox to a temporary file""""""

        tmp_path = tempfile.mktemp(prefix='perceval_')

        with mbox.container as f_in:
            with open(tmp_path, mode='wb') as f_out:
                for l in f_in:
                    f_out.write(l)
        return tmp_path",Copy the contents of a mbox to a temporary file,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return TwitterClient(self.api_token, self.max_items,
                             self.sleep_for_rate, self.min_rate_to_sleep, self.sleep_time,
                             self.archive, from_archive)",Init client,
"def fetch(self, category=CATEGORY_HITS):
        """"""Fetch data from Google API.

        The method retrieves a list of hits for some
        given keywords using the Google API.

        :param category: the category of items to fetch

        :returns: a generator of data
        """"""
        kwargs = {}
        items = super().fetch(category, **kwargs)

        return items","Fetch data from Google API.

        The method retrieves a list of hits for some
        given keywords using the Google API.

        :param category: the category of items to fetch

        :returns: a generator of data",
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return GoogleHitsClient(self.sleep_time, self.max_retries,
                                archive=self.archive, from_archive=from_archive)",Init client,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return GitHubClient(self.owner, self.repository, self.api_token, self.base_url,
                            self.sleep_for_rate, self.min_rate_to_sleep,
                            self.sleep_time, self.max_retries,
                            self.archive, from_archive)",Init client,
"def __fetch_repo_info(self):
        """"""Get repo info about stars, watchers and forks""""""

        raw_repo = self.client.repo()
        repo = json.loads(raw_repo)

        fetched_on = datetime_utcnow()
        repo['fetched_on'] = fetched_on.timestamp()

        yield repo","Get repo info about stars, watchers and forks",
"def __get_issue_assignees(self, raw_assignees):
        """"""Get issue assignees""""""

        assignees = []
        for ra in raw_assignees:
            assignees.append(self.__get_user(ra['login']))

        return assignees",Get issue assignees,
"def __get_pull_commits(self, pr_number):
        """"""Get pull request commit hashes""""""

        hashes = []
        group_pull_commits = self.client.pull_commits(pr_number)

        for raw_pull_commits in group_pull_commits:

            for commit in json.loads(raw_pull_commits):
                commit_hash = commit['sha']
                hashes.append(commit_hash)

        return hashes",Get pull request commit hashes,
"def __get_user(self, login):
        """"""Get user and org data for the login""""""

        user = {}

        if not login:
            return user

        user_raw = self.client.user(login)
        user = json.loads(user_raw)
        user_orgs_raw = \
            self.client.user_orgs(login)
        user['organizations'] = json.loads(user_orgs_raw)

        return user",Get user and org data for the login,
"def issue_reactions(self, issue_number):
        """"""Get reactions of an issue""""""

        payload = {
            'per_page': PER_PAGE,
            'direction': 'asc',
            'sort': 'updated'
        }

        path = urijoin(""issues"", str(issue_number), ""reactions"")
        return self.fetch_items(path, payload)",Get reactions of an issue,
"def repo(self):
        """"""Get repository data""""""

        path = urijoin(self.base_url, 'repos', self.owner, self.repository)

        r = self.fetch(path)
        repo = r.text

        return repo",Get repository data,
"def pull_requested_reviewers(self, pr_number):
        """"""Get pull requested reviewers""""""

        requested_reviewers_url = urijoin(""pulls"", str(pr_number), ""requested_reviewers"")
        return self.fetch_items(requested_reviewers_url, {})",Get pull requested reviewers,
"def pull_commits(self, pr_number):
        """"""Get pull request commits""""""

        payload = {
            'per_page': PER_PAGE,
        }

        commit_url = urijoin(""pulls"", str(pr_number), ""commits"")
        return self.fetch_items(commit_url, payload)",Get pull request commits,
"def pull_review_comments(self, pr_number):
        """"""Get pull request review comments""""""

        payload = {
            'per_page': PER_PAGE,
            'direction': 'asc',
            'sort': 'updated'
        }

        comments_url = urijoin(""pulls"", str(pr_number), ""comments"")
        return self.fetch_items(comments_url, payload)",Get pull request review comments,
"def pull_review_comment_reactions(self, comment_id):
        """"""Get reactions of a review comment""""""

        payload = {
            'per_page': PER_PAGE,
            'direction': 'asc',
            'sort': 'updated'
        }

        path = urijoin(""pulls"", ""comments"", str(comment_id), ""reactions"")
        return self.fetch_items(path, payload)",Get reactions of a review comment,
"def _search_files(self):
        """"""Retrieve the file paths stored under the base path.""""""

        for root, _, files in os.walk(self.dirpath):
            for filename in files:
                location = os.path.join(root, filename)
                yield location",Retrieve the file paths stored under the base path.,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return RedmineClient(self.url, self.api_token, self.archive, from_archive)",Init client,
"def user(self, user_id):
        """"""Get the information of the given user.

        :param user_id: user identifier
        """"""
        resource = urijoin(self.RUSERS, str(user_id) + self.CJSON)

        params = {}

        response = self._call(resource, params)

        return response","Get the information of the given user.

        :param user_id: user identifier",
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return DockerHubClient(archive=self.archive, from_archive=from_archive)",Init client,
"def repository(self, owner, repository):
        """"""Fetch information about a repository.""""""

        url = urijoin(self.base_url, self.RREPOSITORY, owner, repository)

        logger.debug(""DockerHub client requests: %s"", url)

        response = self.fetch(url)

        return response.text",Fetch information about a repository.,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return JiraClient(self.url, self.project, self.user, self.password,
                          self.verify, self.cert, self.max_results,
                          self.archive, from_archive)",Init client,
"def __get_issue_comments(self, issue_id):
        """"""Get issue comments""""""

        comments = []
        page_comments = self.client.get_comments(issue_id)

        for page_comment in page_comments:
            raw_comments = json.loads(page_comment)

            comments.extend(raw_comments['comments'])

        return comments",Get issue comments,
"def get_issues(self, from_date):
        """"""Retrieve all the issues from a given date.

        :param from_date: obtain issues updated since this date
        """"""
        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, 'search')
        issues = self.get_items(from_date, url)

        return issues","Retrieve all the issues from a given date.

        :param from_date: obtain issues updated since this date",
"def get_comments(self, issue_id):
        """"""Retrieve all the comments of a given issue.

        :param issue_id: ID of the issue
        """"""
        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, self.ISSUE, issue_id, self.COMMENT)
        comments = self.get_items(DEFAULT_DATETIME, url, expand_fields=False)

        return comments","Retrieve all the comments of a given issue.

        :param issue_id: ID of the issue",
"def get_fields(self):
        """"""Retrieve all the fields available.""""""

        url = urijoin(self.base_url, self.RESOURCE, self.VERSION_API, 'field')
        req = self.fetch(url)

        return req.text",Retrieve all the fields available.,
"def fetch(self, category=CATEGORY_BUILD):
        """"""Fetch the builds from the url.

        The method retrieves, from a Jenkins url, the
        builds updated since the given date.

        :param category: the category of items to fetch

        :returns: a generator of builds
        """"""

        kwargs = {}
        items = super().fetch(category, **kwargs)

        return items","Fetch the builds from the url.

        The method retrieves, from a Jenkins url, the
        builds updated since the given date.

        :param category: the category of items to fetch

        :returns: a generator of builds",
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return JenkinsClient(self.url, self.blacklist_jobs, self.detail_depth,
                             self.sleep_time,
                             archive=self.archive, from_archive=from_archive)",Init client,
"def get_jobs(self):
        """""" Retrieve all jobs""""""

        url_jenkins = urijoin(self.base_url, ""api"", ""json"")

        response = self.fetch(url_jenkins)
        return response.text",Retrieve all jobs,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return StackExchangeClient(self.site, self.tagged, self.api_token, self.max_questions,
                                   self.archive, from_archive)",Init client,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return MediaWikiClient(self.url, self.archive, from_archive)",Init client,
"def __get_max_date(self, reviews):
        """"""""Get the max date in unixtime format from reviews.""""""
        max_ts = 0
        for review in reviews:
            ts = str_to_datetime(review['timestamp'])
            ts = datetime_to_utc(ts)
            if ts.timestamp() > max_ts:
                max_ts = ts.timestamp()
        return max_ts",Get the max date in unixtime format from reviews.,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return TelegramBotClient(self.bot_token, self.archive, from_archive)",Init client,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return NNTTPClient(self.host, self.archive, from_archive)",Init client,
"def _fetch_article(self, article_id):
        """"""Fetch article data

        :param article_id: id of the article to fetch
        """"""
        fetched_data = self.handler.article(article_id)
        data = {
            'number': fetched_data[1].number,
            'message_id': fetched_data[1].message_id,
            'lines': fetched_data[1].lines
        }

        return data","Fetch article data

        :param article_id: id of the article to fetch",
"def __list_supybot_archives(self):
        """"""List the filepath of the archives stored in dirpath""""""

        archives = []

        for root, _, files in os.walk(self.dirpath):
            for filename in files:
                location = os.path.join(root, filename)
                archives.append(location)

        return archives",List the filepath of the archives stored in dirpath,
"def _parse_supybot_timestamp(self, line):
        """"""Parse timestamp section""""""

        m = self.SUPYBOT_TIMESTAMP_REGEX.match(line)

        if not m:
            msg = ""date expected on line %s"" % (str(self.nline))
            raise ParseError(cause=msg)

        ts = m.group('ts')
        msg = m.group('msg')

        return ts, msg",Parse timestamp section,
"def topic(self, topic_id):
        """"""Retrive the topic with `topic_id` identifier.

        :param topic_id: identifier of the topic to retrieve
        """"""
        params = {
            self.PKEY: self.api_key
        }

        # http://example.com/t/8.json
        response = self._call(self.TOPIC, topic_id,
                              params=params)

        return response","Retrive the topic with `topic_id` identifier.

        :param topic_id: identifier of the topic to retrieve",
"def post(self, post_id):
        """"""Retrieve the post whit `post_id` identifier.

        :param post_id: identifier of the post to retrieve
        """"""
        params = {
            self.PKEY: self.api_key
        }

        # http://example.com/posts/10.json
        response = self._call(self.POSTS, post_id,
                              params=params)

        return response","Retrieve the post whit `post_id` identifier.

        :param post_id: identifier of the post to retrieve",
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return ConduitClient(self.url, self.api_token,
                             self.max_retries, self.sleep_time,
                             self.archive, from_archive)",Init client,
"def transactions(self, *phids):
        """"""Retrieve tasks transactions.

        :param phids: list of tasks identifiers
        """"""
        params = {
            self.PIDS: phids
        }

        response = self._call(self.MANIPHEST_TRANSACTIONS, params)

        return response","Retrieve tasks transactions.

        :param phids: list of tasks identifiers",
"def users(self, *phids):
        """"""Retrieve users.

        :params phids: list of users identifiers
        """"""
        params = {
            self.PHIDS: phids
        }

        response = self._call(self.PHAB_USERS, params)

        return response","Retrieve users.

        :params phids: list of users identifiers",
"def phids(self, *phids):
        """"""Retrieve data about PHIDs.

        :params phids: list of PHIDs
        """"""
        params = {
            self.PHIDS: phids
        }

        response = self._call(self.PHAB_PHIDS, params)

        return response","Retrieve data about PHIDs.

        :params phids: list of PHIDs",
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return ConfluenceClient(self.url, archive=self.archive, from_archive=from_archive)",Init client,
"def readString(self, st):
        """"""Parse a WFS capabilities document, returning an
        instance of WFSCapabilitiesInfoset

        string should be an XML capabilities document
        """"""
        if not isinstance(st, str) and not isinstance(st, bytes):
            raise ValueError(""String must be of type string or bytes, not %s"" % type(st))
        return etree.fromstring(st)","Parse a WFS capabilities document, returning an
        instance of WFSCapabilitiesInfoset

        string should be an XML capabilities document",
"def _parse_result(self):
        ''' Parse the result element of the observation type '''
        if self.result is not None:
            result = self.result.find(nspv(
                     ""wml2:MeasurementTimeseries""))
            self.result = MeasurementTimeseries(result)",Parse the result element of the observation type,
"def conformance(self):
        """"""
        implements Requirement 5 (/req/core/conformance-op)

        @returns: conformance object
        """"""

        url = self._build_url('conformance')
        LOGGER.debug('Request: {}'.format(url))
        response = requests.get(url, headers=REQUEST_HEADERS).json()
        return response","implements Requirement 5 (/req/core/conformance-op)

        @returns: conformance object",
"def _get_elements(complex_type, root):
    """"""Get attribute elements
    """"""

    found_elements = []
    element = findall(root, '{%s}complexType' % XS_NAMESPACE,
                       attribute_name='name', attribute_value=complex_type)[0]
    found_elements = findall(element, '{%s}element' % XS_NAMESPACE)

    return found_elements",Get attribute elements,
"def tv_list(self, **kwargs):
        """"""
        Get the list of TV genres.

        Args:
            language: (optional) ISO 639-1 code.

        Returns:
            A dict respresentation of the JSON returned from the API.
        """"""
        path = self._get_path('tv_list')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","Get the list of TV genres.

        Args:
            language: (optional) ISO 639-1 code.

        Returns:
            A dict respresentation of the JSON returned from the API.",
"def keywords(self):
        """"""
        Get the plot keywords for a specific movie id.

        Returns:
            A dict representation of the JSON returned from the API.
        """"""
        path = self._get_id_path('keywords')

        response = self._GET(path)
        self._set_attrs_to_values(response)
        return response","Get the plot keywords for a specific movie id.

        Returns:
            A dict representation of the JSON returned from the API.",
"def info(self, **kwargs):
        """"""
        Get the system wide configuration info.

        Returns:
            A dict respresentation of the JSON returned from the API.
        """"""
        path = self._get_path('info')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","Get the system wide configuration info.

        Returns:
            A dict respresentation of the JSON returned from the API.",
"def list(self, **kwargs):
        """"""
        Get the list of supported certifications for movies.

        Returns:
            A dict respresentation of the JSON returned from the API.
        """"""
        path = self._get_path('movie_list')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","Get the list of supported certifications for movies.

        Returns:
            A dict respresentation of the JSON returned from the API.",
"def guest_session_new(self, **kwargs):
        """"""
        Generate a guest session id.

        Returns:
            A dict respresentation of the JSON returned from the API.
        """"""
        path = self._get_path('guest_session_new')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","Generate a guest session id.

        Returns:
            A dict respresentation of the JSON returned from the API.",
"def credits(self, **kwargs):
        """"""
        Get the cast & crew credits for a TV season by season number.

        Returns:
            A dict respresentation of the JSON returned from the API.
        """"""
        path = self._get_series_id_season_number_path('credits')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","Get the cast & crew credits for a TV season by season number.

        Returns:
            A dict respresentation of the JSON returned from the API.",
"def cook_ref_set(ref, n=4):
    '''Takes a reference sentences for a single segment
    and returns an object that encapsulates everything that BLEU
    needs to know about them.  Also provides a set cause bleualign wants it'''
    ref = normalize(ref)
    counts = count_ngrams(ref, n)
    return (len(ref), counts, frozenset(counts))","Takes a reference sentences for a single segment
    and returns an object that encapsulates everything that BLEU
    needs to know about them.  Also provides a set cause bleualign wants it",
"def register_json(self, obj):
        """"""Register Descriptors from json descriptor objects.

        Parameters:
            obj(list or dict): descriptors to register

        """"""
        if not isinstance(obj, list):
            obj = [obj]

        self.register(Descriptor.from_json(j) for j in obj)","Register Descriptors from json descriptor objects.

        Parameters:
            obj(list or dict): descriptors to register",
"def is_descriptor_class(desc, include_abstract=False):
    r""""""Check calculatable descriptor class or not.

    Returns:
        bool

    """"""
    return (
        isinstance(desc, type)
        and issubclass(desc, Descriptor)
        and (True if include_abstract else not inspect.isabstract(desc))
    )","r""""""Check calculatable descriptor class or not.

    Returns:
        bool",
"def to_json(self):
        """"""Convert to json serializable dictionary.

        Returns:
            dict: dictionary of descriptor

        """"""
        d, ps = self._to_json()
        if len(ps) == 0:
            return {""name"": d}
        else:
            return {""name"": d, ""args"": ps}","Convert to json serializable dictionary.

        Returns:
            dict: dictionary of descriptor",
"def coord(self):
        """"""Get 3D coordinate.

        Returns:
            numpy.array[3, N]: coordinate matrix

        """"""
        if not self.require_3D:
            self.fail(AttributeError(""use 3D coordinate in 2D descriptor""))

        return self._context.get_coord(self)","Get 3D coordinate.

        Returns:
            numpy.array[3, N]: coordinate matrix",
"def rethrow_zerodiv(self):
        """"""[contextmanager] treat zero div as known exception.""""""
        with np.errstate(divide=""raise"", invalid=""raise""):
            try:
                yield
            except (FloatingPointError, ZeroDivisionError) as e:
                self.fail(ZeroDivisionError(*e.args))",[contextmanager] treat zero div as known exception.,
"def surface_area(self):
        r""""""Calculate all atomic surface area.

        :rtype: [float]
        """"""
        return [self.atomic_sa(i) for i in range(len(self.rads))]","r""""""Calculate all atomic surface area.

        :rtype: [float]",
"def fill_missing(self, value=np.nan):
        r""""""Replace missing value to ""value"".

        Parameters:
            value: value that missing value is replaced

        Returns:
            Result

        """"""
        return self.__class__(
            self.mol,
            [(value if is_missing(v) else v) for v in self.values()],
            self.keys(),
        )","r""""""Replace missing value to ""value"".

        Parameters:
            value: value that missing value is replaced

        Returns:
            Result",
"def drop_missing(self):
        r""""""Delete missing value.

        Returns:
            Result

        """"""
        newvalues = []
        newdescs = []
        for d, v in self.items():
            if not is_missing(v):
                newvalues.append(v)
                newdescs.append(d)

        return self.__class__(self.mol, newvalues, newdescs)","r""""""Delete missing value.

        Returns:
            Result",
"def items(self):
        r""""""Get items.

        Returns:
            Iterable[(Descriptor, value)]

        """"""
        return ((k, v) for k, v in zip(self.keys(), self.values()))","r""""""Get items.

        Returns:
            Iterable[(Descriptor, value)]",
"def log_calls(func):
  '''Decorator to log function calls.'''
  def wrapper(*args, **kargs):
    callStr = ""%s(%s)"" % (func.__name__, "", "".join([repr(p) for p in args] + [""%s=%s"" % (k, repr(v)) for (k, v) in list(kargs.items())]))
    debug("">> %s"", callStr)
    ret = func(*args, **kargs)
    debug(""<< %s: %s"", callStr, repr(ret))
    return ret
  return wrapper",Decorator to log function calls.,
"def synchronized(func):
  '''Decorator to synchronize function.'''
  func.__lock__ = threading.Lock()
  def synced_func(*args, **kargs):
    with func.__lock__:
      return func(*args, **kargs)
  return synced_func",Decorator to synchronize function.,
"def message(msg, *args):
  '''Program message output.'''
  clear_progress()
  text = (msg % args)
  sys.stdout.write(text + '\n')",Program message output.,
"def tempfile_get(target):
  '''Get a temp filename for atomic download.'''
  fn = '%s-%s.tmp' % (target, ''.join(random.Random().sample(""0123456789abcdefghijklmnopqrstuvwxyz"", 15)))
  TEMP_FILES.add(fn)
  return fn",Get a temp filename for atomic download.,
"def tempfile_set(tempfile, target):
  '''Atomically rename and clean tempfile'''
  if target:
    os.rename(tempfile, target)
  else:
    os.unlink(tempfile)

  if target in TEMP_FILES:
    TEMP_FILES.remove(tempfile)",Atomically rename and clean tempfile,
"def clean_tempfiles():
  '''Clean up temp files'''
  for fn in TEMP_FILES:
    if os.path.exists(fn):
      os.unlink(fn)",Clean up temp files,
"def get_loggers(self):
    '''Return a list of the logger methods: (debug, info, warn, error)'''

    return self.log.debug, self.log.info, self.log.warn, self.log.error","Return a list of the logger methods: (debug, info, warn, error)",
"def get_fixed_path(self):
    '''Get the fixed part of the path without wildcard'''
    pi = self.path.split(PATH_SEP)
    fi = []
    for p in pi:
      if '*' in p or '?' in p:
        break
      fi.append(p)
    return PATH_SEP.join(fi)",Get the fixed part of the path without wildcard,
"def add_options(parser):
    '''Add the whole list of API parameters into optparse.'''
    for param, param_type, param_doc in BotoClient.EXTRA_CLIENT_PARAMS:
      parser.add_option('--API-' + param, help=param_doc, type=param_type, dest=param)",Add the whole list of API parameters into optparse.,
"def terminate(self, exc_info=None):
    '''Terminate all threads by deleting the queue and forcing the child threads
       to quit.
    '''
    if exc_info:
      self.exc_info = exc_info
    try:
      while self.get_nowait():
        self.task_done()
    except Queue.Empty:
      pass","Terminate all threads by deleting the queue and forcing the child threads
       to quit.",
"def add_task(self, func_name, *args, **kargs):
    '''Utility function to add a single task into task queue'''
    self.tasks.put((func_name, 0, args, kargs))",Utility function to add a single task into task queue,
"def join(self):
    '''Utility function to wait all tasks to complete'''
    self.tasks.join()

    # Force each thread to break loop.
    for worker in self.workers:
      self.tasks.put(None)

    # Wait for all thread to terminate.
    for worker in self.workers:
      worker.join()
      worker.s3 = None",Utility function to wait all tasks to complete,
"def processed(self):
    '''Increase the processed task counter and show progress message'''
    self.processed_tasks += 1
    qsize = self.tasks.qsize()
    if qsize > 0:
      progress('[%d task(s) completed, %d remaining, %d thread(s)]', self.processed_tasks, qsize, len(self.workers))
    else:
      progress('[%d task(s) completed, %d thread(s)]', self.processed_tasks, len(self.workers))",Increase the processed task counter and show progress message,
"def s3_keys_from_env():
    '''Retrieve S3 access keys from the environment, or None if not present.'''
    env = os.environ
    if S3_ACCESS_KEY_NAME in env and S3_SECRET_KEY_NAME in env:
      keys = (env[S3_ACCESS_KEY_NAME], env[S3_SECRET_KEY_NAME])
      debug(""read S3 keys from environment"")
      return keys
    else:
      return None","Retrieve S3 access keys from the environment, or None if not present.",
"def s3_keys_from_cmdline(opt):
    '''Retrieve S3 access keys from the command line, or None if not present.'''
    if opt.access_key != None and opt.secret_key != None:
      keys = (opt.access_key, opt.secret_key)
      debug(""read S3 keys from commandline"")
      return keys
    else:
      return None","Retrieve S3 access keys from the command line, or None if not present.",
"def init_s3_keys(opt):
    '''Initialize s3 access keys from environment variable or s3cfg config file.'''
    S3Handler.S3_KEYS = S3Handler.s3_keys_from_cmdline(opt) or S3Handler.s3_keys_from_env() \
                        or S3Handler.s3_keys_from_s3cfg(opt)",Initialize s3 access keys from environment variable or s3cfg config file.,
"def connect(self):
    '''Connect to S3 storage'''
    try:
      if S3Handler.S3_KEYS:
        self.s3 = BotoClient(self.opt, S3Handler.S3_KEYS[0], S3Handler.S3_KEYS[1])
      else:
        self.s3 = BotoClient(self.opt)
    except Exception as e:
      raise RetryFailure('Unable to connect to s3: %s' % e)",Connect to S3 storage,
"def list_buckets(self):
    '''List all buckets'''
    result = []
    for bucket in self.s3.list_buckets().get('Buckets') or []:
      result.append({
          'name': S3URL.combine('s3', bucket['Name'], ''),
          'is_dir': True,
          'size': 0,
          'last_modified': bucket['CreationDate']
        })
    return result",List all buckets,
"def local_walk(self, basedir):
    '''Walk through local directories from root basedir'''
    result = []

    for root, dirs, files in os.walk(basedir):
      for f in files:
        result.append(os.path.join(root, f))
    return result",Walk through local directories from root basedir,
"def get_basename(self, path):
    '''Unix style basename.
       This fuction will return 'bar' for '/foo/bar/' instead of empty string.
       It is used to normalize the input trailing slash.
    '''
    if path[-1] == PATH_SEP:
      path = path[0:-1]
    return os.path.basename(path)","Unix style basename.
       This fuction will return 'bar' for '/foo/bar/' instead of empty string.
       It is used to normalize the input trailing slash.",
"def create_bucket(self, source):
    '''Use the create_bucket API to create a new bucket'''
    s3url = S3URL(source)

    message('Creating %s', source)
    if not self.opt.dry_run:
      resp = self.s3.create_bucket(Bucket=s3url.bucket)
      if resp['ResponseMetadata'][""HTTPStatusCode""] == 200:
        message('Done.')
      else:
        raise Failure('Unable to create bucket %s' % source)",Use the create_bucket API to create a new bucket,
"def update_privilege(self, obj, target):
    '''Get privileges from metadata of the source in s3, and apply them to target'''
    if 'privilege' in obj['Metadata']:
      os.chmod(target, int(obj['Metadata']['privilege'], 8))","Get privileges from metadata of the source in s3, and apply them to target",
"def print_files(self, source):
    '''Print out a series of files'''
    sources = self.source_expand(source)

    for source in sources:
      s3url = S3URL(source)
      response = self.s3.get_object(Bucket=s3url.bucket, Key=s3url.path)
      message('%s', response['Body'].read())",Print out a series of files,
"def del_files(self, source):
    '''Delete files on S3'''
    src_files = []
    for obj in self.s3walk(source):
      if not obj['is_dir']: # ignore directories
        src_files.append(obj['name'])

    pool = ThreadPool(ThreadUtil, self.opt)
    pool.batch_delete(src_files)
    pool.join()",Delete files on S3,
"def file_hash(self, filename, block_size=2**20):
    '''Calculate MD5 hash code for a local file'''
    m = hashlib.md5()
    with open(filename, 'rb') as f:
      while True:
        data = f.read(block_size)
        if not data:
          break
        m.update(data)
    return m.hexdigest()",Calculate MD5 hash code for a local file,
"def get_md5(self):
    '''Get or calculate MD5 value of the local file.'''
    if self.md5 is None:
      self.md5 = self.file_hash(self.filename)
    return self.md5",Get or calculate MD5 value of the local file.,
"def get_file_privilege(self, source):
    '''Get privileges of a local file'''
    try:
      return str(oct(os.stat(source).st_mode)[-3:])
    except Exception as e:
      raise Failure('Could not get stat for %s, error_message = %s', source, e)",Get privileges of a local file,
"def lookup(self, s3url):
    '''Get the s3 object with the S3 URL. Return None if not exist.'''
    try:
      return self.s3.head_object(Bucket=s3url.bucket, Key=s3url.path)
    except BotoClient.ClientError as e:
      if e.response['ResponseMetadata']['HTTPStatusCode'] == 404:
        return None
      else:
        raise e",Get the s3 object with the S3 URL. Return None if not exist.,
"def read_file_chunk(self, source, pos, chunk):
    '''Read local file chunk'''
    if chunk==0:
        return StringIO()
    data = None
    with open(source, 'rb') as f:
      f.seek(pos)
      data = f.read(chunk)
    if not data:
      raise Failure('Unable to read data from source: %s' % source)
    return StringIO(data)",Read local file chunk,
"def _verify_file_size(self, obj, downloaded_file):
    '''Verify the file size of the downloaded file.'''
    file_size = os.path.getsize(downloaded_file)
    if int(obj['ContentLength']) != file_size:
      raise RetryFailure('Downloaded file size inconsistent: %s' % (repr(obj)))",Verify the file size of the downloaded file.,
"def delete(self, source):
    '''Thread worker for download operation.'''
    s3url = S3URL(source)

    message('Delete %s', source)
    if not self.opt.dry_run:
      self.s3.delete_object(Bucket=s3url.bucket, Key=s3url.path)",Thread worker for download operation.,
"def run(self, args):
    '''Main entry to handle commands. Dispatch to individual command handler.'''
    if len(args) == 0:
      raise InvalidArgument('No command provided')
    cmd = args[0]
    if cmd + '_handler' in CommandHandler.__dict__:
      CommandHandler.__dict__[cmd + '_handler'](self, args)
    else:
      raise InvalidArgument('Unknown command %s' % cmd)",Main entry to handle commands. Dispatch to individual command handler.,
"def ls_handler(self, args):
    '''Handler for ls command'''
    if len(args) == 1:
      self.pretty_print(self.s3handler().list_buckets())
      return

    self.validate('cmd|s3', args)
    self.pretty_print(self.s3handler().s3walk(args[1]))",Handler for ls command,
"def mb_handler(self, args):
    '''Handler for mb command'''
    if len(args) == 1:
      raise InvalidArgument('No s3 bucketname provided')

    self.validate('cmd|s3', args)
    self.s3handler().create_bucket(args[1])",Handler for mb command,
"def put_handler(self, args):
    '''Handler for put command'''

    # Special check for shell expansion
    if len(args) < 3:
      raise InvalidArgument('Invalid number of parameters')
    self.validate('|'.join(['cmd'] + ['local'] * (len(args) - 2) + ['s3']), args)

    source = args[1:-1] # shell expansion
    target = args[-1]

    self.s3handler().put_files(source, target)",Handler for put command,
"def get_handler(self, args):
    '''Handler for get command'''

    # Special case when we don't have target directory.
    if len(args) == 2:
      args += ['.']

    self.validate('cmd|s3|local', args)
    source = args[1]
    target = args[2]
    self.s3handler().get_files(source, target)",Handler for get command,
"def cat_handler(self, args):
    '''Handler for cat command'''

    self.validate('cmd|s3', args)
    source = args[1]

    self.s3handler().print_files(source)",Handler for cat command,
"def dsync_handler(self, args):
    '''Handler for dsync command.'''
    self.opt.recursive = True
    self.opt.sync_check = True
    self.opt.force = True

    self.validate('cmd|s3,local|s3,local', args)
    source = args[1]
    target = args[2]

    self.s3handler().dsync_files(source, target)",Handler for dsync command.,
"def cp_handler(self, args):
    '''Handler for cp command'''

    self.validate('cmd|s3|s3', args)
    source = args[1]
    target = args[2]
    self.s3handler().cp_files(source, target)",Handler for cp command,
"def mv_handler(self, args):
    '''Handler for mv command'''

    self.validate('cmd|s3|s3', args)
    source = args[1]
    target = args[2]
    self.s3handler().cp_files(source, target, delete_source=True)",Handler for mv command,
"def del_handler(self, args):
    '''Handler for del command'''
    self.validate('cmd|s3', args)
    source = args[1]
    self.s3handler().del_files(source)",Handler for del command,
"def du_handler(self, args):
    '''Handler for size command'''
    for src, size in self.s3handler().size(args[1:]):
      message('%s\t%s' % (size, src))",Handler for size command,
"def _totalsize_handler(self, args):
    '''Handler of total_size command'''
    total_size = 0
    for src, size in self.s3handler().size(args[1:]):
      total_size += size
    message(str(total_size))",Handler of total_size command,
"def match_date(self, value):
    '''Search for date information in the string'''
    m = self.REGEX_DATE.search(value)
    date = datetime.datetime.utcnow().date()
    if m:
      date = datetime.date(int(m.group(1)), int(m.group(2)), int(m.group(3)))
      value = self.REGEX_DATE.sub('', value)
    return (date, value)",Search for date information in the string,
"def match_time(self, value):
    '''Search for time information in the string'''
    m = self.REGEX_TIME.search(value)
    time = datetime.datetime.utcnow().time()
    if m:
      time = datetime.time(int(m.group(1)), int(m.group(2)))
      value = self.REGEX_TIME.sub('', value)
    return (time, value)",Search for time information in the string,
"def check_dict(self, opt, value):
    '''Take json as dictionary parameter'''
    try:
      return json.loads(value)
    except:
      raise optparse.OptionValueError(""Option %s: invalid dict value: %r"" % (opt, value))",Take json as dictionary parameter,
"def listen(self):
        """"""Start listening.""""""

        _LOGGER.info('Creating Multicast Socket')
        self._mcastsocket = self._create_mcast_socket()
        self._listening = True
        thread = Thread(target=self._listen_to_msg, args=())
        self._threads.append(thread)
        thread.daemon = True
        thread.start()",Start listening.,
"def stop_listen(self):
        """"""Stop listening.""""""
        self._listening = False

        if self._mcastsocket is not None:
            _LOGGER.info('Closing multisocket')
            self._mcastsocket.close()
            self._mcastsocket = None

        for thread in self._threads:
            thread.join()",Stop listening.,
"def get_from_hub(self, sid):
        """"""Get data from gateway""""""
        cmd = '{ ""cmd"":""read"",""sid"":""' + sid + '""}'
        resp = self._send_cmd(cmd, ""read_ack"") if int(self.proto[0:1]) == 1 else self._send_cmd(cmd, ""read_rsp"")
        _LOGGER.debug(""read_ack << %s"", resp)
        return self.push_data(resp)",Get data from gateway,
"def _build_payload(data):
    """"""
    Returns the full payload as a string.
    """"""

    for k, v in iteritems(data):
        data[k] = _transform(v, key=(k,))

    payload = {
        'access_token': SETTINGS['access_token'],
        'data': data
    }

    return payload",Returns the full payload as a string.,
"def main():
    rollbar.init('ACCESS_TOKEN', environment='test', handler='twisted')

    """"""This runs the protocol on port 8000""""""
    factory = protocol.ServerFactory()
    factory.protocol = Echo
    reactor.listenTCP(8000, factory)
    reactor.run()",This runs the protocol on port 8000,
"def has_jongsung(letter):
    """"""Check whether this letter contains Jongsung""""""
    if len(letter) != 1:
        raise Exception('The target string must be one letter.')
    if not is_hangul(letter):
        raise NotHangulException('The target string must be Hangul')

    code = lt.hangul_index(letter)
    return code % NUM_JONG > 0",Check whether this letter contains Jongsung,
"def attach(word, josa=EUN_NEUN):
    """"""add josa at the end of this word""""""
    last_letter = word.strip()[-1]
    try:
        _, _, letter_jong = letter.decompose(last_letter)
    except NotHangulException:
        letter_jong = letter.get_substituent_of(last_letter)

    if letter_jong in ('', josa['except']):
        return word + josa['has']

    return word + josa['not']",add josa at the end of this word,
"def is_inside_except(node):
    """"""Returns true if node is inside the name of an except handler.""""""
    current = node
    while current and not isinstance(current.parent, astroid.ExceptHandler):
        current = current.parent

    return current and current is current.parent.name",Returns true if node is inside the name of an except handler.,
"def is_inside_lambda(node: astroid.node_classes.NodeNG) -> bool:
    """"""Return true if given node is inside lambda""""""
    parent = node.parent
    while parent is not None:
        if isinstance(parent, astroid.Lambda):
            return True
        parent = parent.parent
    return False",Return true if given node is inside lambda,
"def get_all_elements(
    node: astroid.node_classes.NodeNG
) -> Iterable[astroid.node_classes.NodeNG]:
    """"""Recursively returns all atoms in nested lists and tuples.""""""
    if isinstance(node, (astroid.Tuple, astroid.List)):
        for child in node.elts:
            for e in get_all_elements(child):
                yield e
    else:
        yield node",Recursively returns all atoms in nested lists and tuples.,
"def is_super(node: astroid.node_classes.NodeNG) -> bool:
    """"""return True if the node is referencing the ""super"" builtin function
    """"""
    if getattr(node, ""name"", None) == ""super"" and node.root().name == BUILTINS_NAME:
        return True
    return False","return True if the node is referencing the ""super"" builtin function",
"def is_error(node: astroid.node_classes.NodeNG) -> bool:
    """"""return true if the function does nothing but raising an exception""""""
    for child_node in node.get_children():
        if isinstance(child_node, astroid.Raise):
            return True
    return False",return true if the function does nothing but raising an exception,
"def is_builtin_object(node: astroid.node_classes.NodeNG) -> bool:
    """"""Returns True if the given node is an object from the __builtin__ module.""""""
    return node and node.root().name == BUILTINS_NAME",Returns True if the given node is an object from the __builtin__ module.,
"def assign_parent(node: astroid.node_classes.NodeNG) -> astroid.node_classes.NodeNG:
    """"""return the higher parent which is not an AssignName, Tuple or List node
    """"""
    while node and isinstance(node, (astroid.AssignName, astroid.Tuple, astroid.List)):
        node = node.parent
    return node","return the higher parent which is not an AssignName, Tuple or List node",
"def overrides_a_method(class_node: astroid.node_classes.NodeNG, name: str) -> bool:
    """"""return True if <name> is a method overridden from an ancestor""""""
    for ancestor in class_node.ancestors():
        if name in ancestor and isinstance(ancestor[name], astroid.FunctionDef):
            return True
    return False",return True if <name> is a method overridden from an ancestor,
"def check_messages(*messages: str) -> Callable:
    """"""decorator to store messages that are handled by a checker method""""""

    def store_messages(func):
        func.checks_msgs = messages
        return func

    return store_messages",decorator to store messages that are handled by a checker method,
"def is_attr_protected(attrname: str) -> bool:
    """"""return True if attribute name is protected (start with _ and some other
    details), False otherwise.
    """"""
    return (
        attrname[0] == ""_""
        and attrname != ""_""
        and not (attrname.startswith(""__"") and attrname.endswith(""__""))
    )","return True if attribute name is protected (start with _ and some other
    details), False otherwise.",
"def is_attr_private(attrname: str) -> Optional[Match[str]]:
    """"""Check that attribute name is private (at least two leading underscores,
    at most one trailing underscore)
    """"""
    regex = re.compile(""^_{2,}.*[^_]+_?$"")
    return regex.match(attrname)","Check that attribute name is private (at least two leading underscores,
    at most one trailing underscore)",
"def class_is_abstract(node: astroid.ClassDef) -> bool:
    """"""return true if the given class node should be considered as an abstract
    class
    """"""
    for method in node.methods():
        if method.parent.frame() is node:
            if method.is_abstract(pass_is_abstract=False):
                return True
    return False","return true if the given class node should be considered as an abstract
    class",
"def is_postponed_evaluation_enabled(node: astroid.node_classes.NodeNG) -> bool:
    """"""Check if the postponed evaluation of annotations is enabled""""""
    name = ""annotations""
    module = node.root()
    stmt = module.locals.get(name)
    return (
        stmt
        and isinstance(stmt[0], astroid.ImportFrom)
        and stmt[0].modname == ""__future__""
    )",Check if the postponed evaluation of annotations is enabled,
"def _qualified_names(modname):
    """"""Split the names of the given module into subparts

    For example,
        _qualified_names('pylint.checkers.ImportsChecker')
    returns
        ['pylint', 'pylint.checkers', 'pylint.checkers.ImportsChecker']
    """"""
    names = modname.split(""."")
    return [""."".join(names[0 : i + 1]) for i in range(len(names))]","Split the names of the given module into subparts

    For example,
        _qualified_names('pylint.checkers.ImportsChecker')
    returns
        ['pylint', 'pylint.checkers', 'pylint.checkers.ImportsChecker']",
"def _make_graph(filename, dep_info, sect, gtype):
    """"""generate a dependencies graph and add some information about it in the
    report's section
    """"""
    _dependencies_graph(filename, dep_info)
    sect.append(Paragraph(""%simports graph has been written to %s"" % (gtype, filename)))","generate a dependencies graph and add some information about it in the
    report's section",
"def close(self):
        """"""called before visiting project (i.e set of modules)""""""
        if self.linter.is_message_enabled(""cyclic-import""):
            graph = self._import_graph_without_ignored_edges()
            vertices = list(graph)
            for cycle in get_cycles(graph, vertices=vertices):
                self.add_message(""cyclic-import"", args="" -> "".join(cycle))",called before visiting project (i.e set of modules),
"def _check_deprecated_module(self, node, mod_path):
        """"""check if the module is deprecated""""""
        for mod_name in self.config.deprecated_modules:
            if mod_path == mod_name or mod_path.startswith(mod_name + "".""):
                self.add_message(""deprecated-module"", node=node, args=mod_path)",check if the module is deprecated,
"def _check_preferred_module(self, node, mod_path):
        """"""check if the module has a preferred replacement""""""
        if mod_path in self.preferred_modules:
            self.add_message(
                ""preferred-module"",
                node=node,
                args=(self.preferred_modules[mod_path], mod_path),
            )",check if the module has a preferred replacement,
"def _report_external_dependencies(self, sect, _, _dummy):
        """"""return a verbatim layout for displaying dependencies""""""
        dep_info = _make_tree_defs(self._external_dependencies_info().items())
        if not dep_info:
            raise EmptyReportError()
        tree_str = _repr_tree_defs(dep_info)
        sect.append(VerbatimText(tree_str))",return a verbatim layout for displaying dependencies,
"def get_default_options():
    """"""
    Read config file and return list of options
    """"""
    options = []
    home = os.environ.get(""HOME"", """")
    if home:
        rcfile = os.path.join(home, RCFILE)
        try:
            options = open(rcfile).read().split()
        except IOError:
            pass  # ignore if no config file found
    return options",Read config file and return list of options,
"def insert_default_options():
    """"""insert default options to sys.argv
    """"""
    options = get_default_options()
    options.reverse()
    for arg in options:
        sys.argv.insert(1, arg)",insert default options to sys.argv,
"def get_visibility(name):
    """"""return the visibility from a name: public, protected, private or special
    """"""
    if SPECIAL.match(name):
        visibility = ""special""
    elif PRIVATE.match(name):
        visibility = ""private""
    elif PROTECTED.match(name):
        visibility = ""protected""

    else:
        visibility = ""public""
    return visibility","return the visibility from a name: public, protected, private or special",
"def show_attr(self, node):
        """"""return true if the node should be treated
        """"""
        visibility = get_visibility(getattr(node, ""name"", node))
        return not self.__mode & VIS_MOD[visibility]",return true if the node should be treated,
"def visit(self, node):
        """"""walk on the tree from <node>, getting callbacks from handler""""""
        method = self.get_callbacks(node)[0]
        if method is not None:
            method(node)","walk on the tree from <node>, getting callbacks from handler",
"def leave(self, node):
        """"""walk on the tree from <node>, getting callbacks from handler""""""
        method = self.get_callbacks(node)[1]
        if method is not None:
            method(node)","walk on the tree from <node>, getting callbacks from handler",
"def _check_datetime(self, node):
        """""" Check that a datetime was infered.
        If so, emit boolean-datetime warning.
        """"""
        try:
            infered = next(node.infer())
        except astroid.InferenceError:
            return
        if isinstance(infered, Instance) and infered.qname() == ""datetime.time"":
            self.add_message(""boolean-datetime"", node=node)","Check that a datetime was infered.
        If so, emit boolean-datetime warning.",
"def display_messages(self, layout):
        """"""Launch layouts display""""""
        print(json.dumps(self.messages, indent=4), file=self.out)",Launch layouts display,
"def get_title(self, node):
        """"""get title for objects""""""
        title = node.name
        if self.module_names:
            title = ""%s.%s"" % (node.root().name, title)
        return title",get title for objects,
"def show_node(self, node):
        """"""true if builtins and not show_builtins""""""
        if self.config.show_builtin:
            return True
        return node.root().name != BUILTINS_NAME",true if builtins and not show_builtins,
"def add_class(self, node):
        """"""visit one class and add it to diagram""""""
        self.linker.visit(node)
        self.classdiagram.add_object(self.get_title(node), node)",visit one class and add it to diagram,
"def get_ancestors(self, node, level):
        """"""return ancestor nodes of a class node""""""
        if level == 0:
            return
        for ancestor in node.ancestors(recurs=False):
            if not self.show_node(ancestor):
                continue
            yield ancestor",return ancestor nodes of a class node,
"def leave_project(self, node):  # pylint: disable=unused-argument
        """"""leave the pyreverse.utils.Project node

        return the generated diagram definition
        """"""
        if self.pkgdiagram:
            return self.pkgdiagram, self.classdiagram
        return (self.classdiagram,)","leave the pyreverse.utils.Project node

        return the generated diagram definition",
"def visit_module(self, node):
        """"""visit an astroid.Module node

        add this class to the package diagram definition
        """"""
        if self.pkgdiagram:
            self.linker.visit(node)
            self.pkgdiagram.add_object(node.name, node)","visit an astroid.Module node

        add this class to the package diagram definition",
"def visit_classdef(self, node):
        """"""visit an astroid.Class node

        add this class to the class diagram definition
        """"""
        anc_level, association_level = self._get_levels()
        self.extract_classes(node, anc_level, association_level)","visit an astroid.Class node

        add this class to the class diagram definition",
"def visit_importfrom(self, node):
        """"""visit astroid.ImportFrom  and catch modules for package diagram
        """"""
        if self.pkgdiagram:
            self.pkgdiagram.add_from_depend(node, node.modname)",visit astroid.ImportFrom  and catch modules for package diagram,
"def _has_parent_of_type(node, node_type, statement):
    """"""Check if the given node has a parent of the given type.""""""
    parent = node.parent
    while not isinstance(parent, node_type) and statement.parent_of(parent):
        parent = parent.parent
    return isinstance(parent, node_type)",Check if the given node has a parent of the given type.,
"def _is_name_used_as_variadic(name, variadics):
    """"""Check if the given name is used as a variadic argument.""""""
    return any(
        variadic.value == name or variadic.value.parent_of(name)
        for variadic in variadics
    )",Check if the given name is used as a variadic argument.,
"def register(linter):
    """"""required method to auto register this checker """"""
    linter.register_checker(TypeChecker(linter))
    linter.register_checker(IterableChecker(linter))",required method to auto register this checker,
"def visit_unaryop(self, node):
        """"""Detect TypeErrors for unary operands.""""""

        for error in node.type_errors():
            # Let the error customize its output.
            self.add_message(""invalid-unary-operand-type"", args=str(error), node=node)",Detect TypeErrors for unary operands.,
"def visit_project(self, node):
        """"""visit a pyreverse.utils.Project node

         * optionally tag the node with a unique id
        """"""
        if self.tag:
            node.uid = self.generate_id()
        for module in node.modules:
            self.visit(module)","visit a pyreverse.utils.Project node

         * optionally tag the node with a unique id",
"def visit_package(self, node):
        """"""visit an astroid.Package node

         * optionally tag the node with a unique id
        """"""
        if self.tag:
            node.uid = self.generate_id()
        for subelmt in node.values():
            self.visit(subelmt)","visit an astroid.Package node

         * optionally tag the node with a unique id",
"def visit_functiondef(self, node):
        """"""visit an astroid.Function node

         * set the locals_type mapping
         * optionally tag the node with a unique id
        """"""
        if hasattr(node, ""locals_type""):
            return
        node.locals_type = collections.defaultdict(list)
        if self.tag:
            node.uid = self.generate_id()","visit an astroid.Function node

         * set the locals_type mapping
         * optionally tag the node with a unique id",
"def handle_assignattr_type(node, parent):
        """"""handle an astroid.assignattr node

        handle instance_attrs_type
        """"""
        try:
            values = set(node.infer())
            current = set(parent.instance_attrs_type[node.attrname])
            parent.instance_attrs_type[node.attrname] = list(current | values)
        except astroid.InferenceError:
            pass","handle an astroid.assignattr node

        handle instance_attrs_type",
"def visit_import(self, node):
        """"""visit an astroid.Import node

        resolve module dependencies
        """"""
        context_file = node.root().file
        for name in node.names:
            relative = modutils.is_relative(name[0], context_file)
            self._imported_module(node, name[0], relative)","visit an astroid.Import node

        resolve module dependencies",
"def compute_module(self, context_name, mod_path):
        """"""return true if the module should be added to dependencies""""""
        package_dir = os.path.dirname(self.project.path)
        if context_name == mod_path:
            return 0
        if modutils.is_standard_module(mod_path, (package_dir,)):
            return 1
        return 0",return true if the module should be added to dependencies,
"def register(linter):
    """"""Register the reporter classes with the linter.""""""
    linter.register_reporter(TextReporter)
    linter.register_reporter(ParseableTextReporter)
    linter.register_reporter(VSTextReporter)
    linter.register_reporter(ColorizedTextReporter)",Register the reporter classes with the linter.,
"def handle_message(self, msg):
        """"""manage message of different type and in the context of path""""""
        if msg.module not in self._modules:
            if msg.module:
                self.writeln(""************* Module %s"" % msg.module)
                self._modules.add(msg.module)
            else:
                self.writeln(""************* "")
        self.write_message(msg)",manage message of different type and in the context of path,
"def _display(self, layout):
        """"""launch layouts display""""""
        print(file=self.out)
        TextWriter().format(layout, self.out)",launch layouts display,
"def open_graph(self, **args):
        """"""open a vcg graph
        """"""
        self._stream.write(""%sgraph:{\n"" % self._indent)
        self._inc_indent()
        self._write_attributes(GRAPH_ATTRS, **args)",open a vcg graph,
"def node(self, title, **args):
        """"""draw a node
        """"""
        self._stream.write('%snode: {title:""%s""' % (self._indent, title))
        self._write_attributes(NODE_ATTRS, **args)
        self._stream.write(""}\n"")",draw a node,
"def edge(self, from_node, to_node, edge_type="""", **args):
        """"""draw an edge from a node to another.
        """"""
        self._stream.write(
            '%s%sedge: {sourcename:""%s"" targetname:""%s""'
            % (self._indent, edge_type, from_node, to_node)
        )
        self._write_attributes(EDGE_ATTRS, **args)
        self._stream.write(""}\n"")",draw an edge from a node to another.,
"def get_access_path(key, parts):
    """""" Given a list of format specifiers, returns
    the final access path (e.g. a.b.c[0][1]).
    """"""
    path = []
    for is_attribute, specifier in parts:
        if is_attribute:
            path.append("".{}"".format(specifier))
        else:
            path.append(""[{!r}]"".format(specifier))
    return str(key) + """".join(path)","Given a list of format specifiers, returns
    the final access path (e.g. a.b.c[0][1]).",
"def register(linter):
    """"""required method to auto register this checker """"""
    linter.register_checker(StringFormatChecker(linter))
    linter.register_checker(StringConstantChecker(linter))",required method to auto register this checker,
"def visit_section(self, layout):
        """"""display a section as text
        """"""
        self.section += 1
        self.writeln()
        self.format_children(layout)
        self.section -= 1
        self.writeln()",display a section as text,
"def visit_evaluationsection(self, layout):
        """"""Display an evaluation section as a text.""""""
        self.section += 1
        self.format_children(layout)
        self.section -= 1
        self.writeln()",Display an evaluation section as a text.,
"def visit_verbatimtext(self, layout):
        """"""display a verbatim layout as text (so difficult ;)
        """"""
        self.writeln(""::\n"")
        for line in layout.data.splitlines():
            self.writeln(""    "" + line)
        self.writeln()",display a verbatim layout as text (so difficult ;),
"def register_messages_from_checker(self, checker):
        """"""Register all messages from a checker.

        :param BaseChecker checker:
        """"""
        checker.check_consistency()
        for message in checker.messages:
            self.register_message(message)","Register all messages from a checker.

        :param BaseChecker checker:",
"def _register_alternative_name(self, msg, msgid, symbol):
        """"""helper for register_message()""""""
        self._check_id_and_symbol_consistency(msgid, symbol)
        self._alternative_names[msgid] = msg
        self._alternative_names[symbol] = msg",helper for register_message(),
"def list_messages(self):
        """"""Output full messages list documentation in ReST format. """"""
        messages = sorted(self._messages_definitions.values(), key=lambda m: m.msgid)
        for message in messages:
            if not message.may_be_emitted():
                continue
            print(message.format_help(checkerref=False))
        print("""")",Output full messages list documentation in ReST format.,
"def register(linter):
    """"""Required method to auto register this checker.

    :param linter: Main interface object for Pylint plugins
    :type linter: Pylint object
    """"""
    warnings.warn(
        ""This plugin is deprecated, use pylint.extensions.docparams instead."",
        DeprecationWarning,
    )
    linter.register_checker(docparams.DocstringParameterChecker(linter))","Required method to auto register this checker.

    :param linter: Main interface object for Pylint plugins
    :type linter: Pylint object",
"def run_pylint():
    """"""run pylint""""""
    from pylint.lint import Run

    try:
        Run(sys.argv[1:])
    except KeyboardInterrupt:
        sys.exit(1)",run pylint,
"def _cpu_count() -> int:
    """"""Use sched_affinity if available for virtualized or containerized environments.""""""
    sched_getaffinity = getattr(os, ""sched_getaffinity"", None)
    # pylint: disable=not-callable,using-constant-test
    if sched_getaffinity:
        return len(sched_getaffinity(0))
    if multiprocessing:
        return multiprocessing.cpu_count()
    return 1",Use sched_affinity if available for virtualized or containerized environments.,
"def report_total_messages_stats(sect, stats, previous_stats):
    """"""make total errors / warnings report""""""
    lines = [""type"", ""number"", ""previous"", ""difference""]
    lines += checkers.table_lines_from_stats(
        stats, previous_stats, (""convention"", ""refactor"", ""warning"", ""error"")
    )
    sect.append(report_nodes.Table(children=lines, cols=4, rheaders=1))",make total errors / warnings report,
"def load_plugin_modules(self, modnames):
        """"""take a list of module names which are pylint plugins and load
        and register them
        """"""
        for modname in modnames:
            if modname in self._dynamic_plugins:
                continue
            self._dynamic_plugins.add(modname)
            module = modutils.load_module_from_name(modname)
            module.register(self)","take a list of module names which are pylint plugins and load
        and register them",
"def disable_reporters(self):
        """"""disable all reporters""""""
        for _reporters in self._reports.values():
            for report_id, _, _ in _reporters:
                self.disable_report(report_id)",disable all reporters,
"def get_checkers(self):
        """"""return all available checkers as a list""""""
        return [self] + [
            c
            for _checkers in self._checkers.values()
            for c in _checkers
            if c is not self
        ]",return all available checkers as a list,
"def get_checker_names(self):
        """"""Get all the checker names that this linter knows about.""""""
        current_checkers = self.get_checkers()
        return sorted(
            {check.name for check in current_checkers if check.name != ""master""}
        )",Get all the checker names that this linter knows about.,
"def cb_add_plugins(self, name, value):
        """"""callback for option preprocessing (i.e. before option parsing)""""""
        self._plugins.extend(utils._splitstrip(value))",callback for option preprocessing (i.e. before option parsing),
"def cb_generate_config(self, *args, **kwargs):
        """"""optik callback for sample config file generation""""""
        self.linter.generate_config(skipsections=(""COMMANDS"",))
        sys.exit(0)",optik callback for sample config file generation,
"def cb_generate_manpage(self, *args, **kwargs):
        """"""optik callback for sample config file generation""""""
        from pylint import __pkginfo__

        self.linter.generate_manpage(__pkginfo__)
        sys.exit(0)",optik callback for sample config file generation,
"def cb_help_message(self, option, optname, value, parser):
        """"""optik callback for printing some help about a particular message""""""
        self.linter.msgs_store.help_message(utils._splitstrip(value))
        sys.exit(0)",optik callback for printing some help about a particular message,
"def cb_full_documentation(self, option, optname, value, parser):
        """"""optik callback for printing full documentation""""""
        self.linter.print_full_documentation()
        sys.exit(0)",optik callback for printing full documentation,
"def cb_list_messages(self, option, optname, value, parser):  # FIXME
        """"""optik callback for printing available messages""""""
        self.linter.msgs_store.list_messages()
        sys.exit(0)",optik callback for printing available messages,
"def cb_list_groups(self, *args, **kwargs):
        """"""List all the check groups that pylint knows about

        These should be useful to know what check groups someone can disable
        or enable.
        """"""
        for check in self.linter.get_checker_names():
            print(check)
        sys.exit(0)","List all the check groups that pylint knows about

        These should be useful to know what check groups someone can disable
        or enable.",
"def normalize_text(text, line_len=80, indent=""""):
    """"""Wrap the text on the given line length.""""""
    return ""\n"".join(
        textwrap.wrap(
            text, width=line_len, initial_indent=indent, subsequent_indent=indent
        )
    )",Wrap the text on the given line length.,
"def safe_decode(line, encoding, *args, **kwargs):
    """"""return decoded line from encoding or decode with default encoding""""""
    try:
        return line.decode(encoding or sys.getdefaultencoding(), *args, **kwargs)
    except LookupError:
        return line.decode(sys.getdefaultencoding(), *args, **kwargs)",return decoded line from encoding or decode with default encoding,
"def _comment(string):
    """"""return string as a comment""""""
    lines = [line.strip() for line in string.splitlines()]
    return ""# "" + (""%s# "" % linesep).join(lines)",return string as a comment,
"def format_section(stream, section, options, doc=None):
    """"""format an options section using the INI format""""""
    if doc:
        print(_comment(doc), file=stream)
    print(""[%s]"" % section, file=stream)
    _ini_format(stream, options)",format an options section using the INI format,
"def insert(self, index, child):
        """"""insert a child node""""""
        self.children.insert(index, child)
        child.parent = self",insert a child node,
"def append(self, child):
        """"""overridden to detect problems easily""""""
        assert child not in self.parents()
        VNode.append(self, child)",overridden to detect problems easily,
"def parents(self):
        """"""return the ancestor nodes""""""
        assert self.parent is not self
        if self.parent is None:
            return []
        return [self.parent] + self.parent.parents()",return the ancestor nodes,
"def set_msg_status(self, msg, line, status):
        """"""Set status (enabled/disable) for a given message at a given line""""""
        assert line > 0
        try:
            self._module_msgs_state[msg.msgid][line] = status
        except KeyError:
            self._module_msgs_state[msg.msgid] = {line: status}",Set status (enabled/disable) for a given message at a given line,
"def register_report(self, reportid, r_title, r_cb, checker):
        """"""register a report

        reportid is the unique identifier for the report
        r_title the report's title
        r_cb the method to call to make the report
        checker is the checker defining the report
        """"""
        reportid = reportid.upper()
        self._reports[checker].append((reportid, r_title, r_cb))","register a report

        reportid is the unique identifier for the report
        r_title the report's title
        r_cb the method to call to make the report
        checker is the checker defining the report",
"def enable_report(self, reportid):
        """"""disable the report of the given id""""""
        reportid = reportid.upper()
        self._reports_state[reportid] = True",disable the report of the given id,
"def disable_report(self, reportid):
        """"""disable the report of the given id""""""
        reportid = reportid.upper()
        self._reports_state[reportid] = False",disable the report of the given id,
"def add_stats(self, **kwargs):
        """"""add some stats entries to the statistic dictionary
        raise an AssertionError if there is a key conflict
        """"""
        for key, value in kwargs.items():
            if key[-1] == ""_"":
                key = key[:-1]
            assert key not in self.stats
            self.stats[key] = value
        return self.stats","add some stats entries to the statistic dictionary
        raise an AssertionError if there is a key conflict",
"def register(linter):
    """"""required method to auto register this checker""""""
    linter.register_checker(EncodingChecker(linter))
    linter.register_checker(ByIdManagedMessagesChecker(linter))",required method to auto register this checker,
"def process_module(self, module):
        """"""inspect the source file to find encoding problem""""""
        if module.file_encoding:
            encoding = module.file_encoding
        else:
            encoding = ""ascii""

        with module.stream() as stream:
            for lineno, line in enumerate(stream):
                self._check_encoding(lineno + 1, line, encoding)",inspect the source file to find encoding problem,
"def in_for_else_branch(parent, stmt):
    """"""Returns True if stmt in inside the else branch for a parent For stmt.""""""
    return isinstance(parent, astroid.For) and any(
        else_stmt.parent_of(stmt) or else_stmt == stmt for else_stmt in parent.orelse
    )",Returns True if stmt in inside the else branch for a parent For stmt.,
"def _assigned_locally(name_node):
    """"""
    Checks if name_node has corresponding assign statement in same scope
    """"""
    assign_stmts = name_node.scope().nodes_of_class(astroid.AssignName)
    return any(a.name == name_node.name for a in assign_stmts)",Checks if name_node has corresponding assign statement in same scope,
"def mark_as_consumed(self, name, new_node):
        """"""
        Mark the name as consumed and delete it from
        the to_consume dictionary
        """"""
        self.consumed[name] = new_node
        del self.to_consume[name]","Mark the name as consumed and delete it from
        the to_consume dictionary",
"def ensure_scripts(linux_scripts):
    """"""Creates the proper script names required for each platform
    (taken from 4Suite)
    """"""
    from distutils import util

    if util.get_platform()[:3] == ""win"":
        return linux_scripts + [script + "".bat"" for script in linux_scripts]
    return linux_scripts","Creates the proper script names required for each platform
    (taken from 4Suite)",
"def report_similarities(sect, stats, old_stats):
    """"""make a layout with some stats about duplication""""""
    lines = ["""", ""now"", ""previous"", ""difference""]
    lines += table_lines_from_stats(
        stats, old_stats, (""nb_duplicated_lines"", ""percent_duplicated_lines"")
    )
    sect.append(Table(children=lines, cols=4, rheaders=1, cheaders=1))",make a layout with some stats about duplication,
"def _iter_sims(self):
        """"""iterate on similarities among all files, by making a cartesian
        product
        """"""
        for idx, lineset in enumerate(self.linesets[:-1]):
            for lineset2 in self.linesets[idx + 1 :]:
                for sim in self._find_common(lineset, lineset2):
                    yield sim","iterate on similarities among all files, by making a cartesian
        product",
"def _mk_index(self):
        """"""create the index for this set""""""
        index = defaultdict(list)
        for line_no, line in enumerate(self._stripped_lines):
            if line:
                index[line].append(line_no)
        return index",create the index for this set,
"def open(self):
        """"""init the checkers: reset linesets and statistics information""""""
        self.linesets = []
        self.stats = self.linter.add_stats(
            nb_duplicated_lines=0, percent_duplicated_lines=0
        )",init the checkers: reset linesets and statistics information,
"def process_module(self, node):
        """"""process a module

        the module's content is accessible via the stream object

        stream must implement the readlines method
        """"""
        with node.stream() as stream:
            self.append_stream(self.linter.current_name, stream, node.file_encoding)","process a module

        the module's content is accessible via the stream object

        stream must implement the readlines method",
"def register(linter):
    """"""required method to auto register this checker """"""
    linter.register_checker(ClassChecker(linter))
    linter.register_checker(SpecialMethodsChecker(linter))",required method to auto register this checker,
"def set_accessed(self, node):
        """"""Set the given node as accessed.""""""

        frame = node_frame_class(node)
        if frame is None:
            # The node does not live in a class.
            return
        self._scopes[frame][node.attrname].append(node)",Set the given node as accessed.,
"def visit_name(self, node):
        """"""check if the name handle an access to a class member
        if so, register it
        """"""
        if self._first_attrs and (
            node.name == self._first_attrs[-1] or not self._first_attrs[-1]
        ):
            self._meth_could_be_func = False","check if the name handle an access to a class member
        if so, register it",
"def _is_mandatory_method_param(self, node):
        """"""Check if astroid.Name corresponds to first attribute variable name

        Name is `self` for method, `cls` for classmethod and `mcs` for metaclass.
        """"""
        return (
            self._first_attrs
            and isinstance(node, astroid.Name)
            and node.name == self._first_attrs[-1]
        )","Check if astroid.Name corresponds to first attribute variable name

        Name is `self` for method, `cls` for classmethod and `mcs` for metaclass.",
"def _is_raising(body: typing.List) -> bool:
    """"""Return true if the given statement node raise an exception""""""
    for node in body:
        if isinstance(node, astroid.Raise):
            return True
    return False",Return true if the given statement node raise an exception,
"def display_reports(self, layout):
        """"""display results encapsulated in the layout tree""""""
        self.section = 0
        if hasattr(layout, ""report_id""):
            layout.children[0].children[0].data += "" (%s)"" % layout.report_id
        self._display(layout)",display results encapsulated in the layout tree,
"def _is_typing_namedtuple(node: astroid.ClassDef) -> bool:
    """"""Check if a class node is a typing.NamedTuple class""""""
    for base in node.ancestors():
        if base.qname() == TYPING_NAMEDTUPLE:
            return True
    return False",Check if a class node is a typing.NamedTuple class,
"def open(self):
        """"""initialize visit variables""""""
        self.stats = self.linter.add_stats()
        self._returns = []
        self._branches = defaultdict(int)
        self._stmts = []",initialize visit variables,
"def visit_tryexcept(self, node):
        """"""increments the branches counter""""""
        branches = len(node.handlers)
        if node.orelse:
            branches += 1
        self._inc_branch(node, branches)
        self._inc_all_stmts(branches)",increments the branches counter,
"def visit_while(self, node):
        """"""increments the branches counter""""""
        branches = 1
        if node.orelse:
            branches += 1
        self._inc_branch(node, branches)",increments the branches counter,
"def _check_docstring(self, node):
        """"""check the node has any spelling errors""""""
        docstring = node.doc
        if not docstring:
            return

        start_line = node.lineno + 1

        # Go through lines of docstring
        for idx, line in enumerate(docstring.splitlines()):
            self._check_spelling(""wrong-spelling-in-docstring"", line, start_line + idx)",check the node has any spelling errors,
"def _is_len_call(node):
    """"""Checks if node is len(SOMETHING).""""""
    return (
        isinstance(node, astroid.Call)
        and isinstance(node.func, astroid.Name)
        and node.func.name == ""len""
    )",Checks if node is len(SOMETHING).,
"def register(linter):
    """"""Required method to auto register this checker.""""""
    linter.register_checker(RefactoringChecker(linter))
    linter.register_checker(NotChecker(linter))
    linter.register_checker(RecommandationChecker(linter))
    linter.register_checker(LenChecker(linter))",Required method to auto register this checker.,
"def _check_exception_inherit_from_stopiteration(exc):
        """"""Return True if the exception node in argument inherit from StopIteration""""""
        stopiteration_qname = ""{}.StopIteration"".format(utils.EXCEPTIONS_MODULE)
        return any(_class.qname() == stopiteration_qname for _class in exc.mro())",Return True if the exception node in argument inherit from StopIteration,
"def set_printer(self, file_name, basename):
        """"""initialize DotWriter and add options for layout.
        """"""
        layout = dict(rankdir=""BT"")
        self.printer = DotBackend(basename, additional_param=layout)
        self.file_name = file_name",initialize DotWriter and add options for layout.,
"def may_be_emitted(self):
        """"""return True if message may be emitted using the current interpreter""""""
        if self.minversion is not None and self.minversion > sys.version_info:
            return False
        if self.maxversion is not None and self.maxversion <= sys.version_info:
            return False
        return True",return True if message may be emitted using the current interpreter,
"def process_module(self, node):
        """"""process a module

        the module's content is accessible via node.stream() function
        """"""
        with node.stream() as stream:
            for (lineno, line) in enumerate(stream):
                if line.rstrip().endswith(""\\""):
                    self.add_message(""backslash-line-continuation"", line=lineno)","process a module

        the module's content is accessible via node.stream() function",
"def _get_env():
    """"""Extracts the environment PYTHONPATH and appends the current sys.path to
    those.""""""
    env = dict(os.environ)
    env[""PYTHONPATH""] = os.pathsep.join(sys.path)
    return env","Extracts the environment PYTHONPATH and appends the current sys.path to
    those.",
"def target_info_from_filename(filename):
    """"""Transforms /some/path/foo.png into ('/some/path', 'foo.png', 'png').""""""
    basename = osp.basename(filename)
    storedir = osp.dirname(osp.abspath(filename))
    target = filename.split(""."")[-1]
    return storedir, basename, target","Transforms /some/path/foo.png into ('/some/path', 'foo.png', 'png').",
"def get_source(self):
        """"""returns self._source""""""
        if self._source is None:
            self.emit(""}\n"")
            self._source = ""\n"".join(self.lines)
            del self.lines
        return self._source",returns self._source,
"def emit_node(self, name, **props):
        """"""emit a node with given properties.
        node properties: see http://www.graphviz.org/doc/info/attrs.html
        """"""
        attrs = ['%s=""%s""' % (prop, value) for prop, value in props.items()]
        self.emit(""%s [%s];"" % (normalize_node_id(name), "", "".join(sorted(attrs))))","emit a node with given properties.
        node properties: see http://www.graphviz.org/doc/info/attrs.html",
"def open(self):
        """"""init statistics""""""
        self.stats = self.linter.add_stats(
            total_lines=0,
            code_lines=0,
            empty_lines=0,
            docstring_lines=0,
            comment_lines=0,
        )",init statistics,
"def process_tokens(self, tokens):
        """"""update stats""""""
        i = 0
        tokens = list(tokens)
        while i < len(tokens):
            i, lines_number, line_type = get_type(tokens, i)
            self.stats[""total_lines""] += lines_number
            self.stats[line_type] += lines_number",update stats,
"def disable(self, msgid, scope=""package"", line=None, ignore_unknown=False):
        """"""don't output message of the given id""""""
        self._set_msg_status(
            msgid, enable=False, scope=scope, line=line, ignore_unknown=ignore_unknown
        )
        self._register_by_id_managed_msg(msgid, line)",don't output message of the given id,
"def enable(self, msgid, scope=""package"", line=None, ignore_unknown=False):
        """"""reenable message of the given id""""""
        self._set_msg_status(
            msgid, enable=True, scope=scope, line=line, ignore_unknown=ignore_unknown
        )
        self._register_by_id_managed_msg(msgid, line, is_disabled=False)",reenable message of the given id,
"def _message_symbol(self, msgid):
        """"""Get the message symbol of the given message id

        Return the original message id if the message does not
        exist.
        """"""
        try:
            return [md.symbol for md in self.msgs_store.get_message_definitions(msgid)]
        except UnknownMessageError:
            return msgid","Get the message symbol of the given message id

        Return the original message id if the message does not
        exist.",
"def _get_indent_length(line):
    """"""Return the length of the indentation on the given token's line.""""""
    result = 0
    for char in line:
        if char == "" "":
            result += 1
        elif char == ""\t"":
            result += _TAB_LENGTH
        else:
            break
    return result",Return the length of the indentation on the given token's line.,
"def _check_surrounded_by_space(self, tokens, i):
        """"""Check that a binary operator is surrounded by exactly one space.""""""
        self._check_space(tokens, i, (_MUST, _MUST))",Check that a binary operator is surrounded by exactly one space.,
"def _is_conditional_import(node):
    """"""Checks if an import node is in the context of a conditional.
    """"""
    parent = node.parent
    return isinstance(
        parent, (astroid.TryExcept, astroid.ExceptHandler, astroid.If, astroid.IfExp)
    )",Checks if an import node is in the context of a conditional.,
"def _validate(value, optdict, name=""""):
    """"""return a validated value for an option according to its type

    optional argument name is only used for error message formatting
    """"""
    try:
        _type = optdict[""type""]
    except KeyError:
        # FIXME
        return value
    return _call_validator(_type, optdict, name, value)","return a validated value for an option according to its type

    optional argument name is only used for error message formatting",
"def _match_long_opt(self, opt):
        """"""Disable abbreviations.""""""
        if opt not in self._long_opt:
            raise optparse.BadOptionError(opt)
        return opt",Disable abbreviations.,
"def global_set_option(self, opt, value):
        """"""set option on the correct option provider""""""
        self._all_options[opt].set_option(opt, value)",set option on the correct option provider,
"def add_help_section(self, title, description, level=0):
        """"""add a dummy option section for help purpose """"""
        group = optparse.OptionGroup(
            self.cmdline_parser, title=title.capitalize(), description=description
        )
        group.level = level
        self._maxlevel = max(self._maxlevel, level)
        self.cmdline_parser.add_option_group(group)",add a dummy option section for help purpose,
"def help(self, level=0):
        """"""return the usage string for available options """"""
        self.cmdline_parser.formatter.output_level = level
        with _patch_optparse():
            return self.cmdline_parser.format_help()",return the usage string for available options,
"def option_attrname(self, opt, optdict=None):
        """"""get the config attribute corresponding to opt""""""
        if optdict is None:
            optdict = self.get_option_def(opt)
        return optdict.get(""dest"", opt.replace(""-"", ""_""))",get the config attribute corresponding to opt,
"def get_option_def(self, opt):
        """"""return the dictionary defining an option given its name""""""
        assert self.options
        for option in self.options:
            if option[0] == opt:
                return option[1]
        raise optparse.OptionError(
            ""no such option %s in section %r"" % (opt, self.name), opt
        )",return the dictionary defining an option given its name,
"def visit_importfrom(self, node):
        """"""Checks to see if a module uses a non-Python logging module.""""""
        try:
            logging_name = self._from_imports[node.modname]
            for module, as_name in node.names:
                if module == logging_name:
                    self._logging_names.add(as_name or module)
        except KeyError:
            pass",Checks to see if a module uses a non-Python logging module.,
"def visit_import(self, node):
        """"""Checks to see if this module uses Python's built-in logging.""""""
        for module, as_name in node.names:
            if module in self._logging_modules:
                self._logging_names.add(as_name or module)",Checks to see if this module uses Python's built-in logging.,
"def in_nested_list(nested_list, obj):
    """"""return true if the object is an element of <nested_list> or of a nested
    list
    """"""
    for elmt in nested_list:
        if isinstance(elmt, (list, tuple)):
            if in_nested_list(elmt, obj):
                return True
        elif elmt == obj:
            return True
    return False","return true if the object is an element of <nested_list> or of a nested
    list",
"def _is_one_arg_pos_call(call):
    """"""Is this a call with exactly 1 argument,
    where that argument is positional?
    """"""
    return isinstance(call, astroid.Call) and len(call.args) == 1 and not call.keywords","Is this a call with exactly 1 argument,
    where that argument is positional?",
"def register(linter):
    """"""required method to auto register this checker""""""
    linter.register_checker(BasicErrorChecker(linter))
    linter.register_checker(BasicChecker(linter))
    linter.register_checker(NameChecker(linter))
    linter.register_checker(DocStringChecker(linter))
    linter.register_checker(PassChecker(linter))
    linter.register_checker(ComparisonChecker(linter))",required method to auto register this checker,
"def visit_unaryop(self, node):
        """"""check use of the non-existent ++ and -- operator operator""""""
        if (
            (node.op in ""+-"")
            and isinstance(node.operand, astroid.UnaryOp)
            and (node.operand.op == node.op)
        ):
            self.add_message(""nonexistent-operator"", node=node, args=node.op * 2)",check use of the non-existent ++ and -- operator operator,
"def visit_call(self, node):
        """""" Check instantiating abstract class with
        abc.ABCMeta as metaclass.
        """"""
        try:
            for inferred in node.func.infer():
                self._check_inferred_class_is_abstract(inferred, node)
        except astroid.InferenceError:
            return","Check instantiating abstract class with
        abc.ABCMeta as metaclass.",
"def open(self):
        """"""initialize visit variables and statistics
        """"""
        self._tryfinallys = []
        self.stats = self.linter.add_stats(module=0, function=0, method=0, class_=0)",initialize visit variables and statistics,
"def visit_functiondef(self, node):
        """"""check function name, docstring, arguments, redefinition,
        variable names, max locals
        """"""
        self.stats[node.is_method() and ""method"" or ""function""] += 1
        self._check_dangerous_default(node)","check function name, docstring, arguments, redefinition,
        variable names, max locals",
"def visit_assert(self, node):
        """"""check the use of an assert statement on a tuple.""""""
        if (
            node.fail is None
            and isinstance(node.test, astroid.Tuple)
            and len(node.test.elts) == 2
        ):
            self.add_message(""assert-on-tuple"", node=node)",check the use of an assert statement on a tuple.,
"def visit_dict(self, node):
        """"""check duplicate key in dictionary""""""
        keys = set()
        for k, _ in node.items:
            if isinstance(k, astroid.Const):
                key = k.value
                if key in keys:
                    self.add_message(""duplicate-key"", node=node, args=key)
                keys.add(key)",check duplicate key in dictionary,
"def _check_unreachable(self, node):
        """"""check unreachable code""""""
        unreach_stmt = node.next_sibling()
        if unreach_stmt is not None:
            self.add_message(""unreachable"", node=unreach_stmt)",check unreachable code,
"def _recursive_check_names(self, args, node):
        """"""check names in a possibly recursive list <arg>""""""
        for arg in args:
            if isinstance(arg, astroid.AssignName):
                self._check_name(""argument"", arg.name, node)
            else:
                self._recursive_check_names(arg.elts, node)",check names in a possibly recursive list <arg>,
"def add_relationship(self, from_object, to_object, relation_type, name=None):
        """"""create a relation ship
        """"""
        rel = Relationship(from_object, to_object, relation_type, name)
        self.relationships.setdefault(relation_type, []).append(rel)",create a relation ship,
"def get_relationship(self, from_object, relation_type):
        """"""return a relation ship or None
        """"""
        for rel in self.relationships.get(relation_type, ()):
            if rel.from_object is from_object:
                return rel
        raise KeyError(relation_type)",return a relation ship or None,
"def get_methods(self, node):
        """"""return visible methods""""""
        methods = [
            m
            for m in node.values()
            if isinstance(m, astroid.FunctionDef)
            and not decorated_with_property(m)
            and self.show_attr(m.name)
        ]
        return sorted(methods, key=lambda n: n.name)",return visible methods,
"def add_object(self, title, node):
        """"""create a diagram object
        """"""
        assert node not in self._nodes
        ent = DiagramEntity(title, node)
        self._nodes[node] = ent
        self.objects.append(ent)",create a diagram object,
"def classes(self):
        """"""return all class nodes in the diagram""""""
        return [o for o in self.objects if isinstance(o.node, astroid.ClassDef)]",return all class nodes in the diagram,
"def classe(self, name):
        """"""return a class by its name, raise KeyError if not found
        """"""
        for klass in self.classes():
            if klass.node.name == name:
                return klass
        raise KeyError(name)","return a class by its name, raise KeyError if not found",
"def modules(self):
        """"""return all module nodes in the diagram""""""
        return [o for o in self.objects if isinstance(o.node, astroid.Module)]",return all module nodes in the diagram,
"def module(self, name):
        """"""return a module by its name, raise KeyError if not found
        """"""
        for mod in self.modules():
            if mod.node.name == name:
                return mod
        raise KeyError(name)","return a module by its name, raise KeyError if not found",
"def add_from_depend(self, node, from_module):
        """"""add dependencies created by from-imports
        """"""
        mod_name = node.root().name
        obj = self.module(mod_name)
        if from_module not in obj.node.depends:
            obj.node.depends.append(from_module)",add dependencies created by from-imports,
"def delete(self):
        """"""Removes itself from the cache

        Note: This is required by the oauthlib
        """"""
        log.debug(
            ""Deleting grant %s for client %s"" % (self.code, self.client_id)
        )
        self._cache.delete(self.key)
        return None","Removes itself from the cache

        Note: This is required by the oauthlib",
"def query(self):
        """"""Determines which method of getting the query object for use""""""
        if hasattr(self.model, 'query'):
            return self.model.query
        else:
            return self.session.query(self.model)",Determines which method of getting the query object for use,
"def get(self, client_id, code):
        """"""Get the Grant object with the given client ID and code

        :param client_id: ID of the client
        :param code:
        """"""
        return self.query.filter_by(client_id=client_id, code=code).first()","Get the Grant object with the given client ID and code

        :param client_id: ID of the client
        :param code:",
"def prepare_request(uri, headers=None, data=None, method=None):
    """"""Make request parameters right.""""""
    if headers is None:
        headers = {}

    if data and not method:
        method = 'POST'
    elif not method:
        method = 'GET'

    if method == 'GET' and data:
        uri = add_params_to_uri(uri, data)
        data = None

    return uri, headers, data, method",Make request parameters right.,
"def init_app(self, app):
        """"""Init app with Flask instance.

        You can also pass the instance of Flask later::

            oauth = OAuth()
            oauth.init_app(app)
        """"""
        self.app = app
        app.extensions = getattr(app, 'extensions', {})
        app.extensions[self.state_key] = self","Init app with Flask instance.

        You can also pass the instance of Flask later::

            oauth = OAuth()
            oauth.init_app(app)",
"def client(self):
        """"""The lazy-created OAuth session with the return value of
        :meth:`tokengetter`.

        :returns: The OAuth session instance or ``None`` while token missing.
        """"""
        token = self.obtain_token()
        if token is None:
            raise AccessTokenNotFound
        return self._make_client_with_token(token)","The lazy-created OAuth session with the return value of
        :meth:`tokengetter`.

        :returns: The OAuth session instance or ``None`` while token missing.",
"def get_default_realms(self, client_key, request):
        """"""Default realms of the client.""""""
        log.debug('Get realms for %r', client_key)

        if not request.client:
            request.client = self._clientgetter(client_key=client_key)

        client = request.client
        if hasattr(client, 'default_realms'):
            return client.default_realms
        return []",Default realms of the client.,
"def get_realms(self, token, request):
        """"""Realms for this request token.""""""
        log.debug('Get realms of %r', token)
        tok = request.request_token or self._grantgetter(token=token)
        if not tok:
            return []
        request.request_token = tok
        if hasattr(tok, 'realms'):
            return tok.realms or []
        return []",Realms for this request token.,
"def get_redirect_uri(self, token, request):
        """"""Redirect uri for this request token.""""""
        log.debug('Get redirect uri of %r', token)
        tok = request.request_token or self._grantgetter(token=token)
        return tok.redirect_uri",Redirect uri for this request token.,
"def get_rsa_key(self, client_key, request):
        """"""Retrieves a previously stored client provided RSA key.""""""
        if not request.client:
            request.client = self._clientgetter(client_key=client_key)
        if hasattr(request.client, 'rsa_key'):
            return request.client.rsa_key
        return None",Retrieves a previously stored client provided RSA key.,
"def validate_client_key(self, client_key, request):
        """"""Validates that supplied client key.""""""
        log.debug('Validate client key for %r', client_key)
        if not request.client:
            request.client = self._clientgetter(client_key=client_key)
        if request.client:
            return True
        return False",Validates that supplied client key.,
"def verify_request_token(self, token, request):
        """"""Verify if the request token is existed.""""""
        log.debug('Verify request token %r', token)
        tok = request.request_token or self._grantgetter(token=token)
        if tok:
            request.request_token = tok
            return True
        return False",Verify if the request token is existed.,
"def get_default_redirect_uri(self, client_id, request, *args, **kwargs):
        """"""Default redirect_uri for the given client.""""""
        request.client = request.client or self._clientgetter(client_id)
        redirect_uri = request.client.default_redirect_uri
        log.debug('Found default redirect uri %r', redirect_uri)
        return redirect_uri",Default redirect_uri for the given client.,
"def get_default_scopes(self, client_id, request, *args, **kwargs):
        """"""Default scopes for the given client.""""""
        request.client = request.client or self._clientgetter(client_id)
        scopes = request.client.default_scopes
        log.debug('Found default scopes %r', scopes)
        return scopes",Default scopes for the given client.,
"def save_bearer_token(self, token, request, *args, **kwargs):
        """"""Persist the Bearer token.""""""
        log.debug('Save bearer token %r', token)
        self._tokensetter(token, request, *args, **kwargs)
        return request.client.default_redirect_uri",Persist the Bearer token.,
"def validate_client_id(self, client_id, request, *args, **kwargs):
        """"""Ensure client_id belong to a valid and active client.""""""
        log.debug('Validate client %r', client_id)
        client = request.client or self._clientgetter(client_id)
        if client:
            # attach client to request object
            request.client = client
            return True
        return False",Ensure client_id belong to a valid and active client.,
"def validate_scopes(self, client_id, scopes, client, request,
                        *args, **kwargs):
        """"""Ensure the client is authorized access to requested scopes.""""""
        if hasattr(client, 'validate_scopes'):
            return client.validate_scopes(scopes)
        return set(client.default_scopes).issuperset(set(scopes))",Ensure the client is authorized access to requested scopes.,
"def update_qq_api_request_data(data={}):
    '''Update some required parameters for OAuth2.0 API calls'''
    defaults = {
        'openid': session.get('qq_openid'),
        'access_token': session.get('qq_token')[0],
        'oauth_consumer_key': QQ_APP_ID,
    }
    defaults.update(data)
    return defaults",Update some required parameters for OAuth2.0 API calls,
"def convert_keys_to_string(dictionary):
    '''Recursively converts dictionary keys to strings.'''
    if not isinstance(dictionary, dict):
        return dictionary
    return dict((str(k), convert_keys_to_string(v)) for k, v in dictionary.items())",Recursively converts dictionary keys to strings.,
"def change_weibo_header(uri, headers, body):
    """"""Since weibo is a rubbish server, it does not follow the standard,
    we need to change the authorization header for it.""""""
    auth = headers.get('Authorization')
    if auth:
        auth = auth.replace('Bearer', 'OAuth2')
        headers['Authorization'] = auth
    return uri, headers, body","Since weibo is a rubbish server, it does not follow the standard,
    we need to change the authorization header for it.",
"def register_to(self, oauth, name=None, **kwargs):
        """"""Creates a remote app and registers it.""""""
        kwargs = self._process_kwargs(
            name=(name or self.default_name), **kwargs)
        return oauth.remote_app(**kwargs)",Creates a remote app and registers it.,
"def create(self, oauth, **kwargs):
        """"""Creates a remote app only.""""""
        kwargs = self._process_kwargs(
            name=self.default_name, register=False, **kwargs)
        return oauth.remote_app(**kwargs)",Creates a remote app only.,
"def _get_uri_from_request(request):
    """"""
    The uri returned from request.uri is not properly urlencoded
    (sometimes it's partially urldecoded) This is a weird hack to get
    werkzeug to return the proper urlencoded string uri
    """"""
    uri = request.base_url
    if request.query_string:
        uri += '?' + request.query_string.decode('utf-8')
    return uri","The uri returned from request.uri is not properly urlencoded
    (sometimes it's partially urldecoded) This is a weird hack to get
    werkzeug to return the proper urlencoded string uri",
"def to_bytes(text, encoding='utf-8'):
    """"""Make sure text is bytes type.""""""
    if not text:
        return text
    if not isinstance(text, bytes_type):
        text = text.encode(encoding)
    return text",Make sure text is bytes type.,
"def decode_base64(text, encoding='utf-8'):
    """"""Decode base64 string.""""""
    text = to_bytes(text, encoding)
    return to_unicode(base64.b64decode(text), encoding)",Decode base64 string.,
"def create_response(headers, body, status):
    """"""Create response class for Flask.""""""
    response = Response(body or '')
    for k, v in headers.items():
        response.headers[str(k)] = v

    response.status_code = status
    return response",Create response class for Flask.,
"def _simple(self, **kwargs):
        """"""Returns a :class:`SimpleCache` instance

        .. warning::

            This cache system might not be thread safe. Use with caution.
        """"""
        kwargs.update(dict(threshold=self._config('threshold', 500)))
        return SimpleCache(**kwargs)","Returns a :class:`SimpleCache` instance

        .. warning::

            This cache system might not be thread safe. Use with caution.",
"def _memcache(self, **kwargs):
        """"""Returns a :class:`MemcachedCache` instance""""""
        kwargs.update(dict(
            servers=self._config('MEMCACHED_SERVERS', None),
            key_prefix=self._config('key_prefix', None),
        ))
        return MemcachedCache(**kwargs)",Returns a :class:`MemcachedCache` instance,
"def _filesystem(self, **kwargs):
        """"""Returns a :class:`FileSystemCache` instance""""""
        kwargs.update(dict(
            threshold=self._config('threshold', 500),
        ))
        return FileSystemCache(self._config('dir', None), **kwargs)",Returns a :class:`FileSystemCache` instance,
"def get_cached_clients():
    """"""Gets the cached clients dictionary in current context.""""""
    if OAuth.state_key not in current_app.extensions:
        raise RuntimeError('%r is not initialized.' % current_app)
    state = current_app.extensions[OAuth.state_key]
    return state.cached_clients",Gets the cached clients dictionary in current context.,
"def check_exception(self):
        """"""
        Call the method repeatedly such that it will raise an exception.
        """"""
        for i in xrange(self.iterations):
            cert = X509()
            try:
                cert.get_pubkey()
            except Error:
                pass",Call the method repeatedly such that it will raise an exception.,
"def check_load_privatekey_callback(self):
        """"""
        Call the function with an encrypted PEM and a passphrase callback.
        """"""
        for i in xrange(self.iterations * 10):
            load_privatekey(
                FILETYPE_PEM, self.ENCRYPTED_PEM, lambda *args: ""hello, secret"")",Call the function with an encrypted PEM and a passphrase callback.,
"def check_get_revoked(self):
        """"""
        Create a CRL object with 100 Revoked objects, then call the
        get_revoked method repeatedly.
        """"""
        crl = CRL()
        for i in xrange(100):
            crl.add_revoked(Revoked())
        for i in xrange(self.iterations):
            crl.get_revoked()","Create a CRL object with 100 Revoked objects, then call the
        get_revoked method repeatedly.",
"def check_X509_REVOKED_dup(self):
        """"""
        Copy an empty Revoked object repeatedly. The copy is not garbage
        collected, therefore it needs to be manually freed.
        """"""
        for i in xrange(self.iterations * 100):
            revoked_copy = _X509_REVOKED_dup(Revoked()._revoked)
            _lib.X509_REVOKED_free(revoked_copy)","Copy an empty Revoked object repeatedly. The copy is not garbage
        collected, therefore it needs to be manually freed.",
"def check_to_EC_KEY(self):
        """"""
        Repeatedly create an EC_KEY* from an :py:obj:`_EllipticCurve`.  The
        structure should be automatically garbage collected.
        """"""
        curves = get_elliptic_curves()
        if curves:
            curve = next(iter(curves))
            for i in xrange(self.iterations * 1000):
                curve._to_EC_KEY()","Repeatedly create an EC_KEY* from an :py:obj:`_EllipticCurve`.  The
        structure should be automatically garbage collected.",
"def createKeyPair(type, bits):
    """"""
    Create a public/private key pair.

    Arguments: type - Key type, must be one of TYPE_RSA and TYPE_DSA
               bits - Number of bits to use in the key
    Returns:   The public/private key pair in a PKey object
    """"""
    pkey = crypto.PKey()
    pkey.generate_key(type, bits)
    return pkey","Create a public/private key pair.

    Arguments: type - Key type, must be one of TYPE_RSA and TYPE_DSA
               bits - Number of bits to use in the key
    Returns:   The public/private key pair in a PKey object",
"def _check_env_vars_set(self, dir_env_var, file_env_var):
        """"""
        Check to see if the default cert dir/file environment vars are present.

        :return: bool
        """"""
        return (
            os.environ.get(file_env_var) is not None or
            os.environ.get(dir_env_var) is not None
        )","Check to see if the default cert dir/file environment vars are present.

        :return: bool",
"def renegotiate(self):
        """"""
        Renegotiate the session.

        :return: True if the renegotiation can be started, False otherwise
        :rtype: bool
        """"""
        if not self.renegotiate_pending():
            _openssl_assert(_lib.SSL_renegotiate(self._ssl) == 1)
            return True
        return False","Renegotiate the session.

        :return: True if the renegotiation can be started, False otherwise
        :rtype: bool",
"def do_handshake(self):
        """"""
        Perform an SSL handshake (usually called after :meth:`renegotiate` or
        one of :meth:`set_accept_state` or :meth:`set_accept_state`). This can
        raise the same exceptions as :meth:`send` and :meth:`recv`.

        :return: None.
        """"""
        result = _lib.SSL_do_handshake(self._ssl)
        self._raise_ssl_error(self._ssl, result)","Perform an SSL handshake (usually called after :meth:`renegotiate` or
        one of :meth:`set_accept_state` or :meth:`set_accept_state`). This can
        raise the same exceptions as :meth:`send` and :meth:`recv`.

        :return: None.",
"def set_shutdown(self, state):
        """"""
        Set the shutdown state of the Connection.

        :param state: bitvector of SENT_SHUTDOWN, RECEIVED_SHUTDOWN.
        :return: None
        """"""
        if not isinstance(state, integer_types):
            raise TypeError(""state must be an integer"")

        _lib.SSL_set_shutdown(self._ssl, state)","Set the shutdown state of the Connection.

        :param state: bitvector of SENT_SHUTDOWN, RECEIVED_SHUTDOWN.
        :return: None",
"def get_certificate(self):
        """"""
        Retrieve the local certificate (if any)

        :return: The local certificate
        """"""
        cert = _lib.SSL_get_certificate(self._ssl)
        if cert != _ffi.NULL:
            _lib.X509_up_ref(cert)
            return X509._from_raw_x509_ptr(cert)
        return None","Retrieve the local certificate (if any)

        :return: The local certificate",
"def get_peer_certificate(self):
        """"""
        Retrieve the other side's certificate (if any)

        :return: The peer's certificate
        """"""
        cert = _lib.SSL_get_peer_certificate(self._ssl)
        if cert != _ffi.NULL:
            return X509._from_raw_x509_ptr(cert)
        return None","Retrieve the other side's certificate (if any)

        :return: The peer's certificate",
"def _bio_to_string(bio):
    """"""
    Copy the contents of an OpenSSL BIO object into a Python byte string.
    """"""
    result_buffer = _ffi.new('char**')
    buffer_length = _lib.BIO_get_mem_data(bio, result_buffer)
    return _ffi.buffer(result_buffer[0], buffer_length)[:]",Copy the contents of an OpenSSL BIO object into a Python byte string.,
"def _to_EC_KEY(self):
        """"""
        Create a new OpenSSL EC_KEY structure initialized to use this curve.

        The structure is automatically garbage collected when the Python object
        is garbage collected.
        """"""
        key = self._lib.EC_KEY_new_by_curve_name(self._nid)
        return _ffi.gc(key, _lib.EC_KEY_free)","Create a new OpenSSL EC_KEY structure initialized to use this curve.

        The structure is automatically garbage collected when the Python object
        is garbage collected.",
"def set_pubkey(self, pkey):
        """"""
        Set the public key of the certificate signing request.

        :param pkey: The public key to use.
        :type pkey: :py:class:`PKey`

        :return: ``None``
        """"""
        set_result = _lib.X509_REQ_set_pubkey(self._req, pkey._pkey)
        _openssl_assert(set_result == 1)","Set the public key of the certificate signing request.

        :param pkey: The public key to use.
        :type pkey: :py:class:`PKey`

        :return: ``None``",
"def set_version(self, version):
        """"""
        Set the version subfield (RFC 2459, section 4.1.2.1) of the certificate
        request.

        :param int version: The version number.
        :return: ``None``
        """"""
        set_result = _lib.X509_REQ_set_version(self._req, version)
        _openssl_assert(set_result == 1)","Set the version subfield (RFC 2459, section 4.1.2.1) of the certificate
        request.

        :param int version: The version number.
        :return: ``None``",
"def to_cryptography(self):
        """"""
        Export as a ``cryptography`` certificate.

        :rtype: ``cryptography.x509.Certificate``

        .. versionadded:: 17.1.0
        """"""
        from cryptography.hazmat.backends.openssl.x509 import _Certificate
        backend = _get_backend()
        return _Certificate(backend, self._x509)","Export as a ``cryptography`` certificate.

        :rtype: ``cryptography.x509.Certificate``

        .. versionadded:: 17.1.0",
"def has_expired(self):
        """"""
        Check whether the certificate has expired.

        :return: ``True`` if the certificate has expired, ``False`` otherwise.
        :rtype: bool
        """"""
        time_string = _native(self.get_notAfter())
        not_after = datetime.datetime.strptime(time_string, ""%Y%m%d%H%M%SZ"")

        return not_after < datetime.datetime.utcnow()","Check whether the certificate has expired.

        :return: ``True`` if the certificate has expired, ``False`` otherwise.
        :rtype: bool",
"def set_issuer(self, issuer):
        """"""
        Set the issuer of this certificate.

        :param issuer: The issuer.
        :type issuer: :py:class:`X509Name`

        :return: ``None``
        """"""
        self._set_name(_lib.X509_set_issuer_name, issuer)
        self._issuer_invalidator.clear()","Set the issuer of this certificate.

        :param issuer: The issuer.
        :type issuer: :py:class:`X509Name`

        :return: ``None``",
"def set_subject(self, subject):
        """"""
        Set the subject of this certificate.

        :param subject: The subject.
        :type subject: :py:class:`X509Name`

        :return: ``None``
        """"""
        self._set_name(_lib.X509_set_subject_name, subject)
        self._subject_invalidator.clear()","Set the subject of this certificate.

        :param subject: The subject.
        :type subject: :py:class:`X509Name`

        :return: ``None``",
"def set_rev_date(self, when):
        """"""
        Set the revocation timestamp.

        :param bytes when: The timestamp of the revocation,
            as ASN.1 TIME.
        :return: ``None``
        """"""
        dt = _lib.X509_REVOKED_get0_revocationDate(self._revoked)
        return _set_asn1_time(dt, when)","Set the revocation timestamp.

        :param bytes when: The timestamp of the revocation,
            as ASN.1 TIME.
        :return: ``None``",
"def to_cryptography(self):
        """"""
        Export as a ``cryptography`` CRL.

        :rtype: ``cryptography.x509.CertificateRevocationList``

        .. versionadded:: 17.1.0
        """"""
        from cryptography.hazmat.backends.openssl.x509 import (
            _CertificateRevocationList
        )
        backend = _get_backend()
        return _CertificateRevocationList(backend, self._crl)","Export as a ``cryptography`` CRL.

        :rtype: ``cryptography.x509.CertificateRevocationList``

        .. versionadded:: 17.1.0",
"def get_type_name(self):
        """"""
        Returns the type name of the PKCS7 structure

        :return: A string with the typename
        """"""
        nid = _lib.OBJ_obj2nid(self._pkcs7.type)
        string_type = _lib.OBJ_nid2sn(nid)
        return _ffi.string(string_type)","Returns the type name of the PKCS7 structure

        :return: A string with the typename",
"def set_certificate(self, cert):
        """"""
        Set the certificate in the PKCS #12 structure.

        :param cert: The new certificate, or :py:const:`None` to unset it.
        :type cert: :py:class:`X509` or :py:const:`None`

        :return: ``None``
        """"""
        if not isinstance(cert, X509):
            raise TypeError(""cert must be an X509 instance"")
        self._cert = cert","Set the certificate in the PKCS #12 structure.

        :param cert: The new certificate, or :py:const:`None` to unset it.
        :type cert: :py:class:`X509` or :py:const:`None`

        :return: ``None``",
"def b64_encode(self):
        """"""
        Generate a base64 encoded representation of this SPKI object.

        :return: The base64 encoded string.
        :rtype: :py:class:`bytes`
        """"""
        encoded = _lib.NETSCAPE_SPKI_b64_encode(self._spki)
        result = _ffi.string(encoded)
        _lib.OPENSSL_free(encoded)
        return result","Generate a base64 encoded representation of this SPKI object.

        :return: The base64 encoded string.
        :rtype: :py:class:`bytes`",
"def set_pubkey(self, pkey):
        """"""
        Set the public key of the certificate

        :param pkey: The public key
        :return: ``None``
        """"""
        set_result = _lib.NETSCAPE_SPKI_set_pubkey(self._spki, pkey._pkey)
        _openssl_assert(set_result == 1)","Set the public key of the certificate

        :param pkey: The public key
        :return: ``None``",
"def accept(self):
        """"""
        This is the other part of the shutdown() workaround.
        Since servers create new sockets, we have to infect
        them with our magic. :)
        """"""
        c, a = self.__dict__[""conn""].accept()
        return (SSLWrapper(c), a)","This is the other part of the shutdown() workaround.
        Since servers create new sockets, we have to infect
        them with our magic. :)",
"def get_service_metadata(self):
        """"""
        Return extra config options to be passed to the TrelloIssue class
        """"""
        return {
            'import_labels_as_tags':
            self.config.get('import_labels_as_tags', False, asbool),
            'label_template':
            self.config.get('label_template', DEFAULT_LABEL_TEMPLATE),
            }",Return extra config options to be passed to the TrelloIssue class,
"def annotations(self, card_json):
        """""" A wrapper around get_comments that build the taskwarrior
        annotations. """"""
        comments = self.get_comments(card_json['id'])
        annotations = self.build_annotations(
            ((c['memberCreator']['username'], c['data']['text']) for c in comments),
            card_json[""shortUrl""])
        return annotations","A wrapper around get_comments that build the taskwarrior
        annotations.",
"def _api_url(self, path, **context):
        """""" Build the full url to the API endpoint """"""
        if self.host == 'github.com':
            baseurl = ""https://api.github.com""
        else:
            baseurl = ""https://{}/api/v3"".format(self.host)
        return baseurl + path.format(**context)",Build the full url to the API endpoint,
"def get_query(self, query):
        """"""Run a generic issue/PR query""""""
        url = self._api_url(
            ""/search/issues?q={query}&per_page=100"", query=query)
        return self._getter(url, subkey='items')",Run a generic issue/PR query,
"def _link_field_to_dict(field):
        """""" Utility for ripping apart github's Link header field.
        It's kind of ugly.
        """"""

        if not field:
            return dict()

        return dict([
            (
                part.split('; ')[1][5:-1],
                part.split('; ')[0][1:-1],
            ) for part in field.split(', ')
        ])","Utility for ripping apart github's Link header field.
        It's kind of ugly.",
"def get_owned_repo_issues(self, tag):
        """""" Grab all the issues """"""
        issues = {}
        for issue in self.client.get_issues(*tag.split('/')):
            issues[issue['url']] = (tag, issue)
        return issues",Grab all the issues,
"def _reqs(self, tag):
        """""" Grab all the pull requests """"""
        return [
            (tag, i) for i in
            self.client.get_pulls(*tag.split('/'))
        ]",Grab all the pull requests,
"def _get_config_or_default(self, key, default, as_type=lambda x: x):
        """"""Return a main config value, or default if it does not exist.""""""

        if self.main_config.has_option(self.main_section, key):
            return as_type(self.main_config.get(self.main_section, key))
        return default","Return a main config value, or default if it does not exist.",
"def _get_bug_attr(bug, attr):
    """"""Default longdescs/flags case to [] since they may not be present.""""""
    if attr in (""longdescs"", ""flags""):
        return getattr(bug, attr, [])
    return getattr(bug, attr)",Default longdescs/flags case to [] since they may not be present.,
"def get_data(self, url):
        """""" Perform a request to the fully qualified url and return json. """"""
        return self.json_response(requests.get(url, **self.requests_kwargs))",Perform a request to the fully qualified url and return json.,
"def hamdist(str1, str2):
    """"""Count the # of differences between equal length strings str1 and str2""""""
    diffs = 0
    for ch1, ch2 in zip(str1, str2):
        if ch1 != ch2:
            diffs += 1
    return diffs",Count the # of differences between equal length strings str1 and str2,
"def log_stop(logger):
    """"""log stop""""""

    handlers = logger.handlers[:]
    for handler in handlers:
        handler.close()
        logger.removeHandler(handler)",log stop,
"def get_marts(self):
        """"""Get available marts and their names.""""""

        mart_names = pd.Series(self.names, name=""Name"")
        mart_descriptions = pd.Series(self.displayNames, name=""Description"")

        return pd.concat([mart_names, mart_descriptions], axis=1)",Get available marts and their names.,
"def get_datasets(self, mart='ENSEMBL_MART_ENSEMBL'):
        """"""Get available datasets from mart you've selected""""""
        datasets = self.datasets(mart, raw=True)
        return pd.read_csv(StringIO(datasets), header=None, usecols=[1, 2],
                            names = [""Name"", ""Description""],sep=""\t"")",Get available datasets from mart you've selected,
"def get_attributes(self, dataset):
        """"""Get available attritbutes from dataset you've selected""""""
        attributes = self.attributes(dataset)
        attr_ = [ (k, v[0]) for k, v in attributes.items()]
        return pd.DataFrame(attr_, columns=[""Attribute"",""Description""])",Get available attritbutes from dataset you've selected,
"def get_filters(self, dataset):
        """"""Get available filters from dataset you've selected""""""
        filters = self.filters(dataset)
        filt_ = [ (k, v[0]) for k, v in filters.items()]
        return pd.DataFrame(filt_, columns=[""Filter"", ""Description""])",Get available filters from dataset you've selected,
"def _set_cores(self):
        """"""set cpu numbers to be used""""""

        cpu_num = cpu_count()-1
        if self._processes > cpu_num:
            cores = cpu_num
        elif self._processes < 1:
            cores = 1
        else:
            cores = self._processes
        # have to be int if user input is float
        self._processes = int(cores)",set cpu numbers to be used,
"def get_libraries(self, database=''):
        """"""return active enrichr library name.Offical API """"""

        lib_url='http://amp.pharm.mssm.edu/%sEnrichr/datasetStatistics'%database
        libs_json = json.loads(requests.get(lib_url).text)
        libs = [lib['libraryName'] for lib in libs_json['statistics']]
        return sorted(libs)",return active enrichr library name.Offical API,
"def delete_lower(script, layer_num=None):
    """""" Delete all layers below the specified one.

    Useful for MeshLab ver 2016.12, whcih will only output layer 0.
    """"""
    if layer_num is None:
        layer_num = script.current_layer()
    if layer_num != 0:
        change(script, 0)
    for i in range(layer_num):
        delete(script, 0)
    return None","Delete all layers below the specified one.

    Useful for MeshLab ver 2016.12, whcih will only output layer 0.",
"def del_layer(self, layer_num):
        """""" Delete mesh layer """"""
        del self.layer_stack[layer_num]
        # Adjust current layer if needed
        if layer_num < self.current_layer():
            self.set_current_layer(self.current_layer() - 1)
        return None",Delete mesh layer,
"def v_multiply(scalar, v1):
    """""" Multiply vector by scalar""""""
    vector = []
    for i, x in enumerate(v1):
        vector.append('(({})*({}))'.format(scalar, v1[i]))
    return vector",Multiply vector by scalar,
"def get_vprof_version(filename):
    """"""Returns actual version specified in filename.""""""
    with open(filename) as src_file:
        version_match = re.search(r""^__version__ = ['\""]([^'\""]*)['\""]"",
                                  src_file.read(), re.M)
        if version_match:
            return version_match.group(1)
        raise RuntimeError('Unable to find version info.')",Returns actual version specified in filename.,
"def _remove_duplicates(objects):
    """"""Removes duplicate objects.

    http://www.peterbe.com/plog/uniqifiers-benchmark.
    """"""
    seen, uniq = set(), []
    for obj in objects:
        obj_id = id(obj)
        if obj_id in seen:
            continue
        seen.add(obj_id)
        uniq.append(obj)
    return uniq","Removes duplicate objects.

    http://www.peterbe.com/plog/uniqifiers-benchmark.",
"def _get_obj_count_difference(objs1, objs2):
    """"""Returns count difference in two collections of Python objects.""""""
    clean_obj_list1 = _process_in_memory_objects(objs1)
    clean_obj_list2 = _process_in_memory_objects(objs2)
    obj_count_1 = _get_object_count_by_type(clean_obj_list1)
    obj_count_2 = _get_object_count_by_type(clean_obj_list2)
    return obj_count_1 - obj_count_2",Returns count difference in two collections of Python objects.,
"def compute_mem_overhead(self):
        """"""Returns memory overhead.""""""
        self.mem_overhead = (self._process.memory_info().rss -
                             builtins.initial_rss_size)",Returns memory overhead.,
"def profile_function(self):
        """"""Returns memory stats for a function.""""""
        target_modules = {self._run_object.__code__.co_filename}
        with _CodeEventsTracker(target_modules) as prof:
            prof.compute_mem_overhead()
            result = self._run_object(*self._run_args, **self._run_kwargs)
        return prof, result",Returns memory stats for a function.,
"def get_run_object_type(run_object):
        """"""Determines run object type.""""""
        if isinstance(run_object, tuple):
            return 'function'
        run_object, _, _ = run_object.partition(' ')
        if os.path.isdir(run_object):
            return 'package'
        return 'module'",Determines run object type.,
"def init_package(self, run_object):
        """"""Initializes profiler with a package.""""""
        self.profile = self.profile_package
        self._run_object, _, self._run_args = run_object.partition(' ')
        self._object_name = '%s (package)' % self._run_object
        self._replace_sysargs()",Initializes profiler with a package.,
"def init_function(self, run_object):
        """"""Initializes profiler with a function.""""""
        self.profile = self.profile_function
        self._run_object, self._run_args, self._run_kwargs = run_object
        filename = inspect.getsourcefile(self._run_object)
        self._object_name = '%s @ %s (function)' % (
            self._run_object.__name__, filename)",Initializes profiler with a function.,
"def _replace_sysargs(self):
        """"""Replaces sys.argv with proper args to pass to script.""""""
        sys.argv[:] = [self._run_object]
        if self._run_args:
            sys.argv += self._run_args.split()",Replaces sys.argv with proper args to pass to script.,
"def _fill_sample_count(self, node):
        """"""Counts and fills sample counts inside call tree.""""""
        node['sampleCount'] += sum(
            self._fill_sample_count(child) for child in node['children'])
        return node['sampleCount']",Counts and fills sample counts inside call tree.,
"def init_db():
    """"""Initializes DB.""""""
    with contextlib.closing(connect_to_db()) as db:
        db.cursor().executescript(DB_SCHEMA)
        db.commit()",Initializes DB.,
"def show_guestbook():
    """"""Returns all existing guestbook records.""""""
    cursor = flask.g.db.execute(
        'SELECT name, message FROM entry ORDER BY id DESC;')
    entries = [{'name': row[0], 'message': row[1]} for row in cursor.fetchall()]
    return jinja2.Template(LAYOUT).render(entries=entries)",Returns all existing guestbook records.,
"def add_entry():
    """"""Adds single guestbook record.""""""
    name, msg = flask.request.form['name'], flask.request.form['message']
    flask.g.db.execute(
        'INSERT INTO entry (name, message) VALUES (?, ?)', (name, msg))
    flask.g.db.commit()
    return flask.redirect('/')",Adds single guestbook record.,
"def profiler_handler(uri):
    """"""Profiler handler.""""""
    # HTTP method should be GET.
    if uri == 'main':
        runner.run(show_guestbook, 'cmhp')
    # In this case HTTP method should be POST singe add_entry uses POST
    elif uri == 'add':
        runner.run(add_entry, 'cmhp')
    return flask.redirect('/')",Profiler handler.,
"def _handle_root():
        """"""Handles index.html requests.""""""
        res_filename = os.path.join(
            os.path.dirname(__file__), _PROFILE_HTML)
        with io.open(res_filename, 'rb') as res_file:
            content = res_file.read()
        return content, 'text/html'",Handles index.html requests.,
"def _handle_other(self):
        """"""Handles static files requests.""""""
        res_filename = os.path.join(
            os.path.dirname(__file__), _STATIC_DIR, self.path[1:])
        with io.open(res_filename, 'rb') as res_file:
            content = res_file.read()
        _, extension = os.path.splitext(self.path)
        return content, 'text/%s' % extension[1:]",Handles static files requests.,
"def _send_response(self, http_code, message=None, headers=None):
        """"""Sends HTTP response code, message and headers.""""""
        self.send_response(http_code, message)
        if headers:
            for header in headers:
                self.send_header(*header)
            self.end_headers()","Sends HTTP response code, message and headers.",
"def check_standard_dir(module_path):
    """"""Checks whether path belongs to standard library or installed modules.""""""
    if 'site-packages' in module_path:
        return True
    for stdlib_path in _STDLIB_PATHS:
        if fnmatch.fnmatchcase(module_path, stdlib_path + '*'):
            return True
    return False",Checks whether path belongs to standard library or installed modules.,
"def fill_heatmap(self):
        """"""Fills code heatmap and execution count dictionaries.""""""
        for module_path, lineno, runtime in self.lines_without_stdlib:
            self._execution_count[module_path][lineno] += 1
            self._heatmap[module_path][lineno] += runtime",Fills code heatmap and execution count dictionaries.,
"def to_scikit(self):
        """"""
        Convert to equivalent StandardScaler
        """"""
        scaler = StandardScaler(with_mean=self.with_mean,
                                with_std=self.with_std,
                                copy=self.copy)
        scaler.__dict__ = self.__dict__
        return scaler",Convert to equivalent StandardScaler,
"def score(self, Z):
        """"""Applies transforms to the data, and the score method of the
        final estimator. Valid only if the final estimator implements
        score.""""""
        Zt = Z
        for name, transform in self.steps[:-1]:
            Zt = transform.transform(Zt)
        return self.steps[-1][-1].score(Zt)","Applies transforms to the data, and the score method of the
        final estimator. Valid only if the final estimator implements
        score.",
"def transform(self, y):
        """"""Transform labels to normalized encoding.
        Parameters
        ----------
        y : ArrayRDD [n_samples]
            Target values.
        Returns
        -------
        y : ArrayRDD [n_samples]
        """"""
        mapper = super(SparkLabelEncoder, self).transform
        mapper = self.broadcast(mapper, y.context)
        return y.transform(mapper)","Transform labels to normalized encoding.
        Parameters
        ----------
        y : ArrayRDD [n_samples]
            Target values.
        Returns
        -------
        y : ArrayRDD [n_samples]",
"def _score(estimator, Z_test, scorer):
    """"""Compute the score of an estimator on a given test set.""""""
    score = scorer(estimator, Z_test)
    if not isinstance(score, numbers.Number):
        raise ValueError(""scoring must return a number, got %s (%s) instead.""
                         % (str(score), type(score)))
    return score",Compute the score of an estimator on a given test set.,
"def shape(self):
        """"""Returns the shape of the data.""""""
        # TODO cache
        first = self.first().shape
        shape = self._rdd.map(lambda x: x.shape[0]).sum()
        return (shape,) + first[1:]",Returns the shape of the data.,
"def toarray(self):
        """"""Returns the data as numpy.array from each partition.""""""
        rdd = self._rdd.map(lambda x: x.toarray())
        return np.concatenate(rdd.collect())",Returns the data as numpy.array from each partition.,
"def check_config(file, printfn=print):
    """"""Command to check configuration file. Raises InvalidConfig on error

    :param str file: path to config file
    :param printfn: print function for success message
    :return: None
    """"""
    Config(file).read()
    printfn('The configuration file ""{}"" is correct'.format(file))","Command to check configuration file. Raises InvalidConfig on error

    :param str file: path to config file
    :param printfn: print function for success message
    :return: None",
"def get_headers(self):
        """"""Get HTTP Headers to send. By default default_headers

        :return: HTTP Headers
        :rtype: dict
        """"""
        headers = copy.copy(self.default_headers or {})
        headers.update(self.data.get('headers') or {})
        return headers","Get HTTP Headers to send. By default default_headers

        :return: HTTP Headers
        :rtype: dict",
"def get_url(self):
        """"""API url

        :return: url
        :rtype: str
        """"""
        url = self.data[self.execute_name]
        parsed = urlparse(url)
        if not parsed.scheme:
            url = '{}://{}'.format(self.default_protocol, url)
        if not url.split(':')[-1].isalnum():
            url += ':{}'.format(self.default_port)
        return url","API url

        :return: url
        :rtype: str",
"def get_body(self):
        """"""Return ""data"" value on self.data

        :return: data to send
        :rtype: str
        """"""
        if self.default_body:
            return self.default_body
        data = self.data.get('data')
        if isinstance(data, dict):
            return json.dumps(data)
        return data","Return ""data"" value on self.data

        :return: data to send
        :rtype: str",
"def get_url(self):
        """"""Home assistant url

        :return: url
        :rtype: str
        """"""
        url = super(ExecuteHomeAssistant, self).get_url()
        if not self.data.get('event'):
            raise InvalidConfig(extra_body='Event option is required for HomeAsistant on {} device.'.format(self.name))
        url += '/api/events/{}'.format(self.data['event'])
        return url","Home assistant url

        :return: url
        :rtype: str",
"def discovery_print(pkt):
    """"""Scandevice callback. Register src mac to avoid src repetition.
    Print device on screen.

    :param scapy.packet.Packet pkt: Scapy Packet
    :return: None
    """"""
    if pkt.src in mac_id_list:
        return
    mac_id_list.append(pkt.src)
    text = pkt_text(pkt)
    click.secho(text, fg='magenta') if 'Amazon' in text else click.echo(text)","Scandevice callback. Register src mac to avoid src repetition.
    Print device on screen.

    :param scapy.packet.Packet pkt: Scapy Packet
    :return: None",
"def discover(interface=None):
    """"""Print help and scan devices on screen.

    :return: None
    """"""
    click.secho(HELP, fg='yellow')
    scan_devices(discovery_print, lfilter=lambda d: d.src not in mac_id_list, iface=interface)","Print help and scan devices on screen.

    :return: None",
"def on_push(self, device):
        """"""Press button. Check DEFAULT_DELAY.

        :param scapy.packet.Packet device: Scapy packet
        :return: None
        """"""
        src = device.src.lower()
        if last_execution[src] + self.settings.get('delay', DEFAULT_DELAY) > time.time():
            return
        last_execution[src] = time.time()
        self.execute(device)","Press button. Check DEFAULT_DELAY.

        :param scapy.packet.Packet device: Scapy packet
        :return: None",
"def run(self, root_allowed=False):
        """"""Start daemon mode

        :param bool root_allowed: Only used for ExecuteCmd
        :return: loop
        """"""
        self.root_allowed = root_allowed
        scan_devices(self.on_push, lambda d: d.src.lower() in self.devices, self.settings.get('interface'))","Start daemon mode

        :param bool root_allowed: Only used for ExecuteCmd
        :return: loop",
"def compatibility(session, install):
    """"""Run the unit test suite with each support library and Python version.""""""

    session.install('-e', '.[dev]')
    session.install(install)
    _run_tests(session)",Run the unit test suite with each support library and Python version.,
"def text_width(self, text: str) -> float:
        """"""Returns the width, in pixels, of a string in DejaVu Sans 110pt.""""""
        width, _ = self._font.getsize(text)
        return width","Returns the width, in pixels, of a string in DejaVu Sans 110pt.",
"def text_width(self, text: str) -> float:
        """"""Returns the width, in pixels, of a string in DejaVu Sans 110pt.""""""
        width = 0
        for index, c in enumerate(text):
            width += self._char_to_width.get(c, self._default_character_width)
            width -= self._pair_to_kern.get(text[index:index + 2], 0)

        return width","Returns the width, in pixels, of a string in DejaVu Sans 110pt.",
"def generate_supported_characters(deja_vu_sans_path: str) -> Iterable[str]:
    """"""Generate the characters support by the font at the given path.""""""
    font = ttLib.TTFont(deja_vu_sans_path)
    for cmap in font['cmap'].tables:
        if cmap.isUnicode():
            for code in cmap.cmap:
                yield chr(code)",Generate the characters support by the font at the given path.,
"def convolve_gaussian_2d(image, gaussian_kernel_1d):
    """"""Convolve 2d gaussian.""""""
    result = scipy.ndimage.filters.correlate1d(
        image, gaussian_kernel_1d, axis=0)
    result = scipy.ndimage.filters.correlate1d(
        result, gaussian_kernel_1d, axis=1)
    return result",Convolve 2d gaussian.,
"def destroy(self):
        """"""
        Correctly destroy SyncObj. Stop autoTickThread, close connections, etc.
        """"""
        if self.__conf.autoTick:
            self.__destroying = True
        else:
            self._doDestroy()","Correctly destroy SyncObj. Stop autoTickThread, close connections, etc.",
"def printStatus(self):
        """"""Dumps different debug info about cluster to default logger""""""
        status = self.getStatus()
        for k, v in iteritems(status):
            logging.info('%s: %s' % (str(k), str(v)))",Dumps different debug info about cluster to default logger,
"def _shouldConnect(self, node):
        """"""
        Check whether this node should initiate a connection to another node

        :param node: the other node
        :type node: Node
        """"""

        return isinstance(node, TCPNode) and node not in self._preventConnectNodes and (self._selfIsReadonlyNode or self._selfNode.address > node.address)","Check whether this node should initiate a connection to another node

        :param node: the other node
        :type node: Node",
"def put(self, item):
        """"""Put an item into the queue.
        True - if item placed in queue.
        False - if queue is full and item can not be placed.""""""
        if self.__maxsize and len(self.__data) >= self.__maxsize:
            return False
        self.__data.append(item)
        return True","Put an item into the queue.
        True - if item placed in queue.
        False - if queue is full and item can not be placed.",
"def put(self, item):
        """"""Put an item into the queue. Items should be comparable, eg. tuples.
        True - if item placed in queue.
        False - if queue is full and item can not be placed.""""""
        if self.__maxsize and len(self.__data) >= self.__maxsize:
            return False
        heapq.heappush(self.__data, item)
        return True","Put an item into the queue. Items should be comparable, eg. tuples.
        True - if item placed in queue.
        False - if queue is full and item can not be placed.",
"def get(self, default=None):
        """"""Extract the smallest item from queue.
        Return default if queue is empty.""""""
        if not self.__data:
            return default
        return heapq.heappop(self.__data)","Extract the smallest item from queue.
        Return default if queue is empty.",
"def isAcquired(self, lockID):
        """"""Check if lock is acquired by ourselves.

        :param lockID: unique lock identifier.
        :type lockID: str
        :return True if lock is acquired by ourselves.
         """"""
        return self.__lockImpl.isAcquired(lockID, self.__selfID, time.time())","Check if lock is acquired by ourselves.

        :param lockID: unique lock identifier.
        :type lockID: str
        :return True if lock is acquired by ourselves.",
"def decode_base64(data):
    """"""
    Decodes a base64 string, with padding being optional

    Args:
        data: A base64 encoded string

    Returns:
        bytes: The decoded bytes

    """"""
    data = bytes(data, encoding=""ascii"")
    missing_padding = len(data) % 4
    if missing_padding != 0:
        data += b'=' * (4 - missing_padding)
    return base64.b64decode(data)","Decodes a base64 string, with padding being optional

    Args:
        data: A base64 encoded string

    Returns:
        bytes: The decoded bytes",
"def _str_to_list(s):
    """"""Converts a comma separated string to a list""""""
    _list = s.split("","")
    return list(map(lambda i: i.lstrip(), _list))",Converts a comma separated string to a list,
"def subscribe_async(self, subject, **kwargs):
        """"""
        Sets the subcription to use a task per message to be processed.

        ..deprecated:: 7.0
          Will be removed 9.0.
        """"""
        kwargs[""is_async""] = True
        sid = yield from self.subscribe(subject, **kwargs)
        return sid","Sets the subcription to use a task per message to be processed.

        ..deprecated:: 7.0
          Will be removed 9.0.",
"def _process_pong(self):
        """"""
        Process PONG sent by server.
        """"""
        if len(self._pongs) > 0:
            future = self._pongs.pop(0)
            future.set_result(True)
            self._pongs_received += 1
            self._pings_outstanding -= 1",Process PONG sent by server.,
"def _load_features_from_array(self, features):
        """""" Load feature data from a 2D ndarray on disk. """"""
        self.feature_images = np.load(features)
        self.feature_names = range(self.feature_images.shape[1])",Load feature data from a 2D ndarray on disk.,
"def _dot_product(self, imgs_to_decode):
        """""" Decoding using the dot product.
        """"""
        return np.dot(imgs_to_decode.T, self.feature_images).T",Decoding using the dot product.,
"def get_feature_order(dataset, features):
    """""" Returns a list with the order that features requested appear in
    dataset """"""
    all_features = dataset.get_feature_names()

    i = [all_features.index(f) for f in features]

    return i","Returns a list with the order that features requested appear in
    dataset",
"def p_list_andnot(self, p):
        'list : list ANDNOT list'
        p[0] = p[1].loc[set(p[1].index) - set(p[3].index)]",list : list ANDNOT list,
"def p_list_and(self, p):
        'list : list AND list'
        p[0] = pd.concat(
            [p[1], p[3]], axis=1).dropna().apply(self.func, axis=1)",list : list AND list,
"def p_list_or(self, p):
        'list : list OR list'
        p[0] = pd.concat(
            [p[1], p[3]], axis=1).fillna(0.0).apply(self.func, axis=1)",list : list OR list,
"def p_list_feature(self, p):
        '''list : feature
            | WORD '''
        p[0] = self.dataset.get_studies(
            features=p[1], frequency_threshold=self.threshold, func=self.func,
            return_type='weights')","list : feature
            | WORD",
"def _get_top_words(model, feature_names, n_top_words=40):
    """""" Return top forty words from each topic in trained topic model.
    """"""
    topic_words = []
    for topic in model.components_:
        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]
        topic_words += [top_words]
    return topic_words",Return top forty words from each topic in trained topic model.,
"def pearson(x, y):
    """""" Correlates row vector x with each row vector in 2D array y. """"""
    data = np.vstack((x, y))
    ms = data.mean(axis=1)[(slice(None, None, None), None)]
    datam = data - ms
    datass = np.sqrt(np.sum(datam**2, axis=1))
    temp = np.dot(datam[1:], datam[0].T)
    rs = temp / (datass[1:] * datass[0])
    return rs",Correlates row vector x with each row vector in 2D array y.,
"def fdr(p, q=.05):
    """""" Determine FDR threshold given a p value array and desired false
    discovery rate q. """"""
    s = np.sort(p)
    nvox = p.shape[0]
    null = np.array(range(1, nvox + 1), dtype='float') * q / nvox
    below = np.where(s <= null)[0]
    return s[max(below)] if len(below) else -1","Determine FDR threshold given a p value array and desired false
    discovery rate q.",
"def get_feature_names(self, features=None):
        """""" Returns names of features. If features is None, returns all
        features. Otherwise assumes the user is trying to find the order of the
        features.  """"""
        if features:
            return self.feature_table.get_ordered_names(features)
        else:
            return self.feature_table.feature_names","Returns names of features. If features is None, returns all
        features. Otherwise assumes the user is trying to find the order of the
        features.",
"def get_feature_counts(self, threshold=0.001):
        """""" Returns a dictionary, where the keys are the feature names
        and the values are the number of studies tagged with the feature. """"""
        counts = np.sum(self.get_feature_data() >= threshold, 0)
        return dict(zip(self.get_feature_names(), list(counts)))","Returns a dictionary, where the keys are the feature names
        and the values are the number of studies tagged with the feature.",
"def save(self, filename):
        """""" Pickle the Dataset instance to the provided file.
        """"""
        if hasattr(self, 'feature_table'):
            self.feature_table._sdf_to_csr()

        pickle.dump(self, open(filename, 'wb'), -1)

        if hasattr(self, 'feature_table'):
            self.feature_table._csr_to_sdf()",Pickle the Dataset instance to the provided file.,
"def get_ids_by_expression(self, expression, threshold=0.001, func=np.sum):
        """""" Use a PEG to parse expression and return study IDs.""""""
        lexer = lp.Lexer()
        lexer.build()
        parser = lp.Parser(
            lexer, self.dataset, threshold=threshold, func=func)
        parser.build()
        return parser.parse(expression).keys().values",Use a PEG to parse expression and return study IDs.,
"def _sdf_to_csr(self):
        """""" Convert FeatureTable to SciPy CSR matrix. """"""
        data = self.data.to_dense()
        self.data = {
            'columns': list(data.columns),
            'index': list(data.index),
            'values': sparse.csr_matrix(data.values)
        }",Convert FeatureTable to SciPy CSR matrix.,
"def _csr_to_sdf(self):
        """""" Inverse of _sdf_to_csr(). """"""
        self.data = pd.DataFrame(self.data['values'].todense(),
                                 index=self.data['index'],
                                 columns=self.data['columns']).to_sparse()",Inverse of _sdf_to_csr().,
"def transform(self, transformer, transpose=False):
        ''' Apply a transformation to the Clusterable instance. Accepts any
        scikit-learn-style class that implements a fit_transform() method. '''
        data = self.data.T if transpose else self.data
        data = transformer.fit_transform(data)
        self.data = data.T if transpose else data
        return self","Apply a transformation to the Clusterable instance. Accepts any
        scikit-learn-style class that implements a fit_transform() method.",
"def transform(foci, mat):
    """""" Convert coordinates from one space to another using provided
    transformation matrix. """"""
    t = linalg.pinv(mat)
    foci = np.hstack((foci, np.ones((foci.shape[0], 1))))
    return np.dot(foci, t)[:, 0:3]","Convert coordinates from one space to another using provided
    transformation matrix.",
"def xyz_to_mat(foci, xyz_dims=None, mat_dims=None):
    """""" Convert an N x 3 array of XYZ coordinates to matrix indices. """"""
    foci = np.hstack((foci, np.ones((foci.shape[0], 1))))
    mat = np.array([[-0.5, 0, 0, 45], [0, 0.5, 0, 63], [0, 0, 0.5, 36]]).T
    result = np.dot(foci, mat)[:, ::-1]  # multiply and reverse column order
    return np.round_(result).astype(int)",Convert an N x 3 array of XYZ coordinates to matrix indices.,
"def reset(self):
        """""" Reset/remove all layers, keeping only the initial volume. """"""
        self.layers = {}
        self.stack = []
        self.set_mask()
        self.n_vox_in_vol = len(np.where(self.current_mask)[0])","Reset/remove all layers, keeping only the initial volume.",
"def parse_address(address, language=None, country=None):
    """"""
    Parse address into components.

    @param address: the address as either Unicode or a UTF-8 encoded string
    @param language (optional): language code
    @param country (optional): country code
    """"""
    address = safe_decode(address, 'utf-8')
    return _parser.parse_address(address, language=language, country=country)","Parse address into components.

    @param address: the address as either Unicode or a UTF-8 encoded string
    @param language (optional): language code
    @param country (optional): country code",
"def remove_api_key(file_name):
    """"""
    Change the api key in the Token object to 40*'0'.  See issue #86.
    :param file: path-to-file to change
    """"""
    with open(file_name, 'r') as fp:
        text = fp.read()
    text = re.sub(real_api_regex, zero_token_string, text)
    with open(file_name, 'w') as fp:
        fp.write(text)
    return","Change the api key in the Token object to 40*'0'.  See issue #86.
    :param file: path-to-file to change",
"def dict_to_object(item, object_name):
    """"""Converts a python dict to a namedtuple, saving memory.""""""
    fields = item.keys()
    values = item.values()
    return json.loads(json.dumps(item),
                      object_hook=lambda d:
                      namedtuple(object_name, fields)(*values))","Converts a python dict to a namedtuple, saving memory.",
"def _invalid_frequency(self, frequency):
        """"""
        Check to see that frequency was specified correctly
        :param frequency (string): frequency string
        :return (boolean):
        """"""
        is_valid = self._is_eod_frequency(frequency) or re.match(self._frequency_pattern, frequency)
        return not is_valid","Check to see that frequency was specified correctly
        :param frequency (string): frequency string
        :return (boolean):",
"def artist(self, spotify_id):
        """"""Get a spotify artist by their ID.

        Parameters
        ----------
        spotify_id : str
            The spotify_id to search by.
        """"""
        route = Route('GET', '/artists/{spotify_id}', spotify_id=spotify_id)
        return self.request(route)","Get a spotify artist by their ID.

        Parameters
        ----------
        spotify_id : str
            The spotify_id to search by.",
"def artist_related_artists(self, spotify_id):
        """"""Get related artists for an artist by their ID.

        Parameters
        ----------
        spotify_id : str
            The spotify_id to search by.
        """"""
        route = Route('GET', '/artists/{spotify_id}/related-artists', spotify_id=spotify_id)
        return self.request(route)","Get related artists for an artist by their ID.

        Parameters
        ----------
        spotify_id : str
            The spotify_id to search by.",
"def artists(self, spotify_ids):
        """"""Get a spotify artists by their IDs.

        Parameters
        ----------
        spotify_id : List[str]
            The spotify_ids to search with.
        """"""
        route = Route('GET', '/artists')
        payload = {'ids': spotify_ids}
        return self.request(route, params=payload)","Get a spotify artists by their IDs.

        Parameters
        ----------
        spotify_id : List[str]
            The spotify_ids to search with.",
"async def get_player(self) -> Player:
        """"""Get information about the users current playback.

        Returns
        -------
        player : Player
            A player object representing the current playback.
        """"""
        self._player = player = Player(self.__client, self, await self.http.current_player())
        return player","Get information about the users current playback.

        Returns
        -------
        player : Player
            A player object representing the current playback.",
"async def get_devices(self) -> List[Device]:
        """"""Get information about the users avaliable devices.

        Returns
        -------
        devices : List[Device]
            The devices the user has available.
        """"""
        data = await self.http.available_devices()
        return [Device(item) for item in data['devices']]","Get information about the users avaliable devices.

        Returns
        -------
        devices : List[Device]
            The devices the user has available.",
"async def get_artist(self, spotify_id: str) -> Artist:
        """"""Retrive an artist with a spotify ID.

        Parameters
        ----------
        spotify_id : str
            The ID to search for.

        Returns
        -------
        artist : Artist
            The artist from the ID
        """"""
        data = await self.http.artist(to_id(spotify_id))
        return Artist(self, data)","Retrive an artist with a spotify ID.

        Parameters
        ----------
        spotify_id : str
            The ID to search for.

        Returns
        -------
        artist : Artist
            The artist from the ID",
"async def get_track(self, spotify_id: str) -> Track:
        """"""Retrive an track with a spotify ID.

        Parameters
        ----------
        spotify_id : str
            The ID to search for.

        Returns
        -------
        track : Track
            The track from the ID
        """"""
        data = await self.http.track(to_id(spotify_id))
        return Track(self, data)","Retrive an track with a spotify ID.

        Parameters
        ----------
        spotify_id : str
            The ID to search for.

        Returns
        -------
        track : Track
            The track from the ID",
"async def get_user(self, spotify_id: str) -> User:
        """"""Retrive an user with a spotify ID.

        Parameters
        ----------
        spotify_id : str
            The ID to search for.

        Returns
        -------
        user : User
            The user from the ID
        """"""
        data = await self.http.user(to_id(spotify_id))
        return User(self, data)","Retrive an user with a spotify ID.

        Parameters
        ----------
        spotify_id : str
            The ID to search for.

        Returns
        -------
        user : User
            The user from the ID",
"def from_client(cls, client, *args, **kwargs):
        """"""Construct a OAuth2 object from a `spotify.Client`.""""""
        return cls(client.http.client_id, *args, **kwargs)",Construct a OAuth2 object from a `spotify.Client`.,
"def attrs(self):
        """"""Attributes used when constructing url parameters.""""""
        data = {
            'client_id': self.client_id,
            'redirect_uri': quote(self.redirect_uri),
        }

        if self.scope is not None:
            data['scope'] = quote(self.scope)

        if self.state is not None:
            data['state'] = self.state

        return data",Attributes used when constructing url parameters.,
"def parameters(self) -> str:
        """"""URL parameters used.""""""
        return '&'.join('{0}={1}'.format(*item) for item in self.attrs.items())",URL parameters used.,
"async def build(self):
        """"""get the track object for each link in the partial tracks data

        Returns
        -------
        tracks : List[Track]
            The tracks
        """"""
        data = await self.__func()
        return list(PlaylistTrack(self.__client, track) for track in data['items'])","get the track object for each link in the partial tracks data

        Returns
        -------
        tracks : List[Track]
            The tracks",
"def _merge_values(self):
        """"""
        Simply merge the older into the new one.
        """"""

        to_remove = []

        self.new_config = Dict(
            Dict(self.upstream_config).merge(PyFunceble.CONFIGURATION)
        ).remove_key(to_remove)",Simply merge the older into the new one.,
"def load(self):
        """"""
        Initiate the IANA database if it is not the case.
        """"""

        if ""iana_db"" not in PyFunceble.INTERN or not PyFunceble.INTERN[""iana_db""]:
            # The global database is empty, None or does not exist.

            # We update it with the database content.
            PyFunceble.INTERN[""iana_db""] = self.iana_db",Initiate the IANA database if it is not the case.,
"def _backup(self):
        """"""
        Backup the mined informations.
        """"""

        if PyFunceble.CONFIGURATION[""mining""]:
            # The mining is activated.

            # We backup our mined informations.
            Dict(PyFunceble.INTERN[""mined""]).to_json(self.file)",Backup the mined informations.,
"def _get_content(cls, file):
        """"""
        Get and return the content of the given log file.

        :param file: The file we have to get the content from.
        :type file: str

        :return The content of the given file.
        :rtype: dict
        """"""

        if PyFunceble.path.isfile(file):
            return Dict().from_json(File(file).read())

        return {}","Get and return the content of the given log file.

        :param file: The file we have to get the content from.
        :type file: str

        :return The content of the given file.
        :rtype: dict",
"def format(self):
        """"""
        Return a well formatted list. Basicaly, it's sort a list and remove duplicate.

        :return: A sorted, without duplicate, list.
        :rtype: list
        """"""

        try:
            return sorted(list(set(self.main_list)), key=str.lower)

        except TypeError:  # pragma: no cover
            return self.main_list","Return a well formatted list. Basicaly, it's sort a list and remove duplicate.

        :return: A sorted, without duplicate, list.
        :rtype: list",
"def not_matching_list(self):
        """"""
        Return a list of string which don't match the
        given regex.
        """"""

        pre_result = comp(self.regex)

        return [x for x in self.data if not pre_result.search(str(x))]","Return a list of string which don't match the
        given regex.",
"def _backup(self):
        """"""
        Save the current database into the inactive-db.json file.
        """"""

        if PyFunceble.CONFIGURATION[""inactive_database""]:
            # The database subsystem is activated.

            # We save the current database state into the database file.
            Dict(PyFunceble.INTERN[""inactive_db""]).to_json(self.inactive_db_path)",Save the current database into the inactive-db.json file.,
"def _backup(self):
        """"""
        Backup the database into its file.
        """"""

        if self._authorization():
            # We are authorized to work.

            # We backup the current state of the datbase.
            Dict(PyFunceble.INTERN[""whois_db""]).to_json(self.whois_db_path)",Backup the database into its file.,
"def _get_version():
    """"""
    This function will extract the version from PyFunceble/__init__.py
    """"""

    to_match = comp(r'VERSION\s=\s""(.*)""\n')
    extracted = to_match.findall(
        open(""PyFunceble/__init__.py"", encoding=""utf-8"").read()
    )[0]

    return ""."".join([x for x in extracted.split(""."") if x.isdigit()])",This function will extract the version from PyFunceble/__init__.py,
"def _register_servicer(self, servicer):
        """"""register serviser

        :param servicer: servicer
        """"""
        name = servicer.__name__
        if name in self._servicers:
            raise exceptions.ConfigException(
                'servicer duplicated: {}'.format(name))
        add_func = self._get_servicer_add_func(servicer)
        self._servicers[name] = (add_func, servicer)","register serviser

        :param servicer: servicer",
"def _register_extension(self, name, ext):
        """"""register extension

        :param name: extension name
        :param ext: extension object
        """"""
        ext.init_app(self)
        if name in self._extensions:
            raise exceptions.ConfigException(
                'extension duplicated: {}'.format(name))
        self._extensions[name] = ext","register extension

        :param name: extension name
        :param ext: extension object",
"def standard_package_names():
    """"""Yield standard module names.""""""
    for name in standard_paths():
        if name.startswith('_') or '-' in name:
            continue

        if '.' in name and name.rsplit('.')[-1] not in ['so', 'py', 'pyc']:
            continue

        yield name.split('.')[0]",Yield standard module names.,
"def unused_import_line_numbers(messages):
    """"""Yield line numbers of unused imports.""""""
    for message in messages:
        if isinstance(message, pyflakes.messages.UnusedImport):
            yield message.lineno",Yield line numbers of unused imports.,
"def star_import_used_line_numbers(messages):
    """"""Yield line number of star import usage.""""""
    for message in messages:
        if isinstance(message, pyflakes.messages.ImportStarUsed):
            yield message.lineno",Yield line number of star import usage.,
"def star_import_usage_undefined_name(messages):
    """"""Yield line number, undefined name, and its possible origin module.""""""
    for message in messages:
        if isinstance(message, pyflakes.messages.ImportStarUsage):
            undefined_name = message.message_args[0]
            module_name = message.message_args[1]
            yield (message.lineno, undefined_name, module_name)","Yield line number, undefined name, and its possible origin module.",
"def unused_variable_line_numbers(messages):
    """"""Yield line numbers of unused variables.""""""
    for message in messages:
        if isinstance(message, pyflakes.messages.UnusedVariable):
            yield message.lineno",Yield line numbers of unused variables.,
"def create_key_to_messages_dict(messages):
    """"""Return dict mapping the key to list of messages.""""""
    dictionary = collections.defaultdict(lambda: [])
    for message in messages:
        dictionary[message.message_args[0]].append(message)
    return dictionary",Return dict mapping the key to list of messages.,
"def multiline_import(line, previous_line=''):
    """"""Return True if import is spans multiples lines.""""""
    for symbol in '()':
        if symbol in line:
            return True

    # Ignore doctests.
    if line.lstrip().startswith('>'):
        return True

    return multiline_statement(line, previous_line)",Return True if import is spans multiples lines.,
"def multiline_statement(line, previous_line=''):
    """"""Return True if this is part of a multiline statement.""""""
    for symbol in '\\:;':
        if symbol in line:
            return True

    sio = io.StringIO(line)
    try:
        list(tokenize.generate_tokens(sio.readline))
        return previous_line.rstrip().endswith('\\')
    except (SyntaxError, tokenize.TokenError):
        return True",Return True if this is part of a multiline statement.,
"def get_messages_by_line(messages):
    """"""Return dictionary that maps line number to message.""""""
    line_messages = {}
    for message in messages:
        line_messages[message.lineno] = message
    return line_messages",Return dictionary that maps line number to message.,
"def filter_star_import(line, marked_star_import_undefined_name):
    """"""Return line with the star import expanded.""""""
    undefined_name = sorted(set(marked_star_import_undefined_name))
    return re.sub(r'\*', ', '.join(undefined_name), line)",Return line with the star import expanded.,
"def filter_duplicate_key(line, message, line_number, marked_line_numbers,
                         source, previous_line=''):
    """"""Return '' if first occurrence of the key otherwise return `line`.""""""
    if marked_line_numbers and line_number == sorted(marked_line_numbers)[0]:
        return ''

    return line",Return '' if first occurrence of the key otherwise return `line`.,
"def get_indentation(line):
    """"""Return leading whitespace.""""""
    if line.strip():
        non_whitespace_index = len(line) - len(line.lstrip())
        return line[:non_whitespace_index]
    else:
        return ''",Return leading whitespace.,
"def get_line_ending(line):
    """"""Return line ending.""""""
    non_whitespace_index = len(line.rstrip()) - len(line)
    if not non_whitespace_index:
        return ''
    else:
        return line[non_whitespace_index:]",Return line ending.,
"def _detect_encoding(readline):
    """"""Return file encoding.""""""
    try:
        from lib2to3.pgen2 import tokenize as lib2to3_tokenize
        encoding = lib2to3_tokenize.detect_encoding(readline)[0]
        return encoding
    except (LookupError, SyntaxError, UnicodeDecodeError):
        return 'latin-1'",Return file encoding.,
"def _split_comma_separated(string):
    """"""Return a set of strings.""""""
    return set(text.strip() for text in string.split(',') if text.strip())",Return a set of strings.,
"def is_exclude_file(filename, exclude):
    """"""Return True if file matches exclude pattern.""""""
    base_name = os.path.basename(filename)

    if base_name.startswith('.'):
        return True

    for pattern in exclude:
        if fnmatch.fnmatch(base_name, pattern):
            return True
        if fnmatch.fnmatch(filename, pattern):
            return True
    return False",Return True if file matches exclude pattern.,
"def match_file(filename, exclude):
    """"""Return True if file is okay for modifying/recursing.""""""
    if is_exclude_file(filename, exclude):
        return False

    if not os.path.isdir(filename) and not is_python_file(filename):
        return False

    return True",Return True if file is okay for modifying/recursing.,
"def validate(self):
        """"""
        Verify that the value of the Boolean object is valid.

        Raises:
            TypeError: if the value is not of type bool.
        """"""
        if self.value:
            if not isinstance(self.value, bool):
                raise TypeError(""expected: {0}, observed: {1}"".format(
                    bool, type(self.value)))","Verify that the value of the Boolean object is valid.

        Raises:
            TypeError: if the value is not of type bool.",
"def get_json_files(p):
    """"""
    Scan the provided policy directory for all JSON policy files.
    """"""
    f = [os.path.join(p, x) for x in os.listdir(p) if x.endswith("".json"")]
    return sorted(f)",Scan the provided policy directory for all JSON policy files.,
"def get_certificate_from_connection(connection):
    """"""
    Extract an X.509 certificate from a socket connection.
    """"""
    certificate = connection.getpeercert(binary_form=True)
    if certificate:
        return x509.load_der_x509_certificate(
            certificate,
            backends.default_backend()
        )
    return None",Extract an X.509 certificate from a socket connection.,
"def get_extended_key_usage_from_certificate(certificate):
    """"""
    Given an X.509 certificate, extract and return the extendedKeyUsage
    extension.
    """"""
    try:
        return certificate.extensions.get_extension_for_oid(
            x509.oid.ExtensionOID.EXTENDED_KEY_USAGE
        ).value
    except x509.ExtensionNotFound:
        return None","Given an X.509 certificate, extract and return the extendedKeyUsage
    extension.",
"def get_common_names_from_certificate(certificate):
    """"""
    Given an X.509 certificate, extract and return all common names.
    """"""

    common_names = certificate.subject.get_attributes_for_oid(
        x509.oid.NameOID.COMMON_NAME
    )
    return [common_name.value for common_name in common_names]","Given an X.509 certificate, extract and return all common names.",
"def validate(self):
        """"""
        Error check the attributes of the ActivateRequestPayload object.
        """"""
        if self.unique_identifier is not None:
            if not isinstance(self.unique_identifier,
                              attributes.UniqueIdentifier):
                msg = ""invalid unique identifier""
                raise TypeError(msg)",Error check the attributes of the ActivateRequestPayload object.,
"def _build_name_attribute(self, name=None):
        '''
        Build a name attribute, returned in a list for ease
        of use in the caller
        '''
        name_list = []
        if name:
            name_list.append(self.attribute_factory.create_attribute(
                enums.AttributeType.NAME,
                name)
            )
        return name_list","Build a name attribute, returned in a list for ease
        of use in the caller",
"def get_group_named(group, path=None):
    """"""Find a group of entry points with unique names.

    Returns a dictionary of names to :class:`EntryPoint` objects.
    """"""
    result = {}
    for ep in get_group_all(group, path=path):
        if ep.name not in result:
            result[ep.name] = ep
    return result","Find a group of entry points with unique names.

    Returns a dictionary of names to :class:`EntryPoint` objects.",
"def load(self):
        """"""Load the object to which this entry point refers.
        """"""
        mod = import_module(self.module_name)
        obj = mod
        if self.object_name:
            for attr in self.object_name.split('.'):
                obj = getattr(obj, attr)
        return obj",Load the object to which this entry point refers.,
"def live():
    """"""Run livereload server""""""
    from livereload import Server

    server = Server(app)

    map(server.watch, glob2.glob(""application/pages/**/*.*""))  # pages
    map(server.watch, glob2.glob(""application/macros/**/*.html""))  # macros
    map(server.watch, glob2.glob(""application/static/**/*.*""))  # public assets

    server.serve(port=PORT)",Run livereload server,
"def generate_form(args):
    """"""Generate form.""""""
    form_name = args.get('<form>')
    logger.info('Start generating form.')
    _generate_form(form_name)
    logger.info('Finish generating form.')",Generate form.,
"def _mkdir_p(path):
    """"""mkdir -p path""""""
    try:
        os.makedirs(path)
    except OSError as exc:
        if exc.errno == errno.EEXIST and os.path.isdir(path):
            pass
        else:
            raise
    else:
        logger.info(""New: %s%s"", path, os.path.sep)",mkdir -p path,
"def check_url(form, field):
    """"""Check url schema.""""""
    url = field.data.strip()
    if not url:
        return
    result = urlparse(url)
    if result.scheme == """":
        field.data = ""http://%s"" % re.sub(r'^:?/*', '', url)",Check url schema.,
"def encode(something):
    """"""Encode something with SECRET_KEY.""""""
    secret_key = current_app.config.get('SECRET_KEY')
    s = URLSafeSerializer(secret_key)
    return s.dumps(something)",Encode something with SECRET_KEY.,
"def decode(something):
    """"""Decode something with SECRET_KEY.""""""
    secret_key = current_app.config.get('SECRET_KEY')
    s = URLSafeSerializer(secret_key)
    try:
        return s.loads(something)
    except BadSignature:
        return None",Decode something with SECRET_KEY.,
"def jsonify(func):
    """"""JSON decorator.""""""

    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        r = func(*args, **kwargs)
        if isinstance(r, tuple):
            code, data = r
        else:
            code, data = 200, r
        return Response(json.dumps(data), status=code, mimetype='application/json')

    return wrapper",JSON decorator.,
"def absolute_url_for(endpoint, **values):
    """"""Absolute url for endpoint.""""""
    config = current_app.config
    site_domain = config.get('SITE_DOMAIN')
    relative_url = url_for(endpoint, **values)
    return join_url(site_domain, relative_url)",Absolute url for endpoint.,
"def signin_user(user, permenent=True):
    """"""Sign in user.""""""
    session.permanent = permenent
    session['user_id'] = user.id",Sign in user.,
"def get_current_user():
    """"""Get current user.""""""
    if not 'user_id' in session:
        return None
    user = User.query.filter(User.id == session['user_id']).first()
    if not user:
        signout_user()
        return None
    return user",Get current user.,
"def signin():
    """"""Signin""""""
    form = SigninForm()
    if form.validate_on_submit():
        signin_user(form.user)
        return redirect(url_for('site.index'))
    return render_template('account/signin/signin.html', form=form)",Signin,
"def signup():
    """"""Signup""""""
    form = SignupForm()
    if form.validate_on_submit():
        params = form.data.copy()
        params.pop('repassword')
        user = User(**params)
        db.session.add(user)
        db.session.commit()
        signin_user(user)
        return redirect(url_for('site.index'))
    return render_template('account/signup/signup.html', form=form)",Signup,
"def register_routes(app):
    """"""Register routes.""""""
    from . import controllers
    from flask.blueprints import Blueprint

    for module in _import_submodules_from_package(controllers):
        bp = getattr(module, 'bp')
        if bp and isinstance(bp, Blueprint):
            app.register_blueprint(bp)",Register routes.,
"def register_error_handle(app):
    """"""Register HTTP error pages.""""""

    @app.errorhandler(403)
    def page_403(error):
        return render_template('site/403/403.html'), 403

    @app.errorhandler(404)
    def page_404(error):
        return render_template('site/404/404.html'), 404

    @app.errorhandler(500)
    def page_500(error):
        return render_template('site/500/500.html'), 500",Register HTTP error pages.,
"def _dataframe_to_csv(writer, dataframe, delimiter, with_header):
    """"""serialize the dataframe with different delimiters""""""
    encoding_writer = codecs.getwriter('utf-8')(writer)
    dataframe.to_csv(
        path_or_buf=encoding_writer,
        sep=delimiter,
        header=with_header,
        index=False
    )",serialize the dataframe with different delimiters,
"def _dataframe_from_csv(reader, delimiter, with_header, skipspace):
    """"""Returns csv data as a pandas Dataframe object""""""
    sep = delimiter
    header = 0
    if not with_header:
        header = None

    return pd.read_csv(
        reader,
        header=header,
        sep=sep,
        skipinitialspace=skipspace,
        encoding='utf-8-sig'
    )",Returns csv data as a pandas Dataframe object,
"def contents_url(self):
        """"""Full URL to the dataset contents.""""""
        loc = self.download_location
        return loc.base_uri + loc.location + loc.access_credential",Full URL to the dataset contents.,
"def open(self):
        '''Open and return a stream for the dataset contents.'''
        return self.workspace._rest.open_intermediate_dataset_contents(
            self.workspace.workspace_id,
            self.experiment.experiment_id,
            self.node_id,
            self.port_name
        )",Open and return a stream for the dataset contents.,
"def read_as_binary(self):
        '''Read and return the dataset contents as binary.'''
        return self.workspace._rest.read_intermediate_dataset_contents_binary(
            self.workspace.workspace_id,
            self.experiment.experiment_id,
            self.node_id,
            self.port_name
        )",Read and return the dataset contents as binary.,
"def read_as_text(self):
        '''Read and return the dataset contents as text.'''
        return self.workspace._rest.read_intermediate_dataset_contents_text(
            self.workspace.workspace_id,
            self.experiment.experiment_id,
            self.node_id,
            self.port_name
        )",Read and return the dataset contents as text.,
"def _to_dataframe(self):
        """"""Read and return the dataset contents as a pandas DataFrame.""""""
        #TODO: figure out why passing in the opened stream directly gives invalid data
        data = self.read_as_binary()
        reader = BytesIO(data)
        return deserialize_dataframe(reader, self.data_type_id)",Read and return the dataset contents as a pandas DataFrame.,
"def get_experiments(self, workspace_id):
        """"""Runs HTTP GET request to retrieve the list of experiments.""""""
        api_path = self.EXPERIMENTS_URI_FMT.format(workspace_id)
        return self._send_get_req(api_path)",Runs HTTP GET request to retrieve the list of experiments.,
"def get_datasets(self, workspace_id):
        """"""Runs HTTP GET request to retrieve the list of datasets.""""""
        api_path = self.DATASOURCES_URI_FMT.format(workspace_id)
        return self._send_get_req(api_path)",Runs HTTP GET request to retrieve the list of datasets.,
"def get_dataset(self, workspace_id, dataset_id):
        """"""Runs HTTP GET request to retrieve a single dataset.""""""
        api_path = self.DATASOURCE_URI_FMT.format(workspace_id, dataset_id)
        return self._send_get_req(api_path)",Runs HTTP GET request to retrieve a single dataset.,
"def service(url, api_key, help_url = None):
    '''Marks a function as having been published and causes all invocations to go to the remote
operationalized service.

>>> @service(url, api_key)
>>> def f(a, b):
>>>     pass
'''
    def do_publish(func):
        return published(url, api_key, help_url, func, None)
    return do_publish","Marks a function as having been published and causes all invocations to go to the remote
operationalized service.

>>> @service(url, api_key)
>>> def f(a, b):
>>>     pass",
"def types(**args):
    """"""Specifies the types used for the arguments of a published service.

@types(a=int, b = str)
def f(a, b):
    pass
""""""
    def l(func):
        if hasattr(func, '__annotations__'):
            func.__annotations__.update(args)
        else:
            func.__annotations__ = args
        return func
    return l","Specifies the types used for the arguments of a published service.

@types(a=int, b = str)
def f(a, b):
    pass",
"def returns(type):
    """"""Specifies the return type for a published service.

@returns(int)
def f(...):
    pass
""""""
    def l(func):
        if hasattr(func, '__annotations__'):
            func.__annotations__['return'] = type
        else:
            func.__annotations__ = {'return': type}
        return func
    return l","Specifies the return type for a published service.

@returns(int)
def f(...):
    pass",
"def copy(self):
        """"""Create a copy of this pen.""""""
        pen = Pen()
        pen.__dict__ = self.__dict__.copy()
        return pen",Create a copy of this pen.,
"def draw(self, cr, highlight=False, bounding=None):
        """"""Draw this shape with the given cairo context""""""
        if bounding is None or self._intersects(bounding):
            self._draw(cr, highlight, bounding)",Draw this shape with the given cairo context,
"def _cubic_bernstein(p0, p1, p2, p3, t):
        """"""
        Evaluate polynomial of given bernstein coefficients
        using de Casteljau's algorithm.
        """"""
        u = 1 - t
        return p0*(u**3) + 3*t*u*(p1*u + p2*t) + p3*(t**3)","Evaluate polynomial of given bernstein coefficients
        using de Casteljau's algorithm.",
"def get_sitetree():
    """"""Returns SiteTree (thread-singleton) object, implementing utility methods.

    :rtype: SiteTree
    """"""
    sitetree = getattr(_THREAD_LOCAL, _THREAD_SITETREE, None)

    if sitetree is None:
        sitetree = SiteTree()
        setattr(_THREAD_LOCAL, _THREAD_SITETREE, sitetree)

    return sitetree","Returns SiteTree (thread-singleton) object, implementing utility methods.

    :rtype: SiteTree",
"def init(self):
        """"""Initializes local cache from Django cache.""""""

        # Drop cache flag set by .reset() method.
        cache.get('sitetrees_reset') and self.empty(init=False)

        self.cache = cache.get(
            'sitetrees', {'sitetrees': {}, 'parents': {}, 'items_by_ids': {}, 'tree_aliases': {}})",Initializes local cache from Django cache.,
"def empty(self, **kwargs):
        """"""Empties cached sitetree data.""""""
        cache.delete('sitetrees')
        cache.delete('sitetrees_reset')

        kwargs.get('init', True) and self.init()",Empties cached sitetree data.,
"def get_entry(self, entry_name, key):
        """"""Returns cache entry parameter value by its name.

        :param str|unicode entry_name:
        :param key:
        :return:
        """"""
        return self.cache[entry_name].get(key, False)","Returns cache entry parameter value by its name.

        :param str|unicode entry_name:
        :param key:
        :return:",
"def update_entry_value(self, entry_name, key, value):
        """"""Updates cache entry parameter with new data.

        :param str|unicode entry_name:
        :param key:
        :param value:
        """"""
        if key not in self.cache[entry_name]:
            self.cache[entry_name][key] = {}

        self.cache[entry_name][key].update(value)","Updates cache entry parameter with new data.

        :param str|unicode entry_name:
        :param key:
        :param value:",
"def set_entry(self, entry_name, key, value):
        """"""Replaces entire cache entry parameter data by its name with new data.

        :param str|unicode entry_name:
        :param key:
        :param value:
        """"""
        self.cache[entry_name][key] = value","Replaces entire cache entry parameter data by its name with new data.

        :param str|unicode entry_name:
        :param key:
        :param value:",
"def get_model_url_name(model_nfo, page, with_namespace=False):
    """"""Returns a URL for a given Tree admin page type.""""""
    prefix = ''
    if with_namespace:
        prefix = 'admin:'
    return ('%s%s_%s' % (prefix, '%s_%s' % model_nfo, page)).lower()",Returns a URL for a given Tree admin page type.,
"def _reregister_tree_admin():
    """"""Forces unregistration of tree admin class with following re-registration.""""""
    try:
        admin.site.unregister(MODEL_TREE_CLASS)
    except NotRegistered:
        pass
    admin.site.register(MODEL_TREE_CLASS, _TREE_ADMIN())",Forces unregistration of tree admin class with following re-registration.,
"def _redirect(self, request, response):
        """"""Generic redirect for item editor.""""""

        if '_addanother' in request.POST:
            return HttpResponseRedirect('../item_add/')

        elif '_save' in request.POST:
            return HttpResponseRedirect('../')

        elif '_continue' in request.POST:
            return response

        return HttpResponseRedirect('')",Generic redirect for item editor.,
"def response_change(self, request, obj, **kwargs):
        """"""Redirects to the appropriate items' 'add' page on item change.

        As we administer tree items within tree itself, we
        should make some changes to redirection process.

        """"""
        return self._redirect(request, super(TreeItemAdmin, self).response_change(request, obj))","Redirects to the appropriate items' 'add' page on item change.

        As we administer tree items within tree itself, we
        should make some changes to redirection process.",
"def dump_view(cls, request):
        """"""Dumps sitetrees with items using django-smuggler.

        :param request:
        :return:
        """"""
        from smuggler.views import dump_to_response
        return dump_to_response(request, [MODEL_TREE, MODEL_TREE_ITEM], filename_prefix='sitetrees')","Dumps sitetrees with items using django-smuggler.

        :param request:
        :return:",
"def encode_pb_list(pb_spans):
    """"""Encode list of protobuf Spans to binary.

    :param pb_spans: list of protobuf Spans.
    :type pb_spans: list of zipkin_pb2.Span
    :return: encoded list.
    :rtype: bytes
    """"""
    pb_list = zipkin_pb2.ListOfSpans()
    pb_list.spans.extend(pb_spans)
    return pb_list.SerializeToString()","Encode list of protobuf Spans to binary.

    :param pb_spans: list of protobuf Spans.
    :type pb_spans: list of zipkin_pb2.Span
    :return: encoded list.
    :rtype: bytes",
"def create_annotation(timestamp, value, host):
    """"""
    Create a zipkin annotation object

    :param timestamp: timestamp of when the annotation occured in microseconds
    :param value: name of the annotation, such as 'sr'
    :param host: zipkin endpoint object

    :returns: zipkin annotation object
    """"""
    return zipkin_core.Annotation(timestamp=timestamp, value=value, host=host)","Create a zipkin annotation object

    :param timestamp: timestamp of when the annotation occured in microseconds
    :param value: name of the annotation, such as 'sr'
    :param host: zipkin endpoint object

    :returns: zipkin annotation object",
"def span_to_bytes(thrift_span):
    """"""
    Returns a TBinaryProtocol encoded Thrift span.

    :param thrift_span: thrift object to encode.
    :returns: thrift object in TBinaryProtocol format bytes.
    """"""
    transport = TMemoryBuffer()
    protocol = TBinaryProtocol(transport)
    thrift_span.write(protocol)

    return bytes(transport.getvalue())","Returns a TBinaryProtocol encoded Thrift span.

    :param thrift_span: thrift object to encode.
    :returns: thrift object in TBinaryProtocol format bytes.",
"def fits(self, current_count, current_size, max_size, new_span):
        """"""Checks if the new span fits in the max payload size.

        Thrift lists have a fixed-size header and no delimiters between elements
        so it's easy to compute the list size.
        """"""
        return thrift.LIST_HEADER_SIZE + current_size + len(new_span) <= max_size","Checks if the new span fits in the max payload size.

        Thrift lists have a fixed-size header and no delimiters between elements
        so it's easy to compute the list size.",
"def fits(self, current_count, current_size, max_size, new_span):
        """"""Checks if the new span fits in the max payload size.""""""
        return current_size + len(new_span) <= max_size",Checks if the new span fits in the max payload size.,
"def _convert_unsigned_long_to_lower_hex(self, value):
        """"""
        Converts the provided unsigned long value to a hex string.

        :param value: the value to convert
        :type value: unsigned long
        :returns: value as a hex string
        """"""
        result = bytearray(16)
        self._write_hex_long(result, 0, value)
        return result.decode(""utf8"")","Converts the provided unsigned long value to a hex string.

        :param value: the value to convert
        :type value: unsigned long
        :returns: value as a hex string",
"def mBank_set_transaction_code(transactions, tag, tag_dict, *args):
    """"""
    mBank Collect uses transaction code 911 to distinguish icoming mass
    payments transactions, adding transaction_code may be helpful in further
    processing
    """"""
    tag_dict['transaction_code'] = int(
        tag_dict[tag.slug].split(';')[0].split(' ', 1)[0])

    return tag_dict","mBank Collect uses transaction code 911 to distinguish icoming mass
    payments transactions, adding transaction_code may be helpful in further
    processing",
"def mBank_set_iph_id(transactions, tag, tag_dict, *args):
    """"""
    mBank Collect uses ID IPH to distinguish between virtual accounts,
    adding iph_id may be helpful in further processing
    """"""
    matches = iph_id_re.search(tag_dict[tag.slug])

    if matches:  # pragma no branch
        tag_dict['iph_id'] = matches.groupdict()['iph_id']

    return tag_dict","mBank Collect uses ID IPH to distinguish between virtual accounts,
    adding iph_id may be helpful in further processing",
"def join_lines(string, strip=Strip.BOTH):
    '''
    Join strings together and strip whitespace in between if needed
    '''
    lines = []

    for line in string.splitlines():
        if strip & Strip.RIGHT:
            line = line.rstrip()

        if strip & Strip.LEFT:
            line = line.lstrip()

        lines.append(line)

    return ''.join(lines)",Join strings together and strip whitespace in between if needed,
"async def json_or_text(response):
    """"""Turns response into a properly formatted json or text object""""""
    text = await response.text()
    if response.headers['Content-Type'] == 'application/json; charset=utf-8':
        return json.loads(text)
    return text",Turns response into a properly formatted json or text object,
"async def limited(until):
    """"""Handles the message shown when we are ratelimited""""""
    duration = int(round(until - time.time()))
    mins = duration / 60
    fmt = 'We have exhausted a ratelimit quota. Retrying in %.2f seconds (%.3f minutes).'
    log.warn(fmt, duration, mins)",Handles the message shown when we are ratelimited,
"async def get_bot_info(self, bot_id):
        '''Gets the information of the given Bot ID'''
        resp = await self.request('GET', '{}/bots/{}'.format(self.BASE, bot_id))
        resp['date'] = datetime.strptime(resp['date'], '%Y-%m-%dT%H:%M:%S.%fZ')
        for k in resp:
            if resp[k] == '':
                resp[k] = None
        return resp",Gets the information of the given Bot ID,
"async def get_bots(self, limit, offset):
        '''Gets an object of bots on DBL'''
        if limit > 500:
            limit = 50
        return await self.request('GET', '{}/bots?limit={}&offset={}'.format(self.BASE, limit, offset))",Gets an object of bots on DBL,
"def guild_count(self):
        """"""Gets the guild count from the Client/Bot object""""""
        try:
            return len(self.bot.guilds)
        except AttributeError:
            return len(self.bot.servers)",Gets the guild count from the Client/Bot object,
"async def close(self):
        """"""This function is a coroutine.

        Closes all connections.""""""
        if self._is_closed:
            return
        else:
            await self.http.close()
            self._is_closed = True","This function is a coroutine.

        Closes all connections.",
"def close(self):
        """"""Close port.""""""
        os.close(self.in_d)
        os.close(self.out_d)",Close port.,
"def stop(self):
        'cleans up and stops the discovery server'

        self.clearRemoteServices()
        self.clearLocalServices()

        self._stopThreads()
        self._serverStarted = False",cleans up and stops the discovery server,
"def clearLocalServices(self):
        'send Bye messages for the services and remove them'

        for service in list(self._localServices.values()):
            self._sendBye(service)

        self._localServices.clear()",send Bye messages for the services and remove them,
"def searchServices(self, types=None, scopes=None, timeout=3):
        'search for services given the TYPES and SCOPES in a given TIMEOUT'

        if not self._serverStarted:
            raise Exception(""Server not started"")

        self._sendProbe(types, scopes)

        time.sleep(timeout)

        return self._filterServices(list(self._remoteServices.values()), types, scopes)",search for services given the TYPES and SCOPES in a given TIMEOUT,
"def discover(scope, loglevel, capture):
    ""Discover systems using WS-Discovery""

    if loglevel:
        level = getattr(logging, loglevel, None)
        if not level:
           print(""Invalid log level '%s'"" % loglevel)
           return
        logger.setLevel(level)

    run(scope=scope, capture=capture)",Discover systems using WS-Discovery,
"def get_all_child_relations(model):
    """"""
    Return a list of RelatedObject records for child relations of the given model,
    including ones attached to ancestors of the model
    """"""
    return [
        field for field in model._meta.get_fields()
        if isinstance(field.remote_field, ParentalKey)
    ]","Return a list of RelatedObject records for child relations of the given model,
    including ones attached to ancestors of the model",
"def get_all_child_m2m_relations(model):
    """"""
    Return a list of ParentalManyToManyFields on the given model,
    including ones attached to ancestors of the model
    """"""
    return [
        field for field in model._meta.get_fields()
        if isinstance(field, ParentalManyToManyField)
    ]","Return a list of ParentalManyToManyFields on the given model,
    including ones attached to ancestors of the model",
"def get_key_for(self, address):
        """"""
        Generates the key associated with the specified address.

        Note that this method will generate the wrong key if the input
        address was generated from a different key!
        """"""
        return self.get_key(
            index=address.key_index,
            iterations=address.security_level,
        )","Generates the key associated with the specified address.

        Note that this method will generate the wrong key if the input
        address was generated from a different key!",
"def _add_trits(left, right):
    # type: (int, int) -> int
    """"""
    Adds two individual trits together.

    The result is always a single trit.
    """"""
    res = left + right
    return res if -2 < res < 2 else (res < 0) - (res > 0)","Adds two individual trits together.

    The result is always a single trit.",
"def _full_add_trits(left, right, carry):
    # type: (int, int, int) -> Tuple[int, int]
    """"""
    Adds two trits together, with support for a carry trit.
    """"""
    sum_both = _add_trits(left, right)
    cons_left = _cons_trits(left, right)
    cons_right = _cons_trits(sum_both, carry)

    return _add_trits(sum_both, carry), _any_trits(cons_left, cons_right)","Adds two trits together, with support for a carry trit.",
"def _log(self, level, message, context=None):
        # type: (int, Text, Optional[dict]) -> None
        """"""
        Sends a message to the instance's logger, if configured.
        """"""
        if self._logger:
            self._logger.log(level, message, extra={'context': context or {}})","Sends a message to the instance's logger, if configured.",
"def is_confirmed(self, new_is_confirmed):
        # type: (bool) -> None
        """"""
        Sets the ``is_confirmed`` for the bundle.
        """"""
        self._is_confirmed = new_is_confirmed

        for txn in self:
            txn.is_confirmed = new_is_confirmed",Sets the ``is_confirmed`` for the bundle.,
"def _execute(self, request):
    # type: (dict) -> dict
    """"""
    Sends the request object to the adapter and returns the response.

    The command name will be automatically injected into the request
    before it is sent (note: this will modify the request object).
    """"""
    request['command'] = self.command
    return self.adapter.send_request(request)","Sends the request object to the adapter and returns the response.

    The command name will be automatically injected into the request
    before it is sent (note: this will modify the request object).",
"def errors(self):
        # type: () -> List[Text]
        """"""
        Returns all errors found with the bundle.
        """"""
        try:
            self._errors.extend(self._validator)  # type: List[Text]
        except StopIteration:
            pass

        return self._errors",Returns all errors found with the bundle.,
"def SecurityLevel():
    """"""
    Generates a filter chain for validating a security level.
    """"""
    return (
            f.Type(int) |
            f.Min(1) |
            f.Max(3) |
            f.Optional(default=AddressGenerator.DEFAULT_SECURITY_LEVEL)
    )",Generates a filter chain for validating a security level.,
"def increment_legacy_tag(self):
        """"""
        Increments the transaction's legacy tag, used to fix insecure
        bundle hashes when finalizing a bundle.

        References:

        - https://github.com/iotaledger/iota.lib.py/issues/84
        """"""
        self._legacy_tag = (
            Tag.from_trits(add_trits(self.legacy_tag.as_trits(), [1]))
        )","Increments the transaction's legacy tag, used to fix insecure
        bundle hashes when finalizing a bundle.

        References:

        - https://github.com/iotaledger/iota.lib.py/issues/84",
"def tag(self):
        # type: () -> Tag
        """"""
        Determines the most relevant tag for the bundle.
        """"""
        for txn in reversed(self):  # type: ProposedTransaction
            if txn.tag:
                return txn.tag

        return Tag(b'')",Determines the most relevant tag for the bundle.,
"def prime_field_inv(a: int, n: int) -> int:
    """"""
    Extended euclidean algorithm to find modular inverses for integers
    """"""
    if a == 0:
        return 0
    lm, hm = 1, 0
    low, high = a % n, n
    while low > 1:
        r = high // low
        nm, new = hm - lm * r, high - low * r
        lm, low, hm, high = nm, new, lm, low
    return lm % n",Extended euclidean algorithm to find modular inverses for integers,
"def from_json_file(cls, filename):
        """"""
        Load a lexicon from a JSON file.

        Args:
            filename (str): The path to a JSON dump.
        """"""
        with open(filename, 'r') as fp:
            return cls(json.load(fp))","Load a lexicon from a JSON file.

        Args:
            filename (str): The path to a JSON dump.",
"def categories(self):
        """"""
        Lists the categories in the lexicon, except the
        optional categories.

        Returns:
            list: A list of strings of category names.
        """"""
        keys = [k for k in self.__dict__.keys() if k not in SPECIAL]
        return keys","Lists the categories in the lexicon, except the
        optional categories.

        Returns:
            list: A list of strings of category names.",
"def random(cls, component):
        """"""
        Returns a minimal Decor with a random colour.
        """"""
        colour = random.sample([i for i in range(256)], 3)
        return cls({'colour': colour, 'component': component, 'width': 1.0})",Returns a minimal Decor with a random colour.,
"def max_width(self):
        """"""
        The maximum width of all the Decors in the Legend. This is needed
        to scale a Legend or Striplog when plotting with widths turned on.
        """"""
        try:
            maximum = max([row.width for row in self.__list if row.width is not None])
            return maximum
        except:
            return 0","The maximum width of all the Decors in the Legend. This is needed
        to scale a Legend or Striplog when plotting with widths turned on.",
"def plot(self, fmt=None):
        """"""
        Make a simple plot of the legend.

        Simply calls Decor.plot() on all of its members.

        TODO: Build a more attractive plot.
        """"""
        for d in self.__list:
            d.plot(fmt=fmt)

        return None","Make a simple plot of the legend.

        Simply calls Decor.plot() on all of its members.

        TODO: Build a more attractive plot.",
"def _repr_html_(self):
        """"""
        Jupyter Notebook magic repr function.
        """"""
        rows = ''
        s = '<tr><td><strong>{k}</strong></td><td>{v}</td></tr>'
        for k, v in self.__dict__.items():
            rows += s.format(k=k, v=v)
        html = '<table>{}</table>'.format(rows)
        return html",Jupyter Notebook magic repr function.,
"def Rock(*args, **kwargs):
    """"""
    Graceful deprecation for old class name.
    """"""

    with warnings.catch_warnings():
        warnings.simplefilter(""always"")
        w = ""The 'Rock' class was renamed 'Component'. ""
        w += ""Please update your code.""
        warnings.warn(w, DeprecationWarning, stacklevel=2)

    return Component(*args, **kwargs)",Graceful deprecation for old class name.,
"def get_template(name):
    """"""
    Still unsure about best way to do this, hence cruft.
    """"""
    text = re.sub(r'\r\n', r'\n', name)
    text = re.sub(r'\{([FISDE].*?)\}', r'{{\1}}', text)
    return text","Still unsure about best way to do this, hence cruft.",
"def __strict(self):
        """"""
        Private method. Checks if striplog is monotonically increasing in
        depth.

        Returns:
            Bool.
        """"""
        def conc(a, b):
            return a + b

        # Check boundaries, b
        b = np.array(reduce(conc, [[i.top.z, i.base.z] for i in self]))

        return all(np.diff(b) >= 0)","Private method. Checks if striplog is monotonically increasing in
        depth.

        Returns:
            Bool.",
"def top(self):
        """"""
        Property.
        """"""
        # For backwards compatibility.
        with warnings.catch_warnings():
            warnings.simplefilter(""always"")
            w = ""Striplog.top is deprecated; please use Striplog.unique""
            warnings.warn(w, DeprecationWarning, stacklevel=2)
        return self.unique",Property.,
"def from_img(cls, *args, **kwargs):
        """"""
        For backwards compatibility.
        """"""
        with warnings.catch_warnings():
            warnings.simplefilter(""always"")
            w = ""from_img() is deprecated; please use from_image()""
            warnings.warn(w)
        return cls.from_image(*args, **kwargs)",For backwards compatibility.,
"def copy(self):
        """"""Returns a shallow copy.""""""
        return Striplog([i.copy() for i in self],
                        order=self.order,
                        source=self.source)",Returns a shallow copy.,
"def depth(self, d):
        """"""
        For backwards compatibility.
        """"""
        with warnings.catch_warnings():
            warnings.simplefilter(""always"")
            w = ""depth() is deprecated; please use read_at()""
            warnings.warn(w)
        return self.read_at(d)",For backwards compatibility.,
"def find_overlaps(self, index=False):
        """"""
        Find overlaps in a striplog.

        Args:
            index (bool): If True, returns indices of intervals with
            gaps after them.

        Returns:
            Striplog: A striplog of all the overlaps as intervals.
        """"""
        return self.__find_incongruities(op=operator.gt, index=index)","Find overlaps in a striplog.

        Args:
            index (bool): If True, returns indices of intervals with
            gaps after them.

        Returns:
            Striplog: A striplog of all the overlaps as intervals.",
"def find_gaps(self, index=False):
        """"""
        Finds gaps in a striplog.

        Args:
            index (bool): If True, returns indices of intervals with
            gaps after them.

        Returns:
            Striplog: A striplog of all the gaps. A sort of anti-striplog.
        """"""
        return self.__find_incongruities(op=operator.lt, index=index)","Finds gaps in a striplog.

        Args:
            index (bool): If True, returns indices of intervals with
            gaps after them.

        Returns:
            Striplog: A striplog of all the gaps. A sort of anti-striplog.",
"def dict_repr_html(dictionary):
    """"""
    Jupyter Notebook magic repr function.
    """"""
    rows = ''
    s = '<tr><td><strong>{k}</strong></td><td>{v}</td></tr>'
    for k, v in dictionary.items():
        rows += s.format(k=k, v=v)
    html = '<table>{}</table>'.format(rows)
    return html",Jupyter Notebook magic repr function.,
"def hex_to_name(hexx):
    """"""
    Convert hex to a color name, using matplotlib's colour names.

    Args:
        hexx (str): A hexadecimal colour, starting with '#'.

    Returns:
        str: The name of the colour, or None if not found.
    """"""
    for n, h in defaults.COLOURS.items():
        if (len(n) > 1) and (h == hexx.upper()):
            return n.lower()
    return None","Convert hex to a color name, using matplotlib's colour names.

    Args:
        hexx (str): A hexadecimal colour, starting with '#'.

    Returns:
        str: The name of the colour, or None if not found.",
"def _get_random(self, obj_type):
        """"""
        Get a random mutator from a list of mutators
        """"""
        return self.mutator[obj_type][random.randint(0, self.config.level)]",Get a random mutator from a list of mutators,
"def get_mutator(self, obj, obj_type):
        """"""
        Get a random mutator for the given type
        """"""
        if obj_type == unicode:
            obj_type = str
            obj = str(obj)
        return self._get_random(obj_type)(obj)",Get a random mutator for the given type,
"def get_string_polyglot_attack(self, obj):
        """"""
        Return a polyglot attack containing the original object
        """"""
        return self.polyglot_attacks[random.choice(self.config.techniques)] % obj",Return a polyglot attack containing the original object,
"def fuzz(self, obj):
        """"""
        Perform the fuzzing
        """"""
        buf = list(obj)
        FuzzFactor = random.randrange(1, len(buf))
        numwrites=random.randrange(math.ceil((float(len(buf)) / FuzzFactor)))+1
        for j in range(numwrites):
            self.random_action(buf)
        return self.safe_unicode(buf)",Perform the fuzzing,
"def safe_unicode(self, buf):
        """"""
        Safely return an unicode encoded string
        """"""
        tmp = """"
        buf = """".join(b for b in buf)
        for character in buf:
            tmp += character
        return tmp",Safely return an unicode encoded string,
"def run(self):
        """"""
        Start the servers
        """"""
        route(""/"")(self.serve)
        if self.config.html:
            route(""/<filepath:path>"")(self.custom_html)
        if self.config.fuzz_web:
            self.request_checker.start()
        self.httpd.start()
        self.httpsd.start()",Start the servers,
"def stop(self):
        """"""
        Kill the servers
        """"""
        os.kill(self.httpd.pid, signal.SIGKILL)
        os.kill(self.httpsd.pid, signal.SIGKILL)
        self.client_queue.put((0,0))
        if self.config.fuzz_web:
            self.request_checker.join()
        self.logger.debug(""[{0}] - PJFServer successfully completed"".format(time.strftime(""%H:%M:%S"")))",Kill the servers,
"def apply_patch(self):
        """"""
        Fix default socket lib to handle client disconnection while receiving data (Broken pipe)
        """"""
        if sys.version_info >= (3, 0):
            # No patch for python >= 3.0
            pass
        else:
            from .patch.socket import socket as patch
            socket.socket = patch",Fix default socket lib to handle client disconnection while receiving data (Broken pipe),
"def fuzz(self, obj):
        """"""
        Generic fuzz mutator, use a decorator for the given type
        """"""
        decorators = self.decorators

        @decorators.mutate_object_decorate
        def mutate():
            return obj
        return mutate()","Generic fuzz mutator, use a decorator for the given type",
"def run_and_monitor(self):
        """"""
        Run command once and check exit code
        """"""
        signal.signal(signal.SIGINT, self.shutdown)
        self.spawn(self.config.process_to_monitor, timeout=0)
        return self._is_sigsegv(self.return_code)",Run command once and check exit code,
"def preprocess_rules(self):
        """"""Calculate shortest reference-paths of each rule (and Or field),
        and prune all unreachable rules.
        """"""
        to_prune = self._find_shortest_paths()
        self._prune_rules(to_prune)

        self._rules_processed = True","Calculate shortest reference-paths of each rule (and Or field),
        and prune all unreachable rules.",
"def post_revert(self, cat, res, total_num, num, info):
        """"""Commit any staged rule definition changes (rule generation went
        smoothly).
        """"""
        if self._staged_defs is None:
            return
        for cat,def_name,def_value in self._staged_defs:
            self.defs.setdefault(cat, {}).setdefault(def_name, deque()).append(def_value)
        self._staged_defs = None","Commit any staged rule definition changes (rule generation went
        smoothly).",
"def mutate_object_decorate(self, func):
        """"""
        Mutate a generic object based on type
        """"""
        def mutate():
            obj = func()
            return self.Mutators.get_mutator(obj, type(obj))
        return mutate",Mutate a generic object based on type,
"def cli_command_quit(self, msg):
        """"""\
        kills the child and exits
        """"""
        if self.state == State.RUNNING and self.sprocess and self.sprocess.proc:
            self.sprocess.proc.kill()
        else:
            sys.exit(0)","\
        kills the child and exits",
"def cli_command_resume(self, msg):
        """"""\
        sets state to waiting - so we resume spawning children
        """"""
        if self.state == State.PAUSED:
            self.state = State.WAITING","\
        sets state to waiting - so we resume spawning children",
"def setAvatar(self, image):
        """"""
        Update the profile picture for the current user.

        Args:
            image (file): a file-like object to read the image from
        """"""
        self.conn(""PUT"", ""{0}/users/{1}/profile/avatar"".format(SkypeConnection.API_USER, self.userId),
                  auth=SkypeConnection.Auth.SkypeToken, data=image.read())","Update the profile picture for the current user.

        Args:
            image (file): a file-like object to read the image from",
"def syncFlags(self):
        """"""
        Update the cached list of all enabled flags, and store it in the :attr:`flags` attribute.
        """"""
        self.flags = set(self.skype.conn(""GET"", SkypeConnection.API_FLAGS,
                                         auth=SkypeConnection.Auth.SkypeToken).json())","Update the cached list of all enabled flags, and store it in the :attr:`flags` attribute.",
"def merge(self, obj):
        """"""
        Add a given object to the cache, or update an existing entry to include more fields.

        Args:
            obj (SkypeObj): object to add to the cache
        """"""
        if obj.id in self.cache:
            self.cache[obj.id].merge(obj)
        else:
            self.cache[obj.id] = obj
        return self.cache[obj.id]","Add a given object to the cache, or update an existing entry to include more fields.

        Args:
            obj (SkypeObj): object to add to the cache",
"def getUserId(self):
        """"""
        Ask Skype for the authenticated user's identifier, and store it on the connection object.
        """"""
        self.userId = self(""GET"", ""{0}/users/self/profile"".format(self.API_USER),
                           auth=self.Auth.SkypeToken).json().get(""username"")","Ask Skype for the authenticated user's identifier, and store it on the connection object.",
"def ping(self, timeout=12):
        """"""
        Send a keep-alive request for the endpoint.

        Args:
            timeout (int): maximum amount of time for the endpoint to stay active
        """"""
        self.conn(""POST"", ""{0}/users/ME/endpoints/{1}/active"".format(self.conn.msgsHost, self.id),
                  auth=SkypeConnection.Auth.RegToken, json={""timeout"": timeout})","Send a keep-alive request for the endpoint.

        Args:
            timeout (int): maximum amount of time for the endpoint to stay active",
"def chatToId(url):
        """"""
        Extract the conversation ID from a conversation URL.

        Matches addresses containing ``conversations/<chat>``.

        Args:
            url (str): Skype API URL

        Returns:
            str: extracted identifier
        """"""
        match = re.search(r""conversations/([0-9]+:[^/]+)"", url)
        return match.group(1) if match else None","Extract the conversation ID from a conversation URL.

        Matches addresses containing ``conversations/<chat>``.

        Args:
            url (str): Skype API URL

        Returns:
            str: extracted identifier",
"def u(text, encoding='utf-8'):
    ""Return unicode text, no matter what""

    if isinstance(text, six.binary_type):
        text = text.decode(encoding)

    # it's already unicode
    text = text.replace('\r\n', '\n')
    return text","Return unicode text, no matter what",
"def to_dict(self):
        ""Post as a dict, for serializing""
        d = self.metadata.copy()
        d['content'] = self.content
        return d","Post as a dict, for serializing",
"def load(self, fm, **kwargs):
        """"""
        Parse YAML front matter. This uses yaml.SafeLoader by default. 
        """"""
        kwargs.setdefault('Loader', SafeLoader)
        return yaml.load(fm, **kwargs)",Parse YAML front matter. This uses yaml.SafeLoader by default.,
"def export(self, metadata, **kwargs):
        """"""
        Export metadata as YAML. This uses yaml.SafeDumper by default.
        """"""
        kwargs.setdefault('Dumper', SafeDumper)
        kwargs.setdefault('default_flow_style', False)
        kwargs.setdefault('allow_unicode', True)

        metadata = yaml.dump(metadata, **kwargs).strip()
        return u(metadata)",Export metadata as YAML. This uses yaml.SafeDumper by default.,
"def export(self, metadata, **kwargs):
        ""Turn metadata into JSON""
        kwargs.setdefault('indent', 4)
        metadata = json.dumps(metadata, **kwargs)
        return u(metadata)",Turn metadata into JSON,
"def items(self) -> List[str]:
        """"""Return items as a list of strings.

        Don't include sub-items and the start pattern.
        """"""
        items = []  # type: List[str]
        append = items.append
        string = self.string
        match = self._match
        ms = match.start()
        for s, e in match.spans('item'):
            append(string[s - ms:e - ms])
        return items","Return items as a list of strings.

        Don't include sub-items and the start pattern.",
"def convert(self, newstart: str) -> None:
        """"""Convert to another list type by replacing starting pattern.""""""
        match = self._match
        ms = match.start()
        for s, e in reversed(match.spans('pattern')):
            self[s - ms:e - ms] = newstart
        self.pattern = escape(newstart)",Convert to another list type by replacing starting pattern.,
"def lists(self, pattern: str = None) -> List[WikiList]:
        """"""Return the lists in all arguments.

        For performance reasons it is usually preferred to get a specific
        Argument and use the `lists` method of that argument instead.
        """"""
        return [
            lst for arg in self.arguments for lst in arg.lists(pattern) if lst]","Return the lists in all arguments.

        For performance reasons it is usually preferred to get a specific
        Argument and use the `lists` method of that argument instead.",
"def name(self) -> str:
        """"""Return template's name (includes whitespace).""""""
        h = self._atomic_partition(self._first_arg_sep)[0]
        if len(h) == len(self.string):
            return h[2:-2]
        return h[2:]",Return template's name (includes whitespace).,
"def string(self) -> str:
        """"""Return str(self).""""""
        start, end = self._span
        return self._lststr[0][start:end]",Return str(self).,
"def _atomic_partition(self, char: int) -> Tuple[str, str, str]:
        """"""Partition self.string where `char`'s not in atomic sub-spans.""""""
        s, e = self._span
        index = self._shadow.find(char)
        if index == -1:
            return self._lststr[0][s:e], '', ''
        lststr0 = self._lststr[0]
        return lststr0[s:s + index], chr(char), lststr0[s + index + 1:e]",Partition self.string where `char`'s not in atomic sub-spans.,
"def _subspans(self, type_: str) -> List[List[int]]:
        """"""Return all the sub-span including self._span.""""""
        return self._type_to_spans[type_]",Return all the sub-span including self._span.,
"def pprint(self, indent: str = '    ', remove_comments=False):
        """"""Deprecated, use self.pformat instead.""""""
        warn(
            'pprint method is deprecated, use pformat instead.',
            DeprecationWarning,
        )
        return self.pformat(indent, remove_comments)","Deprecated, use self.pformat instead.",
"def parameters(self) -> List['Parameter']:
        """"""Return a list of parameter objects.""""""
        _lststr = self._lststr
        _type_to_spans = self._type_to_spans
        return [
            Parameter(_lststr, _type_to_spans, span, 'Parameter')
            for span in self._subspans('Parameter')]",Return a list of parameter objects.,
"def parser_functions(self) -> List['ParserFunction']:
        """"""Return a list of parser function objects.""""""
        _lststr = self._lststr
        _type_to_spans = self._type_to_spans
        return [
            ParserFunction(_lststr, _type_to_spans, span, 'ParserFunction')
            for span in self._subspans('ParserFunction')]",Return a list of parser function objects.,
"def templates(self) -> List['Template']:
        """"""Return a list of templates as template objects.""""""
        _lststr = self._lststr
        _type_to_spans = self._type_to_spans
        return [
            Template(_lststr, _type_to_spans, span, 'Template')
            for span in self._subspans('Template')]",Return a list of templates as template objects.,
"def wikilinks(self) -> List['WikiLink']:
        """"""Return a list of wikilink objects.""""""
        _lststr = self._lststr
        _type_to_spans = self._type_to_spans
        return [
            WikiLink(_lststr, _type_to_spans, span, 'WikiLink')
            for span in self._subspans('WikiLink')]",Return a list of wikilink objects.,
"def comments(self) -> List['Comment']:
        """"""Return a list of comment objects.""""""
        _lststr = self._lststr
        _type_to_spans = self._type_to_spans
        return [
            Comment(_lststr, _type_to_spans, span, 'Comment')
            for span in self._subspans('Comment')]",Return a list of comment objects.,
"def mode(list_: List[T]) -> T:
    """"""Return the most common item in the list.

    Return the first one if there are more than one most common items.

    Example:

    >>> mode([1,1,2,2,])
    1
    >>> mode([1,2,2])
    2
    >>> mode([])
    ...
    ValueError: max() arg is an empty sequence
    """"""
    return max(set(list_), key=list_.count)","Return the most common item in the list.

    Return the first one if there are more than one most common items.

    Example:

    >>> mode([1,1,2,2,])
    1
    >>> mode([1,2,2])
    2
    >>> mode([])
    ...
    ValueError: max() arg is an empty sequence",
"def get_arg(self, name: str) -> Optional[Argument]:
        """"""Return the last argument with the given name.

        Return None if no argument with that name is found.
        """"""
        return get_arg(name, reversed(self.arguments))","Return the last argument with the given name.

        Return None if no argument with that name is found.",
"def del_arg(self, name: str) -> None:
        """"""Delete all arguments with the given then.""""""
        for arg in reversed(self.arguments):
            if arg.name.strip(WS) == name.strip(WS):
                del arg[:]",Delete all arguments with the given then.,
"def to_ogc_wkt(self):
        """"""
        Returns the CS as a OGC WKT formatted string.
        """"""
        return 'GEOGCS[""%s"", %s, %s, %s, AXIS[""Lon"", %s], AXIS[""Lat"", %s]]' % (self.name, self.datum.to_ogc_wkt(), self.prime_mer.to_ogc_wkt(), self.angunit.to_ogc_wkt(), self.twin_ax[0].ogc_wkt, self.twin_ax[1].ogc_wkt )",Returns the CS as a OGC WKT formatted string.,
"def to_esri_wkt(self):
        """"""
        Returns the CS as a ESRI WKT formatted string.
        """"""
        return 'GEOGCS[""%s"", %s, %s, %s, AXIS[""Lon"", %s], AXIS[""Lat"", %s]]' % (self.name, self.datum.to_esri_wkt(), self.prime_mer.to_esri_wkt(), self.angunit.to_esri_wkt(), self.twin_ax[0].esri_wkt, self.twin_ax[1].esri_wkt )",Returns the CS as a ESRI WKT formatted string.,
"def write_to(self, out):
        """""" Write the raw header content to the out stream

        Parameters:
        ----------
        out : {file object}
            The output stream
        """"""

        out.write(bytes(self.header))
        out.write(self.record_data)","Write the raw header content to the out stream

        Parameters:
        ----------
        out : {file object}
            The output stream",
"def copy_fields_from(self, other_record):
        """""" Tries to copy the values of the current dimensions from other_record
        """"""
        for dim_name in self.dimensions_names:
            try:
                self[dim_name] = other_record[dim_name]
            except ValueError:
                pass",Tries to copy the values of the current dimensions from other_record,
"def _append_zeros_if_too_small(self, value):
        """""" Appends zeros to the points stored if the value we are trying to
        fit is bigger
        """"""
        size_diff = len(value) - len(self.array)
        if size_diff:
            self.array = np.append(
                self.array, np.zeros(size_diff, dtype=self.array.dtype)
            )","Appends zeros to the points stored if the value we are trying to
        fit is bigger",
"def all_dimensions_names(self):
        """""" Returns all the dimensions names, including the names of sub_fields
        and their corresponding packed fields
        """"""
        return frozenset(self.array.dtype.names + tuple(self.sub_fields_dict.keys()))","Returns all the dimensions names, including the names of sub_fields
        and their corresponding packed fields",
"def x(self):
        """""" Returns the scaled x positions of the points as doubles
        """"""
        return scale_dimension(self.X, self.header.x_scale, self.header.x_offset)",Returns the scaled x positions of the points as doubles,
"def y(self):
        """""" Returns the scaled y positions of the points as doubles
        """"""
        return scale_dimension(self.Y, self.header.y_scale, self.header.y_offset)",Returns the scaled y positions of the points as doubles,
"def z(self):
        """""" Returns the scaled z positions of the points as doubles
        """"""
        return scale_dimension(self.Z, self.header.z_scale, self.header.z_offset)",Returns the scaled z positions of the points as doubles,
"def min_file_version_for_point_format(point_format_id):
    """"""  Returns the minimum file version that supports the given point_format_id
    """"""
    for version, point_formats in sorted(VERSION_TO_POINT_FMT.items()):
        if point_format_id in point_formats:
            return version
    else:
        raise errors.PointFormatNotSupported(point_format_id)",Returns the minimum file version that supports the given point_format_id,
"def is_point_fmt_compatible_with_version(point_format_id, file_version):
    """"""  Returns true if the file version support the point_format_id
    """"""
    try:
        return point_format_id in VERSION_TO_POINT_FMT[str(file_version)]
    except KeyError:
        raise errors.FileVersionNotSupported(file_version)",Returns true if the file version support the point_format_id,
"def files_have_same_point_format_id(las_files):
    """""" Returns true if all the files have the same points format id
    """"""
    point_format_found = {las.header.point_format_id for las in las_files}
    return len(point_format_found) == 1",Returns true if all the files have the same points format id,
"def files_have_same_dtype(las_files):
    """""" Returns true if all the files have the same numpy datatype
    """"""
    dtypes = {las.points.dtype for las in las_files}
    return len(dtypes) == 1",Returns true if all the files have the same numpy datatype,
"def _raise_if_wrong_file_signature(stream):
    """""" Reads the 4 first bytes of the stream to check that is LASF""""""
    file_sig = stream.read(len(headers.LAS_FILE_SIGNATURE))
    if file_sig != headers.LAS_FILE_SIGNATURE:
        raise errors.PylasError(
            ""File Signature ({}) is not {}"".format(file_sig, headers.LAS_FILE_SIGNATURE)
        )",Reads the 4 first bytes of the stream to check that is LASF,
"def read_header(self):
        """""" Reads the head of the las file and returns it
        """"""
        self.stream.seek(self.start_pos)
        return headers.HeaderFactory().read_from_stream(self.stream)",Reads the head of the las file and returns it,
"def read_vlrs(self):
        """""" Reads and return the vlrs of the file
        """"""
        self.stream.seek(self.start_pos + self.header.size)
        return VLRList.read_from(self.stream, num_to_read=self.header.number_of_vlr)",Reads and return the vlrs of the file,
"def read_evlrs(self):
        """""" Reads the EVLRs of the file, will fail if the file version
        does not support evlrs
        """"""
        self.stream.seek(self.start_pos + self.header.start_of_first_evlr)
        return evlrs.EVLRList.read_from(self.stream, self.header.number_of_evlr)","Reads the EVLRs of the file, will fail if the file version
        does not support evlrs",
"def _warn_if_not_at_expected_pos(self, expected_pos, end_of, start_of):
        """""" Helper function to warn about unknown bytes found in the file""""""
        diff = expected_pos - self.stream.tell()
        if diff != 0:
            logger.warning(
                ""There are {} bytes between {} and {}"".format(diff, end_of, start_of)
            )",Helper function to warn about unknown bytes found in the file,
"def write_then_read_again(las, do_compress=False):
    """""" writes the given las into memory using BytesIO and 
    reads it again, returning the newly read file.

    Mostly used for testing purposes, without having to write to disk
    """"""
    out = io.BytesIO()
    las.write(out, do_compress=do_compress)
    out.seek(0)
    return read_las(out)","writes the given las into memory using BytesIO and 
    reads it again, returning the newly read file.

    Mostly used for testing purposes, without having to write to disk",
"def date(self):
        """""" Returns the creation date stored in the las file

        Returns
        -------
        datetime.date

        """"""
        try:
            return datetime.date(self.creation_year, 1, 1) + datetime.timedelta(
                self.creation_day_of_year - 1
            )
        except ValueError:
            return None","Returns the creation date stored in the las file

        Returns
        -------
        datetime.date",
"def date(self, date):
        """""" Returns the date of file creation as a python date object
        """"""
        self.creation_year = date.year
        self.creation_day_of_year = date.timetuple().tm_yday",Returns the date of file creation as a python date object,
"def mins(self):
        """""" Returns de minimum values of x, y, z as a numpy array
        """"""
        return np.array([self.x_min, self.y_min, self.z_min])","Returns de minimum values of x, y, z as a numpy array",
"def mins(self, value):
        """""" Sets de minimum values of x, y, z as a numpy array
        """"""
        self.x_min, self.y_min, self.z_min = value","Sets de minimum values of x, y, z as a numpy array",
"def maxs(self):
        """""" Returns de maximum values of x, y, z as a numpy array
        """"""
        return np.array([self.x_max, self.y_max, self.z_max])","Returns de maximum values of x, y, z as a numpy array",
"def maxs(self, value):
        """""" Sets de maximum values of x, y, z as a numpy array
        """"""
        self.x_max, self.y_max, self.z_max = value","Sets de maximum values of x, y, z as a numpy array",
"def scales(self):
        """""" Returns the scaling values of x, y, z as a numpy array
        """"""
        return np.array([self.x_scale, self.y_scale, self.z_scale])","Returns the scaling values of x, y, z as a numpy array",
"def offsets(self):
        """""" Returns the offsets values of x, y, z as a numpy array
        """"""
        return np.array([self.x_offset, self.y_offset, self.z_offset])","Returns the offsets values of x, y, z as a numpy array",
"def dtype(self):
        """""" Returns the numpy.dtype used to store the point records in a numpy array

        .. note::

            The dtype corresponds to the dtype with sub_fields *packed* into their
            composed fields

        """"""
        dtype = self._access_dict(dims.ALL_POINT_FORMATS_DTYPE, self.id)
        dtype = self._dtype_add_extra_dims(dtype)
        return dtype","Returns the numpy.dtype used to store the point records in a numpy array

        .. note::

            The dtype corresponds to the dtype with sub_fields *packed* into their
            composed fields",
"def unpacked_dtype(self):
        """""" Returns the numpy.dtype used to store the point records in a numpy array

        .. note::

            The dtype corresponds to the dtype with sub_fields *unpacked*

        """"""
        dtype = self._access_dict(dims.UNPACKED_POINT_FORMATS_DTYPES, self.id)
        dtype = self._dtype_add_extra_dims(dtype)
        return dtype","Returns the numpy.dtype used to store the point records in a numpy array

        .. note::

            The dtype corresponds to the dtype with sub_fields *unpacked*",
"def num_extra_bytes(self):
        """""" Returns the number of extra bytes
        """"""
        return sum(np.dtype(extra_dim[1]).itemsize for extra_dim in self.extra_dims)",Returns the number of extra bytes,
"def has_waveform_packet(self):
        """""" Returns True if the point format has waveform packet dimensions
        """"""
        dimensions = set(self.dimension_names)
        return all(name in dimensions for name in dims.WAVEFORM_FIELDS_NAMES)",Returns True if the point format has waveform packet dimensions,
"def main(port, ip, command, loglevel):
    """"""Console script for satel_integra.""""""
    numeric_level = getattr(logging, loglevel.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError('Invalid log level: %s' % loglevel)
        
    logging.basicConfig(level=numeric_level)

    click.echo(""Demo of satel_integra library"")
    if command == ""demo"":
        demo(ip, port)",Console script for satel_integra.,
"def checksum(command):
    """"""Function to calculate checksum as per Satel manual.""""""
    crc = 0x147A
    for b in command:
        # rotate (crc 1 bit left)
        crc = ((crc << 1) & 0xFFFF) | (crc & 0x8000) >> 15
        crc = crc ^ 0xFFFF
        crc = (crc + (crc >> 8) + b) & 0xFFFF
    return crc",Function to calculate checksum as per Satel manual.,
"def print_hex(data):
    """"""Debugging method to print out frames in hex.""""""
    hex_msg = """"
    for c in data:
        hex_msg += ""\\x"" + format(c, ""02x"")
    _LOGGER.debug(hex_msg)",Debugging method to print out frames in hex.,
"def generate_query(command):
    """"""Add header, checksum and footer to command data.""""""
    data = bytearray(command)
    c = checksum(data)
    data.append(c >> 8)
    data.append(c & 0xFF)
    data.replace(b'\xFE', b'\xFE\xF0')

    data = bytearray.fromhex(""FEFE"") + data + bytearray.fromhex(""FE0D"")
    return data","Add header, checksum and footer to command data.",
"async def disarm(self, code, partition_list):
        """"""Send command to disarm.""""""
        _LOGGER.info(""Sending disarm command."")
        while len(code) < 16:
            code += 'F'

        code_bytes = bytearray.fromhex(code)

        data = generate_query(b'\x84' + code_bytes
                              + partition_bytes(partition_list))

        await self._send_data(data)",Send command to disarm.,
"def close(self):
        """"""Stop monitoring and close connection.""""""
        _LOGGER.debug(""Closing..."")
        self.closed = True
        if self.connected:
            self._writer.close()",Stop monitoring and close connection.,
"def purge_db(self):
        """"""
        Clear all matching our user_id.
        """"""
        with self.engine.begin() as db:
            purge_user(db, self.user_id)",Clear all matching our user_id.,
"def _save_file(self, db, model, path):
        """"""
        Save a non-notebook file.
        """"""
        save_file(
            db,
            self.user_id,
            path,
            to_b64(model['content'], model.get('format', None)),
            self.crypto.encrypt,
            self.max_file_size_bytes,
        )
        return None",Save a non-notebook file.,
"def delete_file(self, path):
        """"""
        Delete object corresponding to path.
        """"""
        if self.file_exists(path):
            self._delete_non_directory(path)
        elif self.dir_exists(path):
            self._delete_directory(path)
        else:
            self.no_such_entity(path)",Delete object corresponding to path.,
"def ensure_db_user(db, user_id):
    """"""
    Add a new user if they don't already exist.
    """"""
    with ignore_unique_violation():
        db.execute(
            users.insert().values(id=user_id),
        )",Add a new user if they don't already exist.,
"def purge_user(db, user_id):
    """"""
    Delete a user and all of their resources.
    """"""
    db.execute(files.delete().where(
        files.c.user_id == user_id
    ))
    db.execute(directories.delete().where(
        directories.c.user_id == user_id
    ))
    db.execute(users.delete().where(
        users.c.id == user_id
    ))",Delete a user and all of their resources.,
"def _is_in_directory(table, user_id, db_dirname):
    """"""
    Return a WHERE clause that matches entries in a directory.

    Parameterized on table because this clause is re-used between files and
    directories.
    """"""
    return and_(
        table.c.parent_name == db_dirname,
        table.c.user_id == user_id,
    )","Return a WHERE clause that matches entries in a directory.

    Parameterized on table because this clause is re-used between files and
    directories.",
"def _dir_exists(db, user_id, db_dirname):
    """"""
    Internal implementation of dir_exists.

    Expects a db-style path name.
    """"""
    return db.execute(
        select(
            [func.count(directories.c.name)],
        ).where(
            and_(
                directories.c.user_id == user_id,
                directories.c.name == db_dirname,
            ),
        )
    ).scalar() != 0","Internal implementation of dir_exists.

    Expects a db-style path name.",
"def directories_in_directory(db, user_id, db_dirname):
    """"""
    Return subdirectories of a directory.
    """"""
    fields = _directory_default_fields()
    rows = db.execute(
        select(
            fields,
        ).where(
            _is_in_directory(directories, user_id, db_dirname),
        )
    )
    return [to_dict_no_content(fields, row) for row in rows]",Return subdirectories of a directory.,
"def _file_where(user_id, api_path):
    """"""
    Return a WHERE clause matching the given API path and user_id.
    """"""
    directory, name = split_api_filepath(api_path)
    return and_(
        files.c.name == name,
        files.c.user_id == user_id,
        files.c.parent_name == directory,
    )",Return a WHERE clause matching the given API path and user_id.,
"def _select_file(user_id, api_path, fields, limit):
    """"""
    Return a SELECT statement that returns the latest N versions of a file.
    """"""
    query = select(fields).where(
        _file_where(user_id, api_path),
    ).order_by(
        _file_creation_order(),
    )
    if limit is not None:
        query = query.limit(limit)

    return query",Return a SELECT statement that returns the latest N versions of a file.,
"def _file_default_fields():
    """"""
    Default fields returned by a file query.
    """"""
    return [
        files.c.name,
        files.c.created_at,
        files.c.parent_name,
    ]",Default fields returned by a file query.,
"def get_file(db, user_id, api_path, include_content, decrypt_func):
    """"""
    Get file data for the given user_id and path.

    Include content only if include_content=True.
    """"""
    query_fields = _file_default_fields()
    if include_content:
        query_fields.append(files.c.content)

    return _get_file(db, user_id, api_path, query_fields, decrypt_func)","Get file data for the given user_id and path.

    Include content only if include_content=True.",
"def get_file_id(db, user_id, api_path):
    """"""
    Get the value in the 'id' column for the file with the given
    user_id and path.
    """"""
    return _get_file(
        db,
        user_id,
        api_path,
        [files.c.id],
        unused_decrypt_func,
    )['id']","Get the value in the 'id' column for the file with the given
    user_id and path.",
"def delete_file(db, user_id, api_path):
    """"""
    Delete a file.

    TODO: Consider making this a soft delete.
    """"""
    result = db.execute(
        files.delete().where(
            _file_where(user_id, api_path)
        )
    )

    rowcount = result.rowcount
    if not rowcount:
        raise NoSuchFile(api_path)

    return rowcount","Delete a file.

    TODO: Consider making this a soft delete.",
"def file_exists(db, user_id, path):
    """"""
    Check if a file exists.
    """"""
    try:
        get_file(
            db,
            user_id,
            path,
            include_content=False,
            decrypt_func=unused_decrypt_func,
        )
        return True
    except NoSuchFile:
        return False",Check if a file exists.,
"def purge_remote_checkpoints(db, user_id):
    """"""
    Delete all database records for the given user_id.
    """"""
    db.execute(
        remote_checkpoints.delete().where(
            remote_checkpoints.c.user_id == user_id,
        )
    )",Delete all database records for the given user_id.,
"def select_file_ids(db, user_id):
    """"""
    Get all file ids for a user.
    """"""
    return list(
        db.execute(
            select([files.c.id])
            .where(files.c.user_id == user_id)
        )
    )",Get all file ids for a user.,
"def select_remote_checkpoint_ids(db, user_id):
    """"""
    Get all file ids for a user.
    """"""
    return list(
        db.execute(
            select([remote_checkpoints.c.id])
            .where(remote_checkpoints.c.user_id == user_id)
        )
    )",Get all file ids for a user.,
"def memoize_single_arg(f):
    """"""
    Decorator memoizing a single-argument function
    """"""
    memo = {}

    @wraps(f)
    def memoized_f(arg):
        try:
            return memo[arg]
        except KeyError:
            result = memo[arg] = f(arg)
            return result
    return memoized_f",Decorator memoizing a single-argument function,
"def _get_name(column_like):
    """"""
    Get the name from a column-like SQLAlchemy expression.

    Works for Columns and Cast expressions.
    """"""
    if isinstance(column_like, Column):
        return column_like.name
    elif isinstance(column_like, Cast):
        return column_like.clause.name","Get the name from a column-like SQLAlchemy expression.

    Works for Columns and Cast expressions.",
"def delete_checkpoint(self, checkpoint_id, path):
        """"""delete a checkpoint for a file""""""
        with self.engine.begin() as db:
            return delete_single_remote_checkpoint(
                db, self.user_id, path, checkpoint_id,
            )",delete a checkpoint for a file,
"def get_checkpoint_content(self, checkpoint_id, path):
        """"""Get the content of a checkpoint.""""""
        with self.engine.begin() as db:
            return get_remote_checkpoint(
                db,
                self.user_id,
                path,
                checkpoint_id,
                self.crypto.decrypt,
            )['content']",Get the content of a checkpoint.,
"def list_checkpoints(self, path):
        """"""Return a list of checkpoints for a given file""""""
        with self.engine.begin() as db:
            return list_remote_checkpoints(db, self.user_id, path)",Return a list of checkpoints for a given file,
"def rename_all_checkpoints(self, old_path, new_path):
        """"""Rename all checkpoints for old_path to new_path.""""""
        with self.engine.begin() as db:
            return move_remote_checkpoints(
                db,
                self.user_id,
                old_path,
                new_path,
            )",Rename all checkpoints for old_path to new_path.,
"def delete_all_checkpoints(self, path):
        """"""Delete all checkpoints for the given path.""""""
        with self.engine.begin() as db:
            delete_remote_checkpoints(db, self.user_id, path)",Delete all checkpoints for the given path.,
"def purge_db(self):
        """"""
        Purge all database records for the current user.
        """"""
        with self.engine.begin() as db:
            purge_remote_checkpoints(db, self.user_id)",Purge all database records for the current user.,
"def _managers_changed(self, name, old, new):
        """"""
        Strip slashes from directories before updating.
        """"""
        for key in new:
            if '/' in key:
                raise ValueError(
                    ""Expected directory names w/o slashes.  Got [%s]"" % key
                )
            self.managers = {k.strip('/'): v for k, v in new.items()}",Strip slashes from directories before updating.,
"def normalize_api_path(api_path):
    """"""
    Resolve paths with '..' to normalized paths, raising an error if the final
    result is outside root.
    """"""
    normalized = posixpath.normpath(api_path.strip('/'))
    if normalized == '.':
        normalized = ''
    elif normalized.startswith('..'):
        raise PathOutsideRoot(normalized)
    return normalized","Resolve paths with '..' to normalized paths, raising an error if the final
    result is outside root.",
"def split_api_filepath(path):
    """"""
    Split an API file path into directory and name.
    """"""
    parts = path.rsplit('/', 1)
    if len(parts) == 1:
        name = parts[0]
        dirname = '/'
    else:
        name = parts[1]
        dirname = parts[0] + '/'

    return from_api_dirname(dirname), name",Split an API file path into directory and name.,
"def writes_base64(nb, version=NBFORMAT_VERSION):
    """"""
    Write a notebook as base64.
    """"""
    return b64encode(writes(nb, version=version).encode('utf-8'))",Write a notebook as base64.,
"def reads_base64(nb, as_version=NBFORMAT_VERSION):
    """"""
    Read a notebook from base64.
    """"""
    try:
        return reads(b64decode(nb).decode('utf-8'), as_version=as_version)
    except Exception as e:
        raise CorruptedFile(e)",Read a notebook from base64.,
"def _decode_unknown_from_base64(path, bcontent):
    """"""
    Decode base64 data of unknown format.

    Attempts to interpret data as utf-8, falling back to ascii on failure.
    """"""
    content = b64decode(bcontent)
    try:
        return (content.decode('utf-8'), 'text')
    except UnicodeError:
        pass
    return bcontent.decode('ascii'), 'base64'","Decode base64 data of unknown format.

    Attempts to interpret data as utf-8, falling back to ascii on failure.",
"def prefix_dirs(path):
    """"""
    Return an iterable of all prefix directories of path, descending from root.
    """"""
    _dirname = posixpath.dirname
    path = path.strip('/')
    out = []
    while path != '':
        path = _dirname(path)
        out.append(path)
    return reversed(out)","Return an iterable of all prefix directories of path, descending from root.",
"def outside_root_to_404(fn):
    """"""
    Decorator for converting PathOutsideRoot errors to 404s.
    """"""
    @wraps(fn)
    def wrapped(*args, **kwargs):
        try:
            return fn(*args, **kwargs)
        except PathOutsideRoot as e:
            raise HTTPError(404, ""Path outside root: [%s]"" % e.args[0])
    return wrapped",Decorator for converting PathOutsideRoot errors to 404s.,
"def create_user(db_url, user):
    """"""
    Create a user.
    """"""
    PostgresCheckpoints(
        db_url=db_url,
        user_id=user,
        create_user_on_startup=True,
    )",Create a user.,
"def _separate_dirs_files(models):
    """"""
    Split an iterable of models into a list of file paths and a list of
    directory paths.
    """"""
    dirs = []
    files = []
    for model in models:
        if model['type'] == 'directory':
            dirs.append(model['path'])
        else:
            files.append(model['path'])
    return dirs, files","Split an iterable of models into a list of file paths and a list of
    directory paths.",
"def walk_files(mgr):
    """"""
    Iterate over all files visible to ``mgr``.
    """"""
    for dir_, subdirs, files in walk_files(mgr):
        for file_ in files:
            yield file_",Iterate over all files visible to ``mgr``.,
"def walk_files_with_content(mgr):
    """"""
    Iterate over the contents of all files visible to ``mgr``.
    """"""
    for _, _, files in walk(mgr):
        for f in files:
            yield mgr.get(f, content=True)",Iterate over the contents of all files visible to ``mgr``.,
"def unencrypt_single_user(engine, user_id, old_crypto, logger):
    """"""
    Unencrypt all files and checkpoints for a single user.
    """"""
    reencrypt_user_content(
        engine=engine,
        user_id=user_id,
        old_decrypt_func=old_crypto.decrypt,
        new_encrypt_func=lambda s: s,
        logger=logger,
    )",Unencrypt all files and checkpoints for a single user.,
"def upgrade(db_url, revision):
    """"""
    Upgrade the given database to revision.
    """"""
    with temp_alembic_ini(ALEMBIC_DIR_LOCATION, db_url) as alembic_ini:
        subprocess.check_call(
            ['alembic', '-c', alembic_ini, 'upgrade', revision]
        )",Upgrade the given database to revision.,
"def queue_instance(self, embed_type, data):
        """"""Queue an instance to be fetched from the database.""""""

        serializer = self.serializers.get(embed_type, None)

        if serializer is None:
            return

        instance_id = serializer.get_id(data)

        if embed_type not in self.ids:
            self.ids[embed_type] = []

        self.ids[embed_type].append(instance_id)",Queue an instance to be fetched from the database.,
"def load_instances(self, embed_type, ids):
        """"""Fetch all queued instances of type `embed_type`, save results
        to `self.instances`""""""

        serializer = self.serializers.get(embed_type, None)

        if serializer is None:
            return

        self.instances[embed_type] = serializer.fetch(ids)","Fetch all queued instances of type `embed_type`, save results
        to `self.instances`",
"def load_data(self):
        """"""Load data in bulk for each embed block.""""""

        for embed_type in self.ids.keys():
            self.load_instances(embed_type, self.ids[embed_type])",Load data in bulk for each embed block.,
"def admin(request):
    """"""Render HTML entry point for manager app.""""""
    context = {
        'api_url': settings.API_URL,
        'app_js_bundle': 'manager-%s.js' % dispatch.__version__,
        'app_css_bundle': 'manager-%s.css' % dispatch.__version__
    }
    
    return render_to_response('manager/index.html', context)",Render HTML entry point for manager app.,
"def to_json(self):
        """"""Return JSON representation for this template""""""
        result = {}

        for field in self.fields:
            result[field.name] = field.to_json(self.data.get(field.name))

        return result",Return JSON representation for this template,
"def hide_authenticated_fields(self):
        """"""Hides authenticated_fields if request context is missing or
        user is not authenticated""""""
        authenticated_fields = getattr(self.Meta, 'authenticated_fields', [])

        if not self.is_authenticated():
            for field in authenticated_fields:
                self.fields.pop(field)","Hides authenticated_fields if request context is missing or
        user is not authenticated",
"def get_attribute(self, instance):
        """"""Overrides the default get_attribute method to convert None values to False.""""""

        attr = super(NullBooleanField, self).get_attribute(instance)
        return True if attr else False",Overrides the default get_attribute method to convert None values to False.,
"def validate_zone(zone):
    """"""Checks that the given zone contains the required fields""""""

    if not has_valid_id(zone):
        raise InvalidZone(""%s must contain a valid 'id' attribute"" % zone.__name__)

    if not has_valid_name(zone):
        raise InvalidZone(""%s must contain a valid 'name' attribute"" % zone.__name__)",Checks that the given zone contains the required fields,
"def is_valid_uuid(id):
    """"""Return True if id is a valid UUID, False otherwise.""""""
    if not isinstance(id, basestring):
        return False

    try:
        val = UUID(id, version=4)
    except ValueError:
        return False

    return True","Return True if id is a valid UUID, False otherwise.",
"def get_permissions(self):
        """"""Returns the user's permissions.""""""

        permissions = ''
        if self.groups.filter(name='Admin').exists() or self.is_superuser:
            permissions = 'admin'

        return permissions",Returns the user's permissions.,
"def modify_permissions(self, permissions):
        """"""Modify the user's permissions.""""""

        group = Group.objects.get(name='Admin')

        if permissions == 'admin':
            self.groups.add(group)
        else:
            self.groups.remove(group)",Modify the user's permissions.,
"def get_data(self):
        """"""Returns data from each field.""""""
        result = {}

        for field in self.fields:
            result[field.name] = self.data.get(field.name)

        return result",Returns data from each field.,
"def prepare_data(self):
        """"""Prepare widget data for template.""""""
        result = {}

        for field in self.fields:
            data = self.data.get(field.name)
            result[field.name] = field.prepare_data(data)

        return result",Prepare widget data for template.,
"def content_to_json(content):
    """"""Returns article/page content as JSON""""""

    def render_node(node):
        """"""Renders node as JSON""""""

        if node['type'] == 'paragraph':
            return node
        else:
            return {
                'type': node['type'],
                'data': embeds.to_json(node['type'], node['data'])
            }

    return map(render_node, content)",Returns article/page content as JSON,
"def get_settings(cls, show_hidden=False):
        """"""
        Retrieves the settings for this integration as a dictionary.

        Removes all hidden fields if show_hidden=False
        """"""
        settings = Integration.objects.get_settings(cls.ID)

        if not show_hidden:
            for field in cls.HIDDEN_FIELDS:
                settings.pop(field, None)

        return settings","Retrieves the settings for this integration as a dictionary.

        Removes all hidden fields if show_hidden=False",
"def get_settings(self, integration_id):
        """"""Return settings for given integration as a dictionary.""""""

        try:
            integration = self.get(integration_id=integration_id)
            return json.loads(integration.settings)
        except (self.model.DoesNotExist, ValueError):
            return {}",Return settings for given integration as a dictionary.,
"def maptag(tagname, contents):
    """"""Returns the HTML produced from enclosing each item in
    `contents` in a tag of type `tagname`""""""
    return u''.join(tag(tagname, item) for item in contents)","Returns the HTML produced from enclosing each item in
    `contents` in a tag of type `tagname`",
"def zone(zone_id, **kwargs):
    """"""Renders the contents of the zone with given zone_id.""""""

    try:
        zone = ThemeManager.Zones.get(zone_id)
    except ZoneNotFound:
        return ''

    try:
        return zone.widget.render(add_context=kwargs)
    except (WidgetNotFound, AttributeError):
        pass

    return ''",Renders the contents of the zone with given zone_id.,
"def save_subsection(self, subsection_id):
        """""" Save the subsection to the parent article """"""
        Article.objects.filter(parent_id=self.parent.id).update(subsection_id=subsection_id)",Save the subsection to the parent article,
"def get_extension(self):
        """"""Returns the file extension.""""""
        ext = os.path.splitext(self.img.name)[1]
        if ext:
            # Remove period from extension
            return ext[1:]
        return ext",Returns the file extension.,
"def get_medium_url(self):
        """"""Returns the medium size image URL.""""""
        if self.is_gif():
            return self.get_absolute_url()
        return '%s%s-%s.jpg' % (settings.MEDIA_URL, self.get_name(), 'medium')",Returns the medium size image URL.,
"def connection(self):
        """"""Attempts to connect to the MySQL server.

        :return: Bound MySQL connection object if successful or ``None`` if
            unsuccessful.
        """"""

        ctx = _app_ctx_stack.top
        if ctx is not None:
            if not hasattr(ctx, 'mysql_db'):
                ctx.mysql_db = self.connect
            return ctx.mysql_db","Attempts to connect to the MySQL server.

        :return: Bound MySQL connection object if successful or ``None`` if
            unsuccessful.",
"def decrement(self):
        """"""Decrement the count by one""""""
        with self._lock:
            if self._count == 0:
                raise RuntimeError(
                    'Counter is at zero. It cannot dip below zero')
            self._count -= 1
            if self._is_finalized and self._count == 0:
                self._callback()",Decrement the count by one,
"def finalize(self):
        """"""Finalize the counter

        Once finalized, the counter never be incremented and the callback
        can be invoked once the count reaches zero
        """"""
        with self._lock:
            self._is_finalized = True
            if self._count == 0:
                self._callback()","Finalize the counter

        Once finalized, the counter never be incremented and the callback
        can be invoked once the count reaches zero",
"def _main(self, fileobj, data, offset):
        """"""Pulls off an io queue to write contents to a file

        :param fileobj: The file handle to write content to
        :param data: The data to write
        :param offset: The offset to write the data to.
        """"""
        fileobj.seek(offset)
        fileobj.write(data)","Pulls off an io queue to write contents to a file

        :param fileobj: The file handle to write content to
        :param data: The data to write
        :param offset: The offset to write the data to.",
"def set_exception(self, exception):
        """"""Sets the exception on the future.""""""
        if not self.done():
            raise TransferNotDoneError(
                'set_exception can only be called once the transfer is '
                'complete.')
        self._coordinator.set_exception(exception, override=True)",Sets the exception on the future.,
"def add_done_callback(self, function, *args, **kwargs):
        """"""Add a done callback to be invoked when transfer is done""""""
        with self._done_callbacks_lock:
            self._done_callbacks.append(
                FunctionContainer(function, *args, **kwargs)
            )",Add a done callback to be invoked when transfer is done,
"def add_failure_cleanup(self, function, *args, **kwargs):
        """"""Adds a callback to call upon failure""""""
        with self._failure_cleanups_lock:
            self._failure_cleanups.append(
                FunctionContainer(function, *args, **kwargs))",Adds a callback to call upon failure,
"def iter_steps(self):
        """"""Iterate over steps in the parsed file.""""""
        for func, decorator in self._iter_step_func_decorators():
            step = self._step_decorator_args(decorator)
            if step:
                span = self._span_from_pos(decorator.start_pos, func.end_pos)
                yield step, func.name.value, span",Iterate over steps in the parsed file.,
"def _iter_step_func_decorators(self):
        """"""Find functions with step decorator in parsed file.""""""  
        for node in self.py_tree.find_all('def'):
            for decorator in node.decorators:
                if decorator.name.value == 'step':
                    yield node, decorator
                    break",Find functions with step decorator in parsed file.,
"def iter_steps(self):
        """"""Iterate over steps in the parsed file.""""""
        for func, decorator in self._iter_step_func_decorators():
            step = self._step_decorator_args(decorator)
            if step:
                yield step, func.name, self._span_for_node(func, True)",Iterate over steps in the parsed file.,
"def get_catfact():
    """"""Get a cat fact from catfact.ninja and return it as a string.

    Functions for Soundhound, Google, IBM Watson, or other APIs can be added
    to create the desired functionality into this bot.

    """"""
    response = requests.get(CAT_FACTS_URL, verify=False)
    response.raise_for_status()
    json_data = response.json()
    return json_data['fact']","Get a cat fact from catfact.ninja and return it as a string.

    Functions for Soundhound, Google, IBM Watson, or other APIs can be added
    to create the desired functionality into this bot.",
"def is_web_url(string):
    """"""Check to see if string is an validly-formatted web url.""""""
    assert isinstance(string, basestring)
    parsed_url = urllib.parse.urlparse(string)
    return (
        (
            parsed_url.scheme.lower() == 'http'
            or parsed_url.scheme.lower() == 'https'
        )
        and parsed_url.netloc
    )",Check to see if string is an validly-formatted web url.,
"def strptime(cls, date_string, format=WEBEX_TEAMS_DATETIME_FORMAT):
        """"""strptime with the Webex Teams DateTime format as the default.""""""
        return super(WebexTeamsDateTime, cls).strptime(
            date_string, format
        ).replace(tzinfo=ZuluTimeZone())",strptime with the Webex Teams DateTime format as the default.,
"def created(self):
        """"""Creation date and time in ISO8601 format.""""""
        created = self._json_data.get('created')
        if created:
            return WebexTeamsDateTime.strptime(created)
        else:
            return None",Creation date and time in ISO8601 format.,
"def single_request_timeout(self, value):
        """"""The timeout (seconds) for a single HTTP REST API request.""""""
        check_type(value, int)
        assert value is None or value > 0
        self._single_request_timeout = value",The timeout (seconds) for a single HTTP REST API request.,
"def wait_on_rate_limit(self, value):
        """"""Enable or disable automatic rate-limit handling.""""""
        check_type(value, bool, may_be_none=False)
        self._wait_on_rate_limit = value",Enable or disable automatic rate-limit handling.,
"def me(self):
        """"""Get the details of the person accessing the API.

        Raises:
            ApiError: If the Webex Teams cloud returns an error.

        """"""
        # API request
        json_data = self._session.get(API_ENDPOINT + '/me')

        # Return a person object created from the response JSON data
        return self._object_factory(OBJECT_TYPE, json_data)","Get the details of the person accessing the API.

        Raises:
            ApiError: If the Webex Teams cloud returns an error.",
"def lastActivity(self):
        """"""The date and time of the person's last activity.""""""
        last_activity = self._json_data.get('lastActivity')
        if last_activity:
            return WebexTeamsDateTime.strptime(last_activity)
        else:
            return None",The date and time of the person's last activity.,
"def delete_webhooks_with_name(api, name):
    """"""Find a webhook by name.""""""
    for webhook in api.webhooks.list():
        if webhook.name == name:
            print(""Deleting Webhook:"", webhook.name, webhook.targetUrl)
            api.webhooks.delete(webhook.id)",Find a webhook by name.,
"def main():
    """"""Delete previous webhooks. If local ngrok tunnel, create a webhook.""""""
    api = WebexTeamsAPI()
    delete_webhooks_with_name(api, name=WEBHOOK_NAME)
    public_url = get_ngrok_public_url()
    if public_url is not None:
        create_ngrok_webhook(api, public_url)","Delete previous webhooks. If local ngrok tunnel, create a webhook.",
"def read(self):
		""""""
		Since there isn't a real sensor connected, read() creates random
		data.
		""""""
		data = [0]*6
		for i in range(6):
			data[i] = random.uniform(-2048, 2048)
		accel = data[:3]
		mag = data[3:]
		return (accel, mag)","Since there isn't a real sensor connected, read() creates random
		data.",
"def create_dsmr_reader(port, dsmr_version, telegram_callback, loop=None):
    """"""Creates a DSMR asyncio protocol coroutine using serial port.""""""
    protocol, serial_settings = create_dsmr_protocol(
        dsmr_version, telegram_callback, loop=None)
    serial_settings['url'] = port

    conn = create_serial_connection(loop, protocol, **serial_settings)
    return conn",Creates a DSMR asyncio protocol coroutine using serial port.,
"def create_tcp_dsmr_reader(host, port, dsmr_version,
                           telegram_callback, loop=None):
    """"""Creates a DSMR asyncio protocol coroutine using TCP connection.""""""
    protocol, _ = create_dsmr_protocol(
        dsmr_version, telegram_callback, loop=None)
    conn = loop.create_connection(protocol, host, port)
    return conn",Creates a DSMR asyncio protocol coroutine using TCP connection.,
"def data_received(self, data):
        """"""Add incoming data to buffer.""""""
        data = data.decode('ascii')
        self.log.debug('received data: %s', data)
        self.telegram_buffer.append(data)

        for telegram in self.telegram_buffer.get_all():
            self.handle_telegram(telegram)",Add incoming data to buffer.,
"def connection_lost(self, exc):
        """"""Stop when connection is lost.""""""
        if exc:
            self.log.exception('disconnected due to exception')
        else:
            self.log.info('disconnected because of close/abort.')
        self._closed.set()",Stop when connection is lost.,
"def get_version(file, name='__version__'):
    """"""Get the version of the package from the given file by
    executing it and extracting the given `name`.
    """"""
    path = os.path.realpath(file)
    version_ns = {}
    with io.open(path, encoding=""utf8"") as f:
        exec(f.read(), {}, version_ns)
    return version_ns[name]","Get the version of the package from the given file by
    executing it and extracting the given `name`.",
"def command_for_func(func):
    """"""Create a command that calls the given function.""""""

    class FuncCommand(BaseCommand):

        def run(self):
            func()
            update_package_data(self.distribution)

    return FuncCommand",Create a command that calls the given function.,
"def run(cmd, **kwargs):
    """"""Echo a command before running it.  Defaults to repo as cwd""""""
    log.info('> ' + list2cmdline(cmd))
    kwargs.setdefault('cwd', HERE)
    kwargs.setdefault('shell', os.name == 'nt')
    if not isinstance(cmd, (list, tuple)) and os.name != 'nt':
        cmd = shlex.split(cmd)
    cmd[0] = which(cmd[0])
    return subprocess.check_call(cmd, **kwargs)",Echo a command before running it.  Defaults to repo as cwd,
"def _iexplode_path(path):
    """"""Iterate over all the parts of a path.

    Splits path recursively with os.path.split().
    """"""
    (head, tail) = os.path.split(path)
    if not head or (not tail and head == path):
        if head:
            yield head
        if tail or not head:
            yield tail
        return
    for p in _iexplode_path(head):
        yield p
    yield tail","Iterate over all the parts of a path.

    Splits path recursively with os.path.split().",
"def _translate_glob(pat):
    """"""Translate a glob PATTERN to a regular expression.""""""
    translated_parts = []
    for part in _iexplode_path(pat):
        translated_parts.append(_translate_glob_part(part))
    os_sep_class = '[%s]' % re.escape(SEPARATORS)
    res = _join_translated(translated_parts, os_sep_class)
    return '{res}\\Z(?ms)'.format(res=res)",Translate a glob PATTERN to a regular expression.,
"def write_indexes(self, table):
        """"""Write DDL of `table` indexes to the output file

        :Parameters:
          - `table`: an instance of a :py:class:`mysql2pgsql.lib.mysql_reader.MysqlReader.Table` object that represents the table to read/write.

        Returns None
        """"""
        self.f.write('\n'.join(super(PostgresFileWriter, self).write_indexes(table)))","Write DDL of `table` indexes to the output file

        :Parameters:
          - `table`: an instance of a :py:class:`mysql2pgsql.lib.mysql_reader.MysqlReader.Table` object that represents the table to read/write.

        Returns None",
"def write_constraints(self, table):
        """"""Write DDL of `table` constraints to the output file

        :Parameters:
          - `table`: an instance of a :py:class:`mysql2pgsql.lib.mysql_reader.MysqlReader.Table` object that represents the table to read/write.

        Returns None
        """"""
        self.f.write('\n'.join(super(PostgresFileWriter, self).write_constraints(table)))","Write DDL of `table` constraints to the output file

        :Parameters:
          - `table`: an instance of a :py:class:`mysql2pgsql.lib.mysql_reader.MysqlReader.Table` object that represents the table to read/write.

        Returns None",
"def write_triggers(self, table):
        """"""Write TRIGGERs existing on `table` to the output file

        :Parameters:
          - `table`: an instance of a :py:class:`mysql2pgsql.lib.mysql_reader.MysqlReader.Table` object that represents the table to read/write.

        Returns None
        """"""
        self.f.write('\n'.join(super(PostgresFileWriter, self).write_triggers(table)))","Write TRIGGERs existing on `table` to the output file

        :Parameters:
          - `table`: an instance of a :py:class:`mysql2pgsql.lib.mysql_reader.MysqlReader.Table` object that represents the table to read/write.

        Returns None",
"def qsize(self, extra_predicate=None):
        """""" Return an approximate number of queued tasks in the queue. """"""
        count = self._query_queued('COUNT(*) AS count', extra_predicate=extra_predicate)
        return count[0].count",Return an approximate number of queued tasks in the queue.,
"def enqueue(self, data):
        """""" Enqueue task with specified data. """"""
        jsonified_data = json.dumps(data)
        with self._db_conn() as conn:
            return conn.execute(
                'INSERT INTO %s (created, data) VALUES (%%(created)s, %%(data)s)' % self.table_name,
                created=datetime.utcnow(),
                data=jsonified_data
            )",Enqueue task with specified data.,
"def simplejson_datetime_serializer(obj):
    """"""
    Designed to be passed as the default kwarg in simplejson.dumps.  Serializes dates and datetimes to ISO strings.
    """"""
    if hasattr(obj, 'isoformat'):
        return obj.isoformat()
    else:
        raise TypeError('Object of type %s with value of %s is not JSON serializable' % (type(obj), repr(obj)))",Designed to be passed as the default kwarg in simplejson.dumps.  Serializes dates and datetimes to ISO strings.,
"def reconnect(self):
        """"""Closes the existing database connection and re-opens it.""""""
        conn = _mysql.connect(**self._db_args)
        if conn is not None:
            self.close()
            self._db = conn",Closes the existing database connection and re-opens it.,
"def query(self, query, *parameters, **kwparameters):
        """"""
        Query the connection and return the rows (or affected rows if not a
        select query).  Mysql errors will be propogated as exceptions.
        """"""
        return self._query(query, parameters, kwparameters)","Query the connection and return the rows (or affected rows if not a
        select query).  Mysql errors will be propogated as exceptions.",
"def execute(self, query, *parameters, **kwparameters):
        """"""Executes the given query, returning the lastrowid from the query.""""""
        return self.execute_lastrowid(query, *parameters, **kwparameters)","Executes the given query, returning the lastrowid from the query.",
"def execute_lastrowid(self, query, *parameters, **kwparameters):
        """"""Executes the given query, returning the lastrowid from the query.""""""
        self._execute(query, parameters, kwparameters)
        self._result = self._db.store_result()
        return self._db.insert_id()","Executes the given query, returning the lastrowid from the query.",
"def get_connection(db=DATABASE):
    """""" Returns a new connection to the database. """"""
    return database.connect(host=HOST, port=PORT, user=USER, password=PASSWORD, database=db)",Returns a new connection to the database.,
"def _pool_connect(self, agg):
        """""" `agg` should be (host, port)
            Returns a live connection from the connection pool
        """"""
        return self._pool.connect(agg[0], agg[1], self._user, self._password, self._database)","`agg` should be (host, port)
            Returns a live connection from the connection pool",
"def lookup_by_number(errno):
    """""" Used for development only """"""
    for key, val in globals().items():
        if errno == val:
            print(key)",Used for development only,
"def size(self):
        """""" Returns the number of connections cached by the pool. """"""
        return sum(q.qsize() for q in self._connections.values()) + len(self._fairies)",Returns the number of connections cached by the pool.,
"def update(table_name, **fields):
    """""" Build a update query.

    >>> update('foo_table', a=5, b=2)
    ""UPDATE `foo_table` SET `a`=%(_QB_a)s, `b`=%(_QB_b)s"", { '_QB_a': 5, '_QB_b': 2 }
    """"""
    prefix = ""UPDATE `%s` SET "" % table_name
    sets, params = simple_expression(', ', **fields)
    return prefix + sets, params","Build a update query.

    >>> update('foo_table', a=5, b=2)
    ""UPDATE `foo_table` SET `a`=%(_QB_a)s, `b`=%(_QB_b)s"", { '_QB_a': 5, '_QB_b': 2 }",
"def setup(self):
        """""" Initialize the required tables in the database """"""
        with self._db_conn() as conn:
            for table_defn in self._tables.values():
                conn.execute(table_defn)
        return self",Initialize the required tables in the database,
"def destroy(self):
        """""" Destroy the SQLStepQueue tables in the database """"""
        with self._db_conn() as conn:
            for table_name in self._tables:
                conn.execute('DROP TABLE IF EXISTS %s' % table_name)
        return self",Destroy the SQLStepQueue tables in the database,
"def _load_steps(self, raw_steps):
        """""" load steps -> basically load all the datetime isoformats into datetimes """"""
        for step in raw_steps:
            if 'start' in step:
                step['start'] = parser.parse(step['start'])
            if 'stop' in step:
                step['stop'] = parser.parse(step['stop'])
        return raw_steps",load steps -> basically load all the datetime isoformats into datetimes,
"def disconnect(self):
        """"""Disconnects from the websocket connection and joins the Thread.

        :return:
        """"""
        self.log.debug(""disconnect(): Disconnecting from API.."")
        self.reconnect_required.clear()
        self.disconnect_called.set()
        if self.socket:
            self.socket.close()
        self.join(timeout=1)","Disconnects from the websocket connection and joins the Thread.

        :return:",
"def reconnect(self):
        """"""Issues a reconnection by setting the reconnect_required event.

        :return:
        """"""
        # Reconnect attempt at self.reconnect_interval
        self.log.debug(""reconnect(): Initialzion reconnect sequence.."")
        self.connected.clear()
        self.reconnect_required.set()
        if self.socket:
            self.socket.close()","Issues a reconnection by setting the reconnect_required event.

        :return:",
"def _stop_timers(self):
        """"""Stops ping, pong and connection timers.

        :return:
        """"""
        if self.ping_timer:
            self.ping_timer.cancel()

        if self.connection_timer:
            self.connection_timer.cancel()

        if self.pong_timer:
            self.pong_timer.cancel()
        self.log.debug(""_stop_timers(): Timers stopped."")","Stops ping, pong and connection timers.

        :return:",
"def send_ping(self):
        """"""Sends a ping message to the API and starts pong timers.

        :return:
        """"""
        self.log.debug(""send_ping(): Sending ping to API.."")
        self.socket.send(json.dumps({'event': 'ping'}))
        self.pong_timer = Timer(self.pong_timeout, self._check_pong)
        self.pong_timer.start()","Sends a ping message to the API and starts pong timers.

        :return:",
"def pass_to_client(self, event, data, *args):
        """"""Passes data up to the client via a Queue().

        :param event:
        :param data:
        :param args:
        :return:
        """"""
        self.q.put((event, data, *args))","Passes data up to the client via a Queue().

        :param event:
        :param data:
        :param args:
        :return:",
"def _unpause(self):
        """"""Unpauses the connection.

        Send a message up to client that he should re-subscribe to all
        channels.

        :return:
        """"""
        self.log.debug(""_unpause(): Clearing paused() Flag!"")
        self.paused.clear()
        self.log.debug(""_unpause(): Re-subscribing softly.."")
        self._resubscribe(soft=True)","Unpauses the connection.

        Send a message up to client that he should re-subscribe to all
        channels.

        :return:",
"def _response_handler(self, event, data, ts):
        """"""Handles responses to (un)subscribe and conf commands.

        Passes data up to client.

        :param data:
        :param ts:
        :return:
        """"""
        self.log.debug(""_response_handler(): Passing %s to client.."", data)
        self.pass_to_client(event, data, ts)","Handles responses to (un)subscribe and conf commands.

        Passes data up to client.

        :param data:
        :param ts:
        :return:",
"def _data_handler(self, data, ts):
        """"""Handles data messages by passing them up to the client.

        :param data:
        :param ts:
        :return:
        """"""
        # Pass the data up to the Client
        self.log.debug(""_data_handler(): Passing %s to client.."",
                  data)
        self.pass_to_client('data', data, ts)","Handles data messages by passing them up to the client.

        :param data:
        :param ts:
        :return:",
"def join(self, timeout=None):
        """"""Set sentinel for run() method and join thread.

        :param timeout:
        :return:
        """"""
        self._stopped.set()
        super(QueueProcessor, self).join(timeout=timeout)","Set sentinel for run() method and join thread.

        :param timeout:
        :return:",
"def _handle_conf(self, dtype, data, ts):
        """"""Handles configuration messages.

        :param dtype:
        :param data:
        :param ts:
        :return:
        """"""
        self.log.debug(""_handle_conf: %s - %s - %s"", dtype, data, ts)
        self.log.info(""Configuration accepted: %s"", dtype)
        return","Handles configuration messages.

        :param dtype:
        :param data:
        :param ts:
        :return:",
"def reset(self):
        """"""Reset the client.

        :return:
        """"""
        self.conn.reconnect()
        while not self.conn.connected.is_set():
            log.info(""reset(): Waiting for connection to be set up.."")
            time.sleep(1)

        for key in self.channel_configs:
            self.conn.send(**self.channel_configs[key])","Reset the client.

        :return:",
"def candles(self, pair, timeframe=None):
        """"""Return a queue containing all received candles data.

        :param pair: str, Symbol pair to request data for
        :param timeframe: str
        :return: Queue()
        """"""
        timeframe = '1m' if not timeframe else timeframe
        key = ('candles', pair, timeframe)
        return self.queue_processor.candles[key]","Return a queue containing all received candles data.

        :param pair: str, Symbol pair to request data for
        :param timeframe: str
        :return: Queue()",
"def subscribe_to_ticker(self, pair, **kwargs):
        """"""Subscribe to the passed pair's ticker channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:
        """"""
        identifier = ('ticker', pair)
        self._subscribe('ticker', identifier, symbol=pair, **kwargs)","Subscribe to the passed pair's ticker channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:",
"def unsubscribe_from_ticker(self, pair, **kwargs):
        """"""Unsubscribe to the passed pair's ticker channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:
        """"""
        identifier = ('ticker', pair)
        self._unsubscribe('ticker', identifier, symbol=pair, **kwargs)","Unsubscribe to the passed pair's ticker channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:",
"def subscribe_to_order_book(self, pair, **kwargs):
        """"""Subscribe to the passed pair's order book channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:
        """"""
        identifier = ('book', pair)
        self._subscribe('book', identifier, symbol=pair, **kwargs)","Subscribe to the passed pair's order book channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:",
"def unsubscribe_from_order_book(self, pair, **kwargs):
        """"""Unsubscribe to the passed pair's order book channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:
        """"""
        identifier = ('book', pair)
        self._unsubscribe('book', identifier, symbol=pair, **kwargs)","Unsubscribe to the passed pair's order book channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:",
"def subscribe_to_trades(self, pair, **kwargs):
        """"""Subscribe to the passed pair's trades channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:
        """"""
        identifier = ('trades', pair)
        self._subscribe('trades', identifier, symbol=pair, **kwargs)","Subscribe to the passed pair's trades channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:",
"def unsubscribe_from_trades(self, pair, **kwargs):
        """"""Unsubscribe to the passed pair's trades channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:
        """"""
        identifier = ('trades', pair)
        self._unsubscribe('trades', identifier, symbol=pair, **kwargs)","Unsubscribe to the passed pair's trades channel.

        :param pair: str, Symbol pair to request data for
        :param kwargs:
        :return:",
"def authenticate(self):
        """"""Authenticate with the Bitfinex API.

        :return:
        """"""
        if not self.key and not self.secret:
            raise ValueError(""Must supply both key and secret key for API!"")
        self.channel_configs['auth'] = {'api_key': self.key, 'secret': self.secret}
        self.conn.send(api_key=self.key, secret=self.secret, auth=True)","Authenticate with the Bitfinex API.

        :return:",
"def create(self, deviceType):
        """"""
        Register one or more new device types, each request can contain a maximum of 512KB.
        """"""

        r = self._apiClient.post(""api/v0002/device/types"", deviceType)

        if r.status_code == 201:
            return DeviceType(apiClient=self._apiClient, **r.json())
        else:
            raise ApiException(r)","Register one or more new device types, each request can contain a maximum of 512KB.",
"def serviceStatus(self):
        """"""
        Retrieve the organization-specific status of each of the services offered by the IBM Watson IoT Platform.
        In case of failure it throws APIException
        """"""

        r = self._apiClient.get(""api/v0002/service-status"")

        if r.status_code == 200:
            return ServiceStatus(**r.json())
        else:
            raise ApiException(r)","Retrieve the organization-specific status of each of the services offered by the IBM Watson IoT Platform.
        In case of failure it throws APIException",
"def find(self, status=None, connectedAfter=None):
        """"""
        Iterate through all Connectors
        """"""
        queryParms = {}
        if status:
            queryParms[""status""] = status
        if connectedAfter:
            queryParms[""connectedAfter""] = connectedAfter

        return IterableClientStatusList(self._apiClient, filters=queryParms)",Iterate through all Connectors,
"def list(self):
        """"""
        List all device management extension packages
        """"""
        url = ""api/v0002/mgmt/custom/bundle""
        r = self._apiClient.get(url)

        if r.status_code == 200:
            return r.json()
        else:
            raise ApiException(r)",List all device management extension packages,
"def create(self, dmeData):
        """"""
        Create a new device management extension package
        In case of failure it throws APIException
        """"""
        url = ""api/v0002/mgmt/custom/bundle""
        r = self._apiClient.post(url, dmeData)

        if r.status_code == 201:
            return r.json()
        else:
            raise ApiException(r)","Create a new device management extension package
        In case of failure it throws APIException",
"def _makeApiCall(self, parameters=None):
        """"""
        Retrieve bulk devices
        It accepts accepts a list of parameters
        In case of failure it throws Exception
        """"""
        r = self._apiClient.get(self._url, parameters)
        if r.status_code == 200:
            return r.json()
        else:
            raise Exception(""HTTP %s %s"" % (r.status_code, r.text))","Retrieve bulk devices
        It accepts accepts a list of parameters
        In case of failure it throws Exception",
"def initiate(self, request):
        """"""
        Initiates a device management request, such as reboot.
        In case of failure it throws APIException
        """"""
        url = MgmtRequests.mgmtRequests
        r = self._apiClient.post(url, request)

        if r.status_code == 202:
            return r.json()
        else:
            raise ApiException(r)","Initiates a device management request, such as reboot.
        In case of failure it throws APIException",
"def close(self):
        """"""Force a flush of the index to storage. Renders index
        inaccessible.""""""
        if self.handle:
            self.handle.destroy()
            self.handle = None
        else:
            raise IOError(""Unclosable index"")","Force a flush of the index to storage. Renders index
        inaccessible.",
"def destroy(self, context, returnError):
        """"""please override""""""
        returnError.contents.value = self.IllegalStateError
        raise NotImplementedError(""You must override this method."")",please override,
"def loadByteArray(self, context, page, resultLen, resultData, returnError):
        """"""please override""""""
        returnError.contents.value = self.IllegalStateError
        raise NotImplementedError(""You must override this method."")",please override,
"def storeByteArray(self, context, page, len, data, returnError):
        """"""please override""""""
        returnError.contents.value = self.IllegalStateError
        raise NotImplementedError(""You must override this method."")",please override,
"def deleteByteArray(self, context, page, returnError):
        """"""please override""""""
        returnError.contents.value = self.IllegalStateError
        raise NotImplementedError(""You must override this method."")",please override,
"def flush(self, context, returnError):
        """"""please override""""""
        returnError.contents.value = self.IllegalStateError
        raise NotImplementedError(""You must override this method."")",please override,
"def loadByteArray(self, page, returnError):
        """"""Must be overridden. Must return a string with the loaded data.""""""
        returnError.contents.value = self.IllegalStateError
        raise NotImplementedError(""You must override this method."")
        return ''",Must be overridden. Must return a string with the loaded data.,
"def check_return(result, func, cargs):
    ""Error checking for Error calls""
    if result != 0:
        s = rt.Error_GetLastErrorMsg().decode()
        msg = 'LASError in ""%s"": %s' % \
            (func.__name__, s)
        rt.Error_Reset()
        raise RTreeError(msg)
    return True",Error checking for Error calls,
"def check_void(result, func, cargs):
    ""Error checking for void* returns""
    if not bool(result):
        s = rt.Error_GetLastErrorMsg().decode()
        msg = 'Error in ""%s"": %s' % (func.__name__, s)
        rt.Error_Reset()
        raise RTreeError(msg)
    return result",Error checking for void* returns,
"def check_void_done(result, func, cargs):
    ""Error checking for void* returns that might be empty with no error""
    if rt.Error_GetErrorCount():
        s = rt.Error_GetLastErrorMsg().decode()
        msg = 'Error in ""%s"": %s' % (func.__name__, s)
        rt.Error_Reset()
        raise RTreeError(msg)
    return result",Error checking for void* returns that might be empty with no error,
"def load(self):
        """""" Attempt an import of the specified application """"""

        if isinstance(self.application, str):
            return util.import_app(self.application)
        else:
            return self.application",Attempt an import of the specified application,
"def to_native(self, value):
        """"""For djangorestframework <=2.3.14""""""
        context_request = None
        if self.context:
            context_request = self.context.get('request', None)
        return build_versatileimagefield_url_set(
            value,
            self.sizes,
            request=context_request
        )",For djangorestframework <=2.3.14,
"def process_image(self, image, image_format, save_kwargs={}):
        """"""Return a BytesIO instance of `image` with inverted colors.""""""
        imagefile = BytesIO()
        inv_image = ImageOps.invert(image)
        inv_image.save(
            imagefile,
            **save_kwargs
        )
        return imagefile",Return a BytesIO instance of `image` with inverted colors.,
"def to_python(self, data):
        """"""Ensure data is prepped properly before handing off to ImageField.""""""
        if data is not None:
            if hasattr(data, 'open'):
                data.open()
            return super(VersatileImageFormField, self).to_python(data)",Ensure data is prepped properly before handing off to ImageField.,
"def pre_save(self, model_instance, add):
        """"""Return field's value just before saving.""""""
        file = super(VersatileImageField, self).pre_save(model_instance, add)
        self.update_ppoi_field(model_instance)
        return file",Return field's value just before saving.,
"def value_to_string(self, obj):
        """"""Prepare field for serialization.""""""
        if DJANGO_VERSION > (1, 9):
            value = self.value_from_object(obj)
        else:
            value = self._get_val_from_obj(obj)
        return self.get_prep_value(value)",Prepare field for serialization.,
"def ppoi(self, value):
        """"""Primary Point of Interest (ppoi) setter.""""""
        ppoi = validate_ppoi(
            value,
            return_converted_tuple=True
        )
        if ppoi is not False:
            self._ppoi_value = ppoi
            self.build_filters_and_sizers(ppoi, self.create_on_demand)",Primary Point of Interest (ppoi) setter.,
"def get_filtered_root_folder(self):
        """"""Return the location where filtered images are stored.""""""
        folder, filename = os.path.split(self.name)
        return os.path.join(folder, VERSATILEIMAGEFIELD_FILTERED_DIRNAME, '')",Return the location where filtered images are stored.,
"def get_sized_root_folder(self):
        """"""Return the location where sized images are stored.""""""
        folder, filename = os.path.split(self.name)
        return os.path.join(VERSATILEIMAGEFIELD_SIZED_DIRNAME, folder, '')",Return the location where sized images are stored.,
"def get_filtered_sized_root_folder(self):
        """"""Return the location where filtered + sized images are stored.""""""
        sized_root_folder = self.get_sized_root_folder()
        return os.path.join(
            sized_root_folder,
            VERSATILEIMAGEFIELD_FILTERED_DIRNAME
        )",Return the location where filtered + sized images are stored.,
"def ppoi_as_str(self):
        """"""Return PPOI value as a string.""""""
        return ""%s__%s"" % (
            str(self.ppoi[0]).replace('.', '-'),
            str(self.ppoi[1]).replace('.', '-')
        )",Return PPOI value as a string.,
"def build_attrs(self, base_attrs, extra_attrs=None):
        """"""Build an attribute dictionary.""""""
        attrs = base_attrs.copy()
        if extra_attrs is not None:
            attrs.update(extra_attrs)
        return attrs",Build an attribute dictionary.,
"def get_url_from_image_key(image_instance, image_key):
    """"""Build a URL from `image_key`.""""""
    img_key_split = image_key.split('__')
    if 'x' in img_key_split[-1]:
        size_key = img_key_split.pop(-1)
    else:
        size_key = None
    img_url = reduce(getattr, img_key_split, image_instance)
    if size_key:
        img_url = img_url[size_key].url
    return img_url",Build a URL from `image_key`.,
"def close(self):
        """"""Close the connection""""""
        if self.pinger:
            self.pinger.cancel()
            self.pinger = None
        if getattr(self, 'protocol', None):
            self.protocol.close()",Close the connection,
"def _read_result(self):
        """"""Parse read a response from the AGI and parse it.

        :return dict: The AGI response parsed into a dict.
        """"""
        response = yield from self.reader.readline()
        return parse_agi_result(response.decode(self.encoding)[:-1])","Parse read a response from the AGI and parse it.

        :return dict: The AGI response parsed into a dict.",
"def reset(cls, uid=None):
        """"""Mostly used for unit testing. Allow to use a static uuid and reset
        all counter""""""
        for instance in cls.instances:
            if uid:
                instance.uid = uid
            instance.generator = instance.get_generator()","Mostly used for unit testing. Allow to use a static uuid and reset
        all counter",
"def get_instances(self):
        """"""Mostly used for debugging""""""
        return [""<%s prefix:%s (uid:%s)>"" % (self.__class__.__name__,
                                             i.prefix, self.uid)
                for i in self.instances]",Mostly used for debugging,
"def get_primary_keys(model):
    """"""Get primary key properties for a SQLAlchemy model.

    :param model: SQLAlchemy model class
    """"""
    mapper = model.__mapper__
    return [mapper.get_property_by_column(column) for column in mapper.primary_key]","Get primary key properties for a SQLAlchemy model.

    :param model: SQLAlchemy model class",
"def gc():
    """"""Deletes old stellar tables that are not used anymore""""""
    def after_delete(database):
        click.echo(""Deleted table %s"" % database)

    app = get_app()
    upgrade_from_old_version(app)
    app.delete_orphan_snapshots(after_delete)",Deletes old stellar tables that are not used anymore,
"def list():
    """"""Returns a list of snapshots""""""
    snapshots = get_app().get_snapshots()

    click.echo('\n'.join(
        '%s: %s' % (
            s.snapshot_name,
            humanize.naturaltime(datetime.utcnow() - s.created_at)
        )
        for s in snapshots
    ))",Returns a list of snapshots,
"def remove(name):
    """"""Removes a snapshot""""""
    app = get_app()

    snapshot = app.get_snapshot(name)
    if not snapshot:
        click.echo(""Couldn't find snapshot %s"" % name)
        sys.exit(1)

    click.echo(""Deleting snapshot %s"" % name)
    app.remove_snapshot(snapshot)
    click.echo(""Deleted"")",Removes a snapshot,
"def replace(name):
    """"""Replaces a snapshot""""""
    app = get_app()

    snapshot = app.get_snapshot(name)
    if not snapshot:
        click.echo(""Couldn't find snapshot %s"" % name)
        sys.exit(1)

    app.remove_snapshot(snapshot)
    app.create_snapshot(name)
    click.echo(""Replaced snapshot %s"" % name)",Replaces a snapshot,
"def on_epoch_end(self) -> None:
        'Updates indexes after each epoch for shuffling'
        self.indexes = np.arange(self.nrows)
        if self.shuffle:
            np.random.shuffle(self.indexes)",Updates indexes after each epoch for shuffling,
"def token_count_pandas(self):
        """""" See token counts as pandas dataframe""""""
        freq_df = pd.DataFrame.from_dict(self.indexer.word_counts, orient='index')
        freq_df.columns = ['count']
        return freq_df.sort_values('count', ascending=False)",See token counts as pandas dataframe,
"def _isdupitem(self, key, val, dedup_result):
        """"""Return whether (key, val) duplicates an existing item.""""""
        isdupkey, isdupval, nodeinv, nodefwd = dedup_result
        isdupitem = nodeinv is nodefwd
        if isdupitem:
            assert isdupkey
            assert isdupval
        return isdupitem","Return whether (key, val) duplicates an existing item.",
"def _make_empty(typename, keyname, valname, base_type):
    """"""Create a named bidict with the indicated arguments and return an empty instance.
    Used to make :func:`bidict.namedbidict` instances picklable.
    """"""
    cls = namedbidict(typename, keyname, valname, base_type=base_type)
    return cls()","Create a named bidict with the indicated arguments and return an empty instance.
    Used to make :func:`bidict.namedbidict` instances picklable.",
"def clear(self):
        """"""Remove all items.""""""
        self._fwdm.clear()
        self._invm.clear()
        self._sntl.nxt = self._sntl.prv = self._sntl",Remove all items.,
"def forceput(self, key, val):
        """"""
        Associate *key* with *val* unconditionally.

        Replace any existing mappings containing key *key* or value *val*
        as necessary to preserve uniqueness.
        """"""
        self._put(key, val, self._ON_DUP_OVERWRITE)","Associate *key* with *val* unconditionally.

        Replace any existing mappings containing key *key* or value *val*
        as necessary to preserve uniqueness.",
"def pop(self, key, default=_MISS):
        u""""""*x.pop(k[, d])  v*

        Remove specified key and return the corresponding value.

        :raises KeyError: if *key* is not found and no *default* is provided.
        """"""
        try:
            return self._pop(key)
        except KeyError:
            if default is _MISS:
                raise
            return default","u""""""*x.pop(k[, d])  v*

        Remove specified key and return the corresponding value.

        :raises KeyError: if *key* is not found and no *default* is provided.",
"def popitem(self):
        u""""""*x.popitem()  (k, v)*

        Remove and return some item as a (key, value) pair.

        :raises KeyError: if *x* is empty.
        """"""
        if not self:
            raise KeyError('mapping is empty')
        key, val = self._fwdm.popitem()
        del self._invm[val]
        return key, val","u""""""*x.popitem()  (k, v)*

        Remove and return some item as a (key, value) pair.

        :raises KeyError: if *x* is empty.",
"def update(self, *args, **kw):
        """"""Like :meth:`putall` with default duplication policies.""""""
        if args or kw:
            self._update(False, None, *args, **kw)",Like :meth:`putall` with default duplication policies.,
"def forceupdate(self, *args, **kw):
        """"""Like a bulk :meth:`forceput`.""""""
        self._update(False, self._ON_DUP_OVERWRITE, *args, **kw)",Like a bulk :meth:`forceput`.,
"def putall(self, items, on_dup_key=RAISE, on_dup_val=RAISE, on_dup_kv=None):
        """"""
        Like a bulk :meth:`put`.

        If one of the given items causes an exception to be raised,
        none of the items is inserted.
        """"""
        if items:
            on_dup = self._get_on_dup((on_dup_key, on_dup_val, on_dup_kv))
            self._update(False, on_dup, items)","Like a bulk :meth:`put`.

        If one of the given items causes an exception to be raised,
        none of the items is inserted.",
"def new_contact(cls, address_book, supported_private_objects, version,
            localize_dates):
        """"""Use this to create a new and empty contact.""""""
        return cls(address_book, None, supported_private_objects, version,
                localize_dates)",Use this to create a new and empty contact.,
"def from_file(cls, address_book, filename, supported_private_objects,
            localize_dates):
        """"""
        Use this if you want to create a new contact from an existing .vcf
        file.
        """"""
        return cls(address_book, filename, supported_private_objects, None,
                localize_dates)","Use this if you want to create a new contact from an existing .vcf
        file.",
"def from_user_input(cls, address_book, user_input,
                        supported_private_objects, version, localize_dates):
        """"""Use this if you want to create a new contact from user input.""""""
        contact = cls(address_book, None, supported_private_objects, version,
                localize_dates)
        contact._process_user_input(user_input)
        return contact",Use this if you want to create a new contact from user input.,
"def _get_organisations(self):
        """"""
        :returns: list of organisations, sorted alphabetically
        :rtype: list(list(str))
        """"""
        organisations = []
        for child in self.vcard.getChildren():
            if child.name == ""ORG"":
                organisations.append(child.value)
        return sorted(organisations)",":returns: list of organisations, sorted alphabetically
        :rtype: list(list(str))",
"def _get_titles(self):
        """"""
        :rtype: list(list(str))
        """"""
        titles = []
        for child in self.vcard.getChildren():
            if child.name == ""TITLE"":
                titles.append(child.value)
        return sorted(titles)",:rtype: list(list(str)),
"def _get_roles(self):
        """"""
        :rtype: list(list(str))
        """"""
        roles = []
        for child in self.vcard.getChildren():
            if child.name == ""ROLE"":
                roles.append(child.value)
        return sorted(roles)",:rtype: list(list(str)),
"def _add_category(self, categories):
        """""" categories variable must be a list """"""
        categories_obj = self.vcard.add('categories')
        categories_obj.value = helpers.convert_to_vcard(
            ""category"", categories, ObjectType.list_with_strings)",categories variable must be a list,
"def get_nicknames(self):
        """"""
        :rtype: list(list(str))
        """"""
        nicknames = []
        for child in self.vcard.getChildren():
            if child.name == ""NICKNAME"":
                nicknames.append(child.value)
        return sorted(nicknames)",:rtype: list(list(str)),
"def _get_notes(self):
        """"""
        :rtype: list(list(str))
        """"""
        notes = []
        for child in self.vcard.getChildren():
            if child.name == ""NOTE"":
                notes.append(child.value)
        return sorted(notes)",:rtype: list(list(str)),
"def _get_webpages(self):
        """"""
        :rtype: list(list(str))
        """"""
        urls = []
        for child in self.vcard.getChildren():
            if child.name == ""URL"":
                urls.append(child.value)
        return sorted(urls)",:rtype: list(list(str)),
"def get_abook(self, name):
        """"""Get one of the backing abdress books by its name,

        :param name: the name of the address book to get
        :type name: str
        :returns: the matching address book or None
        :rtype: AddressBook or NoneType

        """"""
        for abook in self._abooks:
            if abook.name == name:
                return abook","Get one of the backing abdress books by its name,

        :param name: the name of the address book to get
        :type name: str
        :returns: the matching address book or None
        :rtype: AddressBook or NoneType",
"def dump(raw_data, output_file):
    """"""
    Writes given line to given output file.
    See :func:`encode_output` for details.
    """"""
    data = encode_output(raw_data, output_file)
    output_file.write(data)","Writes given line to given output file.
    See :func:`encode_output` for details.",
"def count(self, conn, filters):
        '''
        Returns the count of the items that match the provided filters.

        For the meaning of what the ``filters`` argument means, see the
        ``.search()`` method docs.
        '''
        pipe, intersect, temp_id = self._prepare(conn, filters)
        pipe.zcard(temp_id)
        pipe.delete(temp_id)
        return pipe.execute()[-2]","Returns the count of the items that match the provided filters.

        For the meaning of what the ``filters`` argument means, see the
        ``.search()`` method docs.",
"def _connect(obj):
    '''
    Tries to get the _conn attribute from a model. Barring that, gets the
    global default connection using other methods.
    '''
    from .columns import MODELS
    if isinstance(obj, MODELS['Model']):
        obj = obj.__class__
    if hasattr(obj, '_conn'):
        return obj._conn
    if hasattr(obj, 'CONN'):
        return obj.CONN
    return get_connection()","Tries to get the _conn attribute from a model. Barring that, gets the
    global default connection using other methods.",
"def add(self, obj):
        '''
        Adds an entity to the session.
        '''
        if self.null_session:
            return
        self._init()
        pk = obj._pk
        if not pk.endswith(':None'):
            self.known[pk] = obj
            self.wknown[pk] = obj",Adds an entity to the session.,
"def forget(self, obj):
        '''
        Forgets about an entity (automatically called when an entity is
        deleted). Call this to ensure that an entity that you've modified is
        not automatically saved on ``session.commit()`` .
        '''
        self._init()
        self.known.pop(obj._pk, None)
        self.wknown.pop(obj._pk, None)","Forgets about an entity (automatically called when an entity is
        deleted). Call this to ensure that an entity that you've modified is
        not automatically saved on ``session.commit()`` .",
"def get(self, pk):
        '''
        Fetches an entity from the session based on primary key.
        '''
        self._init()
        return self.known.get(pk) or self.wknown.get(pk)",Fetches an entity from the session based on primary key.,
"def copy(self):
        '''
        Creates a shallow copy of the given entity (any entities that can be
        retrieved from a OneToMany relationship will not be copied).
        '''
        x = self.to_dict()
        x.pop(self._pkey)
        return self.__class__(**x)","Creates a shallow copy of the given entity (any entities that can be
        retrieved from a OneToMany relationship will not be copied).",
"def dump(obj, file, reducers=None, protocol=None):
    '''Replacement for pickle.dump() using _LokyPickler.'''
    global _LokyPickler
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)",Replacement for pickle.dump() using _LokyPickler.,
"def Queue(self, maxsize=0, reducers=None):
        '''Returns a queue object'''
        from .queues import Queue
        return Queue(maxsize, reducers=reducers,
                     ctx=self.get_context())",Returns a queue object,
"def SimpleQueue(self, reducers=None):
        '''Returns a queue object'''
        from .queues import SimpleQueue
        return SimpleQueue(reducers=reducers, ctx=self.get_context())",Returns a queue object,
"def _get_chunks(chunksize, *iterables):
    """"""Iterates over zip()ed iterables in chunks. """"""
    if sys.version_info < (3, 3):
        it = itertools.izip(*iterables)
    else:
        it = zip(*iterables)
    while True:
        chunk = tuple(itertools.islice(it, chunksize))
        if not chunk:
            return
        yield chunk",Iterates over zip()ed iterables in chunks.,
"def _sendback_result(result_queue, work_id, result=None, exception=None):
    """"""Safely send back the given result or exception""""""
    try:
        result_queue.put(_ResultItem(work_id, result=result,
                                     exception=exception))
    except BaseException as e:
        exc = _ExceptionWithTraceback(e)
        result_queue.put(_ResultItem(work_id, exception=exc))",Safely send back the given result or exception,
"def _ensure_executor_running(self):
        """"""ensures all workers and management thread are running
        """"""
        with self._processes_management_lock:
            if len(self._processes) != self._max_workers:
                self._adjust_process_count()
            self._start_queue_management_thread()",ensures all workers and management thread are running,
"def _format_exitcodes(exitcodes):
    """"""Format a list of exit code with names of the signals if possible""""""
    str_exitcodes = [""{}({})"".format(_get_exitcode_name(e), e)
                     for e in exitcodes if e is not None]
    return ""{"" + "", "".join(str_exitcodes) + ""}""",Format a list of exit code with names of the signals if possible,
"def run_hooks(obj, hooks, *args):
    """"""Run each function in `hooks' with args""""""
    for hook in hooks:
        if hook(obj, *args): return True
        pass
    return False",Run each function in `hooks' with args,
"def forget(self):
        """""" Remove memory of state variables set in the command processor """"""
        self.stack       = []
        self.curindex    = 0
        self.curframe    = None
        self.thread_name = None
        self.frame_thread_name = None
        return",Remove memory of state variables set in the command processor,
"def read_history_file(self):
        """"""Read the command history file -- possibly.""""""
        histfile = self.debugger.intf[-1].histfile
        try:
            import readline
            readline.read_history_file(histfile)
        except IOError:
                pass
        except ImportError:
            pass
        return",Read the command history file -- possibly.,
"def complete_token_filtered(aliases, prefix, expanded):
    """"""Find all starting matches in dictionary *aliases* that start
     with *prefix*, but filter out any matches already in *expanded*""""""

    complete_ary = aliases.keys()
    return [cmd for cmd in complete_ary if cmd.startswith(prefix)]","Find all starting matches in dictionary *aliases* that start
     with *prefix*, but filter out any matches already in *expanded*",
"def close(self):
        """""" Closes both input and output """"""
        self.state = 'closing'
        if self.input:
            self.input.close()
            pass
        if self.output:
            self.output.close()
            pass
        self.state = 'disconnnected'
        return",Closes both input and output,
"def count_frames(frame, count_start=0):
    ""Return a count of the number of frames""
    count = -count_start
    while frame:
        count += 1
        frame = frame.f_back
    return count",Return a count of the number of frames,
"def print_stack_trace(proc_obj, count=None, color='plain', opts={}):
    ""Print count entries of the stack trace""
    if count is None:
        n=len(proc_obj.stack)
    else:
        n=min(len(proc_obj.stack), count)
    try:
        for i in range(n):
            print_stack_entry(proc_obj, i, color=color, opts=opts)
    except KeyboardInterrupt:
        pass
    return",Print count entries of the stack trace,
"def lookup(self, subcmd_prefix):
        """"""Find subcmd in self.subcmds""""""
        for subcmd_name in list(self.subcmds.keys()):
            if subcmd_name.startswith(subcmd_prefix) \
               and len(subcmd_prefix) >= \
               self.subcmds[subcmd_name].__class__.min_abbrev:
                return self.subcmds[subcmd_name]
            pass
        return None",Find subcmd in self.subcmds,
"def run(self, subcmd_name, arg):
        """"""Run subcmd_name with args using obj for the environent""""""
        entry=self.lookup(subcmd_name)
        if entry:
            entry['callback'](arg)
        else:
            self.cmdproc.undefined_cmd(entry.__class__.name, subcmd_name)
            pass
        return",Run subcmd_name with args using obj for the environent,
"def readable(path):
    """"""Test whether a path exists and is readable.  Returns None for
    broken symbolic links or a failing stat() and False if
    the file exists but does not have read permission. True is returned
    if the file is readable.""""""
    try:
        st = os.stat(path)
        return 0 != st.st_mode & READABLE_MASK
    except os.error:
        return None
    return True","Test whether a path exists and is readable.  Returns None for
    broken symbolic links or a failing stat() and False if
    the file exists but does not have read permission. True is returned
    if the file is readable.",
"def map_thread_names():
    '''Invert threading._active'''
    name2id = {}
    for thread_id in list(threading._active.keys()):
        thread = threading._active[thread_id]
        name = thread.getName()
        if name not in list(name2id.keys()):
            name2id[name] = thread_id
            pass
        pass
    return name2id",Invert threading._active,
"def open(self, inp, opts=None):
        """"""Use this to set where to read from.
        """"""
        if isinstance(inp, list):
            self.input = inp
        else:
            raise IOError(""Invalid input type (%s) for %s"" % (type(inp), inp))
        return",Use this to set where to read from.,
"def readline(self, use_raw=None, prompt=''):
        """"""Read a line of input. EOFError will be raised on EOF.

        Note that we don't support prompting""""""
        if self.closed: raise ValueError
        if 0 == len(self.input):
            self.closed = True
            raise EOFError
        line = self.input[0]
        del self.input[0]
        return line","Read a line of input. EOFError will be raised on EOF.

        Note that we don't support prompting",
"def write(self, msg):
        """""" This method the debugger uses to write. In contrast to
        writeline, no newline is added to the end to `str'.
        """"""
        if self.closed: raise ValueError
        if [] == self.output:
            self.output = [msg]
        else:
            self.output[-1] += msg
            pass
        return","This method the debugger uses to write. In contrast to
        writeline, no newline is added to the end to `str'.",
"def read_remote(self):
        '''Send a message back to the server (in contrast to
        the local user output channel).'''
        coded_line = self.inout.read_msg()
        if isinstance(coded_line, bytes):
            coded_line = coded_line.decode(""utf-8"")
        control = coded_line[0]
        remote_line = coded_line[1:]
        return (control, remote_line)","Send a message back to the server (in contrast to
        the local user output channel).",
"def run_set_bool(obj, args):
    """"""set a Boolean-valued debugger setting. 'obj' is a generally a
    subcommand that has 'name' and 'debugger.settings' attributes""""""
    try:
        if 0 == len(args): args = ['on']
        obj.debugger.settings[obj.name] = get_onoff(obj.errmsg, args[0])
    except ValueError:
        pass
    return","set a Boolean-valued debugger setting. 'obj' is a generally a
    subcommand that has 'name' and 'debugger.settings' attributes",
"def run_show_bool(obj, what=None):
    """"""Generic subcommand showing a boolean-valued debugger setting.
    'obj' is generally a subcommand that has 'name' and
    'debugger.setting' attributes.""""""
    val = show_onoff(obj.debugger.settings[obj.name])
    if not what: what = obj.name
    return obj.msg(""%s is %s."" % (what, val))","Generic subcommand showing a boolean-valued debugger setting.
    'obj' is generally a subcommand that has 'name' and
    'debugger.setting' attributes.",
"def run_show_int(obj, what=None):
    """"""Generic subcommand integer value display""""""
    val = obj.debugger.settings[obj.name]
    if not what: what = obj.name
    return obj.msg(""%s is %d."" % (what, val))",Generic subcommand integer value display,
"def run_show_val(obj, name):
    """"""Generic subcommand value display""""""
    val = obj.debugger.settings[obj.name]
    obj.msg(""%s is %s."" % (obj.name, obj.cmd.proc._saferepr(val),))
    return False",Generic subcommand value display,
"def next_opcode(code, offset):
    '''Return the next opcode and offset as a tuple. Tuple (-100,
    -1000) is returned when reaching the end.'''
    n = len(code)
    while offset < n:
        op = code[offset]
        offset += 1
        if op >= HAVE_ARGUMENT:
            offset += 2
            pass
        yield op, offset
        pass
    yield -100, -1000
    pass","Return the next opcode and offset as a tuple. Tuple (-100,
    -1000) is returned when reaching the end.",
"def is_def_stmt(line, frame):
    """"""Return True if we are looking at a def statement""""""
    # Should really also check that operand of 'LOAD_CONST' is a code object
    return (line and _re_def.match(line) and op_at_frame(frame)=='LOAD_CONST'
            and stmt_contains_opcode(frame.f_code, frame.f_lineno,
                                          'MAKE_FUNCTION'))",Return True if we are looking at a def statement,
"def is_class_def(line, frame):
    """"""Return True if we are looking at a class definition statement""""""
    return (line and _re_class.match(line)
            and stmt_contains_opcode(frame.f_code, frame.f_lineno,
                                     'BUILD_CLASS'))",Return True if we are looking at a class definition statement,
"def nothread_quit(self, arg):
        """""" quit command when there's just one thread. """"""

        self.debugger.core.stop()
        self.debugger.core.execution_status = 'Quit command'
        raise Mexcept.DebuggerQuit",quit command when there's just one thread.,
"def threaded_quit(self, arg):
        """""" quit command when several threads are involved. """"""
        threading_list = threading.enumerate()
        mythread =  threading.currentThread()
        for t in threading_list:
            if t != mythread:
                ctype_async_raise(t, Mexcept.DebuggerQuit)
                pass
            pass
        raise Mexcept.DebuggerQuit",quit command when several threads are involved.,
"def set_default_bg():
    """"""Get bacground from
    default values based on the TERM environment variable
    """"""
    term = environ.get('TERM', None)
    if term:
        if (term.startswith('xterm',) or term.startswith('eterm')
            or term == 'dtterm'):
            return False
    return True","Get bacground from
    default values based on the TERM environment variable",
"def get_name():
    """"""Get the name caller's caller.
    NB: f_code.co_filenames and thus this code kind of broken for
    zip'ed eggs circa Jan 2009
    """"""
    caller = sys._getframe(2)
    filename = caller.f_code.co_filename
    filename = os.path.normcase(os.path.basename(filename))
    return os.path.splitext(filename)[0]","Get the name caller's caller.
    NB: f_code.co_filenames and thus this code kind of broken for
    zip'ed eggs circa Jan 2009",
"def signature(frame):
    '''return suitable frame signature to key display expressions off of.'''
    if not frame: return None
    code = frame.f_code
    return (code.co_name, code.co_filename, code.co_firstlineno)",return suitable frame signature to key display expressions off of.,
"def all(self):
        """"""List all display items; return 0 if none""""""
        found = False
        s = []
        for display in self.list:
            if not found:
                s.append(""""""Auto-display expressions now in effect:
Num Enb Expression"""""")
                found = True
                pass
            s.append(display.format())
        return s",List all display items; return 0 if none,
"def delete_index(self, display_number):
        """"""Delete display expression *display_number*""""""
        old_size = len(self.list)
        self.list = [disp for disp in self.list
                     if display_number != disp.number]
        return old_size != len(self.list)",Delete display expression *display_number*,
"def display(self, frame):
        '''display any items that are active'''
        if not frame: return
        s = []
        sig = signature(frame)
        for display in self.list:
            if display.signature == sig and display.enabled:
                s.append(display.to_s(frame))
                pass
            pass
        return s",display any items that are active,
"def debugger():
    """"""Return the current debugger instance (if any),
    or creates a new one.""""""
    dbg = _current[0]
    if dbg is None or not dbg.active:
        dbg = _current[0] = RemoteCeleryTrepan()
    return dbg","Return the current debugger instance (if any),
    or creates a new one.",
"def debug(frame=None):
    """"""Set breakpoint at current location, or a specified frame""""""
    # ???
    if frame is None:
        frame = _frame().f_back

    dbg = RemoteCeleryTrepan()
    dbg.say(BANNER.format(self=dbg))
    # dbg.say(SESSION_STARTED.format(self=dbg))
    trepan.api.debug(dbg_opts=dbg.dbg_opts)","Set breakpoint at current location, or a specified frame",
"def undefined_subcmd(self, cmd, subcmd):
        """"""Error message when subcommand asked for but doesn't exist""""""
        self.proc.intf[-1].errmsg(('Undefined ""%s"" subcommand: ""%s"". ' +
                                  'Try ""help %s *"".') % (cmd, subcmd, cmd))
        return",Error message when subcommand asked for but doesn't exist,
"def run(self, args):
        """"""**down** [*count*]

Move the current frame down in the stack trace (to a newer frame). 0
is the most recent frame. If no count is given, move down 1.

See also:
---------

`up` and `frame`.""""""

        Mframe.adjust_relative(self.proc, self.name, args, self.signum)
        return False","**down** [*count*]

Move the current frame down in the stack trace (to a newer frame). 0
is the most recent frame. If no count is given, move down 1.

See also:
---------

`up` and `frame`.",
"def write(self, msg):
        """""" This method the debugger uses to write. In contrast to
        writeline, no newline is added to the end to `str'.
        """"""
        if self.output.closed:
            raise IOError(""writing %s on a closed file"" % msg)
        self.output.write(msg)
        if self.flush_after_write: self.flush()
        return","This method the debugger uses to write. In contrast to
        writeline, no newline is added to the end to `str'.",
"def lookup_signame(num):
    """"""Find the corresponding signal name for 'num'. Return None
    if 'num' is invalid.""""""
    signames = signal.__dict__
    num = abs(num)
    for signame in list(signames.keys()):
        if signame.startswith('SIG') and signames[signame] == num:
            return signame
        pass
    # Something went wrong. Should have returned above
    return None","Find the corresponding signal name for 'num'. Return None
    if 'num' is invalid.",
"def lookup_signum(name):
    """"""Find the corresponding signal number for 'name'. Return None
    if 'name' is invalid.""""""
    uname = name.upper()
    if (uname.startswith('SIG') and hasattr(signal, uname)):
        return getattr(signal, uname)
    else:
        uname = ""SIG""+uname
        if hasattr(signal, uname):
            return getattr(signal, uname)
        return None
    return","Find the corresponding signal number for 'name'. Return None
    if 'name' is invalid.",
"def check_and_adjust_sighandlers(self):
        """"""Check to see if any of the signal handlers we are interested in have
        changed or is not initially set. Change any that are not right. """"""
        for signame in list(self.sigs.keys()):
            if not self.check_and_adjust_sighandler(signame, self.sigs):
                break
            pass
        return","Check to see if any of the signal handlers we are interested in have
        changed or is not initially set. Change any that are not right.",
"def handle_print_stack(self, signame, print_stack):
        """"""Set whether we stop or not when this signal is caught.
        If 'set_stop' is True your program will stop when this signal
        happens.""""""
        self.sigs[signame].print_stack = print_stack
        return print_stack","Set whether we stop or not when this signal is caught.
        If 'set_stop' is True your program will stop when this signal
        happens.",
"def handle_print(self, signame, set_print):
        """"""Set whether we print or not when this signal is caught.""""""
        if set_print:
            self.sigs[signame].print_method = self.dbgr.intf[-1].msg
        else:
            self.sigs[signame].print_method = None
            pass
        return set_print",Set whether we print or not when this signal is caught.,
"def file2module(filename):
    """"""Given a file name, extract the most likely module name. """"""
    basename = osp.basename(filename)
    if '.' in basename:
        pos = basename.rfind('.')
        return basename[:pos]
    else:
        return basename
    return None","Given a file name, extract the most likely module name.",
"def _populate_cmd_lists(self):
        """""" Populate self.commands""""""
        self.commands = {}
        for cmd_instance in self.cmd_instances:
            cmd_name = cmd_instance.name
            self.commands[cmd_name] = cmd_instance
            pass
        return",Populate self.commands,
"def msg(self, msg):
        """""" used to write to a debugger that is connected to this
        server; `str' written will have a newline added to it
        """"""
        if hasattr(self.output, 'writeline'):
            self.output.writeline(msg)
        elif hasattr(self.output, 'writelines'):
            self.output.writelines(msg + ""\n"")
            pass
        return","used to write to a debugger that is connected to this
        server; `str' written will have a newline added to it",
"def columnize_commands(self, commands):
        """"""List commands arranged in an aligned columns""""""
        commands.sort()
        width = self.debugger.settings['width']
        return columnize.columnize(commands, displaywidth=width,
                                   lineprefix='    ')",List commands arranged in an aligned columns,
"def confirm(self, msg, default=False):
        """""" Convenience short-hand for self.debugger.intf[-1].confirm """"""
        return self.debugger.intf[-1].confirm(msg, default)",Convenience short-hand for self.debugger.intf[-1].confirm,
"def errmsg(self, msg, opts={}):
        """""" Convenience short-hand for self.debugger.intf[-1].errmsg """"""
        try:
            return(self.debugger.intf[-1].errmsg(msg))
        except EOFError:
            # FIXME: what do we do here?
            pass
        return None",Convenience short-hand for self.debugger.intf[-1].errmsg,
"def msg(self, msg, opts={}):
        """""" Convenience short-hand for self.debugger.intf[-1].msg """"""
        try:
            return(self.debugger.intf[-1].msg(msg))
        except EOFError:
            # FIXME: what do we do here?
            pass
        return None",Convenience short-hand for self.debugger.intf[-1].msg,
"def msg_nocr(self, msg, opts={}):
        """""" Convenience short-hand for self.debugger.intf[-1].msg_nocr """"""
        try:
            return(self.debugger.intf[-1].msg_nocr(msg))
        except EOFError:
            # FIXME: what do we do here?
            pass
        return None",Convenience short-hand for self.debugger.intf[-1].msg_nocr,
"def rst_msg(self, text, opts={}):
        """"""Convert ReStructuredText and run through msg()""""""
        text = Mformat.rst_text(text,
                                'plain' == self.debugger.settings['highlight'],
                                self.debugger.settings['width'])
        return self.msg(text)",Convert ReStructuredText and run through msg(),
"def close(self):
        """""" Closes both socket and server connection. """"""
        self.state = 'closing'
        if self.inout:
            self.inout.close()
            pass
        self.state = 'closing connection'
        if self.conn:
            self.conn.close()
        self.state = 'disconnected'
        return",Closes both socket and server connection.,
"def errmsg(self, message, opts={}):
        """""" Convenience short-hand for self.intf[-1].errmsg """"""
        if 'plain' != self.debugger.settings['highlight']:
            message = colorize('standout', message)
            pass
        return(self.intf[-1].errmsg(message))",Convenience short-hand for self.intf[-1].errmsg,
"def rst_msg(self, text, opts={}):
        """"""Convert ReStructuredText and run through msg()""""""
        from trepan.lib.format import rst_text
        text = rst_text(text,
                        'plain' == self.debugger.settings['highlight'],
                        self.debugger.settings['width'])
        return self.msg(text)",Convert ReStructuredText and run through msg(),
"def dbgr(self, string):
        '''Invoke a debugger command from inside a python shell called inside
        the debugger.
        '''
        print('')
        self.proc.cmd_queue.append(string)
        self.proc.process_command()
        return","Invoke a debugger command from inside a python shell called inside
        the debugger.",
"def nothread_quit(self, arg):
        """""" quit command when there's just one thread. """"""

        self.debugger.core.stop()
        self.debugger.core.execution_status = 'Quit command'
        self.proc.response['event'] = 'terminated'
        self.proc.response['name']  = 'status'
        self.proc.intf[-1].msg(self.proc.response)
        raise Mexcept.DebuggerQuit",quit command when there's just one thread.,
"def add_ignore(self, *frames_or_fns):
        """"""Add `frame_or_fn' to the list of functions that are not to
        be debugged""""""
        for frame_or_fn in frames_or_fns:
            rc = self.ignore_filter.add_include(frame_or_fn)
            pass
        return rc","Add `frame_or_fn' to the list of functions that are not to
        be debugged",
"def is_started(self):
        '''Return True if debugging is in progress.'''
        return (tracer.is_started() and
                not self.trace_hook_suspend
                and tracer.find_hook(self.trace_dispatch))",Return True if debugging is in progress.,
"def stack_trace(self, f):
        """"""A mini stack trace routine for threads.""""""
        while f:
            if (not self.core.ignore_filter.is_included(f)
                or self.settings['dbg_trepan']):
                s = Mstack.format_stack_entry(self, (f, f.f_lineno))
                self.msg("" ""*4 + s)
                pass
            f = f.f_back
            pass
        return",A mini stack trace routine for threads.,
"def delete_breakpoint_by_number(self, bpnum):
        ""Remove a breakpoint given its breakpoint number.""
        success, msg, bp = self.get_breakpoint(bpnum)
        if not success:
            return False, msg
        self.delete_breakpoint(bp)
        return (True, '')",Remove a breakpoint given its breakpoint number.,
"def readline(self, prompt='', use_raw=None):
        """"""Read a line of input. Prompt and use_raw exist to be
        compatible with other input routines and are ignored.
        EOFError will be raised on EOF.
        """"""
        line = self.input.readline()
        if not line: raise EOFError
        return line.rstrip(""\n"")","Read a line of input. Prompt and use_raw exist to be
        compatible with other input routines and are ignored.
        EOFError will be raised on EOF.",
"def t_whitespace(self, s):
        r'\s+'
        self.add_token('SPACE', s)
        self.pos += len(s)
        pass",r'\s+,
"def t_single_quote_file(self, s):
        r""'[^'].+'""
        # Pick out text inside of singe-quoted string
        base = s[1:-1]
        self.add_token('FILENAME', base)
        self.pos += len(s)","r""'[^'].+",
"def t_double_quote_file(self, s):
        r'""[^""]+""'
        # Pick out text inside of singe-quoted string
        base = s[1:-1]
        self.add_token('FILENAME', base)
        self.pos += len(s)","r'""[^""]+""",
"def t_colon(self, s):
        r':'
        # Used to separate a filename from a line number
        self.add_token('COLON', s)
        self.pos += len(s)",r':,
"def t_comma(self, s):
        r','
        # Used in ""list"" to separate first from last
        self.add_token('COMMA', s)
        self.pos += len(s)","r',",
"def t_direction(self, s):
        r'^[+-]$'
        # Used in the ""list"" command
        self.add_token('DIRECTION', s)
        self.pos += len(s)",r'^[+-]$,
"def t_number(self, s):
        r'\d+'
        pos = self.pos
        self.add_token('NUMBER', int(s))
        self.pos = pos + len(s)",r'\d+,
"def t_offset(self, s):
        r'[+]\d+'
        pos = self.pos
        self.add_token('OFFSET', s)
        self.pos = pos + len(s)",r'[+]\d+,
"def t_address(self, s):
        r'[*]\d+'
        pos = self.pos
        self.add_token('ADDRESS', s)
        self.pos = pos + len(s)",r'[*]\d+,
"def _convert_date(date_string, date_format):
    """"""
    Convert a date in a given format to epoch time. Mostly a wrapper for
    datetime's strptime.
    """"""
    if date_format != 'epoch':
        return datetime.strptime(date_string, date_format).timestamp()
    else:
        return float(date_string)","Convert a date in a given format to epoch time. Mostly a wrapper for
    datetime's strptime.",
"def stream_json_lines(file):
    """"""
    Load a JSON stream and return a generator, yielding one object at a time.
    """"""
    if isinstance(file, string_type):
        file = open(file, 'rb')
    for line in file:
        line = line.strip()
        if line:
            if isinstance(line, bytes):
                line = line.decode('utf-8')
            yield json.loads(line)","Load a JSON stream and return a generator, yielding one object at a time.",
"def transcode_to_utf8(filename, encoding):
    """"""
    Convert a file in some other encoding into a temporary file that's in
    UTF-8.
    """"""
    tmp = tempfile.TemporaryFile()
    for line in io.open(filename, encoding=encoding):
        tmp.write(line.strip('\uFEFF').encode('utf-8'))

    tmp.seek(0)
    return tmp","Convert a file in some other encoding into a temporary file that's in
    UTF-8.",
"def upload(self, path, docs, **params):
        """"""
        A deprecated alias for post(path, docs=docs), included only for
        backward compatibility.
        """"""
        logger.warning('The upload method is deprecated; use post instead.')
        return self.post(path, docs=docs)","A deprecated alias for post(path, docs=docs), included only for
        backward compatibility.",
"def documentation(self):
        """"""
        Get the documentation that the server sends for the API.
        """"""
        newclient = self.__class__(self.session, self.root_url)
        return newclient.get_raw('/')",Get the documentation that the server sends for the API.,
"def get_raw(self, path, **params):
        """"""
        Get the raw text of a response.

        This is only generally useful for specific URLs, such as documentation.
        """"""
        url = ensure_trailing_slash(self.url + path.lstrip('/'))
        return self._request('get', url, params=params).text","Get the raw text of a response.

        This is only generally useful for specific URLs, such as documentation.",
"def _print_csv(result):
    """"""Print a JSON list of JSON objects in CSV format.""""""
    if type(result) is not list:
        raise TypeError(""output not able to be displayed as CSV."")
    first_line = result[0]
    w = csv.DictWriter(sys.stdout, fieldnames=sorted(first_line.keys()))
    w.writeheader()
    for line in result:
        w.writerow(line)",Print a JSON list of JSON objects in CSV format.,
"def _batches(iterable, size):
    """"""
    Take an iterator and yield its contents in groups of `size` items.
    """"""
    sourceiter = iter(iterable)
    while True:
        try:
            batchiter = islice(sourceiter, size)
            yield chain([next(batchiter)], batchiter)
        except StopIteration:
            return",Take an iterator and yield its contents in groups of `size` items.,
"def batches(iterable, size):
    """"""
    Take an iterator and yield its contents in groups of `size` items.
    """"""
    sourceiter = iter(iterable)
    while True:
        batchiter = islice(sourceiter, size)
        yield chain([next(batchiter)], batchiter)",Take an iterator and yield its contents in groups of `size` items.,
"def login(self):
        """"""Set http session.""""""
        if self._session is None:
            self._session = requests.session()
            # adding fake user-agent header
            self._session.headers.update({'User-agent': str(UserAgent().random)})
        return self._post_login_page()",Set http session.,
"def fetch_data(self):
        """"""Get the latest data from Enedis.""""""

        for t in [HOURLY, DAILY, MONTHLY, YEARLY]:
            self._data[t] = self.get_data_per_period(t)",Get the latest data from Enedis.,
"def on_dom_modified(self, change):
        """""" When an event from enaml occurs, send it out the websocket
        so the client's browser can update accordingly.

        """"""
        log.debug(f'Update from enaml: {change}')
        self.write_message(json.dumps(change['value']))","When an event from enaml occurs, send it out the websocket
        so the client's browser can update accordingly.",
"def create_widget(self):
        """""" Create the toolkit widget for the proxy object.

        This method is called during the top-down pass, just before the
        'init_widget()' method is called. This method should create the
        toolkit widget and assign it to the 'widget' attribute.

        """"""
        self.widget = SubElement(self.parent_widget(), self.declaration.tag)","Create the toolkit widget for the proxy object.

        This method is called during the top-down pass, just before the
        'init_widget()' method is called. This method should create the
        toolkit widget and assign it to the 'widget' attribute.",
"def child_widgets(self):
        """""" Get the child toolkit widgets for this object.

        Returns
        -------
        result : iterable of QObject
            The child widgets defined for this object.

        """"""
        for child in self.children():
            w = child.widget
            if w is not None:
                yield w","Get the child toolkit widgets for this object.

        Returns
        -------
        result : iterable of QObject
            The child widgets defined for this object.",
"def set_attribute(self, name, value):
        """""" Default handler for those not explicitly defined """"""
        if value is True:
            self.widget.set(name, name)
        elif value is False:
            del self.widget.attrib[name]
        else:
            self.widget.set(name, str(value))",Default handler for those not explicitly defined,
"def xpath(self, query, **kwargs):
        """""" Find nodes matching the given xpath query """"""
        nodes = self.proxy.find(query, **kwargs)
        return [n.declaration for n in nodes]",Find nodes matching the given xpath query,
"def prepare(self, **kwargs):
        """""" Prepare for rendering """"""
        for k, v in kwargs.items():
            setattr(self, k, v)
        if not self.is_initialized:
            self.initialize()
        if not self.proxy_is_active:
            self.activate_proxy()",Prepare for rendering,
"def init_widget(self):
        """""" Initialize the widget with the source. """"""
        d = self.declaration
        if d.source:
            self.set_source(d.source)
        else:
            super(RawComponent, self).init_widget()",Initialize the widget with the source.,
"def set_source(self, source):
        """""" Set the source by parsing the source and inserting it into the 
        component. 
        """"""
        self.widget.clear()
        html = etree.HTML(source)
        self.widget.extend(html[0])

        # Clear removes everything so it must be reinitialized
        super(RawComponent, self).init_widget()","Set the source by parsing the source and inserting it into the 
        component.",
"def read(*pathcomponents):
    """"""Read the contents of a file located relative to setup.py""""""
    with open(join(abspath(dirname(__file__)), *pathcomponents)) as thefile:
        return thefile.read()",Read the contents of a file located relative to setup.py,
"def error(msg, exit_code):
    """"""
    Print `msg` error and exit with status `exit_code`
    """"""
    sys.stderr.write(""%s\ntry 'mongotail --help' for more information\n"" % msg)
    sys.stderr.flush()
    exit(exit_code)",Print `msg` error and exit with status `exit_code`,
"def error_parsing(msg=""unknown options""):
    """"""
    Print any parsing error and exit with status -1
    """"""
    sys.stderr.write(""Error parsing command line: %s\ntry 'mongotail --help' for more information\n"" % msg)
    sys.stderr.flush()
    exit(EINVAL)",Print any parsing error and exit with status -1,
"def new_session(self, session):
        '''
        Clear out the current session on the remote and setup a new one.

        :return: A response from having expired the current session.
        :rtype: requests.Response
        '''
        response = self.__get('/Home/SessionExpire')
        self.session = update_session_headers(session)

        return response","Clear out the current session on the remote and setup a new one.

        :return: A response from having expired the current session.
        :rtype: requests.Response",
"def add_exit(self):
        """"""
        Add the exit item if necessary. Used to make sure there aren't multiple exit items

        :return: True if item needed to be added, False otherwise
        :rtype: bool
        """"""
        if self.items:
            if self.items[-1] is not self.exit_item:
                self.items.append(self.exit_item)
                return True
        return False","Add the exit item if necessary. Used to make sure there aren't multiple exit items

        :return: True if item needed to be added, False otherwise
        :rtype: bool",
"def show(self, index):
        """"""
        This class overrides this method
        """"""
        if self.menu and self.menu.parent:
            self.text = ""Return to %s menu"" % self.menu.parent.title
        else:
            self.text = ""Exit""
        return super(ExitItem, self).show(index)",This class overrides this method,
"def action(self):
        """"""
        This class overrides this method
        """"""
        self.return_value = self.function(*self.args, **self.kwargs)",This class overrides this method,
"def set_up(self):
        """"""
        This class overrides this method
        """"""
        self.menu.pause()
        curses.def_prog_mode()
        self.menu.clear_screen()",This class overrides this method,
"def clean_up(self):
        """"""
        This class overrides this method
        """"""
        self.submenu.join()
        self.menu.clear_screen()
        curses.reset_prog_mode()
        curses.curs_set(1)  # reset doesn't do this right
        curses.curs_set(0)
        self.menu.resume()",This class overrides this method,
"def add(df, new_column, column_1, column_2):
    """"""
    DEPRECATED -  use `formula` instead
    """"""
    return _basic_math_operation(df, new_column, column_1, column_2, op='add')",DEPRECATED -  use `formula` instead,
"def subtract(df, new_column, column_1, column_2):
    """"""
    DEPRECATED -  use `formula` instead
    """"""
    return _basic_math_operation(df, new_column, column_1, column_2, op='sub')",DEPRECATED -  use `formula` instead,
"def multiply(df, new_column, column_1, column_2):
    """"""
    DEPRECATED -  use `formula` instead
    """"""
    return _basic_math_operation(df, new_column, column_1, column_2, op='mul')",DEPRECATED -  use `formula` instead,
"def divide(df, new_column, column_1, column_2):
    """"""
    DEPRECATED -  use `formula` instead
    """"""
    return _basic_math_operation(df, new_column, column_1, column_2, op='truediv')",DEPRECATED -  use `formula` instead,
"def read_entry(self, file_name):
        """"""
        Args:
            file_name (str):

        Returns:
            pd.DataFrame:
        """"""
        file_path = os.path.join(self.EXTRACTION_CACHE_PATH, file_name)
        logger.info(f'Reading cache entry: {file_path}')
        return joblib.load(file_path)","Args:
            file_name (str):

        Returns:
            pd.DataFrame:",
"def log_message(logger, message=""""):
    """"""
    Decorator to log a message before executing a function
    """"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            _log_message(logger, func.__name__, message)
            result = func(*args, **kwargs)
            return result
        return wrapper
    return decorator",Decorator to log a message before executing a function,
"def slugify(name, separator='-'):
    """"""Returns a slugified name (we allow _ to be used)""""""
    return _slugify(name, regex_pattern=re.compile('[^-_a-z0-9]+'), separator=separator)",Returns a slugified name (we allow _ to be used),
"def _learning_updates(self):
        """"""
        Return updates in the training.
        """"""
        params = self.training_params()
        gradients = self.get_gradients(params)
        return self.optimization_updates(params, gradients)",Return updates in the training.,
"def optimization_updates(self, params, gradients):
        """"""
        Return updates from optimization.
        """"""
        updates, free_parameters = optimize_updates(params, gradients, self.config)
        self.network.free_parameters.extend(free_parameters)
        logging.info(""Added %d free parameters for optimization"" % len(free_parameters))
        return updates",Return updates from optimization.,
"def _action_network(self, h_t):
        """"""
        Parameters:
            h_t - 256x1 vector
        Returns:
            10x1 vector
        """"""
        z = self._relu(T.dot(h_t, self.W_a) + self.B_a)
        return self._softmax(z)","Parameters:
            h_t - 256x1 vector
        Returns:
            10x1 vector",
"def map(self, func):
        """"""
        Process all data with given function.
        The scheme of function should be x,y -> x,y.
        """"""
        if self._train_set:
            self._train_set = map(func, self._train_set)
        if self._valid_set:
            self._valid_set = map(func, self._valid_set)
        if self._test_set:
            self._test_set = map(func, self._test_set)","Process all data with given function.
        The scheme of function should be x,y -> x,y.",
"def vectorize_target(self, size):
        """"""
        Make targets be one-hot vectors.
        """"""
        if self._train_set:
            self._train_set = self._vectorize_set(self._train_set, size)
        if self._valid_set:
            self._valid_set = self._vectorize_set(self._valid_set, size)
        if self._test_set:
            self._test_set = self._vectorize_set(self._test_set, size)",Make targets be one-hot vectors.,
"def sample(self, input, steps):
        """"""
        Sample outputs from LM.
        """"""
        inputs = [[onehot(self.input_dim, x) for x in input]]
        for _ in range(steps):
            target = self.compute(inputs)[0,-1].argmax()
            input.append(target)
            inputs[0].append(onehot(self.input_dim, target))
        return input",Sample outputs from LM.,
"def report(self):
        """"""
        Report elapsed time.
        """"""
        if not self.end_time:
            self.end()
        print (""Time: {} mins"".format((self.end_time - self.start_time )/ 60))",Report elapsed time.,
"def run(self, data_x):
        """"""
        Run the model with validation data and return costs.
        """"""
        output_vars = self.compute(*data_x)
        return self._extract_costs(output_vars)",Run the model with validation data and return costs.,
"def iftrain(self, then_branch, else_branch):
        """"""
        Execute `then_branch` when training.
        """"""
        return ifelse(self._training_flag, then_branch, else_branch, name=""iftrain"")",Execute `then_branch` when training.,
"def switch_training(self, flag):
        """"""
        Switch training mode.
        :param flag: switch on training mode when flag is True.
        """"""
        if self._is_training == flag: return
        self._is_training = flag
        if flag:
            self._training_flag.set_value(1)
        else:
            self._training_flag.set_value(0)","Switch training mode.
        :param flag: switch on training mode when flag is True.",
"def skip(self, n_batches, n_epochs=0):
        """"""
        Skip N batches in the training.
        """"""
        logging.info(""skip %d epochs and %d batches"" % (n_epochs, n_batches))
        self._skip_batches = n_batches
        self._skip_epochs = n_epochs",Skip N batches in the training.,
"def add_epoch_controllers(self, *controllers):
        """"""
        Add epoch callbacks function.
        :param controllers: can be a `TrainingController` or a function.
        """"""
        for controller in controllers:
            if isinstance(controller, TrainingController):
                controller.bind(self)
            self._epoch_controllers.append(controller)","Add epoch callbacks function.
        :param controllers: can be a `TrainingController` or a function.",
"def _run_train(self, epoch, train_set, train_size=None):
        """"""
        Run one training iteration.
        """"""
        self.network.train_logger.record_epoch(epoch + 1)
        costs = self.train_step(train_set, train_size)
        if not epoch % self.config.monitor_frequency:
            self.report(dict(costs), ""train"", epoch)
        self.last_run_costs = costs
        return costs",Run one training iteration.,
"def get_data(self, data_split=""train""):
        """"""
        Get specified split of data.
        """"""
        if data_split == 'train':
            return self._current_train_set
        elif data_split == 'valid':
            return self._current_valid_set
        elif data_split == 'test':
            return self._current_test_set
        else:
            return None",Get specified split of data.,
"def _cut_to_pieces(self, bunch_stack):
        """"""
        :type bunch_stack: list of list of int
        """"""
        stack_len = len(bunch_stack[0])
        for i in xrange(0, stack_len, self.fragment_length):
            yield np.array(map(lambda stack: stack[i: i + self.fragment_length], bunch_stack))",:type bunch_stack: list of list of int,
"def _pad_zeros(self, bunch_stack):
        """"""
        :type bunch_stack: list of list
        """"""
        min_len = min(map(len, bunch_stack))
        for i in range(len(bunch_stack)):
            bunch_stack[i] = bunch_stack[i][:min_len]",:type bunch_stack: list of list,
"def apply(self, func, dim=None):
        """"""
        Apply a function to tensors.
        """"""
        output_dim = dim if dim else self.output_dim
        return NeuralVariable(func(self.tensor), output_dim)",Apply a function to tensors.,
"def report(self):
        """"""
        Report usage of training parameters.
        """"""
        if self.logger:
            self.logger.info(""accessed parameters:"")
            for key in self.used_parameters:
                self.logger.info("" - %s %s"" % (key, ""(undefined)"" if key in self.undefined_parameters else """"))",Report usage of training parameters.,
"def new_block(self, *layers, **kwargs):
        """"""
        Create a parameters block.
        :param layers: register some layers in the block
        :param name: specify the name of this block
        """"""
        from deepy.layers.block import Block
        block = Block(*layers, **kwargs)
        return block","Create a parameters block.
        :param layers: register some layers in the block
        :param name: specify the name of this block",
"def var(self, tensor_type, last_dim=0, test_shape=None):
        """"""
        An alias of deepy.tensor.var.
        """"""
        from deepy.tensor import var
        return var(tensor_type, last_dim=last_dim, test_shape=test_shape)",An alias of deepy.tensor.var.,
"def get_trainer(self, model,  method='sgd', config=None, annealer=None, validator=None):
        """"""
        Get a trainer to optimize given model.
        :rtype: deepy.trainers.GeneralNeuralTrainer
        """"""
        from deepy.trainers import GeneralNeuralTrainer
        return GeneralNeuralTrainer(model, method=method, config=config, annealer=annealer, validator=validator)","Get a trainer to optimize given model.
        :rtype: deepy.trainers.GeneralNeuralTrainer",
"def shared(self, value, name=None):
        """"""
        Create a shared theano scalar value.
        """"""
        if type(value) == int:
            final_value = np.array(value, dtype=""int32"")
        elif type(value) == float:
            final_value = np.array(value, dtype=env.FLOATX)
        else:
            final_value = value

        return theano.shared(final_value, name=name)",Create a shared theano scalar value.,
"def train_size(self):
        """"""
        Return size of training data. (optional)
        :rtype: number
        """"""
        train_set = self.train_set()
        if isinstance(train_set, collections.Iterable):
            return len(list(train_set))
        else:
            return None","Return size of training data. (optional)
        :rtype: number",
"def invoke(self):
        """"""
        Run it, return whether to end training.
        """"""
        self._iter += 1
        logging.info(""{} epochs left to run"".format(self._patience - self._iter))
        if self._iter >= self._patience:
            self._trainer.exit()","Run it, return whether to end training.",
"def stack_reparameterization_layer(self, layer_size):
        """"""
        Perform reparameterization trick for latent variables.
        :param layer_size: the size of latent variable
        """"""
        self.rep_layer = ReparameterizationLayer(layer_size, sample=self.sample)
        self.stack_encoders(self.rep_layer)","Perform reparameterization trick for latent variables.
        :param layer_size: the size of latent variable",
"def stack_encoders(self, *layers):
        """"""
        Stack encoding layers, this must be done before stacking decoding layers.
        """"""
        self.stack(*layers)
        self.encoding_layes.extend(layers)","Stack encoding layers, this must be done before stacking decoding layers.",
"def stack_decoders(self, *layers):
        """"""
        Stack decoding layers.
        """"""
        self.stack(*layers)
        self.decoding_layers.extend(layers)",Stack decoding layers.,
"def monitor_layer_outputs(self):
        """"""
        Monitoring the outputs of each layer.
        Useful for troubleshooting convergence problems.
        """"""
        for layer, hidden in zip(self.layers, self._hidden_outputs):
            self.training_monitors.append(('mean(%s)' % (layer.name), abs(hidden).mean()))","Monitoring the outputs of each layer.
        Useful for troubleshooting convergence problems.",
"def all_parameters(self):
        """"""
        Return all parameters.
        """"""
        params = []
        params.extend(self.parameters)
        params.extend(self.free_parameters)

        return params",Return all parameters.,
"def compute(self, *x):
        """"""
        Return network output.
        """"""
        self._compile()
        outs = self._compute(*x)
        if self._output_keys:
            return MapDict(dict(zip(self._output_keys, outs)))
        else:
            return outs",Return network output.,
"def register_parameters(self, *parameters):
        """"""
        Register parameters.
        """"""
        for param in parameters:
            self.parameter_count += np.prod(param.get_value().shape)
        self.parameters.extend(parameters)",Register parameters.,
"def register_updates(self, *updates):
        """"""
        Register updates that will be executed in each iteration.
        """"""
        for key, node in updates:
            if key not in self._registered_updates:
                self.updates.append((key, node))
                self._registered_updates.add(key)",Register updates that will be executed in each iteration.,
"def register_training_updates(self, *updates):
        """"""
        Register updates that will only be executed in training phase.
        """"""
        for key, node in updates:
            if key not in self._registered_training_updates:
                self.training_updates.append((key, node))
                self._registered_training_updates.add(key)",Register updates that will only be executed in training phase.,
"def dump_one(elt_to_pickle, file_obj):
        """"""
        dumps one element to file_obj, a file opened in write mode
        """"""
        pickled_elt_str = dumps(elt_to_pickle)
        file_obj.write(pickled_elt_str)
        # record separator is a blank line
        # (since pickled_elt_str might contain its own newlines)
        file_obj.write('\n\n')","dumps one element to file_obj, a file opened in write mode",
"def register_layer(self, layer):
        """"""
        Register one connected layer.
        :type layer: NeuralLayer
        """"""
        if self.fixed:
            raise Exception(""After a block is fixed, no more layers can be registered."")
        self.layers.append(layer)","Register one connected layer.
        :type layer: NeuralLayer",
"def load_params(self, path, exclude_free_params=False):
        from deepy.core import graph
        """"""
        Load parameters to the block.
        """"""
        from deepy.core.comp_graph import ComputationalGraph
        model = graph.compile(blocks=[self])
        model.load_params(path, exclude_free_params=exclude_free_params)",Load parameters to the block.,
"def onehot_tensor(i_matrix, vocab_size):
    """"""
    # batch x time
    """"""
    dim0, dim1 = i_matrix.shape
    i_vector = i_matrix.reshape((-1,))
    hot_matrix = T.extra_ops.to_one_hot(i_vector, vocab_size).reshape((dim0, dim1, vocab_size))
    return hot_matrix",# batch x time,
"def normalize_dict(dict_):
    """"""
    Replaces all values that are single-item iterables with the value of its
    index 0.

    :param dict dict_:
        Dictionary to normalize.

    :returns:
        Normalized dictionary.

    """"""

    return dict([(k, v[0] if not isinstance(v, str) and len(v) == 1 else v)
                 for k, v in list(dict_.items())])","Replaces all values that are single-item iterables with the value of its
    index 0.

    :param dict dict_:
        Dictionary to normalize.

    :returns:
        Normalized dictionary.",
"def items_to_dict(items):
    """"""
    Converts list of tuples to dictionary with duplicate keys converted to
    lists.

    :param list items:
        List of tuples.

    :returns:
        :class:`dict`

    """"""

    res = collections.defaultdict(list)

    for k, v in items:
        res[k].append(v)

    return normalize_dict(dict(res))","Converts list of tuples to dictionary with duplicate keys converted to
    lists.

    :param list items:
        List of tuples.

    :returns:
        :class:`dict`",
"def _get_data(self):
        """"""
        Extracts the session data from cookie.
        """"""
        cookie = self.adapter.cookies.get(self.name)
        return self._deserialize(cookie) if cookie else {}",Extracts the session data from cookie.,
"def data(self):
        """"""
        Gets session data lazily.
        """"""
        if not self._data:
            self._data = self._get_data()
        # Always return a dict, even if deserialization returned nothing
        if self._data is None:
            self._data = {}
        return self._data",Gets session data lazily.,
"def _signature(self, *parts):
        """"""
        Creates signature for the session.
        """"""
        signature = hmac.new(six.b(self.secret), digestmod=hashlib.sha1)
        signature.update(six.b('|'.join(parts)))
        return signature.hexdigest()",Creates signature for the session.,
"def expire_in(self, value):
        """"""
        Computes :attr:`.expiration_time` when the value is set.
        """"""

        # pylint:disable=attribute-defined-outside-init
        if value:
            self._expiration_time = int(time.time()) + int(value)
            self._expire_in = value",Computes :attr:`.expiration_time` when the value is set.,
"def valid(self):
        """"""
        ``True`` if credentials are valid, ``False`` if expired.
        """"""

        if self.expiration_time:
            return self.expiration_time > int(time.time())
        else:
            return True","``True`` if credentials are valid, ``False`` if expired.",
"def is_binary_string(content):
        """"""
        Return true if string is binary data.
        """"""

        textchars = (bytearray([7, 8, 9, 10, 12, 13, 27]) +
                     bytearray(range(0x20, 0x100)))
        return bool(content.translate(None, textchars))",Return true if string is binary data.,
"def content(self):
        """"""
        The whole response content.
        """"""

        if not self._content:
            content = self.httplib_response.read()
            if self.is_binary_string(content):
                self._content = content
            else:
                self._content = content.decode('utf-8')
        return self._content",The whole response content.,
"def data(self):
        """"""
        A :class:`dict` of data parsed from :attr:`.content`.
        """"""

        if not self._data:
            self._data = self.content_parser(self.content)
        return self._data",A :class:`dict` of data parsed from :attr:`.content`.,
"def _create_base_string(method, base, params):
    """"""
    Returns base string for HMAC-SHA1 signature as specified in:
    http://oauth.net/core/1.0a/#rfc.section.9.1.3.
    """"""

    normalized_qs = _normalize_params(params)
    return _join_by_ampersand(method, base, normalized_qs)","Returns base string for HMAC-SHA1 signature as specified in:
    http://oauth.net/core/1.0a/#rfc.section.9.1.3.",
"def values(cls):
        """"""
        Resembles the :meth:`dict.values` method.
        """"""

        # get all items
        results = cls.query().fetch()
        # return list of dictionaries
        return [result.to_dict() for result in results]",Resembles the :meth:`dict.values` method.,
"def _session_key(self, key):
        """"""
        Generates session key string.

        :param str key:
            e.g. ``""authomatic:facebook:key""``

        """"""

        return '{0}:{1}:{2}'.format(self.settings.prefix, self.name, key)","Generates session key string.

        :param str key:
            e.g. ``""authomatic:facebook:key""``",
"def _session_set(self, key, value):
        """"""
        Saves a value to session.
        """"""

        self.session[self._session_key(key)] = value",Saves a value to session.,
"def _http_status_in_category(status, category):
        """"""
        Checks whether a HTTP status code is in the category denoted by the
        hundreds digit.
        """"""

        assert category < 10, 'HTTP status category must be a one-digit int!'
        cat = category * 100
        return status >= cat and status < cat + 100","Checks whether a HTTP status code is in the category denoted by the
        hundreds digit.",
"def async_access(self, *args, **kwargs):
        """"""
        Same as :meth:`.access` but runs asynchronously in a separate thread.

        .. warning::

            |async|

        :returns:
            :class:`.Future` instance representing the separate thread.

        """"""

        return authomatic.core.Future(self.access, *args, **kwargs)","Same as :meth:`.access` but runs asynchronously in a separate thread.

        .. warning::

            |async|

        :returns:
            :class:`.Future` instance representing the separate thread.",
"def _split_url(url):
        """"""
        Splits given url to url base and params converted to list of tuples.
        """"""

        split = parse.urlsplit(url)
        base = parse.urlunsplit((split.scheme, split.netloc, split.path, 0, 0))
        params = parse.parse_qsl(split.query, True)

        return base, params",Splits given url to url base and params converted to list of tuples.,
"def _access_user_info(self):
        """"""
        Accesses the :attr:`.user_info_url`.

        :returns:
            :class:`.UserInfoResponse`

        """"""
        url = self.user_info_url.format(**self.user.__dict__)
        return self.access(url)","Accesses the :attr:`.user_info_url`.

        :returns:
            :class:`.UserInfoResponse`",
"def get_app_kwarg_dict(appInstance):
    """"""Returns the dictionary of CORS specific app configurations.""""""
    # In order to support blueprints which do not have a config attribute
    app_config = getattr(appInstance, 'config', {})
    return dict(
        (k.lower().replace('cors_', ''), app_config.get(k))
        for k in CONFIG_OPTIONS
        if app_config.get(k) is not None
    )",Returns the dictionary of CORS specific app configurations.,
"def ensure_iterable(inst):
    """"""
    Wraps scalars or string types as a list, or returns the iterable instance.
    """"""
    if isinstance(inst, str):
        return [inst]
    elif not isinstance(inst, collections.abc.Iterable):
        return [inst]
    else:
        return inst","Wraps scalars or string types as a list, or returns the iterable instance.",
"def deprecated(func):
    """"""
    Deprecator decorator.
    """"""
    @functools.wraps(func)
    def new_func(*args, **kwargs):
        warnings.warn(""Call to deprecated function {}."".format(func.__name__), category=DeprecationWarning, stacklevel=2)
        return func(*args, **kwargs)

    return new_func",Deprecator decorator.,
"def deserialize(bstr):
    """"""
    Attempts to deserialize a bytestring into an audiosegment.

    :param bstr: The bytestring serialized via an audiosegment's serialize() method.
    :returns: An AudioSegment object deserialized from `bstr`.
    """"""
    d = pickle.loads(bstr)
    seg = pickle.loads(d['seg'])
    return AudioSegment(seg, d['name'])","Attempts to deserialize a bytestring into an audiosegment.

    :param bstr: The bytestring serialized via an audiosegment's serialize() method.
    :returns: An AudioSegment object deserialized from `bstr`.",
"def serialize(self):
        """"""
        Serializes into a bytestring.

        :returns: An object of type Bytes.
        """"""
        d = self.__getstate__()
        return pickle.dumps({
            'name': d['name'],
            'seg': pickle.dumps(d['seg'], protocol=-1),
        }, protocol=-1)","Serializes into a bytestring.

        :returns: An object of type Bytes.",
"def _remove_overlaps(segmentation_mask, fronts):
    """"""
    Removes all points in the fronts that overlap with the segmentation mask.
    """"""
    fidxs, sidxs = np.where((segmentation_mask != fronts) & (segmentation_mask != 0) & (fronts != 0))
    fronts[fidxs, sidxs] = 0",Removes all points in the fronts that overlap with the segmentation mask.,
"def equal_ignore_order(a, b):
  """"""
  Used to check whether the two edge lists have the same edges 
  when elements are neither hashable nor sortable.
  """"""
  unmatched = list(b)
  for element in a:
    try:
      unmatched.remove(element)
    except ValueError:
      return False
  return not unmatched","Used to check whether the two edge lists have the same edges 
  when elements are neither hashable nor sortable.",
"def list_to_tf_input(data, response_index, num_outcomes):
  """"""
  Separates the outcome feature from the data.
  """"""
  matrix = np.matrix([row[:response_index] + row[response_index+1:] for row in data])
  outcomes = np.asarray([row[response_index] for row in data], dtype=np.uint8)

  return matrix, outcomes",Separates the outcome feature from the data.,
"def wait_for_consumers(self, timeout):
        """"""Wait until some consumer shows up (without wasting resources).

        Returns True if the wait was successful, False if the timeout expired.

        """"""
        return bool(lib.lsl_wait_for_consumers(self.obj, c_double(timeout)))","Wait until some consumer shows up (without wasting resources).

        Returns True if the wait was successful, False if the timeout expired.",
"def child(self, name):
        """"""Get a child with a specified name.""""""
        return XMLElement(lib.lsl_child(self.e, str.encode(name)))",Get a child with a specified name.,
"def next_sibling(self, name=None):
        """"""Get the next sibling in the children list of the parent node.

        If a name is provided, the next sibling with the given name is returned.

        """"""
        if name is None:
            return XMLElement(lib.lsl_next_sibling(self.e))
        else:
            return XMLElement(lib.lsl_next_sibling_n(self.e, str.encode(name)))","Get the next sibling in the children list of the parent node.

        If a name is provided, the next sibling with the given name is returned.",
"def append_child_value(self, name, value):
        """"""Append a child node with a given name, which has a (nameless) 
        plain-text child with the given text value.""""""
        return XMLElement(lib.lsl_append_child_value(self.e,
                                                     str.encode(name),
                                                     str.encode(value)))","Append a child node with a given name, which has a (nameless) 
        plain-text child with the given text value.",
"def prepend_child_value(self, name, value):
        """"""Prepend a child node with a given name, which has a (nameless) 
        plain-text child with the given text value.""""""
        return XMLElement(lib.lsl_prepend_child_value(self.e,
                                                      str.encode(name),
                                                      str.encode(value)))","Prepend a child node with a given name, which has a (nameless) 
        plain-text child with the given text value.",
"def set_child_value(self, name, value):
        """"""Set the text value of the (nameless) plain-text child of a named 
        child node.""""""
        return XMLElement(lib.lsl_set_child_value(self.e,
                                                  str.encode(name),
                                                  str.encode(value)))","Set the text value of the (nameless) plain-text child of a named 
        child node.",
"def set_name(self, name):
        """"""Set the element's name. Returns False if the node is empty.""""""
        return bool(lib.lsl_set_name(self.e, str.encode(name)))",Set the element's name. Returns False if the node is empty.,
"def set_value(self, value):
        """"""Set the element's value. Returns False if the node is empty.""""""
        return bool(lib.lsl_set_value(self.e, str.encode(value)))",Set the element's value. Returns False if the node is empty.,
"def append_child(self, name):
        """"""Append a child element with the specified name.""""""
        return XMLElement(lib.lsl_append_child(self.e, str.encode(name)))",Append a child element with the specified name.,
"def prepend_child(self, name):
        """"""Prepend a child element with the specified name.""""""
        return XMLElement(lib.lsl_prepend_child(self.e, str.encode(name)))",Prepend a child element with the specified name.,
"def append_copy(self, elem):
        """"""Append a copy of the specified element as a child.""""""
        return XMLElement(lib.lsl_append_copy(self.e, elem.e))",Append a copy of the specified element as a child.,
"def prepend_copy(self, elem):
        """"""Prepend a copy of the specified element as a child.""""""
        return XMLElement(lib.lsl_prepend_copy(self.e, elem.e))",Prepend a copy of the specified element as a child.,
"def remove_child(self, rhs):
        """"""Remove a given child element, specified by name or as element.""""""
        if type(rhs) is XMLElement:
            lib.lsl_remove_child(self.e, rhs.e)
        else:
            lib.lsl_remove_child_n(self.e, rhs)","Remove a given child element, specified by name or as element.",
"def pair(cmd, word):
    """"""See all token associated with a given token.
    PAIR lilas""""""
    word = list(preprocess_query(word))[0]
    key = pair_key(word)
    tokens = [t.decode() for t in DB.smembers(key)]
    tokens.sort()
    print(white(tokens))
    print(magenta('(Total: {})'.format(len(tokens))))","See all token associated with a given token.
    PAIR lilas",
"def do_AUTOCOMPLETE(cmd, s):
    """"""Shows autocomplete results for a given token.""""""
    s = list(preprocess_query(s))[0]
    keys = [k.decode() for k in DB.smembers(edge_ngram_key(s))]
    print(white(keys))
    print(magenta('({} elements)'.format(len(keys))))",Shows autocomplete results for a given token.,
"def compute_edge_ngrams(token, min=None):
    """"""Compute edge ngram of token from min. Does not include token itself.""""""
    if min is None:
        min = config.MIN_EDGE_NGRAMS
    token = token[:config.MAX_EDGE_NGRAMS + 1]
    return [token[:i] for i in range(min, len(token))]",Compute edge ngram of token from min. Does not include token itself.,
"def iter_pipe(pipe, processors):
    """"""Allow for iterators to return either an item or an iterator of items.""""""
    if isinstance(pipe, str):
        pipe = [pipe]
    for it in processors:
        pipe = it(pipe)
    yield from pipe",Allow for iterators to return either an item or an iterator of items.,
"def import_by_path(path):
    """"""
    Import functions or class by their path. Should be of the form:
    path.to.module.func
    """"""
    if not isinstance(path, str):
        return path
    module_path, *name = path.rsplit('.', 1)
    func = import_module(module_path)
    if name:
        func = getattr(func, name[0])
    return func","Import functions or class by their path. Should be of the form:
    path.to.module.func",
"def do_fuzzy(self, word):
    """"""Compute fuzzy extensions of word.
    FUZZY lilas""""""
    word = list(preprocess_query(word))[0]
    print(white(make_fuzzy(word)))","Compute fuzzy extensions of word.
    FUZZY lilas",
"def do_BENCH(self, query):
        """"""Run a search many times to benchmark it.
        BENCH [100] rue des Lilas""""""
        try:
            count = int(re.match(r'^(\d+).*', query).group(1))
        except AttributeError:
            count = 100
        self._search(query, count=count)","Run a search many times to benchmark it.
        BENCH [100] rue des Lilas",
"def do_DBKEY(self, key):
        """"""Print raw content of a DB key.
        DBKEY g|u09tyzfe""""""
        type_ = DB.type(key).decode()
        if type_ == 'set':
            out = DB.smembers(key)
        elif type_ == 'string':
            out = DB.get(key)
        else:
            out = 'Unsupported type {}'.format(type_)
        print('type:', magenta(type_))
        print('value:', white(out))","Print raw content of a DB key.
        DBKEY g|u09tyzfe",
"def do_GEOHASH(self, latlon):
        """"""Compute a geohash from latitude and longitude.
        GEOHASH 48.1234 2.9876""""""
        try:
            lat, lon = map(float, latlon.split())
        except ValueError:
            print(red('Invalid lat and lon {}'.format(latlon)))
        else:
            print(white(geohash.encode(lat, lon, config.GEOHASH_PRECISION)))","Compute a geohash from latitude and longitude.
        GEOHASH 48.1234 2.9876",
"def do_INDEX(self, _id):
        """"""Get index details for a document by its id.
        INDEX 772210180J""""""
        doc = doc_by_id(_id)
        if not doc:
            return self.error('id ""{}"" not found'.format(_id))
        for field in config.FIELDS:
            key = field['key']
            if key in doc:
                self._print_field_index_details(doc[key], _id)","Get index details for a document by its id.
        INDEX 772210180J",
"def do_BESTSCORE(self, word):
        """"""Return document linked to word with higher score.
        BESTSCORE lilas""""""
        key = keys.token_key(indexed_string(word)[0])
        for _id, score in DB.zrevrange(key, 0, 20, withscores=True):
            result = Result(_id)
            print(white(result), blue(score), green(result._id))","Return document linked to word with higher score.
        BESTSCORE lilas",
"def do_REVERSE(self, latlon):
        """"""Do a reverse search. Args: lat lon.
        REVERSE 48.1234 2.9876""""""
        lat, lon = latlon.split()
        for r in reverse(float(lat), float(lon)):
            print('{} ({} | {} km | {})'.format(white(r), blue(r.score),
                                                blue(r.distance), blue(r._id)))","Do a reverse search. Args: lat lon.
        REVERSE 48.1234 2.9876",
"def do_STRDISTANCE(self, s):
        """"""Print the distance score between two strings. Use |as separator.
        STRDISTANCE rue des lilas|porte des lilas""""""
        s = s.split('|')
        if not len(s) == 2:
            print(red('Malformed string. Use | between the two strings.'))
            return
        one, two = s
        print(white(compare_str(one, two)))","Print the distance score between two strings. Use |as separator.
        STRDISTANCE rue des lilas|porte des lilas",
"def do_CONFIG(self, name):
        """"""Inspect loaded Addok config. Output all config without argument.
        CONFIG [CONFIG_KEY]""""""
        if not name:
            for name in self.complete_CONFIG():
                self.do_CONFIG(name)
            return
        value = getattr(config, name.upper(), 'Not found.')
        print(blue(name), white(format_config(value)))","Inspect loaded Addok config. Output all config without argument.
        CONFIG [CONFIG_KEY]",
"def send(r, stream=False):
    """"""Just sends the request using its send method and returns its response.  """"""
    r.send(stream=stream)
    return r.response",Just sends the request using its send method and returns its response.,
"def getBusWordBitRange(self) -> Tuple[int, int]:
        """"""
        :return: bit range which contains data of this part on bus data signal
        """"""
        offset = self.startOfPart % self.parent.wordWidth
        return (offset + self.bit_length(), offset)",:return: bit range which contains data of this part on bus data signal,
"def getFieldBitRange(self) -> Tuple[int, int]:
        """"""
        :return: bit range which contains data of this part on interface
            of field
        """"""
        offset = self.inFieldOffset
        return (self.bit_length() + offset, offset)",":return: bit range which contains data of this part on interface
            of field",
"def In(sigOrVal, iterable):
    """"""
    Hdl convertible in operator, check if any of items
    in ""iterable"" equals ""sigOrVal""
    """"""
    res = None
    for i in iterable:
        i = toHVal(i)
        if res is None:
            res = sigOrVal._eq(i)
        else:
            res = res | sigOrVal._eq(i)

    assert res is not None, ""Parameter iterable is empty""
    return res","Hdl convertible in operator, check if any of items
    in ""iterable"" equals ""sigOrVal""",
"def rol(sig, howMany) -> RtlSignalBase:
    ""Rotate left""
    width = sig._dtype.bit_length()
    return sig[(width - howMany):]._concat(sig[:(width - howMany)])",Rotate left,
"def sll(sig, howMany) -> RtlSignalBase:
    ""Logical shift left""
    width = sig._dtype.bit_length()
    return sig[(width - howMany):]._concat(vec(0, howMany))",Logical shift left,
"def log2ceil(x):
    """"""
    Returns no of bits required to store x-1
    for example x=8 returns 3
    """"""

    if not isinstance(x, (int, float)):
        x = int(x)

    if x == 0 or x == 1:
        res = 1
    else:
        res = math.ceil(math.log2(x))

    return hInt(res)","Returns no of bits required to store x-1
    for example x=8 returns 3",
"def isPow2(num) -> bool:
    """"""
    Check if number or constant is power of two
    """"""
    if not isinstance(num, int):
        num = int(num)
    return num != 0 and ((num & (num - 1)) == 0)",Check if number or constant is power of two,
"def addCases(self, tupesValStmnts):
        """"""
        Add multiple case statements from iterable of tuleles
        (caseVal, statements)
        """"""
        s = self
        for val, statements in tupesValStmnts:
            s = s.Case(val, statements)
        return s","Add multiple case statements from iterable of tuleles
        (caseVal, statements)",
"def Default(self, *statements):
        """"""c-like default of switch statement
        """"""
        assert self.parentStm is None
        self.rank += 1
        self.default = []
        self._register_stements(statements, self.default)
        return self",c-like default of switch statement,
"def vcdTypeInfoForHType(t) -> Tuple[str, int, Callable[[RtlSignalBase, Value], str]]:
    """"""
    :return: (vcd type name, vcd width)
    """"""
    if isinstance(t, (SimBitsT, Bits, HBool)):
        return (VCD_SIG_TYPE.WIRE, t.bit_length(), vcdBitsFormatter)
    elif isinstance(t, HEnum):
        return (VCD_SIG_TYPE.REAL, 1, vcdEnumFormatter)
    else:
        raise ValueError(t)",":return: (vcd type name, vcd width)",
"def beforeSim(self, simulator, synthesisedUnit):
        """"""
        This method is called before first step of simulation.
        """"""
        vcd = self.vcdWriter
        vcd.date(datetime.now())
        vcd.timescale(1)

        self.vcdRegisterInterfaces(synthesisedUnit, None)
        self.vcdRegisterRemainingSignals(synthesisedUnit)

        vcd.enddefinitions()",This method is called before first step of simulation.,
"def logChange(self, nowTime, sig, nextVal):
        """"""
        This method is called for every value change of any signal.
        """"""
        try:
            self.vcdWriter.logChange(nowTime, sig, nextVal)
        except KeyError:
            # not every signal has to be registered
            pass",This method is called for every value change of any signal.,
"def setLevel(self, lvl):
        """"""
        Trim or extend scope
        lvl = 1 -> only one scope (global)
        """"""
        while len(self) != lvl:
            if len(self) > lvl:
                self.pop()
            else:
                self.append(NameScopeItem(len(self)))","Trim or extend scope
        lvl = 1 -> only one scope (global)",
"def _size(self):
        """"""
        :return: how many bits is this slice selecting
        """"""
        assert isinstance(self, Value)
        return int(self.val[0]) - int(self.val[1])",:return: how many bits is this slice selecting,
"def valuesToInts(values):
    """"""
    Iterable of values to ints (nonvalid = None)
    """"""
    res = []
    append = res.append
    for d in values:
        if isinstance(d, int):
            append(d)
        else:
            append(valToInt(d))
    return res",Iterable of values to ints (nonvalid = None),
"def Architecture_var(cls, v, serializerVars, extraTypes,
                         extraTypes_serialized, ctx, childCtx):
        """"""
        :return: list of extra discovered processes
        """"""
        v.name = ctx.scope.checkedName(v.name, v)
        serializedVar = cls.SignalItem(v, childCtx, declaration=True)
        serializerVars.append(serializedVar)",:return: list of extra discovered processes,
"def distinctBy(iterable, fn):
    """"""
    uniq operation with key selector
    """"""
    s = set()
    for i in iterable:
        r = fn(i)
        if r not in s:
            s.add(r)
            yield i",uniq operation with key selector,
"def take(iterrable, howMay):
    """"""
    :return: generator of first n items from iterrable
    """"""
    assert howMay >= 0

    if not howMay:
        return

    last = howMay - 1
    for i, item in enumerate(iterrable):
        yield item
        if i == last:
            return",:return: generator of first n items from iterrable,
"def iter_with_last(iterable):
    """"""
    :return: generator of tuples (isLastFlag, item)
    """"""
    # Ensure it's an iterator and get the first field
    iterable = iter(iterable)
    prev = next(iterable)
    for item in iterable:
        # Lag by one item so I know I'm not at the end
        yield False, prev
        prev = item
    # Last item
    yield True, prev",":return: generator of tuples (isLastFlag, item)",
"def _iter_stms(self):
        """"""
        Doc on parent class :meth:`HdlStatement._iter_stms`
        """"""
        yield from self.ifTrue
        for _, stms in self.elIfs:
            yield from stms
        if self.ifFalse is not None:
            yield from self.ifFalse",Doc on parent class :meth:`HdlStatement._iter_stms`,
"def _merge_nested_if_from_else(self, ifStm: ""IfContainer""):
        """"""
        Merge nested IfContarner form else branch to this IfContainer
        as elif and else branches
        """"""
        self.elIfs.append((ifStm.cond, ifStm.ifTrue))
        self.elIfs.extend(ifStm.elIfs)

        self.ifFalse = ifStm.ifFalse","Merge nested IfContarner form else branch to this IfContainer
        as elif and else branches",
"def checkIfIsTooSimple(proc):
    """"""check if process is just unconditional assignments
       and it is useless to merge them""""""
    try:
        a, = proc.statements
        if isinstance(a, Assignment):
            return True
    except ValueError:
        pass
    return False","check if process is just unconditional assignments
       and it is useless to merge them",
"def onWriteReq(self, sim, addr, data):
        """"""
        on writeReqRecieved in monitor mode
        """"""
        self.requests.append((WRITE, addr, data))",on writeReqRecieved in monitor mode,
"def getMaxStmIdForStm(stm):
    """"""
    Get maximum _instId from all assigments in statement
    """"""
    maxId = 0
    if isinstance(stm, Assignment):
        return stm._instId
    elif isinstance(stm, WaitStm):
        return maxId
    else:
        for _stm in stm._iter_stms():
            maxId = max(maxId, getMaxStmIdForStm(_stm))
        return maxId",Get maximum _instId from all assigments in statement,
"def maxStmId(proc):
    """"""
    get max statement id,
    used for sorting of processes in architecture
    """"""
    maxId = 0
    for stm in proc.statements:
        maxId = max(maxId, getMaxStmIdForStm(stm))
    return maxId","get max statement id,
    used for sorting of processes in architecture",
"def monitor(self, sim):
        """"""Collect data from interface""""""
        if self.notReset(sim) and self._enabled:
            self.wrRd(sim.write, 1)

            yield sim.waitOnCombUpdate()

            d = self.doRead(sim)
            self.data.append(d)
        else:
            self.wrRd(sim.write, 0)",Collect data from interface,
"def doWrite(self, sim, data):
        """"""write data to interface""""""
        sim.write(data, self.intf.data)",write data to interface,
"def _m(self):
        """"""
        Note that this interface will be master

        :return: self
        """"""
        assert not hasattr(self, ""_interfaces"") or not self._interfaces, \
            ""Too late to change direction of interface""
        self._direction = DIRECTION.asIntfDirection(DIRECTION.opposite(self._masterDir))

        return self","Note that this interface will be master

        :return: self",
"def _getPhysicalName(self):
        """"""Get name in HDL """"""
        if hasattr(self, ""_boundedEntityPort""):
            return self._boundedEntityPort.name
        else:
            return self._getFullName().replace('.', self._NAME_SEPARATOR)",Get name in HDL,
"def _updateParamsFrom(self, otherObj, updater=_default_param_updater,
                          exclude=None, prefix=""""):
        """"""
        :note: doc in :func:`~hwt.synthesizer.interfaceLevel.propDeclCollector._updateParamsFrom`
        """"""
        PropDeclrCollector._updateParamsFrom(self, otherObj, updater, exclude, prefix)",:note: doc in :func:`~hwt.synthesizer.interfaceLevel.propDeclCollector._updateParamsFrom`,
"def _connectTo(self, master, exclude=None, fit=False):
        """"""
        connect to another interface interface (on rtl level)
        works like self <= master in VHDL
        """"""
        return list(self._connectToIter(master, exclude, fit))","connect to another interface interface (on rtl level)
        works like self <= master in VHDL",
"def sensitivityByOp(op):
    """"""
    get sensitivity type for operator
    """"""
    if op == AllOps.RISING_EDGE:
        return SENSITIVITY.RISING
    elif op == AllOps.FALLING_EDGE:
        return SENSITIVITY.FALLING
    else:
        raise TypeError()",get sensitivity type for operator,
"def fullWordCnt(self, start: int, end: int):
        """"""Count of complete words between two addresses
        """"""
        assert end >= start, (start, end)
        gap = max(0, (end - start) - (start % self.wordWidth))
        return gap // self.wordWidth",Count of complete words between two addresses,
"def isSameHVal(a: Value, b: Value) -> bool:
    """"""
    :return: True if two Value instances are same
    :note: not just equal
    """"""
    return a is b or (isinstance(a, Value)
                      and isinstance(b, Value)
                      and a.val == b.val
                      and a.vldMask == b.vldMask)",":return: True if two Value instances are same
    :note: not just equal",
"def statementsAreSame(statements: List[HdlStatement]) -> bool:
    """"""
    :return: True if all statements are same
    """"""
    iterator = iter(statements)
    try:
        first = next(iterator)
    except StopIteration:
        return True

    return all(first.isSame(rest) for rest in iterator)",:return: True if all statements are same,
"def _get_stm_with_branches(stm_it):
    """"""
    :return: first statement with rank > 0 or None if iterator empty
    """"""
    last = None
    while last is None or last.rank == 0:
        try:
            last = next(stm_it)
        except StopIteration:
            last = None
            break

    return last",:return: first statement with rank > 0 or None if iterator empty,
"def _clean_signal_meta(self):
        """"""
        Clean informations about enclosure for outputs and sensitivity
        of this statement
        """"""
        self._enclosed_for = None
        self._sensitivity = None
        for stm in self._iter_stms():
            stm._clean_signal_meta()","Clean informations about enclosure for outputs and sensitivity
        of this statement",
"def _collect_io(self) -> None:
        """"""
        Collect inputs/outputs from all child statements
        to :py:attr:`~_input` / :py:attr:`_output` attribure on this object
        """"""
        in_add = self._inputs.extend
        out_add = self._outputs.extend

        for stm in self._iter_stms():
            in_add(stm._inputs)
            out_add(stm._outputs)","Collect inputs/outputs from all child statements
        to :py:attr:`~_input` / :py:attr:`_output` attribure on this object",
"def _on_parent_event_dependent(self):
        """"""
        After parrent statement become event dependent
        propagate event dependency flag to child statements
        """"""
        if not self._is_completly_event_dependent:
            self._is_completly_event_dependent = True
            for stm in self._iter_stms():
                stm._on_parent_event_dependent()","After parrent statement become event dependent
        propagate event dependency flag to child statements",
"def _register_stements(self, statements: List[""HdlStatement""],
                           target: List[""HdlStatement""]):
        """"""
        Append statements to this container under conditions specified
        by condSet
        """"""
        for stm in flatten(statements):
            assert stm.parentStm is None, stm
            stm._set_parent_stm(self)
            target.append(stm)","Append statements to this container under conditions specified
        by condSet",
"def _cleanAsSubunit(self):
        """"""Disconnect internal signals so unit can be reused by parent unit""""""
        for pi in self._entity.ports:
            pi.connectInternSig()
        for i in chain(self._interfaces, self._private_interfaces):
            i._clean()",Disconnect internal signals so unit can be reused by parent unit,
"def vec(val, width, signed=None):
    """"""create hdl vector value""""""
    return Bits(width, signed, forceVector=True).fromPy(val)",create hdl vector value,
"def evalParam(p):
    """"""
    Get value of parameter
    """"""
    while isinstance(p, Param):
        p = p.get()

    if isinstance(p, RtlSignalBase):
        return p.staticEval()
        # use rather param inheritance instead of param as param value
    return toHVal(p)",Get value of parameter,
"def _eq(self, other):
        """"""
        __eq__ is not overloaded because it will destroy hashability of object
        """"""
        return self.naryOp(AllOps.EQ, tv(self)._eq, other)",__eq__ is not overloaded because it will destroy hashability of object,
"def fromPy(self, v, vldMask=None):
        """"""
        Construct value of this type.
        Delegated on value class for this type
        """"""
        return self.getValueCls().fromPy(v, self, vldMask=vldMask)","Construct value of this type.
        Delegated on value class for this type",
"def walkParams(intf, discovered):
    """"""
    walk parameter instances on this interface
    """"""
    for si in intf._interfaces:
        yield from walkParams(si, discovered)

    for p in intf._params:
        if p not in discovered:
            discovered.add(p)
            yield p",walk parameter instances on this interface,
"def _registerIntfInImpl(self, iName, intf):
        """"""
        Register interface in implementation phase
        """"""
        self._registerInterface(iName, intf, isPrivate=True)
        self._loadInterface(intf, False)
        intf._signalsForInterface(self._ctx)",Register interface in implementation phase,
"def reverseByteOrder(signalOrVal):
    """"""
    Reverse byteorder (littleendian/bigendian) of signal or value
    """"""
    w = signalOrVal._dtype.bit_length()
    i = w
    items = []

    while i > 0:
        # take last 8 bytes or rest
        lower = max(i - 8, 0)
        items.append(signalOrVal[i:lower])
        i -= 8

    return Concat(*items)",Reverse byteorder (littleendian/bigendian) of signal or value,
"def tryReduceAnd(sig, val):
    """"""
    Return sig and val reduced by & operator or None
    if it is not possible to statically reduce expression
    """"""
    m = sig._dtype.all_mask()
    if val._isFullVld():
        v = val.val
        if v == m:
            return sig
        elif v == 0:
            return val","Return sig and val reduced by & operator or None
    if it is not possible to statically reduce expression",
"def tryReduceXor(sig, val):
    """"""
    Return sig and val reduced by ^ operator or None
    if it is not possible to statically reduce expression
    """"""
    m = sig._dtype.all_mask()
    if not val.vldMask:
        return val

    if val._isFullVld():
        v = val.val
        if v == m:
            return ~sig
        elif v == 0:
            return sig","Return sig and val reduced by ^ operator or None
    if it is not possible to statically reduce expression",
"def getBaseNameScope(cls):
        """"""
        Get root of name space
        """"""
        s = NameScope(False)
        s.setLevel(1)
        s[0].update(cls._keywords_dict)
        return s",Get root of name space,
"def Entity(cls, ent: Entity, ctx: SerializerCtx):
        """"""
        Entity is just forward declaration of Architecture, it is not used
        in most HDL languages as there is no recursion in hierarchy
        """"""

        ent.name = ctx.scope.checkedName(ent.name, ent, isGlobal=True)
        return """"","Entity is just forward declaration of Architecture, it is not used
        in most HDL languages as there is no recursion in hierarchy",
"def pullDownAfter(sig, initDelay=6 * Time.ns):
    """"""
    :return: simulation driver which keeps signal value high for initDelay
        then it sets value to 0
    """"""
    def _pullDownAfter(s):
        s.write(True, sig)
        yield s.wait(initDelay)
        s.write(False, sig)

    return _pullDownAfter",":return: simulation driver which keeps signal value high for initDelay
        then it sets value to 0",
"def simBitsT(width: int, signed: Union[bool, None]):
    """"""
    Construct SimBitsT with cache
    """"""
    k = (width, signed)
    try:
        return __simBitsTCache[k]
    except KeyError:
        t = SimBitsT(width, signed)
        __simBitsTCache[k] = t
        return t",Construct SimBitsT with cache,
"def VectSignal(width,
               signed=None,
               masterDir=D.OUT,
               loadConfig=True):
    """"""
    Create basic :class:`.Signal` interface where type is vector
    """"""
    return Signal(masterDir,
                  Bits(width, signed, forceVector=True),
                  loadConfig)",Create basic :class:`.Signal` interface where type is vector,
"def _cut_off_drivers_of(self, sig: RtlSignalBase):
        """"""
        Cut off statements which are driver of specified signal
        """"""
        if self.dst is sig:
            self.parentStm = None
            return self
        else:
            return None",Cut off statements which are driver of specified signal,
"def _loadFromArray(self, dtype: HdlType, bitAddr: int) -> int:
        """"""
        Parse HArray type to this transaction template instance

        :return: address of it's end
        """"""
        self.itemCnt = evalParam(dtype.size).val
        self.children = TransTmpl(
            dtype.elmType, 0, parent=self, origin=self.origin)
        return bitAddr + self.itemCnt * self.children.bitAddrEnd","Parse HArray type to this transaction template instance

        :return: address of it's end",
"def _loadFromUnion(self, dtype: HdlType, bitAddr: int) -> int:
        """"""
        Parse HUnion type to this transaction template instance

        :return: address of it's end
        """"""
        for field in dtype.fields.values():
            ch = TransTmpl(field.dtype, 0, parent=self, origin=field)
            self.children.append(ch)
        return bitAddr + dtype.bit_length()","Parse HUnion type to this transaction template instance

        :return: address of it's end",
"def _loadFromHStream(self, dtype: HStream, bitAddr: int) -> int:
        """"""
        Parse HUnion type to this transaction template instance

        :return: address of it's end
        """"""
        ch = TransTmpl(dtype.elmType, 0, parent=self, origin=self.origin)
        self.children.append(ch)
        return bitAddr + dtype.elmType.bit_length()","Parse HUnion type to this transaction template instance

        :return: address of it's end",
"def getItemWidth(self) -> int:
        """"""
        Only for transactions derived from HArray

        :return: width of item in original array
        """"""
        if not isinstance(self.dtype, HArray):
            raise TypeError()
        return (self.bitAddrEnd - self.bitAddr) // self.itemCnt","Only for transactions derived from HArray

        :return: width of item in original array",
"def signFix(val, width):
    """"""
    Convert negative int to positive int which has same bits set
    """"""
    if val > 0:
        msb = 1 << (width - 1)
        if val & msb:
            val -= mask(width) + 1
    return val",Convert negative int to positive int which has same bits set,
"def _iter_stms(self):
        """"""
        Doc on parent class :meth:`HdlStatement._iter_stms`
        """"""
        for _, stms in self.cases:
            yield from stms

        if self.default is not None:
            yield from self.default",Doc on parent class :meth:`HdlStatement._iter_stms`,
"def getIndent(indentNum):
    """"""
    Cached indent getter function
    """"""
    try:
        return _indentCache[indentNum]
    except KeyError:
        i = """".join([_indent for _ in range(indentNum)])
        _indentCache[indentNum] = i
        return i",Cached indent getter function,
"def serializeType(self, hdlType: HdlType) -> str:
        """"""
        :see: doc of method on parent class
        """"""

        def createTmpVar(suggestedName, dtype):
            raise NotImplementedError(
                ""Can not seraialize hdl type %r into""
                ""ipcore format"" % (hdlType))

        return VhdlSerializer.HdlType(hdlType, VhdlSerializer.getBaseContext())",:see: doc of method on parent class,
"def getVectorFromType(self, dtype) -> Union[bool, None, Tuple[int, int]]:
        """"""
        :see: doc of method on parent class
        """"""
        if dtype == BIT:
            return False
        elif isinstance(dtype, Bits):
            return [evalParam(dtype.width) - 1, hInt(0)]",:see: doc of method on parent class,
"def getTypeWidth(self, dtype: HdlType, do_eval=False) -> Tuple[int, Union[int, RtlSignal], bool]:
        """"""
        :see: doc of method on parent class
        """"""
        width = dtype.width
        if isinstance(width, int):
            widthStr = str(width)
        else:
            widthStr = self.getExprVal(width, do_eval=do_eval)

        return width, widthStr, False",:see: doc of method on parent class,
"def getObjDebugName(self, obj: Union[Interface, Unit, Param]) -> str:
        """"""
        :see: doc of method on parent class
        """"""
        return obj._getFullName()",:see: doc of method on parent class,
"def nameAvailabilityCheck(obj, propName, prop):
    """"""
    Check if not redefining property on obj
    """"""
    if getattr(obj, propName, None) is not None:
        raise IntfLvlConfErr(""%r already has property %s old:%s new:%s"" % 
                             (obj, propName, repr(getattr(obj, propName)), prop))",Check if not redefining property on obj,
"def _make_association(self, clk=None, rst=None) -> None:
        """"""
        Associate this object with specified clk/rst
        """"""
        if clk is not None:
            assert self._associatedClk is None
            self._associatedClk = clk

        if rst is not None:
            assert self._associatedRst is None
            self._associatedRst = rst",Associate this object with specified clk/rst,
"def _registerUnit(self, uName, unit):
        """"""
        Register unit object on interface level object
        """"""
        nameAvailabilityCheck(self, uName, unit)
        assert unit._parent is None
        unit._parent = self
        unit._name = uName
        self._units.append(unit)",Register unit object on interface level object,
"def _registerArray(self, name, items):
        """"""
        Register array of items on interface level object
        """"""
        items._parent = self
        items._name = name
        for i, item in enumerate(items):
            setattr(self, ""%s_%d"" % (name, i), item)",Register array of items on interface level object,
"def _registerUnitInImpl(self, uName, u):
        """"""
        :attention: unit has to be parametrized before it is registered
            (some components can change interface by parametrization)
        """"""
        self._registerUnit(uName, u)
        u._loadDeclarations()
        self._lazyLoaded.extend(u._toRtl(self._targetPlatform))
        u._signalsForMyEntity(self._ctx, ""sig_"" + uName)",":attention: unit has to be parametrized before it is registered
            (some components can change interface by parametrization)",
"def singleDriver(self):
        """"""
        Returns a first driver if signal has only one driver.
        """"""
        # [TODO] no driver exception
        drv_cnt = len(self.drivers)
        if not drv_cnt:
            raise NoDriverErr(self)
        elif drv_cnt != 1:
            raise MultipleDriversErr(self)

        return self.drivers[0]",Returns a first driver if signal has only one driver.,
"def staticEval(self):
        """"""
        Recursively statistically evaluate result of this operator
        """"""
        for o in self.operands:
            o.staticEval()
        self.result._val = self.evalFn()",Recursively statistically evaluate result of this operator,
"def withIndent(self, indent=1):
        """"""
        Create copy of this context with increased indent
        """"""
        ctx = copy(self)
        ctx.indent += indent
        return ctx",Create copy of this context with increased indent,
"def _tryConnect(src, unit, intfName):
    """"""
    Try connect src to interface of specified name on unit.
    Ignore if interface is not present or if it already has driver.
    """"""
    try:
        dst = getattr(unit, intfName)
    except AttributeError:
        return
    if not dst._sig.drivers:
        connect(src, dst)","Try connect src to interface of specified name on unit.
    Ignore if interface is not present or if it already has driver.",
"def propagateClk(obj):
    """"""
    Propagate ""clk"" clock signal to all subcomponents
    """"""
    clk = obj.clk
    for u in obj._units:
        _tryConnect(clk, u, 'clk')","Propagate ""clk"" clock signal to all subcomponents",
"def propagateClkRstn(obj):
    """"""
    Propagate ""clk"" clock and negative reset ""rst_n"" signal
    to all subcomponents
    """"""
    clk = obj.clk
    rst_n = obj.rst_n

    for u in obj._units:
        _tryConnect(clk, u, 'clk')
        _tryConnect(rst_n, u, 'rst_n')
        _tryConnect(~rst_n, u, 'rst')","Propagate ""clk"" clock and negative reset ""rst_n"" signal
    to all subcomponents",
"def propagateClkRst(obj):
    """"""
    Propagate ""clk"" clock and reset ""rst"" signal to all subcomponents
    """"""
    clk = obj.clk
    rst = obj.rst

    for u in obj._units:
        _tryConnect(clk, u, 'clk')
        _tryConnect(~rst, u, 'rst_n')
        _tryConnect(rst, u, 'rst')","Propagate ""clk"" clock and reset ""rst"" signal to all subcomponents",
"def propagateRstn(obj):
    """"""
    Propagate negative reset ""rst_n"" signal
    to all subcomponents
    """"""
    rst_n = obj.rst_n

    for u in obj._units:
        _tryConnect(rst_n, u, 'rst_n')
        _tryConnect(~rst_n, u, 'rst')","Propagate negative reset ""rst_n"" signal
    to all subcomponents",
"def propagateRst(obj):
    """"""
    Propagate reset ""rst"" signal
    to all subcomponents
    """"""
    rst = obj.rst

    for u in obj._units:
        _tryConnect(~rst, u, 'rst_n')
        _tryConnect(rst, u, 'rst')","Propagate reset ""rst"" signal
    to all subcomponents",
"def get(self, numberOfBits: int) -> Union[RtlSignal, Value]:
        """"""
        :param numberOfBits: number of bits to get from actual possition
        :return: chunk of bits of specified size (instance of Value or RtlSignal)
        """"""
        return self._get(numberOfBits, True)",":param numberOfBits: number of bits to get from actual possition
        :return: chunk of bits of specified size (instance of Value or RtlSignal)",
"def _make_association(self, *args, **kwargs):
        """"""
        Delegate _make_association on items

        :note: doc in :func:`~hwt.synthesizer.interfaceLevel.propDeclCollector._make_association`
        """"""
        for o in self:
            o._make_association(*args, **kwargs)","Delegate _make_association on items

        :note: doc in :func:`~hwt.synthesizer.interfaceLevel.propDeclCollector._make_association`",
"def _updateParamsFrom(self, *args, **kwargs):
        """"""
        :note: doc in :func:`~hwt.synthesizer.interfaceLevel.propDeclCollector._updateParamsFrom`
        """"""
        for o in self:
            o._updateParamsFrom(*args, **kwargs)",:note: doc in :func:`~hwt.synthesizer.interfaceLevel.propDeclCollector._updateParamsFrom`,
"def connectInternSig(self):
        """"""
        connet signal from internal side of of this component to this port
        """"""
        d = self.direction
        if d == DIRECTION.OUT:
            self.src.endpoints.append(self)
        elif d == DIRECTION.IN or d == DIRECTION.INOUT:
            self.dst.drivers.append(self)
        else:
            raise NotImplementedError(d)",connet signal from internal side of of this component to this port,
"def getInternSig(self):
        """"""
        return signal inside unit which has this port
        """"""
        d = self.direction
        if d == DIRECTION.IN:
            return self.dst
        elif d == DIRECTION.OUT:
            return self.src
        else:
            raise NotImplementedError(d)",return signal inside unit which has this port,
"def isEvDependentOn(sig, process) -> bool:
    """"""
    Check if hdl process has event depenency on signal
    """"""
    if sig is None:
        return False

    return process in sig.simFallingSensProcs\
        or process in sig.simRisingSensProcs",Check if hdl process has event depenency on signal,
"def _add_process(self, proc, priority) -> None:
        """"""
        Schedule process on actual time with specified priority
        """"""
        self._events.push(self.now, priority, proc)",Schedule process on actual time with specified priority,
"def read(self, sig) -> Value:
        """"""
        Read value from signal or interface
        """"""
        try:
            v = sig._val
        except AttributeError:
            v = sig._sigInside._val

        return v.clone()",Read value from signal or interface,
"def add_process(self, proc) -> None:
        """"""
        Add process to events with default priority on current time
        """"""
        self._events.push(self.now, PRIORITY_NORMAL, proc)",Add process to events with default priority on current time,
"def systemCTypeOfSig(signalItem):
    """"""
    Check if is register or wire
    """"""
    if signalItem._const or\
       arr_any(signalItem.drivers,
               lambda d: isinstance(d, HdlStatement)
               and d._now_is_event_dependent):

        return SIGNAL_TYPE.REG
    else:
        return SIGNAL_TYPE.WIRE",Check if is register or wire,
"def hash_distance(left_hash, right_hash):
    """"""Compute the hamming distance between two hashes""""""
    if len(left_hash) != len(right_hash):
        raise ValueError('Hamming distance requires two strings of equal length')

    return sum(map(lambda x: 0 if x[0] == x[1] else 1, zip(left_hash, right_hash)))",Compute the hamming distance between two hashes,
"def distance(image_path, other_image_path):
    """""" Compute the hamming distance between two images""""""
    image_hash = average_hash(image_path)
    other_image_hash = average_hash(other_image_path)

    return hash_distance(image_hash, other_image_hash)",Compute the hamming distance between two images,
"def mute_volume(self, mute):
        """"""Mute the volume.""""""
        if mute:
            self._device.mute_on()
        else:
            self._device.mute_off()",Mute the volume.,
"def volume_up(self):
        """"""Increasing volume of the device.""""""
        self._volume_level += self._volume_step / self._max_volume
        self._device.vol_up(num=self._volume_step)",Increasing volume of the device.,
"def volume_down(self):
        """"""Decreasing volume of the device.""""""
        self._volume_level -= self._volume_step / self._max_volume
        self._device.vol_down(num=self._volume_step)",Decreasing volume of the device.,
"def piece_at(self, square):
        '''Gets the piece at the given square.'''
        mask = BB_SQUARES[square]
        color = int(bool(self.occupied[WHITE] & mask))

        piece_type = self.piece_type_at(square)
        if piece_type:
            return Piece(piece_type, color)",Gets the piece at the given square.,
"def is_suicide_or_check_by_dropping_pawn(self, move):
        '''
        Checks if the given move would move would leave the king in check or
        put it into check.
        '''

        self.push(move)
        is_suicide = self.was_suicide()
        is_check_by_dropping_pawn = self.was_check_by_dropping_pawn(move)
        self.pop()
        return is_suicide or is_check_by_dropping_pawn","Checks if the given move would move would leave the king in check or
        put it into check.",
"def was_suicide(self):
        '''
        Checks if the king of the other side is attacked. Such a position is not
        valid and could only be reached by an illegal move.
        '''
        return self.is_attacked_by(self.turn, self.king_squares[self.turn ^ 1])","Checks if the king of the other side is attacked. Such a position is not
        valid and could only be reached by an illegal move.",
"def is_checkmate(self):
        '''Checks if the current position is a checkmate.'''
        if not self.is_check():
            return False

        try:
            next(self.generate_legal_moves().__iter__())
            return False
        except StopIteration:
            return True",Checks if the current position is a checkmate.,
"def push_usi(self, usi):
        '''
        Parses a move in standard coordinate notation, makes the move and puts
        it on the the move stack.
        Raises `ValueError` if neither legal nor a null move.
        Returns the move.
        '''
        move = Move.from_usi(usi)
        self.push(move)
        return move","Parses a move in standard coordinate notation, makes the move and puts
        it on the the move stack.
        Raises `ValueError` if neither legal nor a null move.
        Returns the move.",
"def symbol(self):
        '''
        Gets the symbol `p`, `l`, `n`, etc.
        '''
        if self.color == BLACK:
            return PIECE_SYMBOLS[self.piece_type].upper()
        else:
            return PIECE_SYMBOLS[self.piece_type]","Gets the symbol `p`, `l`, `n`, etc.",
"def from_symbol(cls, symbol):
        '''
        Creates a piece instance from a piece symbol.
        Raises `ValueError` if the symbol is invalid.
        '''
        if symbol.lower() == symbol:
            return cls(PIECE_SYMBOLS.index(symbol), WHITE)
        else:
            return cls(PIECE_SYMBOLS.index(symbol.lower()), BLACK)","Creates a piece instance from a piece symbol.
        Raises `ValueError` if the symbol is invalid.",
"def execute_from_command_line_with_config(config: GoodConf, argv: List[str]):
    """"""Load's config then runs Django's execute_from_command_line""""""
    with load_config_from_cli(config, argv) as args:
        from django.core.management import execute_from_command_line
        execute_from_command_line(args)",Load's config then runs Django's execute_from_command_line,
"def cast(self, val: str):
        """"""converts string to type requested by `cast_as`""""""
        try:
            return getattr(self, 'cast_as_{}'.format(
                self.cast_as.__name__.lower()))(val)
        except AttributeError:
            return self.cast_as(val)",converts string to type requested by `cast_as`,
"def list_dates_between(first_date, last_date):
    """"""Returns all dates from first to last included.""""""
    return [first_date + timedelta(days=n)
            for n in range(1 + (last_date - first_date).days)]",Returns all dates from first to last included.,
"def parse_date(s):
    """"""Fast %Y-%m-%d parsing.""""""
    try:
        return datetime.date(int(s[:4]), int(s[5:7]), int(s[8:10]))
    except ValueError:  # other accepted format used in one-day data set
        return datetime.datetime.strptime(s, '%d %B %Y').date()",Fast %Y-%m-%d parsing.,
"def grouper(iterable, n, fillvalue=None):
    """"""Group iterable by n elements.

    >>> for t in grouper('abcdefg', 3, fillvalue='x'):
    ...     print(''.join(t))
    abc
    def
    gxx
    """"""
    return list(zip_longest(*[iter(iterable)] * n, fillvalue=fillvalue))","Group iterable by n elements.

    >>> for t in grouper('abcdefg', 3, fillvalue='x'):
    ...     print(''.join(t))
    abc
    def
    gxx",
"def load(self, name):
        """"""[DEPRECATED] Load the polynomial series for `name` and return it.""""""
        s = self.sets.get(name)
        if s is None:
            self.sets[name] = s = np.load(self.path('jpl-%s.npy' % name))
        return s",[DEPRECATED] Load the polynomial series for `name` and return it.,
"def position_from_bundle(self, bundle):
        """"""[DEPRECATED] Return position, given the `coefficient_bundle()` return value.""""""

        coefficients, days_per_set, T, twot1 = bundle
        return (T.T * coefficients).sum(axis=2)","[DEPRECATED] Return position, given the `coefficient_bundle()` return value.",
"def read_record(self, n):
        """"""Return record `n` as 1,024 bytes; records are indexed from 1.""""""
        self.file.seek(n * K - K)
        return self.file.read(K)","Return record `n` as 1,024 bytes; records are indexed from 1.",
"def write_record(self, n, data):
        """"""Write `data` to file record `n`; records are indexed from 1.""""""
        self.file.seek(n * K - K)
        return self.file.write(data)",Write `data` to file record `n`; records are indexed from 1.,
"def close(self):
        """"""Close this SPK file.""""""
        self.daf.file.close()
        for segment in self.segments:
            if hasattr(segment, '_data'):
                del segment._data
        self.daf._array = None
        self.daf._map = None",Close this SPK file.,
"def compute(self, tdb, tdb2=0.0):
        """"""Compute the component values for the time `tdb` plus `tdb2`.""""""
        for position in self.generate(tdb, tdb2):
            return position",Compute the component values for the time `tdb` plus `tdb2`.,
"def close(self):
        """"""Close this file.""""""
        self.daf.file.close()
        for segment in self.segments:
            if hasattr(segment, '_data'):
                del segment._data",Close this file.,
"def notify(msg, msg_type=0, t=None):
    ""Show system notification with duration t (ms)""
    if platform.system() == 'Darwin':
        command = notify_command_osx(msg, msg_type, t)
    else:
        command = notify_command_linux(msg, t)
    os.system(command.encode('utf-8'))",Show system notification with duration t (ms),
"def geturls_new_api(song_ids):
    """"""  """"""
    br_to_quality = {128000: 'MD 128k', 320000: 'HD 320k'}
    alters = NetEase().songs_detail_new_api(song_ids)
    urls = [alter['url'] for alter in alters]
    return urls",,
"def visit_ExceptHandler(self, node):
        """"""
        Process except blocks.

        """"""
        name = self.get_except_handler_name(node)
        if not name:
            super(LoggingVisitor, self).generic_visit(node)
            return

        self.current_except_names.append(name)
        super(LoggingVisitor, self).generic_visit(node)
        self.current_except_names.pop()",Process except blocks.,
"def get_except_handler_name(self, node):
        """"""
        Helper to get the exception name from an ExceptHandler node in both py2 and py3.

        """"""
        name = node.name
        if not name:
            return None

        if version_info < (3,):
            return name.id
        return name",Helper to get the exception name from an ExceptHandler node in both py2 and py3.,
"def get_id_attr(self, value):
        """"""Check if value has id attribute and return it.

        :param value: The value to get id from.
        :return: The value.id.
        """"""
        if not hasattr(value, ""id"") and hasattr(value, ""value""):
            value = value.value
        return value.id","Check if value has id attribute and return it.

        :param value: The value to get id from.
        :return: The value.id.",
"def is_bare_exception(self, node):
        """"""
        Checks if the node is a bare exception name from an except block.

        """"""
        return isinstance(node, Name) and node.id in self.current_except_names",Checks if the node is a bare exception name from an except block.,
"def delete_file(instance, filefield_name):
    """"""Delete the file (if any) from the database.

    Call this function immediately AFTER deleting the instance.
    """"""
    file_instance = getattr(instance, filefield_name)
    if file_instance:
        DatabaseFileStorage().delete(file_instance.name)","Delete the file (if any) from the database.

    Call this function immediately AFTER deleting the instance.",
"def _configure(cls, **defaults):
        """"""Updates class-level defaults for :class:`_Options` container.""""""
        for attr in defaults:
            setattr(cls, attr, defaults[attr])",Updates class-level defaults for :class:`_Options` container.,
"def to_underscore(string):
    """"""Converts a given string from CamelCase to under_score.

    >>> to_underscore('FooBar')
    'foo_bar'
    """"""
    new_string = re.sub(r'([A-Z]+)([A-Z][a-z])', r'\1_\2', string)
    new_string = re.sub(r'([a-z\d])([A-Z])', r'\1_\2', new_string)
    return new_string.lower()","Converts a given string from CamelCase to under_score.

    >>> to_underscore('FooBar')
    'foo_bar'",
"def find(self, *args, **kwargs):
        """"""Same as :meth:`pymongo.collection.Collection.find`, except
        it returns the right document class.
        """"""
        return Cursor(self, *args, wrap=self.document_class, **kwargs)","Same as :meth:`pymongo.collection.Collection.find`, except
        it returns the right document class.",
"def find_one(self, *args, **kwargs):
        """"""Same as :meth:`pymongo.collection.Collection.find_one`, except
        it returns the right document class.
        """"""
        data = super(Collection, self).find_one(*args, **kwargs)
        if data:
            return self.document_class(data)
        return None","Same as :meth:`pymongo.collection.Collection.find_one`, except
        it returns the right document class.",
"def load_file(self, file_path) -> List[str]:
        """""" Loads the content of the text file """"""
        content = []
        content = read_lines_from_file(file_path)
        return content",Loads the content of the text file,
"def translate_symbol(self, in_symbol: str) -> str:
        """""" translate the incoming symbol into locally-used """"""
        # read all mappings from the db
        if not self.symbol_maps:
            self.__load_symbol_maps()
        # translate the incoming symbol
        result = self.symbol_maps[in_symbol] if in_symbol in self.symbol_maps else in_symbol

        return result",translate the incoming symbol into locally-used,
"def __load_symbol_maps(self):
        """""" Loads all symbol maps from db """"""
        repo = SymbolMapRepository(self.__get_session())
        all_maps = repo.get_all()
        self.symbol_maps = {}
        for item in all_maps:
            self.symbol_maps[item.in_symbol] = item.out_symbol",Loads all symbol maps from db,
"def __get_session(self):
        """""" Reuses the same db session """"""
        if not self.session:
            self.session = dal.get_default_session()
        return self.session",Reuses the same db session,
"def import_csv(filepath: str, currency: str):
    """""" Import prices from CSV file """"""
    logger.debug(f""currency = {currency}"")
    # auto-convert to uppercase.
    currency = currency.upper()

    app = PriceDbApplication()
    app.logger = logger
    app.import_prices(filepath, currency)",Import prices from CSV file,
"def list_prices(date, currency, last):
    """""" Display all prices """"""
    app = PriceDbApplication()
    app.logger = logger

    if last:
        # fetch only the last prices
        prices = app.get_latest_prices()
    else:
        prices = app.get_prices(date, currency)
    for price in prices:
        print(price)

    print(f""{len(prices)} records found."")",Display all prices,
"def get_default_session():
    """""" Return the default session. The path is read from the default config. """"""
    from .config import Config, ConfigKeys

    db_path = Config().get(ConfigKeys.price_database)
    if not db_path:
        raise ValueError(""Price database not set in the configuration file!"")
    return get_session(db_path)",Return the default session. The path is read from the default config.,
"def add_map(incoming, outgoing):
    """""" Creates a symbol mapping """"""
    db_path = Config().get(ConfigKeys.pricedb_path)
    session = get_session(db_path)

    new_map = SymbolMap()
    new_map.in_symbol = incoming
    new_map.out_symbol = outgoing

    session.add(new_map)
    session.commit()
    click.echo(""Record saved."")",Creates a symbol mapping,
"def list_maps():
    """""" Displays all symbol maps """"""
    db_path = Config().get(ConfigKeys.price_database)
    session = get_session(db_path)

    maps = session.query(SymbolMap).all()
    for item in maps:
        click.echo(item)",Displays all symbol maps,
"def get_by_id(self, symbol: str) -> SymbolMap:
        """""" Finds the map by in-symbol """"""
        return self.query.filter(SymbolMap.in_symbol == symbol).first()",Finds the map by in-symbol,
"def read_lines_from_file(file_path: str) -> List[str]:
    """""" Read text lines from a file """"""
    # check if the file exists?
    with open(file_path) as csv_file:
        content = csv_file.readlines()
    return content",Read text lines from a file,
"def __get_config_template_path(self) -> str:
        """""" gets the default config path from resources """"""
        filename = resource_filename(
            Requirement.parse(package_name),
            template_path + config_filename)
        return filename",gets the default config path from resources,
"def get_config_path(self) -> str:
        """"""
        Returns the path where the active config file is expected.
        This is the user's profile folder.
        """"""
        dst_dir = self.__get_user_path()
        dst = dst_dir + ""/"" + config_filename
        return dst","Returns the path where the active config file is expected.
        This is the user's profile folder.",
"def set(self, option: ConfigKeys, value):
        """""" Sets a value in config """"""
        assert isinstance(option, ConfigKeys)

        # As currently we only have 1 section.
        section = SECTION
        self.config.set(section, option.name, value)
        self.save()",Sets a value in config,
"def get(self, option: ConfigKeys):
        """""" Retrieves a config value """"""
        assert isinstance(option, ConfigKeys)

        # Currently only one section is used
        section = SECTION
        return self.config.get(section, option.name)",Retrieves a config value,
"def save(self):
        """""" Save the config file """"""
        file_path = self.get_config_path()
        contents = self.get_contents()
        with open(file_path, mode='w') as cfg_file:
            cfg_file.write(contents)",Save the config file,
"def add_price(self, price: PriceModel):
        """""" Creates a new price record """"""
        # assert isinstance(price, PriceModel)

        if not price:
            raise ValueError(""Cannot add price. The received model is null!"")

        mapper = mappers.PriceMapper()
        entity = mapper.map_model(price)

        self.add_price_entity(entity)",Creates a new price record,
"def download_price(self, symbol: str, currency: str, agent: str) -> PriceModel:
        """""" Download and save price online """"""
        price = self.__download_price(symbol, currency, agent)
        self.save()
        return price",Download and save price online,
"def session(self):
        """""" Returns the current db session """"""
        if not self.__session:
            self.__session = dal.get_default_session()
        return self.__session",Returns the current db session,
"def get_price_repository(self):
        """""" Price repository """"""
        from .repositories import PriceRepository

        if not self.price_repo:
            self.price_repo = PriceRepository(self.session)
        return self.price_repo",Price repository,
"def get_security_repository(self):
        """""" Security repository """"""
        from .repositories import SecurityRepository

        if not self.security_repo:
            self.security_repo = SecurityRepository(self.session)
        return self.security_repo",Security repository,
"def save(self):
        """""" Save changes """"""
        if self.__session:
            self.session.commit()
        else:
            self.logger.warning(""Save called but no session open."")",Save changes,
"def partial(self):
        """"""Return partial of original function call""""""
        ba = self.data[""bound_args""]
        return state_partial(self.data[""func""], *ba.args[1:], **ba.kwargs)",Return partial of original function call,
"def update_child_calls(self):
        """"""Replace child nodes on original function call with their partials""""""

        for node in filter(lambda n: len(n.arg_name), self.child_list):
            self.data[""bound_args""].arguments[node.arg_name] = node.partial()
        self.updated = True",Replace child nodes on original function call with their partials,
"def descend(self, include_me=True):
        """"""Descend depth first into all child nodes""""""
        if include_me:
            yield self

        for child in self.child_list:
            yield child
            yield from child.descend()",Descend depth first into all child nodes,
"def getResultFromProcess(res, tempname, process):
    """"""Get a value from process, return tuple of value, res if succesful""""""
    if not isinstance(res, (UndefinedValue, Exception)):
        value = getRepresentation(tempname, process)
        return value, res
    else:
        return res, str(res)","Get a value from process, return tuple of value, res if succesful",
"def defined_items(self):
        """"""Return copy of instance, omitting entries that are EMPTY""""""
        return self.__class__(
            [(k, v) for k, v in self.items() if v is not self.EMPTY], is_empty=False
        )","Return copy of instance, omitting entries that are EMPTY",
"def get_t_periastron(self, params):
		""""""
		Return the time of periastron passage (calculated using `params.t0`).
		""""""
		phase = self._get_phase(params, ""primary"")
		return params.t0 - params.per*phase",Return the time of periastron passage (calculated using `params.t0`).,
"def get_t_secondary(self, params):
		""""""
		Return the time of secondary eclipse center (calculated using `params.t0`).
		""""""
		phase = self._get_phase(params, ""primary"")
		phase2 = self._get_phase(params, ""secondary"")
		return params.t0 + params.per*(phase2-phase)",Return the time of secondary eclipse center (calculated using `params.t0`).,
"def get_t_conjunction(self, params):
		""""""
		Return the time of primary transit center (calculated using `params.t_secondary`).
		""""""
		phase = self._get_phase(params, ""primary"")
		phase2 = self._get_phase(params, ""secondary"")
		return params.t_secondary + params.per*(phase-phase2)",Return the time of primary transit center (calculated using `params.t_secondary`).,
"def get_true_anomaly(self):
		""""""
		Return the true anomaly at each time
		""""""
		self.f = _rsky._getf(self.t_supersample, self.t0, self.per, self.a,
							  self.inc*pi/180., self.ecc, self.w*pi/180.,
							  self.transittype, self.nthreads)
		return self.f",Return the true anomaly at each time,
"def detect():
	""""""Does this compiler support OpenMP parallelization?""""""
	compiler = new_compiler()
	hasopenmp = hasfunction(compiler, 'omp_get_num_threads()')
	needs_gomp = hasopenmp
	if not hasopenmp:
		compiler.add_library('gomp')
	hasopenmp = hasfunction(compiler, 'omp_get_num_threads()')
	needs_gomp = hasopenmp
	return hasopenmp",Does this compiler support OpenMP parallelization?,
"def search(self, query=None, args=None):
    '''query a GitLab artifacts folder for a list of images. 
     If query is None, collections are listed. 
    '''
    if query is None:
        bot.exit('You must include a collection query, <collection>/<repo>')

    # or default to listing (searching) all things.
    return self._search_all(query)","query a GitLab artifacts folder for a list of images. 
     If query is None, collections are listed.",
"def announce(self, command=None):
        '''the client will announce itself given that a command is not in a
           particular predefined list.
        '''
        if command is not None:
            if command not in ['get'] and self.quiet is False:
                self.speak()","the client will announce itself given that a command is not in a
           particular predefined list.",
"def post(url,data=None,return_json=True):
    '''post will use requests to get a particular url
    '''
    bot.debug(""POST %s"" %url)
    return call(url,
                headers=headers,
                func=requests.post,
                data=data,
                return_json=return_json)",post will use requests to get a particular url,
"def get(url,headers=None,token=None,data=None,return_json=True):
    '''get will use requests to get a particular url
    '''
    bot.debug(""GET %s"" %url)
    return call(url,
                headers=headers,
                func=requests.get,
                data=data,
                return_json=return_json)",get will use requests to get a particular url,
"def _read_response(self,response, field=""detail""):
        '''attempt to read the detail provided by the response. If none, 
        default to using the reason'''

        try:
            message = json.loads(response._content.decode('utf-8'))[field]
        except:
            message = response.reason
        return message","attempt to read the detail provided by the response. If none, 
        default to using the reason",
"def _init_clients(self):
        '''init_ cliends will obtain the tranfer and access tokens, and then
           use them to create a transfer client.
        '''

        self._client = globus_sdk.NativeAppAuthClient(self._client_id)
        self._load_secrets()","init_ cliends will obtain the tranfer and access tokens, and then
           use them to create a transfer client.",
"def _load_secrets(self):
        '''load the secrets credentials file with the Globus OAuthTokenResponse
        '''

        # Second priority: load from cache
       
        self.auth = self._get_and_update_setting('GLOBUS_AUTH_RESPONSE')
        self.transfer = self._get_and_update_setting('GLOBUS_TRANSFER_RESPONSE')",load the secrets credentials file with the Globus OAuthTokenResponse,
"def list_logs(self):
    '''return a list of logs. We return any file that ends in .log
    '''
    results = []
    for image in self._bucket.list_blobs():
        if image.name.endswith('log'):
            results.append(image)

    if len(results) == 0:
        bot.info(""No containers found, based on extension .log"")

    return results",return a list of logs. We return any file that ends in .log,
"def activate(backend):
    '''activate a backend by adding it to the .sregistry configuration file.
    '''
    settings = read_client_secrets()
    if backend is not None:
        settings['SREGISTRY_CLIENT'] = backend
        update_secrets(settings)
        print('[activate] %s' %backend)",activate a backend by adding it to the .sregistry configuration file.,
"def generate_signature(payload, secret):
    '''use an endpoint specific payload and client secret to generate
    a signature for the request'''
    payload = _encode(payload)
    secret = _encode(secret)
    return hmac.new(secret, digestmod=hashlib.sha256,
                    msg=payload).hexdigest()","use an endpoint specific payload and client secret to generate
    a signature for the request",
"def generate_credential(s):
    '''basic_auth_header will return a base64 encoded header object to
    :param username: the username
    '''
    if sys.version_info[0] >= 3:
        s = bytes(s, 'utf-8')
        credentials = base64.b64encode(s).decode('utf-8')
    else:
        credentials = base64.b64encode(s)
    return credentials","basic_auth_header will return a base64 encoded header object to
    :param username: the username",
"def head(self, url):
    '''head request, typically used for status code retrieval, etc.
    '''
    bot.debug('HEAD %s' %url)
    return self._call(url, func=requests.head)","head request, typically used for status code retrieval, etc.",
"def get_lookup():
    '''get version by way of sregistry.version, returns a 
    lookup dictionary with several global variables without
    needing to import singularity
    '''
    lookup = dict()
    version_file = os.path.join('sregistry', 'version.py')
    with open(version_file) as filey:
        exec(filey.read(), lookup)
    return lookup","get version by way of sregistry.version, returns a 
    lookup dictionary with several global variables without
    needing to import singularity",
"def get_installdir():
    '''get_installdir returns the installation directory of the application
    '''
    return os.path.abspath(os.path.dirname(os.path.dirname(__file__)))",get_installdir returns the installation directory of the application,
"def get_thumbnail():
    '''return the robot.png thumbnail from the database folder.
       if the user has exported a different image, use that instead.
    '''
    from sregistry.defaults import SREGISTRY_THUMBNAIL
    if SREGISTRY_THUMBNAIL is not None:
        if os.path.exists(SREGISTRY_THUMBNAIL):
            return SREGISTRY_THUMBNAIL
    return ""%s/database/robot.png"" %get_installdir()","return the robot.png thumbnail from the database folder.
       if the user has exported a different image, use that instead.",
"def _speak(self):
        '''if you want to add an extra print (of a parameter, for example)
           for the user when the client initalizes, write it here, eg:
           bot.info('[setting] value')
        '''
        if hasattr(self, 'account'):
            bot.info('connected to %s' %self.account.name.display_name)","if you want to add an extra print (of a parameter, for example)
           for the user when the client initalizes, write it here, eg:
           bot.info('[setting] value')",
"def kill(args):
    '''kill is a helper function to call the ""kill"" function of the client,
       meaning we bring down an instance.
    '''
    from sregistry.main import Client as cli
    if len(args.commands) > 0:
        for name in args.commands:
            cli.destroy(name)
    sys.exit(0)","kill is a helper function to call the ""kill"" function of the client,
       meaning we bring down an instance.",
"def get_collections(self):
        '''get a listing of collections that the user has access to.
        '''
        collections = []
        for container in self.conn.get_account()[1]:
            collections.append(container['name'])
        return collections",get a listing of collections that the user has access to.,
"def ipython(args):
    '''give the user an ipython shell, optionally with an endpoint of choice.
    '''

    # The client will announce itself (backend/database) unless it's get
    from sregistry.main import get_client
    client = get_client(args.endpoint)
    client.announce(args.command)
    from IPython import embed
    embed()","give the user an ipython shell, optionally with an endpoint of choice.",
"def _update_secrets(self):
        '''update secrets will update metadata needed for pull and search
        '''
        self.token = self._required_get_and_update('SREGISTRY_GITLAB_TOKEN')
        self.headers[""Private-Token""] = self.token",update secrets will update metadata needed for pull and search,
"def _get_metadata(self):
        '''since the user needs a job id and other parameters, save this
           for them.
        '''
        metadata = {'SREGISTRY_GITLAB_FOLDER': self.artifacts,
                    'api_base': self.api_base,
                    'SREGISTRY_GITLAB_BASE': self.base,
                    'SREGISTRY_GITLAB_JOB': self.job }
        return metadata","since the user needs a job id and other parameters, save this
           for them.",
"def required_get_and_update(self, name, default=None):
    '''a wrapper to get_and_update, but if not successful, will print an
       error and exit.
    '''
    setting = self._get_and_update_setting(name, default=None)
    if setting in [None, """"]:
        bot.exit('You must export %s' % name)
    return setting","a wrapper to get_and_update, but if not successful, will print an
       error and exit.",
"def update_setting(self, name, value):
    '''Just update a setting, doesn't need to be returned.
    ''' 

    if value is not None:
        updates = {name : value}
        update_client_secrets(backend=self.client_name, 
                              updates=updates)","Just update a setting, doesn't need to be returned.",
"def get_templates(self):
    '''list templates in the builder bundle library. If a name is provided,
       look it up

    '''

    base = 'https://singularityhub.github.io/builders'
    base = self._get_and_update_setting('SREGISTRY_BUILDER_REPO', base)
    base = ""%s/configs.json"" %base
    return self._get(base)","list templates in the builder bundle library. If a name is provided,
       look it up",
"def get_uri(self):
        '''generate a uri on the fly from database parameters if one is not
        saved with the initial model (it should be, but might not be possible)
        '''
        uri = ""%s/%s:%s"" %(self.collection.name, self.name, self.tag)
        if self.version not in [None,'']:
            uri = ""%s@%s"" %(uri, self.version)
        return uri","generate a uri on the fly from database parameters if one is not
        saved with the initial model (it should be, but might not be possible)",
"def get_build_template():
    '''get default build template.
    '''
    base = get_installdir()
    name = ""%s/main/templates/build/singularity-cloudbuild.json"" % base

    if os.path.exists(name):
        bot.debug(""Found template %s"" %name)
        return read_json(name)

    bot.warning(""Template %s not found."" % name)",get default build template.,
"def mkdir_p(path):
    '''mkdir_p attempts to get the same functionality as mkdir -p
    :param path: the path to create.
    '''
    try:
        os.makedirs(path)
    except OSError as e:
        if e.errno == errno.EEXIST and os.path.isdir(path):
            pass
        else:
            bot.error(""Error creating path %s, exiting."" % path)
            sys.exit(1)","mkdir_p attempts to get the same functionality as mkdir -p
    :param path: the path to create.",
"def get_file_hash(filename):
    '''find the SHA256 hash string of a file
    '''
    hasher = hashlib.sha256()
    with open(filename, ""rb"") as f:
        for chunk in iter(lambda: f.read(4096), b""""):
            hasher.update(chunk)
    return hasher.hexdigest()",find the SHA256 hash string of a file,
"def read_file(filename, mode=""r"", readlines=True):
    '''write_file will open a file, ""filename"" and write content, ""content""
       and properly close the file
    '''
    with open(filename, mode) as filey:
        if readlines is True:
            content = filey.readlines()
        else:
            content = filey.read()
    return content","write_file will open a file, ""filename"" and write content, ""content""
       and properly close the file",
"def read_json(filename, mode='r'):
    '''read_json reads in a json file and returns
       the data structure as dict.
    '''
    with open(filename, mode) as filey:
        data = json.load(filey)
    return data","read_json reads in a json file and returns
       the data structure as dict.",
"def clean_up(files):
    '''clean up will delete a list of files, only if they exist
    '''
    if not isinstance(files, list):
        files = [files]

    for f in files:
        if os.path.exists(f):
            bot.verbose3(""Cleaning up %s"" % f)
            os.remove(f)","clean up will delete a list of files, only if they exist",
"def get_collection(self, name):
    '''get a collection, if it exists, otherwise return None.
    '''
    from sregistry.database.models import Collection
    return Collection.query.filter(Collection.name == name).first()","get a collection, if it exists, otherwise return None.",
"def rmi(self, image_name):
    '''Remove an image from the database and filesystem.
    '''
    container = self.rm(image_name, delete=True)
    if container is not None:
        bot.info(""[rmi] %s"" % container)",Remove an image from the database and filesystem.,
"def addColor(self, level, text):
        '''addColor to the prompt (usually prefix) if terminal
        supports, and specified to do so'''
        if self.colorize:
            if level in self.colors:
                text = ""%s%s%s"" % (self.colors[level],
                                   text,
                                   self.colors[""OFF""])
        return text","addColor to the prompt (usually prefix) if terminal
        supports, and specified to do so",
"def write(self, stream, message):
        '''write will write a message to a stream,
        first checking the encoding
        '''
        if isinstance(message, bytes):
            message = message.decode('utf-8')
        stream.write(message)","write will write a message to a stream,
        first checking the encoding",
"def get_logs(self, join_newline=True):
        ''''get_logs will return the complete history, joined by newline
        (default) or as is.
        '''
        if join_newline:
            return '\n'.join(self.history)
        return self.history","get_logs will return the complete history, joined by newline
        (default) or as is.",
"def factory(cls, filename, mode, on_close):
        """"""Create a S3File backed with a temporary file.""""""
        _temp_file = tempfile.TemporaryFile()
        proxy = cls(_temp_file, filename, mode, on_close=on_close)
        return proxy",Create a S3File backed with a temporary file.,
"def gravatar_url(user_or_email, size=GRAVATAR_DEFAULT_SIZE):
    """""" Builds a gravatar url from an user or email """"""
    if hasattr(user_or_email, 'email'):
        email = user_or_email.email
    else:
        email = user_or_email

    try:
        return escape(get_gravatar_url(email=email, size=size))
    except:
        return ''",Builds a gravatar url from an user or email,
"def chimera_blocks(M=16, N=16, L=4):
    """"""
    Generator for blocks for a chimera block quotient
    """"""
    for x in xrange(M):
        for y in xrange(N):
            for u in (0, 1):
                yield tuple((x, y, u, k) for k in xrange(L))",Generator for blocks for a chimera block quotient,
"def canonicalize_tautomer(self):
        """"""
        :returns: A callable :class:`~molvs.tautomer.TautomerCanonicalizer` instance.
        """"""
        return TautomerCanonicalizer(transforms=self.tautomer_transforms, scores=self.tautomer_scores,
                                     max_tautomers=self.max_tautomers)",:returns: A callable :class:`~molvs.tautomer.TautomerCanonicalizer` instance.,
"def get_mems_of_org(self):
        """"""
        Retrieves the number of members of the organization.
        """"""
        print 'Getting members.'
        counter = 0
        for member in self.org_retrieved.iter_members():
            self.members_json[member.id] = member.to_json()
            counter += 1
        return counter",Retrieves the number of members of the organization.,
"def get_teams_of_org(self):
        """"""
        Retrieves the number of teams of the organization.
        """"""
        print 'Getting teams.'
        counter = 0
        for team in self.org_retrieved.iter_teams():
            self.teams_json[team.id] = team.to_json()
            counter += 1
        return counter",Retrieves the number of teams of the organization.,
"def checkDir(self, file_path=''):
        """"""
        Checks if a directory exists. If not, it creates one with the specified
        file_path.
        """"""
        if not os.path.exists(os.path.dirname(file_path)):
            try:
                os.makedirs(os.path.dirname(file_path))
            except OSError as e:
                if e.errno != errno.EEXIST:
                    raise","Checks if a directory exists. If not, it creates one with the specified
        file_path.",
"def get_releases(self, url='', headers={}, repo_name=''):
        """"""
        Retrieves the releases for the given repo in JSON.
        """"""
        url_releases = (url + '/releases')
        r = requests.get(url_releases, headers=headers)
        self.releases_json[repo_name] = r.json()",Retrieves the releases for the given repo in JSON.,
"def process_json(filename):
    """"""
    Converts a DOE CODE .json file into DOE CODE projects
    Yields DOE CODE records from a DOE CODE .json file
    """"""

    logger.debug('Processing DOE CODE json: %s', filename)

    doecode_json = json.load(open(filename))

    for record in doecode_json['records']:
        yield record","Converts a DOE CODE .json file into DOE CODE projects
    Yields DOE CODE records from a DOE CODE .json file",
"def connect(url, username, password):
    """"""
    Return a connected Bitbucket session
    """"""

    bb_session = stashy.connect(url, username, password)

    logger.info('Connected to: %s as %s', url, username)

    return bb_session",Return a connected Bitbucket session,
"def query_repos(gl_session, repos=None):
    """"""
    Yields Gitlab project objects for all projects in Bitbucket
    """"""

    if repos is None:
        repos = []

    for repo in repos:
        yield gl_session.projects.get(repo)

    if not repos:
        for project in gl_session.projects.list(as_list=False):
            yield project",Yields Gitlab project objects for all projects in Bitbucket,
"def _prune_dict_null_str(dictionary):
    """"""
    Prune the ""None"" or emptry string values from dictionary items
    """"""
    for key, value in list(dictionary.items()):
        if value is None or str(value) == '':
            del dictionary[key]

        if isinstance(value, dict):
            dictionary[key] = _prune_dict_null_str(dictionary[key])

    return dictionary","Prune the ""None"" or emptry string values from dictionary items",
"def create_tfs_connection(url, token):
    """"""
    Creates the TFS Connection Context
    """"""
    if token is None:
        token = os.environ.get('TFS_API_TOKEN', None)

    tfs_credentials = BasicAuthentication('', token)
    tfs_connection = VssConnection(base_url=url, creds=tfs_credentials)
    return tfs_connection",Creates the TFS Connection Context,
"def incr(self, stat, value=1, tags=None):
        """"""Increment a counter.""""""
        self.client.incr(stat=stat, count=value)",Increment a counter.,
"def timing(self, stat, value, tags=None):
        """"""Measure a timing for statistical distribution.""""""
        self.client.timing(stat=stat, delta=value)",Measure a timing for statistical distribution.,
"def incr(self, stat, value=1, tags=None):
        """"""Increment a counter.""""""
        self.client.increment(metric=stat, value=value, tags=tags)",Increment a counter.,
"def gauge(self, stat, value, tags=None):
        """"""Set a gauge.""""""
        self.client.gauge(metric=stat, value=value, tags=tags)",Set a gauge.,
"def timing(self, stat, value, tags=None):
        """"""Measure a timing for statistical distribution.""""""
        self.client.timing(metric=stat, value=value, tags=tags)",Measure a timing for statistical distribution.,
"def histogram(self, stat, value, tags=None):
        """"""Measure a value for statistical distribution.""""""
        self.client.histogram(metric=stat, value=value, tags=tags)",Measure a value for statistical distribution.,
"def incr(self, stat, value=1, tags=None):
        """"""Increment a counter.""""""
        self._log('incr', stat, value, tags)",Increment a counter.,
"def gauge(self, stat, value, tags=None):
        """"""Set a gauge.""""""
        self._log('gauge', stat, value, tags)",Set a gauge.,
"def timing(self, stat, value, tags=None):
        """"""Report a timing.""""""
        self._log('timing', stat, value, tags)",Report a timing.,
"def histogram(self, stat, value, tags=None):
        """"""Report a histogram.""""""
        self._log('histogram', stat, value, tags)",Report a histogram.,
"def incr(self, stat, value=1, tags=None):
        """"""Increment a counter.""""""
        self.rollup()

        # FIXME(willkg): what to do with tags?
        self.incr_stats.setdefault(stat, []).append(value)",Increment a counter.,
"def gauge(self, stat, value, tags=None):
        """"""Set a gauge.""""""
        self.rollup()

        # FIXME(willkg): what to do with tags?
        self.gauge_stats.setdefault(stat, []).append(value)",Set a gauge.,
"def timing(self, stat, value, tags=None):
        """"""Measure a timing for statistical distribution.

        Note: timing is a special case of histogram.

        """"""
        self.histogram(stat, value, tags)","Measure a timing for statistical distribution.

        Note: timing is a special case of histogram.",
"def histogram(self, stat, value, tags=None):
        """"""Measure a value for statistical distribution.""""""
        self.rollup()

        # FIXME(willkg): what to do with tags?
        self.histogram_stats.setdefault(stat, []).append(value)",Measure a value for statistical distribution.,
"def from_db_value(self, value, expression, connection, context):
        """"""
        Convert a string from the database into an Enum value
        """"""
        if value is None:
            return value
        return self.enum[value]",Convert a string from the database into an Enum value,
"def to_python(self, value):
        """"""
        Convert a string from a form into an Enum value.
        """"""
        if value is None:
            return value
        if isinstance(value, self.enum):
            return value
        return self.enum[value]",Convert a string from a form into an Enum value.,
"def get_prep_value(self, value):
        """"""
        Convert an Enum value into a string for the database
        """"""
        if value is None:
            return None
        if isinstance(value, self.enum):
            return value.name
        raise ValueError(""Unknown value {value:r} of type {cls}"".format(
            value=value, cls=type(value)))",Convert an Enum value into a string for the database,
"def t_parse(self, s):
        """"""Parses the input string, and returns a reference to the created AST's root""""""
        # self.root = None
        # self.path = s
        with self.lock:
            try:
                return self.parser.parse(s, lexer=self.lexer, debug=False)
            except CannotParse as e:
                e.s = s
                raise e","Parses the input string, and returns a reference to the created AST's root",
"def p_path(self, p):
        """"""path : additive_path""""""
        if len(p[1].children) == 1:
            p[0] = p[1].children[0]
        else:
            p[0] = p[1]",path : additive_path,
"def p_path_sum(self, p):
        """""" path_sum : ctx_path
                  | path_sum PLUS ctx_path""""""
        if len(p) == 2:
            p[0] = [p[1]]
        else:
            p[0] = p[1] + [p[3]]","path_sum : ctx_path
                  | path_sum PLUS ctx_path",
"def p_ctx_path(self, p):
        """""" ctx_path : ctx_coords""""""
        if len(p[1]) == 1:
            p[0] = p[1][0]
        else:
            p[0] = ContextPath(p[1])",ctx_path : ctx_coords,
"def p_ctx_coords(self, p):
        """""" ctx_coords : multiplicative_path
                        | ctx_coords COLON multiplicative_path""""""
        if len(p) == 2:
            p[0] = [p[1]]
        else:
            p[0] = p[1] + [p[3]]","ctx_coords : multiplicative_path
                        | ctx_coords COLON multiplicative_path",
"def p_product(self, p):
        """""" product : additive_path_p
                    | coordinate
                    | product additive_path_p
                    | product coordinate""""""
        if len(p) == 2:
            p[0] = [p[1]]
        else:
            p[0] = p[1] + [p[2]]","product : additive_path_p
                    | coordinate
                    | product additive_path_p
                    | product coordinate",
"def p_coordinate(self, p):
        """""" coordinate : COORD_KIND
                        | COORD_KIND COORD_INDEX""""""

        if len(p) == 2:
            p[0] = Coordinate(p[1])
        else:
            p[0] = Coordinate(p[1], int(p[2]))","coordinate : COORD_KIND
                        | COORD_KIND COORD_INDEX",
"def _rotate_sc_additive(s):
    """"""
    s.-S:.U:.-'l.-S:.O:.-'n.-S:.U:.-',+M:.-'M:.-'n.-S:.U:.-',  =>
    n.-S:.U:.-'s.-S:.U:.-'l.-S:.O:.-',+n.-S:.U:.-M:.-M:.-,""""""

    if isinstance(s, AdditiveScript):
        return AdditiveScript([_rotate_sc(_s) for _s in s])
    else:
        return _rotate_sc(s)","s.-S:.U:.-'l.-S:.O:.-'n.-S:.U:.-',+M:.-'M:.-'n.-S:.U:.-',  =>
    n.-S:.U:.-'s.-S:.U:.-'l.-S:.O:.-',+n.-S:.U:.-M:.-M:.-,",
"def _promote_and_split(s):
    """"""
    E:F:.O:M:.t.- => E:.-F:.O:M:.-t.-
    E:F:.M:M:.l.- => E:.-F:.M:M:.-l.-
    """"""
    subst, attr, mode = s
    subst0, subst1, _mode = subst
    assert isinstance(_mode, NullScript)

    return m(m(m(subst0)) ,m(m(subst1), attr) ,m(mode))","E:F:.O:M:.t.- => E:.-F:.O:M:.-t.-
    E:F:.M:M:.l.- => E:.-F:.M:M:.-l.-",
"def _add_mode_t(s):
    """"""
O:O:.O:O:.-  => O:O:.O:O:.t.-
    """"""
    subst, attr, mode = s
    assert isinstance(mode, NullScript)
    return m(subst, attr, script('t.'))",O:O:.O:O:.-  => O:O:.O:O:.t.-,
"def _insert_f_additive(s):
    """"""i.B:.-+u.M:.-O:.-' => i.f.B:.-+u.f.M:.-O:.-'""""""
    subst, attr, mode = s
    assert isinstance(mode, NullScript)

    if isinstance(subst, AdditiveScript):
        subst = AdditiveScript([_insert_attr_f(_s) for _s in subst])
    else:
        subst = _insert_attr_f(subst)

    return m(subst ,attr)",i.B:.-+u.M:.-O:.-' => i.f.B:.-+u.f.M:.-O:.-,
"def _fix_typo(s):
    """"""M:.-O:.-'M:.-wa.e.-'t.x.-s.y.-',  => M:.-O:.-'M:.-wa.e.-'t.-x.-s.y.-',""""""
    subst, attr, mode = s
    return m(subst, attr, script(""t.-x.-s.y.-'""))","M:.-O:.-'M:.-wa.e.-'t.x.-s.y.-',  => M:.-O:.-'M:.-wa.e.-'t.-x.-s.y.-',",
"def translate_mouvements_et_milieux(s):
    """"""i.f.B:.-+u.f.M:.-O:.-' -> i.B:.-+u.M:.-O:.-'""""""
    subst, attr, mode = s
    assert isinstance(mode, NullScript)

    if isinstance(subst, AdditiveScript):
        subst = AdditiveScript([_remove_attr_f(_s) for _s in subst])
    else:
        subst = _remove_attr_f(subst)

    return m(subst, attr)",i.f.B:.-+u.f.M:.-O:.-' -> i.B:.-+u.M:.-O:.-,
"def translate_noetic(s):
    """"""M:.O:.-O:.O:.-B:.T:.n.-' => s.M:O:.O:O:.-""""""
    subst, attr, mode = s
    return m(script('s.'),
             m(subst.children[0].children[0], subst.children[1].children[0]),
             m(attr.children[0].children[0], attr.children[1].children[0]))",M:.O:.-O:.O:.-B:.T:.n.-' => s.M:O:.O:O:.-,
"def translate_tisse_intl_col(s):
    """"""O:M:.-O:M:.-we.h.-' => O:M:.-'O:M:.-'s.o.-k.o.-',""""""
    subst, attr, mode = s
    return m(m(subst), m(attr), script(""s.o.-k.o.-'""))","O:M:.-O:M:.-we.h.-' => O:M:.-'O:M:.-'s.o.-k.o.-',",
"def translate_ecosystem_intl_col(s):
    """"""O:.M:.- => s.o.-k.o.-'M:O:.-',""""""
    subst, attr, mode = s

    return m(script(""s.o.-k.o.-'""), m(m(m(attr.children[0], subst.children[0]))))","O:.M:.- => s.o.-k.o.-'M:O:.-',",
"def translate_ecosystem_intl_col_tern(s):
    """"""O:.M:.-M:.-' => s.o.-k.o.-M:O:.-,M:.-',_""""""
    subst, attr, mode = s

    return m(translate_ecosystem_intl_col(subst), m(m(attr)))","O:.M:.-M:.-' => s.o.-k.o.-M:O:.-,M:.-',_",
"def parse(self, s):
        """"""Parses the input string, and returns a reference to the created AST's root""""""
        with self.lock:
            try:
                return self.parser.parse(s, lexer=self.lexer)
            except InvalidIEMLObjectArgument as e:
                raise CannotParse(s, str(e))
            except CannotParse as e:
                e.s = s
                raise e","Parses the input string, and returns a reference to the created AST's root",
"def p_literal_list(self, p):
        """"""literal_list : literal_list LITERAL
                        | LITERAL""""""

        if len(p) == 3:
            p[0] = p[1] + [p[2][1:-1]]
        else:
            p[0] = [p[1][1:-1]]","literal_list : literal_list LITERAL
                        | LITERAL",
"def p_fact(self, p):
        """"""fact : LBRACKET clauses_sum RBRACKET
                | LBRACKET clauses_sum RBRACKET literal_list""""""
        if len(p) == 4:
            p[0] = Fact(p[2])
        else:
            p[0] = Fact(p[2], literals=p[4])","fact : LBRACKET clauses_sum RBRACKET
                | LBRACKET clauses_sum RBRACKET literal_list",
"def p_theory(self, p):
        """"""theory : LBRACKET superclauses_sum RBRACKET
                  | LBRACKET superclauses_sum RBRACKET literal_list""""""
        if len(p) == 4:
            p[0] = Theory(p[2])
        else:
            p[0] = Theory(p[2], literals=p[4])","theory : LBRACKET superclauses_sum RBRACKET
                  | LBRACKET superclauses_sum RBRACKET literal_list",
"def p_closed_proposition_list(self, p):
        """""" closed_proposition_list :  closed_proposition_list SLASH SLASH closed_proposition
                                    | closed_proposition""""""
        if len(p) == 2:
            p[0] = [p[1]]
        else:
            p[0] = p[1] + [p[4]]","closed_proposition_list :  closed_proposition_list SLASH SLASH closed_proposition
                                    | closed_proposition",
"def connexity(self):
        """"""
        A boolean matrix, m[i, j] == True if there is a relation term(i) -> term(j)
        :return: a np.matrix (len(dictionary), len(dictionary)) of boolean
        """"""
        return np.matrix(sum(self.relations.values()).todense(), dtype=bool)","A boolean matrix, m[i, j] == True if there is a relation term(i) -> term(j)
        :return: a np.matrix (len(dictionary), len(dictionary)) of boolean",
"def p_script_lvl_0(self, p):
        """""" script_lvl_0 : PRIMITIVE LAYER0_MARK
                            | REMARKABLE_ADDITION LAYER0_MARK""""""
        if p[1] == 'E':
            p[0] = NullScript(layer=0)
        elif p[1] in REMARKABLE_ADDITION:
            p[0] = AdditiveScript(character=p[1])
        else:
            p[0] = MultiplicativeScript(character=p[1])","script_lvl_0 : PRIMITIVE LAYER0_MARK
                            | REMARKABLE_ADDITION LAYER0_MARK",
"def p_sum_lvl_0(self, p):
        """""" sum_lvl_0 : script_lvl_0
                    | script_lvl_0 PLUS sum_lvl_0""""""
        if len(p) == 4:
            p[3].append(p[1])
            p[0] = p[3]
        else:
            p[0] = [p[1]]","sum_lvl_0 : script_lvl_0
                    | script_lvl_0 PLUS sum_lvl_0",
"def p_sum_lvl_1(self, p):
        """""" sum_lvl_1 : script_lvl_1
                    |  script_lvl_1 PLUS sum_lvl_1""""""
        if len(p) == 4:
            p[3].append(p[1])
            p[0] = p[3]
        else:
            p[0] = [p[1]]","sum_lvl_1 : script_lvl_1
                    |  script_lvl_1 PLUS sum_lvl_1",
"def mean(self):
        """"""Returns the mean value.""""""
        if self.counter.value > 0:
            return self.sum.value / self.counter.value
        return 0.0",Returns the mean value.,
"def variance(self):
        """"""Returns variance""""""
        if self.counter.value <= 1:
            return 0.0
        return self.var.value[1] / (self.counter.value - 1)",Returns variance,
"def mark(self, value=1):
        """"""Record an event with the meter. By default it will record one event.

        :param value: number of event to record
        """"""
        self.counter += value
        self.m1_rate.update(value)
        self.m5_rate.update(value)
        self.m15_rate.update(value)","Record an event with the meter. By default it will record one event.

        :param value: number of event to record",
"def mean_rate(self):
        """"""
        Returns the mean rate of the events since the start of the process.
        """"""
        if self.counter.value == 0:
            return 0.0
        else:
            elapsed = time() - self.start_time
            return self.counter.value / elapsed",Returns the mean rate of the events since the start of the process.,
"def mark(self, value=1):
        """"""Record an event with the derive.

        :param value: counter value to record
        """"""
        last = self.last.get_and_set(value)
        if last <= value:
            value = value - last
        super(Derive, self).mark(value)","Record an event with the derive.

        :param value: counter value to record",
"def mmap(func, iterable):
    """"""Wrapper to make map() behave the same on Py2 and Py3.""""""

    if sys.version_info[0] > 2:
        return [i for i in map(func, iterable)]
    else:
        return map(func, iterable)",Wrapper to make map() behave the same on Py2 and Py3.,
"def serialize_metric(self, metric, m_name, keys, m_type):
        """"""Serialize and send available measures of a metric.""""""

        return [
            self.format_metric_string(m_name, getattr(metric, key), m_type)
            for key in keys
        ]",Serialize and send available measures of a metric.,
"def _buffered_send_metric(self, metric_str):
        """"""Add a metric to the buffer.""""""

        self.batch_count += 1

        self.batch_buffer += metric_str

        # NOTE(romcheg): Send metrics if the number of metrics in the buffer
        #                has reached the threshold for sending.
        if self.batch_count >= self.batch_size:
            self._send()",Add a metric to the buffer.,
"def _json_safe(data):
    """"""
    json.loads wants an unistr in Python3. Convert it.
    """"""
    if not hasattr(data, 'encode'):
        try:
            data = data.decode('utf-8')
        except UnicodeDecodeError:
            raise ValueError(
                'Expected valid UTF8 for JSON data, got %r' % (data,))
    return data",json.loads wants an unistr in Python3. Convert it.,
"def http_post(url, data=None, opt=opt_default):
    """"""
    Shortcut for urlopen (POST) + read. We'll probably want to add a
    nice timeout here later too.
    """"""
    return _http_request(url, method='POST', data=_marshalled(data), opt=opt)","Shortcut for urlopen (POST) + read. We'll probably want to add a
    nice timeout here later too.",
"def http_put(url, data=None, opt=opt_default):
    """"""
    Shortcut for urlopen (PUT) + read. We'll probably want to add a nice
    timeout here later too.
    """"""
    return _http_request(url, method='PUT', data=_marshalled(data), opt=opt)","Shortcut for urlopen (PUT) + read. We'll probably want to add a nice
    timeout here later too.",
"def get_or_set_default(self, section, option, value):
        """"""
        Base method to fetch values and to set defaults in case they
        don't exist.
        """"""
        try:
            ret = self.get(section, option)
        except MissingSetting:
            self.set(section, option, value)
            ret = value

        return ret","Base method to fetch values and to set defaults in case they
        don't exist.",
"def view(injector):
    """"""Create Django class-based view from injector class.""""""

    handler = create_handler(View, injector)
    apply_http_methods(handler, injector)
    return injector.let(as_view=handler.as_view)",Create Django class-based view from injector class.,
"def form_view(injector):
    """"""Create Django form processing class-based view from injector class.""""""

    handler = create_handler(FormView, injector)
    apply_form_methods(handler, injector)
    return injector.let(as_view=handler.as_view)",Create Django form processing class-based view from injector class.,
"def method_view(injector):
    """"""Create Flask method based dispatching view from injector class.""""""

    handler = create_handler(MethodView)
    apply_http_methods(handler, injector)
    return injector.let(as_view=handler.as_view)",Create Flask method based dispatching view from injector class.,
"def api_view(injector):
    """"""Create DRF class-based API view from injector class.""""""

    handler = create_handler(APIView, injector)
    apply_http_methods(handler, injector)
    apply_api_view_methods(handler, injector)
    return injector.let(as_view=handler.as_view)",Create DRF class-based API view from injector class.,
"def generic_api_view(injector):
    """"""Create DRF generic class-based API view from injector class.""""""

    handler = create_handler(GenericAPIView, injector)
    apply_http_methods(handler, injector)
    apply_api_view_methods(handler, injector)
    apply_generic_api_view_methods(handler, injector)
    return injector.let(as_view=handler.as_view)",Create DRF generic class-based API view from injector class.,
"def model_view_set(injector):
    """"""Create DRF model view set from injector class.""""""

    handler = create_handler(ModelViewSet, injector)
    apply_api_view_methods(handler, injector)
    apply_generic_api_view_methods(handler, injector)
    apply_model_view_set_methods(handler, injector)
    return injector.let(as_viewset=lambda: handler)",Create DRF model view set from injector class.,
"def pause_reading(self):
        """"""Public API: pause reading the transport.""""""
        self._loop.remove_reader(self._fileno)
        self._active = False",Public API: pause reading the transport.,
"def resume_reading(self):
        """"""Public API: resume transport reading.""""""
        self._loop.add_reader(self._fileno, self._read_ready)
        self._active = True",Public API: resume transport reading.,
"def _close(self, error=None):
        """"""Actual closing code, both from manual close and errors.""""""
        self._closing = True
        self.pause_reading()
        self._loop.call_soon(self._call_connection_lost, error)","Actual closing code, both from manual close and errors.",
"def _call_connection_lost(self, error):
        """"""Finalize closing.""""""
        try:
            self._protocol.connection_lost(error)
        finally:
            os.close(self._fileno)
            self._fileno = None
            self._protocol = None
            self._loop = None",Finalize closing.,
"def finish(self):
        """"""
        Respond to ``nsqd`` that you've processed this message successfully (or would like
        to silently discard it).
        """"""
        assert not self._has_responded
        self._has_responded = True
        self.trigger(event.FINISH, message=self)","Respond to ``nsqd`` that you've processed this message successfully (or would like
        to silently discard it).",
"def touch(self):
        """"""
        Respond to ``nsqd`` that you need more time to process the message.
        """"""
        assert not self._has_responded
        self.trigger(event.TOUCH, message=self)",Respond to ``nsqd`` that you need more time to process the message.,
"def run():
    """"""
    Starts any instantiated :class:`nsq.Reader` or :class:`nsq.Writer`
    """"""
    signal.signal(signal.SIGTERM, _handle_term_signal)
    signal.signal(signal.SIGINT, _handle_term_signal)
    tornado.ioloop.IOLoop.instance().start()",Starts any instantiated :class:`nsq.Reader` or :class:`nsq.Writer`,
"def success(self):
        """"""Update the timer to reflect a successfull call""""""
        if self.interval == 0.0:
            return
        self.short_interval -= self.short_unit
        self.long_interval -= self.long_unit
        self.short_interval = max(self.short_interval, Decimal(0))
        self.long_interval = max(self.long_interval, Decimal(0))
        self.update_interval()",Update the timer to reflect a successfull call,
"def failure(self):
        """"""Update the timer to reflect a failed call""""""
        self.short_interval += self.short_unit
        self.long_interval += self.long_unit
        self.short_interval = min(self.short_interval, self.max_short_timer)
        self.long_interval = min(self.long_interval, self.max_long_timer)
        self.update_interval()",Update the timer to reflect a failed call,
"def close(self):
        """"""
        Closes all connections stops all periodic callbacks
        """"""
        for conn in self.conns.values():
            conn.close()

        self.redist_periodic.stop()
        if self.query_periodic is not None:
            self.query_periodic.stop()",Closes all connections stops all periodic callbacks,
"def trigger(self, name, *args, **kwargs):
        """"""
        Execute the callbacks for the listeners on the specified event with the
        supplied arguments.

        All extra arguments are passed through to each callback.

        :param name: the name of the event
        :type name: string
        """"""
        for ev in self.__listeners[name]:
            ev(*args, **kwargs)","Execute the callbacks for the listeners on the specified event with the
        supplied arguments.

        All extra arguments are passed through to each callback.

        :param name: the name of the event
        :type name: string",
"def pub(self, topic, msg, callback=None):
        """"""
        publish a message to nsq

        :param topic: nsq topic
        :param msg: message body (bytes)
        :param callback: function which takes (conn, data) (data may be nsq.Error)
        """"""
        self._pub('pub', topic, msg, callback=callback)","publish a message to nsq

        :param topic: nsq topic
        :param msg: message body (bytes)
        :param callback: function which takes (conn, data) (data may be nsq.Error)",
"def score_function(self, x, W):

        '''
        Score function to calculate score
        '''

        score = super(BinaryClassifier, self).score_function(x, W)
        if score >= 0.5:
            score = 1.0
        else:
            score = -1.0

        return score",Score function to calculate score,
"def score_function(self, x, W):
        # need refector

        '''
        Score function to calculate score
        '''

        score = self.sign * np.sign(x[self.feature_index] - self.theta)

        return score",Score function to calculate score,
"def theta(self, s):

        '''
        Theta sigmoid function
        '''

        s = np.where(s < -709, -709, s)

        return 1 / (1 + np.exp((-1) * s))",Theta sigmoid function,
"def score_function(self, x, W):
        # need refector

        '''
        Score function to calculate score
        '''

        score = self.theta(np.inner(x, W))

        return score",Score function to calculate score,
"def error_function(self, x, y, W):
        # need refector

        '''
        Error function to calculate error: cross entropy error
        '''

        error = np.log(1 + np.exp((-1) * y * np.inner(x, W)))

        return error",Error function to calculate error: cross entropy error,
"def get_assembly_length(self):
        """"""Returns the length of the assembly, without the filtered contigs.

        Returns
        -------
        x : int
            Total length of the assembly.

        """"""

        return sum(
            [vals[""length""] for contig_id, vals in self.contigs.items()
             if contig_id not in self.filtered_ids])","Returns the length of the assembly, without the filtered contigs.

        Returns
        -------
        x : int
            Total length of the assembly.",
"def signal_handler(screen):
    """"""This function is bound to the SIGINT signal (like ctrl+c) to graciously
    exit the program and reset the curses options.
    """"""

    if screen:
        screen.clear()
        screen.refresh()

        curses.nocbreak()
        screen.keypad(0)
        curses.echo()
        curses.endwin()

    print(""Exiting flowcraft inspection... Bye"")
    sys.exit(0)","This function is bound to the SIGINT signal (like ctrl+c) to graciously
    exit the program and reset the curses options.",
"def _updown(self, direction):
        """"""Provides curses scroll functionality.
        """"""

        if direction == ""up"" and self.top_line != 0:
            self.top_line -= 1
        elif direction == ""down"" and \
                self.screen.getmaxyx()[0] + self.top_line\
                <= self.content_lines + 3:
            self.top_line += 1",Provides curses scroll functionality.,
"def _rightleft(self, direction):
        """"""Provides curses horizontal padding""""""

        if direction == ""left"" and self.padding != 0:
            self.padding -= 1

        if direction == ""right"" and \
                self.screen.getmaxyx()[1] + self.padding < self.max_width:
            self.padding += 1",Provides curses horizontal padding,
"def write_report_data(self):
        """"""Writes the JSON report to a json file
        """"""

        json_plot = self.get_plot_data()
        json_table = self.get_table_data()

        json_dic = {**json_plot, **json_table}

        with open("".report.json"", ""w"") as json_report:
            json_report.write(json.dumps(json_dic, separators=("","", "":"")))",Writes the JSON report to a json file,
"def _gc_prop(s, length):
        """"""Get proportion of GC from a string

        Parameters
        ----------
        s : str
            Arbitrary string

        Returns
        -------
        x : float
            GC proportion.
        """"""

        gc = sum(map(s.count, [""c"", ""g""]))

        return gc / length","Get proportion of GC from a string

        Parameters
        ----------
        s : str
            Arbitrary string

        Returns
        -------
        x : float
            GC proportion.",
"def _build_header(self):
        """"""Adds the header template to the master template string
        """"""

        logger.debug(""==============="")
        logger.debug(""Building header"")
        logger.debug(""==============="")
        self.template += hs.header",Adds the header template to the master template string,
"def _build_footer(self):
        """"""Adds the footer template to the master template string""""""

        logger.debug(""==============="")
        logger.debug(""Building header"")
        logger.debug(""==============="")
        self.template += fs.footer",Adds the footer template to the master template string,
"def export_directives(self):
        """"""Export pipeline directives as a JSON to stdout
        """"""

        directives_json = {}

        # Skip first init process
        for p in self.processes[1:]:
            directives_json[p.template] = p.directives

        # Flush params json to stdout
        sys.stdout.write(json.dumps(directives_json))",Export pipeline directives as a JSON to stdout,
"def convert_camel_case(name):
    """"""Convers a CamelCase string into a snake_case one

    Parameters
    ----------
    name : str
        An arbitrary string that may be CamelCase

    Returns
    -------
    str
        The input string converted into snake_case

    """"""
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()","Convers a CamelCase string into a snake_case one

    Parameters
    ----------
    name : str
        An arbitrary string that may be CamelCase

    Returns
    -------
    str
        The input string converted into snake_case",
"def median_filter(X, M=8):
    """"""Median filter along the first axis of the feature matrix X.""""""
    for i in range(X.shape[1]):
        X[:, i] = filters.median_filter(X[:, i], size=M)
    return X",Median filter along the first axis of the feature matrix X.,
"def compute_gaussian_krnl(M):
    """"""Creates a gaussian kernel following Foote's paper.""""""
    g = signal.gaussian(M, M // 3., sym=True)
    G = np.dot(g.reshape(-1, 1), g.reshape(1, -1))
    G[M // 2:, :M // 2] = -G[M // 2:, :M // 2]
    G[:M // 2, M // 2:] = -G[:M // 2, M // 2:]
    return G",Creates a gaussian kernel following Foote's paper.,
"def compute_ssm(X, metric=""seuclidean""):
    """"""Computes the self-similarity matrix of X.""""""
    D = distance.pdist(X, metric=metric)
    D = distance.squareform(D)
    D /= D.max()
    return 1 - D",Computes the self-similarity matrix of X.,
"def compute_nc(X, G):
    """"""Computes the novelty curve from the self-similarity matrix X and
        the gaussian kernel G.""""""
    N = X.shape[0]
    M = G.shape[0]
    nc = np.zeros(N)

    for i in range(M // 2, N - M // 2 + 1):
        nc[i] = np.sum(X[i - M // 2:i + M // 2, i - M // 2:i + M // 2] * G)

    # Normalize
    nc += nc.min()
    nc /= nc.max()
    return nc","Computes the novelty curve from the self-similarity matrix X and
        the gaussian kernel G.",
"def gaussian_filter(X, M=8, axis=0):
    """"""Gaussian filter along the first axis of the feature matrix X.""""""
    for i in range(X.shape[axis]):
        if axis == 1:
            X[:, i] = filters.gaussian_filter(X[:, i], sigma=M / 2.)
        elif axis == 0:
            X[i, :] = filters.gaussian_filter(X[i, :], sigma=M / 2.)
    return X",Gaussian filter along the first axis of the feature matrix X.,
"def compute_nc(X):
    """"""Computes the novelty curve from the structural features.""""""
    N = X.shape[0]
    # nc = np.sum(np.diff(X, axis=0), axis=1) # Difference between SF's

    nc = np.zeros(N)
    for i in range(N - 1):
        nc[i] = distance.euclidean(X[i, :], X[i + 1, :])

    # Normalize
    nc += np.abs(nc.min())
    nc /= float(nc.max())
    return nc",Computes the novelty curve from the structural features.,
"def circular_shift(X):
    """"""Shifts circularly the X squre matrix in order to get a
        time-lag matrix.""""""
    N = X.shape[0]
    L = np.zeros(X.shape)
    for i in range(N):
        L[i, :] = np.asarray([X[(i + j) % N, j] for j in range(N)])
    return L","Shifts circularly the X squre matrix in order to get a
        time-lag matrix.",
"def get_duration(features_file):
    """"""Reads the duration of a given features file.

    Parameters
    ----------
    features_file: str
        Path to the JSON file containing the features.

    Returns
    -------
    dur: float
        Duration of the analyzed file.
    """"""
    with open(features_file) as f:
        feats = json.load(f)
    return float(feats[""globals""][""dur""])","Reads the duration of a given features file.

    Parameters
    ----------
    features_file: str
        Path to the JSON file containing the features.

    Returns
    -------
    dur: float
        Duration of the analyzed file.",
"def _get_dataset_file(self, dir, ext):
        """"""Gets the desired dataset file.""""""
        audio_file_ext = ""."" + self.audio_file.split(""."")[-1]
        base_file = os.path.basename(self.audio_file).replace(
            audio_file_ext, ext)
        return os.path.join(self.ds_path, dir, base_file)",Gets the desired dataset file.,
"def get_param_names(self):
        """"""Returns the parameter names for these features, avoiding
        the global parameters.""""""
        return [name for name in vars(self) if not name.startswith('_') and
                name not in self._global_param_names]","Returns the parameter names for these features, avoiding
        the global parameters.",
"def _compute_framesync_times(self):
        """"""Computes the framesync times based on the framesync features.""""""
        self._framesync_times = librosa.core.frames_to_time(
            np.arange(self._framesync_features.shape[0]), self.sr,
            self.hop_length)",Computes the framesync times based on the framesync features.,
"def print_results(results):
    """"""Print all the results.

    Parameters
    ----------
    results: pd.DataFrame
        Dataframe with all the results
    """"""
    if len(results) == 0:
        logging.warning(""No results to print!"")
        return
    res = results.mean()
    logging.info(""Results:\n%s"" % res)","Print all the results.

    Parameters
    ----------
    results: pd.DataFrame
        Dataframe with all the results",
"def compute_information_gain(ann_inter, est_inter, est_file, bins):
    """"""Computes the information gain of the est_file from the annotated
    intervals and the estimated intervals.""""""
    ann_times = utils.intervals_to_times(ann_inter)
    est_times = utils.intervals_to_times(est_inter)
    return mir_eval.beat.information_gain(ann_times, est_times, bins=bins)","Computes the information gain of the est_file from the annotated
    intervals and the estimated intervals.",
"def compute_all_features(file_struct, framesync):
    """"""Computes all features for the given file.""""""
    for feature_id in msaf.features_registry:
        logging.info(""Computing %s for file %s"" % (feature_id,
                                                   file_struct.audio_file))
        feats = Features.select_features(feature_id, file_struct, False, framesync)
        feats.features",Computes all features for the given file.,
"def gaussian_cost(X):
    '''Return the average log-likelihood of data under a standard normal
    '''

    d, n = X.shape

    if n < 2:
        return 0

    sigma = np.var(X, axis=1, ddof=1)

    cost = -0.5 * d * n * np.log(2. * np.pi) - 0.5 * (n - 1.) * np.sum(sigma)
    return cost",Return the average log-likelihood of data under a standard normal,
"def lognormalize(F, floor=0.1, min_db=-80):
    """"""Log-normalizes features such that each vector is between min_db to 0.""""""
    assert min_db < 0
    F = min_max_normalize(F, floor=floor)
    F = np.abs(min_db) * np.log10(F)  # Normalize from min_db to 0
    return F",Log-normalizes features such that each vector is between min_db to 0.,
"def min_max_normalize(F, floor=0.001):
    """"""Normalizes features such that each vector is between floor to 1.""""""
    F += -F.min() + floor
    F = F / F.max(axis=0)
    return F",Normalizes features such that each vector is between floor to 1.,
"def get_time_frames(dur, anal):
    """"""Gets the time frames and puts them in a numpy array.""""""
    n_frames = get_num_frames(dur, anal)
    return np.linspace(0, dur, num=n_frames)",Gets the time frames and puts them in a numpy array.,
"def get_clustered_data(self, X, labels, label_index):
        """"""Returns the data with a specific label_index, using the previously
         learned labels.""""""
        D = X[np.argwhere(labels == label_index)]
        return D.reshape((D.shape[0], D.shape[-1]))","Returns the data with a specific label_index, using the previously
         learned labels.",
"def run_kmeans(self, X, K):
        """"""Runs k-means and returns the labels assigned to the data.""""""
        wX = vq.whiten(X)
        means, dist = vq.kmeans(wX, K, iter=100)
        labels, dist = vq.vq(wX, means)
        return means, labels",Runs k-means and returns the labels assigned to the data.,
"def magnitude(X):
    """"""Magnitude of a complex matrix.""""""
    r = np.real(X)
    i = np.imag(X)
    return np.sqrt(r * r + i * i);",Magnitude of a complex matrix.,
"def json_to_bounds(segments_json):
    """"""Extracts the boundaries from a json file and puts them into
        an np array.""""""
    f = open(segments_json)
    segments = json.load(f)[""segments""]
    bounds = []
    for segment in segments:
        bounds.append(segment[""start""])
    bounds.append(bounds[-1] + segments[-1][""duration""]) # Add last boundary
    f.close()
    return np.asarray(bounds)","Extracts the boundaries from a json file and puts them into
        an np array.",
"def json_bounds_to_bounds(bounds_json):
    """"""Extracts the boundaries from a bounds json file and puts them into
        an np array.""""""
    f = open(bounds_json)
    segments = json.load(f)[""bounds""]
    bounds = []
    for segment in segments:
        bounds.append(segment[""start""])
    f.close()
    return np.asarray(bounds)","Extracts the boundaries from a bounds json file and puts them into
        an np array.",
"def json_to_beats(beats_json_file):
    """"""Extracts the beats from the beats_json_file and puts them into
        an np array.""""""
    f = open(beats_json_file, ""r"")
    beats_json = json.load(f)
    beats = []
    for beat in beats_json[""beats""]:
        beats.append(beat[""start""])
    f.close()
    return np.asarray(beats)","Extracts the beats from the beats_json_file and puts them into
        an np array.",
"def main():
    '''
    Main Entry point for translator and argument parser
    '''
    args      = command_line()
    translate = partial(translator, args.source, args.dest,
                        version=' '.join([__version__, __build__]))

    return source(spool(set_task(translate, translit=args.translit)), args.text)",Main Entry point for translator and argument parser,
"def print_table(language):
    '''
    Generates a formatted table of language codes
    '''
    table = translation_table(language)

    for code, name in sorted(table.items(), key=operator.itemgetter(0)):
        print(u'{language:<8} {name:\u3000<20}'.format(
            name=name, language=code
        ))

    return None",Generates a formatted table of language codes,
"def bbox(self):
        """"""
        The bounding box for nodes in this network [xmin, ymin, xmax, ymax]
        """"""
        return [self.nodes_df.x.min(), self.nodes_df.y.min(),
                self.nodes_df.x.max(), self.nodes_df.y.max()]","The bounding box for nodes in this network [xmin, ymin, xmax, ymax]",
"def make_osm_query(query):
    """"""
    Make a request to OSM and return the parsed JSON.

    Parameters
    ----------
    query : str
        A string in the Overpass QL format.

    Returns
    -------
    data : dict

    """"""
    osm_url = 'http://www.overpass-api.de/api/interpreter'
    req = requests.get(osm_url, params={'data': query})
    req.raise_for_status()

    return req.json()","Make a request to OSM and return the parsed JSON.

    Parameters
    ----------
    query : str
        A string in the Overpass QL format.

    Returns
    -------
    data : dict",
"def equal(x, y):
    """"""
    Shortcut function for ``unittest.TestCase.assertEqual()``.

    Arguments:
        x (mixed)
        y (mixed)

    Raises:
        AssertionError: in case of assertion error.

    Returns:
        bool
    """"""
    if PY_3:
        return test_case().assertEqual(x, y) or True

    assert x == y","Shortcut function for ``unittest.TestCase.assertEqual()``.

    Arguments:
        x (mixed)
        y (mixed)

    Raises:
        AssertionError: in case of assertion error.

    Returns:
        bool",
"def isregex(value):
    """"""
    Returns ``True`` if the input argument object is a native
    regular expression object, otherwise ``False``.

    Arguments:
        value (mixed): input value to test.

    Returns:
        bool
    """"""
    if not value:
        return False
    return any((isregex_expr(value), isinstance(value, retype)))","Returns ``True`` if the input argument object is a native
    regular expression object, otherwise ``False``.

    Arguments:
        value (mixed): input value to test.

    Returns:
        bool",
"def get(name):
    """"""
    Returns a matcher instance by class or alias name.

    Arguments:
        name (str): matcher class name or alias.

    Returns:
        matcher: found matcher instance, otherwise ``None``.
    """"""
    for matcher in matchers:
        if matcher.__name__ == name or getattr(matcher, 'name', None) == name:
            return matcher","Returns a matcher instance by class or alias name.

    Arguments:
        name (str): matcher class name or alias.

    Returns:
        matcher: found matcher instance, otherwise ``None``.",
"def body(self, body):
        """"""
        Defines response body data.

        Arguments:
            body (str|bytes): response body to use.

        Returns:
            self: ``pook.Response`` current instance.
        """"""
        if isinstance(body, bytes):
            body = body.decode('utf-8')

        self._body = body","Defines response body data.

        Arguments:
            body (str|bytes): response body to use.

        Returns:
            self: ``pook.Response`` current instance.",
"def _append_funcs(target, items):
    """"""
    Helper function to append functions into a given list.

    Arguments:
        target (list): receptor list to append functions.
        items (iterable): iterable that yields elements to append.
    """"""
    [target.append(item) for item in items
     if isfunction(item) or ismethod(item)]","Helper function to append functions into a given list.

    Arguments:
        target (list): receptor list to append functions.
        items (iterable): iterable that yields elements to append.",
"def method(self, method):
        """"""
        Defines the HTTP method to match.
        Use ``*`` to match any method.

        Arguments:
            method (str): method value to match. E.g: ``GET``.

        Returns:
            self: current Mock instance.
        """"""
        self._request.method = method
        self.add_matcher(matcher('MethodMatcher', method))","Defines the HTTP method to match.
        Use ``*`` to match any method.

        Arguments:
            method (str): method value to match. E.g: ``GET``.

        Returns:
            self: current Mock instance.",
"def params(self, params):
        """"""
        Defines a set of URL query params to match.

        Arguments:
            params (dict): set of params to match.

        Returns:
            self: current Mock instance.
        """"""
        url = furl(self._request.rawurl)
        url = url.add(params)
        self._request.url = url.url
        self.add_matcher(matcher('QueryMatcher', params))","Defines a set of URL query params to match.

        Arguments:
            params (dict): set of params to match.

        Returns:
            self: current Mock instance.",
"def body(self, body):
        """"""
        Defines the body data to match.

        ``body`` argument can be a ``str``, ``binary`` or a regular expression.

        Arguments:
            body (str|binary|regex): body data to match.

        Returns:
            self: current Mock instance.
        """"""
        self._request.body = body
        self.add_matcher(matcher('BodyMatcher', body))","Defines the body data to match.

        ``body`` argument can be a ``str``, ``binary`` or a regular expression.

        Arguments:
            body (str|binary|regex): body data to match.

        Returns:
            self: current Mock instance.",
"def xml(self, xml):
        """"""
        Defines a XML body value to match.

        Arguments:
            xml (str|regex): body XML to match.

        Returns:
            self: current Mock instance.
        """"""
        self._request.xml = xml
        self.add_matcher(matcher('XMLMatcher', xml))","Defines a XML body value to match.

        Arguments:
            xml (str|regex): body XML to match.

        Returns:
            self: current Mock instance.",
"def file(self, path):
        """"""
        Reads the body to match from a disk file.

        Arguments:
            path (str): relative or absolute path to file to read from.

        Returns:
            self: current Mock instance.
        """"""
        with open(path, 'r') as f:
            self.body(str(f.read()))","Reads the body to match from a disk file.

        Arguments:
            path (str): relative or absolute path to file to read from.

        Returns:
            self: current Mock instance.",
"def persist(self, status=None):
        """"""
        Enables persistent mode for the current mock.

        Returns:
            self: current Mock instance.
        """"""
        self._persist = status if type(status) is bool else True","Enables persistent mode for the current mock.

        Returns:
            self: current Mock instance.",
"def error(self, error):
        """"""
        Defines a simulated exception error that will be raised.

        Arguments:
            error (str|Exception): error to raise.

        Returns:
            self: current Mock instance.
        """"""
        self._error = RuntimeError(error) if isinstance(error, str) else error","Defines a simulated exception error that will be raised.

        Arguments:
            error (str|Exception): error to raise.

        Returns:
            self: current Mock instance.",
"def remove_mock(self, mock):
        """"""
        Removes a specific mock instance by object reference.

        Arguments:
            mock (pook.Mock): mock instance to remove.
        """"""
        self.mocks = [m for m in self.mocks if m is not mock]","Removes a specific mock instance by object reference.

        Arguments:
            mock (pook.Mock): mock instance to remove.",
"def disable(self):
        """"""
        Disables interceptors and stops intercepting any outgoing HTTP traffic.
        """"""
        if not self.active:
            return None

        # Disable current mock engine
        self.mock_engine.disable()
        # Disable engine state
        self.active = False",Disables interceptors and stops intercepting any outgoing HTTP traffic.,
"def copy(self):
        """"""
        Copies the current Request object instance for side-effects purposes.

        Returns:
            pook.Request: copy of the current Request instance.
        """"""
        req = type(self)()
        req.__dict__ = self.__dict__.copy()
        req._headers = self.headers.copy()
        return req","Copies the current Request object instance for side-effects purposes.

        Returns:
            pook.Request: copy of the current Request instance.",
"def get_setting(connection, key):
    """"""Get key from connection or default to settings.""""""
    if key in connection.settings_dict:
        return connection.settings_dict[key]
    else:
        return getattr(settings, key)",Get key from connection or default to settings.,
"def as_sql(self, compiler, connection):
        """"""Build SQL with decryption and casting.""""""
        sql, params = super(DecryptedCol, self).as_sql(compiler, connection)
        sql = self.target.get_decrypt_sql(connection) % (sql, self.target.get_cast_sql())
        return sql, params",Build SQL with decryption and casting.,
"def pre_save(self, model_instance, add):
        """"""Save the original_value.""""""
        if self.original:
            original_value = getattr(model_instance, self.original)
            setattr(model_instance, self.attname, original_value)

        return super(HashMixin, self).pre_save(model_instance, add)",Save the original_value.,
"def get_col(self, alias, output_field=None):
        """"""Get the decryption for col.""""""
        if output_field is None:
            output_field = self
        if alias != self.model._meta.db_table or output_field != self:
            return DecryptedCol(
                alias,
                self,
                output_field
            )
        else:
            return self.cached_col",Get the decryption for col.,
"def get_placeholder(self, value=None, compiler=None, connection=None):
        """"""Tell postgres to encrypt this field using PGP.""""""
        return self.encrypt_sql.format(get_setting(connection, 'PUBLIC_PGP_KEY'))",Tell postgres to encrypt this field using PGP.,
"def CovInv(self):
        """"""
        Inverse of the covariance matrix

        Returns
        -------

         H : (np.array)
            inverse of the covariance matrix.
        """"""
        self.recurse(full_matrix=True)
        return self.tree.root.cinv","Inverse of the covariance matrix

        Returns
        -------

         H : (np.array)
            inverse of the covariance matrix.",
"def _create_transversion_transition_W(kappa):
    """"""
    Alphabet = [A, C, G, T]
    """"""
    W = np.ones((4,4))
    W[0, 2]=W[1, 3]=W[2, 0]=W[3,1]=kappa
    return W","Alphabet = [A, C, G, T]",
"def attach_to_tree(self):
        '''
        attaches the the merger cost to each branch length interpolator in the tree.
        '''
        for clade in self.tree.find_clades():
            if clade.up is not None:
                clade.branch_length_interpolator.merger_cost = self.cost",attaches the the merger cost to each branch length interpolator in the tree.,
"def gtr(self, value):
        """"""
        Set a new GTR object

        Parameters
        -----------

         value : GTR
            the new GTR object
        """"""
        if not (isinstance(value, GTR) or isinstance(value, GTR_site_specific)):
            raise TypeError("" GTR instance expected"")
        self._gtr = value","Set a new GTR object

        Parameters
        -----------

         value : GTR
            the new GTR object",
"def _exp_lt(self, t):
        """"""
        Parameters
        ----------

         t : float
            time to propagate

        Returns
        --------

         exp_lt : numpy.array
            Array of values exp(lambda(i) * t),
            where (i) - alphabet index (the eigenvalue number).
        """"""
        return np.exp(self.mu * t * self.eigenvals)","Parameters
        ----------

         t : float
            time to propagate

        Returns
        --------

         exp_lt : numpy.array
            Array of values exp(lambda(i) * t),
            where (i) - alphabet index (the eigenvalue number).",
"def delta_function(cls, x_pos, weight=1., min_width=MIN_INTEGRATION_PEAK):
        """"""
        Create delta function distribution.
        """"""

        distribution = cls(x_pos,0.,is_log=True, min_width=min_width)
        distribution.weight  = weight
        return distribution",Create delta function distribution.,
"def client(self):
        """"""
        Socket connection.
        """"""
        if not self._client:
            self._client = socket.create_connection(
                (self.host, self.port), self.timeout)
            self.logger.debug('Client connected with guacd server (%s, %s, %s)'
                              % (self.host, self.port, self.timeout))

        return self._client",Socket connection.,
"def close(self):
        """"""
        Terminate connection with Guacamole guacd server.
        """"""
        self.client.close()
        self._client = None
        self.connected = False
        self.logger.debug('Connection closed.')",Terminate connection with Guacamole guacd server.,
"def send(self, data):
        """"""
        Send encoded instructions to Guacamole guacd server.
        """"""
        self.logger.debug('Sending data: %s' % data)
        self.client.sendall(data.encode())",Send encoded instructions to Guacamole guacd server.,
"def send_instruction(self, instruction):
        """"""
        Send instruction after encoding.
        """"""
        self.logger.debug('Sending instruction: %s' % str(instruction))
        return self.send(instruction.encode())",Send instruction after encoding.,
"def utf8(unicode_str):
    """"""
    Return a utf-8 encoded string from a valid unicode string.

    :param unicode_str: Unicode string.

    :return: str
    """"""
    if six.PY2 and isinstance(unicode_str, __unicode__):
        return unicode_str.encode('utf-8')

    return unicode_str","Return a utf-8 encoded string from a valid unicode string.

    :param unicode_str: Unicode string.

    :return: str",
"def encode_arg(arg):
        """"""
        Encode argument to be sent in a valid GuacamoleInstruction.

        example:
        >> arg = encode_arg('size')
        >> arg == '4.size'
        >> True

        :param arg: arg string.

        :return: str
        """"""
        arg_utf8 = utf8(arg)

        return ELEM_SEP.join([str(len(str(arg_utf8))), str(arg_utf8)])","Encode argument to be sent in a valid GuacamoleInstruction.

        example:
        >> arg = encode_arg('size')
        >> arg == '4.size'
        >> True

        :param arg: arg string.

        :return: str",
"def encode(self):
        """"""
        Prepare the instruction to be sent over the wire.

        :return: str
        """"""
        instruction_iter = itertools.chain([self.opcode], self.args)

        elems = ARG_SEP.join(self.encode_arg(arg) for arg in instruction_iter)

        return elems + INST_TERM","Prepare the instruction to be sent over the wire.

        :return: str",
"def class_url(cls):
        """"""Returns a versioned URI string for this class""""""
        base = 'v{0}'.format(getattr(cls, 'RESOURCE_VERSION', '1'))
        return ""/{0}/{1}"".format(base, class_to_api_name(cls.class_name()))",Returns a versioned URI string for this class,
"def class_url(cls):
        """"""
        Returns a versioned URI string for this class,
        and don't pluralize the class name.
        """"""
        base = 'v{0}'.format(getattr(cls, 'RESOURCE_VERSION', '1'))
        return ""/{0}/{1}"".format(base, class_to_api_name(
            cls.class_name(), pluralize=False))","Returns a versioned URI string for this class,
        and don't pluralize the class name.",
"def parent_object(self):
        """""" Get the commit objects parent Import or Migration """"""
        from . import types
        parent_klass = types.get(self.parent_job_model.split('.')[1])
        return parent_klass.retrieve(self.parent_job_id, client=self._client)",Get the commit objects parent Import or Migration,
"def whoami(*args, **kwargs):
    """"""
    Prints information about the current user.
    Assumes the user is already logged-in.
    """"""
    user = client.whoami()

    if user:
        print_user(user)
    else:
        print('You are not logged-in.')","Prints information about the current user.
    Assumes the user is already logged-in.",
"def print_user(user):
    """"""
    Prints information about the current user.
    """"""
    email = user['email']
    domain = user['account']['domain']
    role = user['role']
    print('You are logged-in to the ""{0}"" domain '
          'as {1} with role {2}.'
          .format(domain, email, role))",Prints information about the current user.,
"def range(self, chromosome, start, stop, exact=False):
        """"""
        Shortcut to do range filters on genomic datasets.
        """"""
        return self._clone(
            filters=[GenomicFilter(chromosome, start, stop, exact)])",Shortcut to do range filters on genomic datasets.,
"def position(self, chromosome, position, exact=False):
        """"""
        Shortcut to do a single position filter on genomic datasets.
        """"""
        return self._clone(
            filters=[GenomicFilter(chromosome, position, exact=exact)])",Shortcut to do a single position filter on genomic datasets.,
"def construct_from(cls, values, **kwargs):
        """"""Used to create a new object from an HTTP response""""""
        instance = cls(values.get(cls.ID_ATTR), **kwargs)
        instance.refresh_from(values)
        return instance",Used to create a new object from an HTTP response,
"def get(self, url, params, **kwargs):
        """"""Issues an HTTP GET across the wire via the Python requests
        library. See *request()* for information on keyword args.""""""
        kwargs['params'] = params
        return self.request('GET', url, **kwargs)","Issues an HTTP GET across the wire via the Python requests
        library. See *request()* for information on keyword args.",
"def delete(self, url, data, **kwargs):
        """"""Issues an HTTP DELETE across the wire via the Python requests
        library. See *request* for information on keyword args.""""""
        kwargs['data'] = data
        return self.request('DELETE', url, **kwargs)","Issues an HTTP DELETE across the wire via the Python requests
        library. See *request* for information on keyword args.",
"def child_object(self):
        """""" Get Task child object class """"""
        from . import types
        child_klass = types.get(self.task_type.split('.')[1])
        return child_klass.retrieve(self.task_id, client=self._client)",Get Task child object class,
"def cancel(self):
        """""" Cancel a task """"""
        _status = self.status
        self.status = ""canceled""
        try:
            self.save()
        except:
            # Reset status to what it was before
            # status update failure
            self.status = _status
            raise",Cancel a task,
"def _isint(string):
    """"""
    >>> _isint(""123"")
    True
    >>> _isint(""123.45"")
    False
    """"""
    return type(string) is int or \
        (isinstance(string, _binary_type) or
         isinstance(string, string_types)) and \
        _isconvertible(int, string)",">>> _isint(""123"")
    True
    >>> _isint(""123.45"")
    False",
"def _build_line(colwidths, padding, begin, fill, sep, end):
    ""Return a string which represents a horizontal line.""
    cells = [fill * (w + 2 * padding) for w in colwidths]
    return _build_row(cells, 0, begin, sep, end)",Return a string which represents a horizontal line.,
"def _mediawiki_cell_attrs(row, colaligns):
    ""Prefix every cell in a row with an HTML alignment attribute.""
    alignment = {""left"": '',
                 ""right"": 'align=""right""| ',
                 ""center"": 'align=""center""| ',
                 ""decimal"": 'align=""right""| '}
    row2 = [alignment[a] + c for c, a in zip(row, colaligns)]
    return row2",Prefix every cell in a row with an HTML alignment attribute.,
"def evaluate(self, data=None, data_type='string', is_list=False):
        """"""Evaluates the expression with the provided context and format.""""""
        payload = {
            'data': data,
            'expression': self.expr,
            'data_type': data_type,
            'is_list': is_list
        }
        res = self._client.post('/v1/evaluate', payload)
        return res['result']",Evaluates the expression with the provided context and format.,
"def _get_column_types(self, data):
        """"""Get a list of the data types for each column in *data*.""""""
        columns = list(zip_longest(*data))
        return [self._get_column_type(column) for column in columns]",Get a list of the data types for each column in *data*.,
"def _get_column_type(self, column):
        """"""Get the most generic data type for iterable *column*.""""""
        type_values = [TYPES[self._get_type(v)] for v in column]
        inverse_types = {v: k for k, v in TYPES.items()}
        return inverse_types[max(type_values)]",Get the most generic data type for iterable *column*.,
"def _get_type(self, value):
        """"""Get the data type for *value*.""""""
        if value is None:
            return type(None)
        elif type(value) in int_types:
            return int
        elif type(value) in float_types:
            return float
        elif isinstance(value, binary_type):
            return binary_type
        else:
            return text_type",Get the data type for *value*.,
"def read(self):
        """"""Read the default, additional, system, and user config files.

        :raises DefaultConfigValidationError: There was a validation error with
                                              the *default* file.
        """"""
        if self.default_file:
            self.read_default_config()
        return self.read_config_files(self.all_config_files())","Read the default, additional, system, and user config files.

        :raises DefaultConfigValidationError: There was a validation error with
                                              the *default* file.",
"def user_config_file(self):
        """"""Get the absolute path to the user config file.""""""
        return os.path.join(
            get_user_config_dir(self.app_name, self.app_author),
            self.filename)",Get the absolute path to the user config file.,
"def system_config_files(self):
        """"""Get a list of absolute paths to the system config files.""""""
        return [os.path.join(f, self.filename) for f in get_system_config_dirs(
            self.app_name, self.app_author)]",Get a list of absolute paths to the system config files.,
"def additional_files(self):
        """"""Get a list of absolute paths to the additional config files.""""""
        return [os.path.join(f, self.filename) for f in self.additional_dirs]",Get a list of absolute paths to the additional config files.,
"def read_config_files(self, files):
        """"""Read a list of config files.

        :param iterable files: An iterable (e.g. list) of files to read.
        """"""
        errors = {}
        for _file in files:
            config, valid = self.read_config_file(_file)
            self.update(config)
            if valid is not True:
                errors[_file] = valid
        return errors or True","Read a list of config files.

        :param iterable files: An iterable (e.g. list) of files to read.",
"def bytes_to_string(b):
    """"""Convert bytes *b* to a string.

    Hexlify bytes that can't be decoded.

    """"""
    if isinstance(b, binary_type):
        try:
            return b.decode('utf8')
        except UnicodeDecodeError:
            return '0x' + binascii.hexlify(b).decode('ascii')
    return b","Convert bytes *b* to a string.

    Hexlify bytes that can't be decoded.",
"def truncate_string(value, max_width=None):
    """"""Truncate string values.""""""
    if isinstance(value, text_type) and max_width is not None and len(value) > max_width:
        return value[:max_width]
    return value",Truncate string values.,
"def filter_dict_by_key(d, keys):
    """"""Filter the dict *d* to remove keys not in *keys*.""""""
    return {k: v for k, v in d.items() if k in keys}",Filter the dict *d* to remove keys not in *keys*.,
"def unique_items(seq):
    """"""Return the unique items from iterable *seq* (in order).""""""
    seen = set()
    return [x for x in seq if not (x in seen or seen.add(x))]",Return the unique items from iterable *seq* (in order).,
"def replace(s, replace):
    """"""Replace multiple values in a string""""""
    for r in replace:
        s = s.replace(*r)
    return s",Replace multiple values in a string,
"def adapter(data, headers, **kwargs):
    """"""Wrap the formatting inside a function for TabularOutputFormatter.""""""
    for row in chain((headers,), data):
        yield ""\t"".join((replace(r, (('\n', r'\n'), ('\t', r'\t'))) for r in row))",Wrap the formatting inside a function for TabularOutputFormatter.,
"def call_and_exit(self, cmd, shell=True):
        """"""Run the *cmd* and exit with the proper exit code.""""""
        sys.exit(subprocess.call(cmd, shell=shell))",Run the *cmd* and exit with the proper exit code.,
"def call_in_sequence(self, cmds, shell=True):
        """"""Run multiple commmands in a row, exiting if one fails.""""""
        for cmd in cmds:
            if subprocess.call(cmd, shell=shell) == 1:
                sys.exit(1)","Run multiple commmands in a row, exiting if one fails.",
"def apply_options(self, cmd, options=()):
        """"""Apply command-line options.""""""
        for option in (self.default_cmd_options + options):
            cmd = self.apply_option(cmd, option,
                                    active=getattr(self, option, False))
        return cmd",Apply command-line options.,
"def apply_option(self, cmd, option, active=True):
        """"""Apply a command-line option.""""""
        return re.sub(r'{{{}\:(?P<option>[^}}]*)}}'.format(option),
                      '\g<option>' if active else '', cmd)",Apply a command-line option.,
"def initialize_options(self):
        """"""Set the default options.""""""
        self.branch = 'master'
        self.fix = False
        super(lint, self).initialize_options()",Set the default options.,
"def run(self):
        """"""Run the linter.""""""
        cmd = 'pep8radius {branch} {{fix: --in-place}}{{verbose: -vv}}'
        cmd = cmd.format(branch=self.branch)
        self.call_and_exit(self.apply_options(cmd, ('fix', )))",Run the linter.,
"def run(self):
        """"""Generate and view the documentation.""""""
        cmds = (self.clean_docs_cmd, self.html_docs_cmd, self.view_docs_cmd)
        self.call_in_sequence(cmds)",Generate and view the documentation.,
"def _format_row(headers, row):
    """"""Format a row.""""""
    formatted_row = [' | '.join(field) for field in zip(headers, row)]
    return '\n'.join(formatted_row)",Format a row.,
"def adapter(data, headers, **kwargs):
    """"""Wrap vertical table in a function for TabularOutputFormatter.""""""
    keys = ('sep_title', 'sep_character', 'sep_length')
    return vertical_table(data, headers, **filter_dict_by_key(kwargs, keys))",Wrap vertical table in a function for TabularOutputFormatter.,
"def flags2text(self):
        """"""
        parse the `self.flags` field and create a list of `CKF_*` strings
        corresponding to bits set in flags

        :return: a list of strings
        :rtype: list
        """"""
        r = []
        for v in self.flags_dict.keys():
            if self.flags & v:
                r.append(self.flags_dict[v])
        return r","parse the `self.flags` field and create a list of `CKF_*` strings
        corresponding to bits set in flags

        :return: a list of strings
        :rtype: list",
"def closeAllSessions(self, slot):
        """"""
        C_CloseAllSessions

        :param slot: slot number
        :type slot: integer
        """"""
        rv = self.lib.C_CloseAllSessions(slot)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)","C_CloseAllSessions

        :param slot: slot number
        :type slot: integer",
"def waitForSlotEvent(self, flags=0):
        """"""
        C_WaitForSlotEvent

        :param flags: 0 (default) or `CKF_DONT_BLOCK`
        :type flags: integer
        :return: slot
        :rtype: integer
        """"""
        tmp = 0
        (rv, slot) = self.lib.C_WaitForSlotEvent(flags, tmp)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)

        return slot","C_WaitForSlotEvent

        :param flags: 0 (default) or `CKF_DONT_BLOCK`
        :type flags: integer
        :return: slot
        :rtype: integer",
"def update(self, data):
        """"""
        C_DigestUpdate

        :param data: data to add to the digest
        :type data: bytes or string
        """"""
        data1 = ckbytelist(data)
        rv = self._lib.C_DigestUpdate(self._session, data1)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)
        return self","C_DigestUpdate

        :param data: data to add to the digest
        :type data: bytes or string",
"def digestKey(self, handle):
        """"""
        C_DigestKey

        :param handle: key handle
        :type handle: CK_OBJECT_HANDLE
        """"""
        rv = self._lib.C_DigestKey(self._session, handle)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)
        return self","C_DigestKey

        :param handle: key handle
        :type handle: CK_OBJECT_HANDLE",
"def closeSession(self):
        """"""
        C_CloseSession
        """"""
        rv = self.lib.C_CloseSession(self.session)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)",C_CloseSession,
"def logout(self):
        """"""
        C_Logout
        """"""
        rv = self.lib.C_Logout(self.session)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)

        del self",C_Logout,
"def initPin(self, pin):
        """"""
        C_InitPIN

        :param pin: new PIN
        """"""
        new_pin1 = ckbytelist(pin)
        rv = self.lib.C_InitPIN(self.session, new_pin1)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)","C_InitPIN

        :param pin: new PIN",
"def setPin(self, old_pin, new_pin):
        """"""
        C_SetPIN

        :param old_pin: old PIN
        :param new_pin: new PIN
        """"""
        old_pin1 = ckbytelist(old_pin)
        new_pin1 = ckbytelist(new_pin)
        rv = self.lib.C_SetPIN(self.session, old_pin1, new_pin1)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)","C_SetPIN

        :param old_pin: old PIN
        :param new_pin: new PIN",
"def createObject(self, template):
        """"""
        C_CreateObject

        :param template: object template
        """"""
        attrs = self._template2ckattrlist(template)
        handle = PyKCS11.LowLevel.CK_OBJECT_HANDLE()
        rv = self.lib.C_CreateObject(self.session, attrs, handle)
        if rv != PyKCS11.CKR_OK:
            raise PyKCS11.PyKCS11Error(rv)
        return handle","C_CreateObject

        :param template: object template",
"def destroyObject(self, obj):
        """"""
        C_DestroyObject

        :param obj: object ID
        """"""
        rv = self.lib.C_DestroyObject(self.session, obj)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)","C_DestroyObject

        :param obj: object ID",
"def isBin(self, type):
        """"""
        is the type a byte array value?

        :param type: PKCS#11 type like `CKA_MODULUS`
        :rtype: bool
        """"""
        return (not self.isBool(type)) \
            and (not self.isString(type)) \
            and (not self.isNum(type))","is the type a byte array value?

        :param type: PKCS#11 type like `CKA_MODULUS`
        :rtype: bool",
"def seedRandom(self, seed):
        """"""
        C_SeedRandom

        :param seed: seed material
        :type seed: iterable
        """"""
        low_seed = ckbytelist(seed)
        rv = self.lib.C_SeedRandom(self.session, low_seed)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)","C_SeedRandom

        :param seed: seed material
        :type seed: iterable",
"def _first_weekday(weekday, d):
    """"""
    Given a weekday and a date, will increment the date until it's
    weekday matches that of the given weekday, then that date is returned.
    """"""
    while weekday != d.weekday():
        d += timedelta(days=1)
    return d","Given a weekday and a date, will increment the date until it's
    weekday matches that of the given weekday, then that date is returned.",
"def sv_variant(institute_id, case_name, variant_id):
    """"""Display a specific structural variant.""""""
    data = controllers.sv_variant(store, institute_id, case_name, variant_id)
    return data",Display a specific structural variant.,
"def str_variant(institute_id, case_name, variant_id):
    """"""Display a specific STR variant.""""""
    data = controllers.str_variant(store, institute_id, case_name, variant_id)
    return data",Display a specific STR variant.,
"def cancer_variants(institute_id, case_name):
    """"""Show cancer variants overview.""""""
    data = controllers.cancer_variants(store, request.args, institute_id, case_name)
    return data",Show cancer variants overview.,
"def acmg():
    """"""Calculate an ACMG classification from submitted criteria.""""""
    criteria = request.args.getlist('criterion')
    classification = get_acmg(criteria)
    return jsonify(dict(classification=classification))",Calculate an ACMG classification from submitted criteria.,
"def add_incomplete_penetrance(genes, alias_genes, hpo_lines):
    """"""Add information of incomplete penetrance""""""
    LOG.info(""Add incomplete penetrance info"")
    for hgnc_symbol in get_incomplete_penetrance_genes(hpo_lines):
        for hgnc_id in get_correct_ids(hgnc_symbol, alias_genes):
            genes[hgnc_id]['incomplete_penetrance'] = True",Add information of incomplete penetrance,
"def get_cytoband_coordinates(chrom, pos):
    """"""Get the cytoband coordinate for a position

    Args:
        chrom(str)
        pos(int)

    Returns:
        coordinate(str)
    """"""
    coordinate = """"

    if chrom in CYTOBANDS:
        for interval in CYTOBANDS[chrom][pos]:
            coordinate = interval.data

    return coordinate","Get the cytoband coordinate for a position

    Args:
        chrom(str)
        pos(int)

    Returns:
        coordinate(str)",
"def panel_update(panel_id):
    """"""Update panel to a new version.""""""
    panel_obj = store.panel(panel_id)
    update_version = request.form.get('version', None)
    new_panel_id = store.apply_pending(panel_obj, update_version)
    return redirect(url_for('panels.panel', panel_id=new_panel_id))",Update panel to a new version.,
"def whitelist(context):
    """"""Show all objects in the whitelist collection""""""
    LOG.info(""Running scout view users"")
    adapter = context.obj['adapter']

    ## TODO add a User interface to the adapter
    for whitelist_obj in adapter.whitelist_collection.find():
        click.echo(whitelist_obj['_id'])",Show all objects in the whitelist collection,
"def genes_to_json(store, query):
    """"""Fetch matching genes and convert to JSON.""""""
    gene_query = store.hgnc_genes(query, search=True)
    json_terms = [{'name': ""{} | {} ({})"".format(gene['hgnc_id'], gene['hgnc_symbol'],
                                                 ', '.join(gene['aliases'])),
                   'id': gene['hgnc_id']} for gene in gene_query]
    return json_terms",Fetch matching genes and convert to JSON.,
"def fetch_resource(url):
    """"""Fetch a resource and return the resulting lines in a list
    Send file_name to get more clean log messages
    
    Args:
        url(str)
    
    Returns:
        lines(list(str))
    """"""
    try:
        data = get_request(url)
        lines = data.split('\n')
    except Exception as err:
        raise err
    
    return lines","Fetch a resource and return the resulting lines in a list
    Send file_name to get more clean log messages
    
    Args:
        url(str)
    
    Returns:
        lines(list(str))",
"def str_variants(store, institute_obj, case_obj, variants_query, page=1, per_page=50):
    """"""Pre-process list of STR variants.""""""
    # Nothing unique to STRs on this level. Inheritance?
    return variants(store, institute_obj, case_obj, variants_query, page, per_page)",Pre-process list of STR variants.,
"def find_bai_file(bam_file):
    """"""Find out BAI file by extension given the BAM file.""""""
    bai_file = bam_file.replace('.bam', '.bai')
    if not os.path.exists(bai_file):
        # try the other convention
        bai_file = ""{}.bai"".format(bam_file)
    return bai_file",Find out BAI file by extension given the BAM file.,
"def parse_transcript(gene_obj, tx_obj, build=None):
    """"""Parse variant gene transcript (VEP).""""""
    build = build or 37
    add_tx_links(tx_obj, build)

    if tx_obj.get('refseq_id'):
        gene_name = (gene_obj['common']['hgnc_symbol'] if gene_obj['common'] else
                     gene_obj['hgnc_id'])
        tx_obj['change_str'] = transcript_str(tx_obj, gene_name)",Parse variant gene transcript (VEP).,
"def end_position(variant_obj):
    """"""Calculate end position for a variant.""""""
    alt_bases = len(variant_obj['alternative'])
    num_bases = max(len(variant_obj['reference']), alt_bases)
    return variant_obj['position'] + (num_bases - 1)",Calculate end position for a variant.,
"def spidex_human(variant_obj):
    """"""Translate SPIDEX annotation to human readable string.""""""
    if variant_obj.get('spidex') is None:
        return 'not_reported'
    elif abs(variant_obj['spidex']) < SPIDEX_HUMAN['low']['pos'][1]:
        return 'low'
    elif abs(variant_obj['spidex']) < SPIDEX_HUMAN['medium']['pos'][1]:
        return 'medium'
    else:
        return 'high'",Translate SPIDEX annotation to human readable string.,
"def expected_inheritance(variant_obj):
    """"""Gather information from common gene information.""""""
    manual_models = set()
    for gene in variant_obj.get('genes', []):
        manual_models.update(gene.get('manual_inheritance', []))
    return list(manual_models)",Gather information from common gene information.,
"def callers(variant_obj, category='snv'):
    """"""Return info about callers.""""""
    calls = set()
    for caller in CALLERS[category]:
        if variant_obj.get(caller['id']):
            calls.add((caller['name'], variant_obj[caller['id']]))

    return list(calls)",Return info about callers.,
"def export_genes(adapter, build='37'):
    """"""Export all genes from the database""""""
    LOG.info(""Exporting all genes to .bed format"")
    
    for gene_obj in adapter.all_genes(build=build):
        yield gene_obj",Export all genes from the database,
"def case(institute_id, case_name):
    """"""Return a variant.""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    if case_obj is None:
        return abort(404)
    return Response(json_util.dumps(case_obj), mimetype='application/json')",Return a variant.,
"def variant(institute_id, case_name, variant_id):
    """"""Display a specific SNV variant.""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    variant_obj = store.variant(variant_id)
    return Response(json_util.dumps(variant_obj), mimetype='application/json')",Display a specific SNV variant.,
"def collections(context):
    """"""Show all collections in the database""""""
    LOG.info(""Running scout view collections"")

    adapter = context.obj['adapter']

    for collection_name in adapter.collections():
        click.echo(collection_name)",Show all collections in the database,
"def get_file_handle(file_path):
    """"""Return a opened file""""""

    if file_path.endswith('.gz'):
        file_handle = getreader('utf-8')(gzip.open(file_path, 'r'), errors='replace')
    else:
        file_handle = open(file_path, 'r', encoding='utf-8')

    return file_handle",Return a opened file,
"def _inc_day(year, month, day, net):
    """"""Increments the day by converting to a datetime.date().""""""
    d = date(year, month, day)
    new_d = d + timezone.timedelta(days=net)
    return new_d.year, new_d.month, new_d.day",Increments the day by converting to a datetime.date().,
"def get_net(req):
    """"""Get the net of any 'next' and 'prev' querystrings.""""""
    try:
        nxt, prev = map(
            int, (req.GET.get('cal_next', 0), req.GET.get('cal_prev', 0))
        )
        net = nxt - prev
    except Exception:
        net = 0
    return net",Get the net of any 'next' and 'prev' querystrings.,
"def get_next_and_prev(net):
    """"""Returns what the next and prev querystrings should be.""""""
    if net == 0:
        nxt = prev = 1
    elif net > 0:
        nxt = net + 1
        prev = -(net - 1)
    else:
        nxt = net + 1
        prev = abs(net) + 1
    return nxt, prev",Returns what the next and prev querystrings should be.,
"def _check_year(year, month, error, error_msg):
    """"""Checks that the year is within 50 years from now.""""""
    if year not in xrange((now.year - 50), (now.year + 51)):
        year = now.year
        month = now.month
        error = error_msg
    return year, month, error",Checks that the year is within 50 years from now.,
"def check_weekday(year, month, day, reverse=False):
    """"""
    Make sure any event day we send back for weekday repeating
    events is not a weekend.
    """"""
    d = date(year, month, day)
    while d.weekday() in (5, 6):
        if reverse:
            d -= timedelta(days=1)
        else:
            d += timedelta(days=1)
    return d.year, d.month, d.day","Make sure any event day we send back for weekday repeating
    events is not a weekend.",
"def index(context):
    """"""Delete all indexes in the database""""""
    LOG.info(""Running scout delete index"")
    adapter = context.obj['adapter']
    
    for collection in adapter.db.collection_names():
        adapter.db[collection].drop_indexes()
    LOG.info(""All indexes deleted"")",Delete all indexes in the database,
"def user(context, mail):
    """"""Delete a user from the database""""""
    LOG.info(""Running scout delete user"")
    adapter = context.obj['adapter']
    user_obj = adapter.user(mail)
    if not user_obj:
        LOG.warning(""User {0} could not be found in database"".format(mail))
    else:
        adapter.delete_user(mail)",Delete a user from the database,
"def genes(context, build):
    """"""Delete all genes in the database""""""
    LOG.info(""Running scout delete genes"")
    adapter = context.obj['adapter']

    if build:
        LOG.info(""Dropping genes collection for build: %s"", build)
    else:
        LOG.info(""Dropping genes collection"")
        adapter.drop_genes()",Delete all genes in the database,
"def exons(context, build):
    """"""Delete all exons in the database""""""
    LOG.info(""Running scout delete exons"")
    adapter = context.obj['adapter']

    adapter.drop_exons(build)",Delete all exons in the database,
"def load_user(user_email):
    """"""Returns the currently active user as an object.""""""
    user_obj = store.user(user_email)
    user_inst = LoginUser(user_obj) if user_obj else None
    return user_inst",Returns the currently active user as an object.,
"def user_events(self, user_obj=None):
        """"""Fetch all events by a specific user.""""""
        query = dict(user_id=user_obj['_id']) if user_obj else dict()
        return self.event_collection.find(query)",Fetch all events by a specific user.,
"def region(context, hgnc_id, case_id, chromosome, start, end):
    """"""Load all variants in a region to a existing case""""""
    adapter = context.obj['adapter']
    load_region(
        adapter=adapter, case_id=case_id, hgnc_id=hgnc_id, chrom=chromosome, start=start, end=end
    )",Load all variants in a region to a existing case,
"def _get_kwargs(self, category, tag):
        """"""Helper function for getting category/tag kwargs.""""""
        vals = {
            'categories__title__iexact': category,
            'tags__name__iexact': tag
        }
        kwargs = {}
        for k, v in vals.items():
            if v:
                kwargs[k] = v
        return kwargs",Helper function for getting category/tag kwargs.,
"def existing_gene(store, panel_obj, hgnc_id):
    """"""Check if gene is already added to a panel.""""""
    existing_genes = {gene['hgnc_id']: gene for gene in panel_obj['genes']}
    return existing_genes.get(hgnc_id)",Check if gene is already added to a panel.,
"def panel_export(store, panel_obj):
    """"""Preprocess a panel of genes.""""""
    panel_obj['institute'] = store.institute(panel_obj['institute'])
    full_name = ""{}({})"".format(panel_obj['display_name'], panel_obj['version'])
    panel_obj['name_and_version'] = full_name

    return dict(panel=panel_obj)",Preprocess a panel of genes.,
"def init_app(self, app):
        """"""Setup via Flask.""""""
        host = app.config.get('MONGO_HOST', 'localhost')
        port = app.config.get('MONGO_PORT', 27017)
        dbname = app.config['MONGO_DBNAME']
        log.info(""connecting to database: %s:%s/%s"", host, port, dbname)
        self.setup(app.config['MONGO_DATABASE'])",Setup via Flask.,
"def index(context, update):
    """"""Create indexes for the database""""""
    LOG.info(""Running scout index"")
    adapter = context.obj['adapter']
    
    if update:
        adapter.update_indexes()
    else:
        adapter.load_indexes()",Create indexes for the database,
"def institutes(self, institute_ids=None):
        """"""Fetch all institutes.
        
        Args:
            institute_ids(list(str))
        
        Returns:
            res(pymongo.Cursor)
        """"""
        query = {}
        if institute_ids:
            query['_id'] = {'$in': institute_ids}
        LOG.debug(""Fetching all institutes"")
        return self.institute_collection.find(query)","Fetch all institutes.
        
        Args:
            institute_ids(list(str))
        
        Returns:
            res(pymongo.Cursor)",
"def match_date(date):
    """"""Check if a string is a valid date

        Args:
            date(str)

        Returns:
            bool
    """"""
    date_pattern = re.compile(""^(19|20)\d\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])"")
    if re.match(date_pattern, date):
        return True

    return False","Check if a string is a valid date

        Args:
            date(str)

        Returns:
            bool",
"def user(self, email):
        """"""Fetch a user from the database.
        
            Args:
                email(str)
        
            Returns:
                user_obj(dict)
        """"""
        LOG.info(""Fetching user %s"", email)
        user_obj = self.user_collection.find_one({'_id': email})

        return user_obj","Fetch a user from the database.
        
            Args:
                email(str)
        
            Returns:
                user_obj(dict)",
"def delete_user(self, email):
        """"""Delete a user from the database
        
        Args:
            email(str)
    
        Returns:
            user_obj(dict)
        
        """"""
        LOG.info(""Deleting user %s"", email)
        user_obj = self.user_collection.delete_one({'_id': email})
        
        return user_obj","Delete a user from the database
        
        Args:
            email(str)
    
        Returns:
            user_obj(dict)",
"def remote_static():
    """"""Stream *large* static files with special requirements.""""""
    file_path = request.args.get('file')

    range_header = request.headers.get('Range', None)
    if not range_header and file_path.endswith('.bam'):
        return abort(500)

    new_resp = send_file_partial(file_path)
    return new_resp",Stream *large* static files with special requirements.,
"def genes():
    """"""Render seach box for genes.""""""
    query = request.args.get('query', '')
    if '|' in query:
        hgnc_id = int(query.split(' | ', 1)[0])
        return redirect(url_for('.gene', hgnc_id=hgnc_id))
    gene_q = store.all_genes().limit(20)
    return dict(genes=gene_q)",Render seach box for genes.,
"def api_genes():
    """"""Return JSON data about genes.""""""
    query = request.args.get('query')
    json_out = controllers.genes_to_json(store, query)
    return jsonify(json_out)",Return JSON data about genes.,
"def user_institutes(store, login_user):
    """"""Preprocess institute objects.""""""
    if login_user.is_admin:
        institutes = store.institutes()
    else:
        institutes = [store.institute(inst_id) for inst_id in login_user.institutes]

    return institutes",Preprocess institute objects.,
"def delete_panel(self, panel_obj):
        """"""Delete a panel by '_id'.

        Args:
            panel_obj(dict)

        Returns:
            res(pymongo.DeleteResult)
        """"""
        res = self.panel_collection.delete_one({'_id': panel_obj['_id']})
        LOG.warning(""Deleting panel %s, version %s"" % (panel_obj['panel_name'], panel_obj['version']))
        return res","Delete a panel by '_id'.

        Args:
            panel_obj(dict)

        Returns:
            res(pymongo.DeleteResult)",
"def drop_indexes(self):
        """"""Delete all indexes for the database""""""
        LOG.warning(""Dropping all indexe"")
        for collection_name in INDEXES:
            LOG.warning(""Dropping all indexes for collection name %s"", collection_name)
            self.db[collection_name].drop_indexes()",Delete all indexes for the database,
"def wipe(ctx):
    """"""Drop the mongo database given.""""""
    LOG.info(""Running scout wipe"")
    db_name = ctx.obj['mongodb']
    LOG.info(""Dropping database %s"", db_name)
    try:
        ctx.obj['client'].drop_database(db_name)
    except Exception as err:
        LOG.warning(err)
        ctx.abort()
    LOG.info(""Dropped whole database"")",Drop the mongo database given.,
"def build_clnsig(clnsig_info):
    """"""docstring for build_clnsig""""""
    clnsig_obj = dict(
        value = clnsig_info['value'],
        accession = clnsig_info.get('accession'),
        revstat = clnsig_info.get('revstat')
    )
    
    return clnsig_obj",docstring for build_clnsig,
"def load_exon_bulk(self, exon_objs):
        """"""Load a bulk of exon objects to the database

        Arguments:
            exon_objs(iterable(scout.models.hgnc_exon))

        """"""
        try:
            result = self.exon_collection.insert_many(transcript_objs)
        except (DuplicateKeyError, BulkWriteError) as err:
            raise IntegrityError(err)
        
        return result","Load a bulk of exon objects to the database

        Arguments:
            exon_objs(iterable(scout.models.hgnc_exon))",
"def all_genes(self, build='37'):
        """"""Fetch all hgnc genes

            Returns:
                result()
        """"""
        LOG.info(""Fetching all genes"")
        return self.hgnc_collection.find({'build': build}).sort('chromosome', 1)","Fetch all hgnc genes

            Returns:
                result()",
"def drop_genes(self, build=None):
        """"""Delete the genes collection""""""
        if build:
            LOG.info(""Dropping the hgnc_gene collection, build %s"", build)
            self.hgnc_collection.delete_many({'build': build})
        else:
            LOG.info(""Dropping the hgnc_gene collection"")
            self.hgnc_collection.drop()",Delete the genes collection,
"def drop_transcripts(self, build=None):
        """"""Delete the transcripts collection""""""
        if build:
            LOG.info(""Dropping the transcripts collection, build %s"", build)
            self.transcript_collection.delete_many({'build': build})
        else:
            LOG.info(""Dropping the transcripts collection"")
            self.transcript_collection.drop()",Delete the transcripts collection,
"def drop_exons(self, build=None):
        """"""Delete the exons collection""""""
        if build:
            LOG.info(""Dropping the exons collection, build %s"", build)
            self.exon_collection.delete_many({'build': build})
        else:
            LOG.info(""Dropping the exons collection"")
            self.exon_collection.drop()",Delete the exons collection,
"def index():
    """"""Display a list of all user institutes.""""""
    institute_objs = user_institutes(store, current_user)
    institutes_count = ((institute_obj, store.cases(collaborator=institute_obj['_id']).count())
                        for institute_obj in institute_objs if institute_obj)
    return dict(institutes=institutes_count)",Display a list of all user institutes.,
"def case(institute_id, case_name):
    """"""Display one case.""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    data = controllers.case(store, institute_obj, case_obj)
    return dict(institute=institute_obj, case=case_obj, **data)",Display one case.,
"def case_synopsis(institute_id, case_name):
    """"""Update (PUT) synopsis of a specific case.""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    user_obj = store.user(current_user.email)
    new_synopsis = request.form.get('synopsis')
    controllers.update_synopsis(store, institute_obj, case_obj, user_obj, new_synopsis)
    return redirect(request.referrer)",Update (PUT) synopsis of a specific case.,
"def case_report(institute_id, case_name):
    """"""Visualize case report""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    data = controllers.case_report_content(store, institute_obj, case_obj)
    return dict(institute=institute_obj, case=case_obj, format='html', **data)",Visualize case report,
"def hpoterms():
    """"""Search for HPO terms.""""""
    query = request.args.get('query')
    if query is None:
        return abort(500)
    terms = sorted(store.hpo_terms(query=query), key=itemgetter('hpo_number'))
    json_terms = [
        {'name': '{} | {}'.format(term['_id'], term['description']),
         'id': term['_id']
        } for term in terms[:7]]

    return jsonify(json_terms)",Search for HPO terms.,
"def check_case(institute_id, case_name):
    """"""Mark a case that is has been checked.
       This means to set case['needs_check'] to False
    """"""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    store.case_collection.find_one_and_update({'_id':case_obj['_id']}, {'$set': {'needs_check': False}})
    return redirect(request.referrer)","Mark a case that is has been checked.
       This means to set case['needs_check'] to False",
"def rerun(institute_id, case_name):
    """"""Request a case to be rerun.""""""
    sender = current_app.config['MAIL_USERNAME']
    recipient = current_app.config['TICKET_SYSTEM_EMAIL']
    controllers.rerun(store, mail, current_user, institute_id, case_name, sender,
                      recipient)
    return redirect(request.referrer)",Request a case to be rerun.,
"def research(institute_id, case_name):
    """"""Open the research list for a case.""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    user_obj = store.user(current_user.email)
    link = url_for('.case', institute_id=institute_id, case_name=case_name)
    store.open_research(institute_obj, case_obj, user_obj, link)
    return redirect(request.referrer)",Open the research list for a case.,
"def default_panels(institute_id, case_name):
    """"""Update default panels for a case.""""""
    panel_ids = request.form.getlist('panel_ids')
    controllers.update_default_panels(store, current_user, institute_id, case_name, panel_ids)
    return redirect(request.referrer)",Update default panels for a case.,
"def multiqc(institute_id, case_name):
    """"""Load multiqc report for the case.""""""
    data = controllers.multiqc(store, institute_id, case_name)
    if data['case'].get('multiqc') is None:
        return abort(404)
    out_dir = os.path.abspath(os.path.dirname(data['case']['multiqc']))
    filename = os.path.basename(data['case']['multiqc'])
    return send_from_directory(out_dir, filename)",Load multiqc report for the case.,
"def clinvar_submissions(store, user_id, institute_id):
    """"""Get all Clinvar submissions for a user and an institute""""""
    submissions = list(store.clinvar_submissions(user_id, institute_id))
    return submissions",Get all Clinvar submissions for a user and an institute,
"def multiqc(store, institute_id, case_name):
    """"""Find MultiQC report for the case.""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    return dict(
        institute=institute_obj,
        case=case_obj,
    )",Find MultiQC report for the case.,
"def parse_simple_id(chrom, pos, ref, alt):
    """"""Parse the simple id for a variant

    Simple id is used as a human readable reference for a position, it is
    in no way unique.

    Args:
        chrom(str)
        pos(str)
        ref(str)
        alt(str)

    Returns:
        simple_id(str): The simple human readable variant id
    """"""
    return '_'.join([chrom, pos, ref, alt])","Parse the simple id for a variant

    Simple id is used as a human readable reference for a position, it is
    in no way unique.

    Args:
        chrom(str)
        pos(str)
        ref(str)
        alt(str)

    Returns:
        simple_id(str): The simple human readable variant id",
"def _add_case(self, case_obj):
        """"""Add a case to the database
           If the case already exists exception is raised

            Args:
                case_obj(Case)
        """"""
        if self.case(case_obj['_id']):
            raise IntegrityError(""Case %s already exists in database"" % case_obj['_id'])

        return self.case_collection.insert_one(case_obj)","Add a case to the database
           If the case already exists exception is raised

            Args:
                case_obj(Case)",
"def parse_omim_line(line, header):
    """"""docstring for parse_omim_2_line""""""
    omim_info = dict(zip(header, line.split('\t')))
    return omim_info",docstring for parse_omim_2_line,
"def parse_omim_morbid(lines):
    """"""docstring for parse_omim_morbid""""""
    header = []
    for i,line in enumerate(lines):
        line = line.rstrip()
        if line.startswith('#'):
            if i < 10:
                if line.startswith('# Phenotype'):
                    header = line[2:].split('\t')
        else:
            yield parse_omim_line(line, header)",docstring for parse_omim_morbid,
"def convert_number(string):
    """"""Convert a string to number
    If int convert to int otherwise float
    
    If not possible return None
    """"""
    res = None
    if isint(string):
        res = int(string)
    elif isfloat(string):
        res = float(string) 
    return res","Convert a string to number
    If int convert to int otherwise float
    
    If not possible return None",
"def export_transcripts(adapter, build='37'):
    """"""Export all transcripts from the database
    
    Args:
        adapter(scout.adapter.MongoAdapter)
        build(str)
    
    Yields:
        transcript(scout.models.Transcript)
    """"""
    LOG.info(""Exporting all transcripts"")

    for tx_obj in adapter.transcripts(build=build):
        yield tx_obj","Export all transcripts from the database
    
    Args:
        adapter(scout.adapter.MongoAdapter)
        build(str)
    
    Yields:
        transcript(scout.models.Transcript)",
"def formatday(self, day, weekday):
        """"""Return a day as a table cell.""""""
        return super(MiniEventCalendar, self).formatday(
            day, weekday,
            day_template='happenings/partials/calendar/mini_day_cell.html',
            popover_template='happenings/partials/calendar/mini_popover.html',
        )",Return a day as a table cell.,
"def hpo(context):
    """"""
    Update the hpo terms in the database. Fetch the latest release and update terms.
    """"""
    LOG.info(""Running scout update hpo"")
    adapter = context.obj['adapter']

    LOG.info(""Dropping HPO terms"")
    adapter.hpo_term_collection.drop()
    LOG.debug(""HPO terms dropped"")

    load_hpo_terms(adapter)",Update the hpo terms in the database. Fetch the latest release and update terms.,
"def render_to_json_response(self, context, **kwargs):
        """"""
        Returns a JSON response, transforming 'context' to make the payload.
        """"""
        return HttpResponse(
            self.convert_context_to_json(context),
            content_type='application/json',
            **kwargs
        )","Returns a JSON response, transforming 'context' to make the payload.",
"def check_for_cancelled_events(self, d):
        """"""Check if any events are cancelled on the given date 'd'.""""""
        for event in self.events:
            for cn in event.cancellations.all():
                if cn.date == d:
                    event.title += ' (CANCELLED)'",Check if any events are cancelled on the given date 'd'.,
"def hpo_term(self, hpo_id):
        """"""Fetch a hpo term

        Args:
            hpo_id(str)

        Returns:
            hpo_obj(dict)
        """"""
        LOG.debug(""Fetching hpo term %s"", hpo_id)

        return self.hpo_term_collection.find_one({'_id': hpo_id})","Fetch a hpo term

        Args:
            hpo_id(str)

        Returns:
            hpo_obj(dict)",
"def calibrate_band_pass_N1(self):
        """""" One way to calibrate the band pass is to take the median value
            for every frequency fine channel, and divide by it.
        """"""

        band_pass = np.median(self.data.squeeze(),axis=0)
        self.data = self.data/band_pass","One way to calibrate the band pass is to take the median value
            for every frequency fine channel, and divide by it.",
"def fracpols(str, **kwargs):
    '''Output fractional linear and circular polarizations for a
    rawspec cross polarization .fil file. NOT STANDARD USE'''

    I,Q,U,V,L=get_stokes(str, **kwargs)
    return L/I,V/I","Output fractional linear and circular polarizations for a
    rawspec cross polarization .fil file. NOT STANDARD USE",
"def closest(xarr, val):
    """""" Return the index of the closest in xarr to value val """"""
    idx_closest = np.argmin(np.abs(np.array(xarr) - val))
    return idx_closest",Return the index of the closest in xarr to value val,
"def populate_freqs(self):
        """"""
         Populate frequency axis
        """"""

        if self.header[b'foff'] < 0:
            f0 = self.f_end
        else:
            f0 = self.f_begin

        self._setup_chans()

        #create freq array
        i_vals = np.arange(self.chan_start_idx, self.chan_stop_idx)
        freqs = self.header[b'foff'] * i_vals + f0

        return freqs",Populate frequency axis,
"def calc_n_blobs(self, blob_dim):
        """""" Given the blob dimensions, calculate how many fit in the data selection.
        """"""

        n_blobs = int(np.ceil(1.0 * np.prod(self.selection_shape) / np.prod(blob_dim)))

        return n_blobs","Given the blob dimensions, calculate how many fit in the data selection.",
"def isheavy(self):
        """""" Check if the current selection is too large.
        """"""

        selection_size_bytes = self._calc_selection_size()

        if selection_size_bytes > self.MAX_DATA_ARRAY_SIZE:
            return True
        else:
            return False",Check if the current selection is too large.,
"def read_data(self, f_start=None, f_stop=None,t_start=None, t_stop=None):
        """""" Reads data selection if small enough.
        """"""

        self.container.read_data(f_start=f_start, f_stop=f_stop,t_start=t_start, t_stop=t_stop)

        self.__load_data()",Reads data selection if small enough.,
"def read_first_header(self):
        """""" Read first header in file

        Returns:
            header (dict): keyword:value pairs of header metadata
        """"""
        self.file_obj.seek(0)
        header_dict, pos = self.read_header()
        self.file_obj.seek(0)
        return header_dict","Read first header in file

        Returns:
            header (dict): keyword:value pairs of header metadata",
"def print_stats(self):
        """""" Compute some basic stats on the next block of data """"""

        header, data = self.read_next_data_block()
        data = data.view('float32')

        print(""AVG: %2.3f"" % data.mean())
        print(""STD: %2.3f"" % data.std())
        print(""MAX: %2.3f"" % data.max())
        print(""MIN: %2.3f"" % data.min())

        import pylab as plt",Compute some basic stats on the next block of data,
"def plot_histogram(self, filename=None):
        """""" Plot a histogram of data values """"""
        header, data = self.read_next_data_block()
        data = data.view('float32')

        plt.figure(""Histogram"")
        plt.hist(data.flatten(), 65, facecolor='#cc0000')
        if filename:
            plt.savefig(filename)
        plt.show()",Plot a histogram of data values,
"def find_header_size(filename):
    ''' Script to find the header size of a filterbank file'''

    # open datafile
    filfile=open(filename,'rb')
    # go to the start of the file
    filfile.seek(0)
    #read some region larger than the header.
    round1 = filfile.read(1000)
    headersize = round1.find('HEADER_END')+len('HEADER_END')

    return headersize",Script to find the header size of a filterbank file,
"def get_Tsys(calON_obs,calOFF_obs,calflux,calfreq,spec_in,oneflux=False,**kwargs):
    '''
    Returns frequency dependent system temperature given observations on and off a calibrator source

    Parameters
    ----------
    (See diode_spec())
    '''
    return diode_spec(calON_obs,calOFF_obs,calflux,calfreq,spec_in,average=False,oneflux=False,**kwargs)[1]","Returns frequency dependent system temperature given observations on and off a calibrator source

    Parameters
    ----------
    (See diode_spec())",
"def serialize(tokens):
    """"""
    Serialize tokens:
    * quote whitespace-containing tokens
    * escape semicolons
    """"""
    ret = []
    for tok in tokens:
        if "" "" in tok:
            tok = '""%s""' % tok

        if "";"" in tok:
            tok = tok.replace("";"", ""\;"")

        ret.append(tok)

    return "" "".join(ret)","Serialize tokens:
    * quote whitespace-containing tokens
    * escape semicolons",
"def remove_comments(text):
    """"""
    Remove comments from a zonefile
    """"""
    ret = []
    lines = text.split(""\n"")
    for line in lines:
        if len(line) == 0:
            continue 

        line = serialize(tokenize_line(line))
        ret.append(line)

    return ""\n"".join(ret)",Remove comments from a zonefile,
"def parse_zone_file(text, ignore_invalid=False):
    """"""
    Parse a zonefile into a dict
    """"""
    text = remove_comments(text)
    text = flatten(text)
    text = remove_class(text)
    text = add_default_name(text)
    json_zone_file = parse_lines(text, ignore_invalid=ignore_invalid)
    return json_zone_file",Parse a zonefile into a dict,
"def process_origin(data, template):
    """"""
    Replace {$origin} in template with a serialized $ORIGIN record
    """"""
    record = """"
    if data is not None:
        record += ""$ORIGIN %s"" % data

    return template.replace(""{$origin}"", record)",Replace {$origin} in template with a serialized $ORIGIN record,
"def process_ttl(data, template):
    """"""
    Replace {$ttl} in template with a serialized $TTL record
    """"""
    record = """"
    if data is not None:
        record += ""$TTL %s"" % data

    return template.replace(""{$ttl}"", record)",Replace {$ttl} in template with a serialized $TTL record,
"def quote_field(data, field):
    """"""
    Quote a field in a list of DNS records.
    Return the new data records.
    """"""
    if data is None:
        return None 

    data_dup = copy.deepcopy(data)
    for i in xrange(0, len(data_dup)):
        data_dup[i][field] = '""%s""' % data_dup[i][field]
        data_dup[i][field] = data_dup[i][field].replace("";"", ""\;"")

    return data_dup","Quote a field in a list of DNS records.
    Return the new data records.",
"def parse_schema_string(schema_string):
    """"""
    Load and return a PySchema class from an avsc string
    """"""
    if isinstance(schema_string, str):
        schema_string = schema_string.decode(""utf8"")
    schema_struct = json.loads(schema_string)

    return AvroSchemaParser().parse_schema_struct(schema_struct)",Load and return a PySchema class from an avsc string,
"def to_json_compatible(record):
    ""Dump record in json-encodable object format""
    d = {}
    for fname, f in record._fields.iteritems():
        val = getattr(record, fname)
        if val is not None:
            d[fname] = f.dump(val)
    return d",Dump record in json-encodable object format,
"def from_json_compatible(schema, dct):
    ""Load from json-encodable""
    kwargs = {}

    for key in dct:
        field_type = schema._fields.get(key)
        if field_type is None:
            raise ParseError(""Unexpected field encountered in line for record %s: %s"" % (schema.__name__, key))
        kwargs[key] = field_type.load(dct[key])

    return schema(**kwargs)",Load from json-encodable,
"def from_json_compatible(schema, dct):
    ""Load from json-encodable""
    kwargs = {}

    for key in dct:
        field_type = schema._fields.get(key)
        if field_type is None:
            warnings.warn(""Unexpected field encountered in line for record %s: %r"" % (schema.__name__, key))
            continue
        kwargs[key] = field_type.avro_load(dct[key])

    return schema(**kwargs)",Load from json-encodable,
"def mr_reader(job, input_stream, loads=core.loads):
    """""" Converts a file object with json serialised pyschema records
        to a stream of pyschema objects

    Can be used as job.reader in luigi.hadoop.JobTask
    """"""
    for line in input_stream:
        yield loads(line),","Converts a file object with json serialised pyschema records
        to a stream of pyschema objects

    Can be used as job.reader in luigi.hadoop.JobTask",
"def ordereddict_push_front(dct, key, value):
    """"""Set a value at the front of an OrderedDict

    The original dict isn't modified, instead a copy is returned
    """"""
    d = OrderedDict()
    d[key] = value
    d.update(dct)
    return d","Set a value at the front of an OrderedDict

    The original dict isn't modified, instead a copy is returned",
"def gen_filter(name, op, value, is_or=False):
    """"""Generates a single filter expression for ``filter[]``.""""""
    if op not in OPERATORS:
        raise ValueError('Unknown operator {}'.format(op))
    result = u'{} {} {}'.format(name, op, escape_filter(value))
    if is_or:
        result = u'or ' + result
    return result",Generates a single filter expression for ``filter[]``.,
"def from_dict(cls, d):
        """"""Creates a query (AND and =) from a dictionary.""""""
        if not d:
            raise ValueError('Empty dictionary!')
        items = list(d.items())
        key, value = items.pop(0)
        q = cls(key, u'=', value)
        for key, value in items:
            q = q & cls(key, u'=', value)
        return q",Creates a query (AND and =) from a dictionary.,
"def query_string(self, **params):
        """"""Specify query string to use with the collection.

        Returns: :py:class:`SearchResult`
        """"""
        return SearchResult(self, self._api.get(self._href, **params))","Specify query string to use with the collection.

        Returns: :py:class:`SearchResult`",
"def raw_filter(self, filters):
        """"""Sends all filters to the API.

        No fancy, just a wrapper. Any advanced functionality shall be implemented as another method.

        Args:
            filters: List of filters (strings)

        Returns: :py:class:`SearchResult`
        """"""
        return SearchResult(self, self._api.get(self._href, **{""filter[]"": filters}))","Sends all filters to the API.

        No fancy, just a wrapper. Any advanced functionality shall be implemented as another method.

        Args:
            filters: List of filters (strings)

        Returns: :py:class:`SearchResult`",
"def all_include_attributes(self, attributes):
        """"""Returns all entities present in the collection with ``attributes`` included.""""""
        self.reload(expand=True, attributes=attributes)
        entities = [Entity(self, r, attributes=attributes) for r in self._resources]
        self.reload()
        return entities",Returns all entities present in the collection with ``attributes`` included.,
"def give_another_quote(q):
    """"""When you pass a quote character, returns you an another one if possible""""""
    for qc in QUOTES:
        if qc != q:
            return qc
    else:
        raise ValueError(u'Could not find a different quote for {}'.format(q))","When you pass a quote character, returns you an another one if possible",
"def parseCommandLineArguments():
  """"""
  Set up command line parsing.
  """"""
  parser = argparse.ArgumentParser(description=""Calculate parallax error for given G and (V-I)"")
  parser.add_argument(""gmag"", help=""G-band magnitude of source"", type=float)
  parser.add_argument(""vmini"", help=""(V-I) colour of source"", type=float)

  args=vars(parser.parse_args())
  return args",Set up command line parsing.,
"def find_next_sibling(self, *args, **kwargs):
        """"""
        Like :meth:`find`, but searches through :attr:`next_siblings`
        """"""
        op = operator.methodcaller('find_next_sibling', *args, **kwargs)
        return self._wrap_node(op)","Like :meth:`find`, but searches through :attr:`next_siblings`",
"def find_parent(self, *args, **kwargs):
        """"""
        Like :meth:`find`, but searches through :attr:`parents`
        """"""
        op = operator.methodcaller('find_parent', *args, **kwargs)
        return self._wrap_node(op)","Like :meth:`find`, but searches through :attr:`parents`",
"def find_previous_sibling(self, *args, **kwargs):
        """"""
        Like :meth:`find`, but searches through :attr:`previous_siblings`
        """"""
        op = operator.methodcaller('find_previous_sibling', *args, **kwargs)
        return self._wrap_node(op)","Like :meth:`find`, but searches through :attr:`previous_siblings`",
"def find_all(self, *args, **kwargs):
        """"""
        Like :meth:`find`, but selects all matches (not just the first one).

        Returns a :class:`Collection`.

        If no elements match, this returns a Collection with no items.
        """"""
        op = operator.methodcaller('find_all', *args, **kwargs)
        return self._wrap_multi(op)","Like :meth:`find`, but selects all matches (not just the first one).

        Returns a :class:`Collection`.

        If no elements match, this returns a Collection with no items.",
"def find_next_siblings(self, *args, **kwargs):
        """"""
        Like :meth:`find_all`, but searches through :attr:`next_siblings`
        """"""
        op = operator.methodcaller('find_next_siblings', *args, **kwargs)
        return self._wrap_multi(op)","Like :meth:`find_all`, but searches through :attr:`next_siblings`",
"def find_parents(self, *args, **kwargs):
        """"""
        Like :meth:`find_all`, but searches through :attr:`parents`
        """"""
        op = operator.methodcaller('find_parents', *args, **kwargs)
        return self._wrap_multi(op)","Like :meth:`find_all`, but searches through :attr:`parents`",
"def find_previous_siblings(self, *args, **kwargs):
        """"""
        Like :meth:`find_all`, but searches through :attr:`previous_siblings`
        """"""
        op = operator.methodcaller('find_previous_siblings', *args, **kwargs)
        return self._wrap_multi(op)","Like :meth:`find_all`, but searches through :attr:`previous_siblings`",
"def select(self, selector):
        """"""
        Like :meth:`find_all`, but takes a CSS selector string as input.
        """"""
        op = operator.methodcaller('select', selector)
        return self._wrap_multi(op)","Like :meth:`find_all`, but takes a CSS selector string as input.",
"def analyze(self):
        """"""Run analysis.""""""
        precision = 'DP' if self.kernel.datatype == 'double' else 'SP'
        self.calculate_cache_access()

        self.results['max_perf'] = self.conv_perf(self.machine['clock'] * self.cores * \
            self.machine['FLOPs per cycle'][precision]['total'])",Run analysis.,
"def round_to_next(x, base):
    """"""Round float to next multiple of base.""""""
    # Based on: http://stackoverflow.com/a/2272174
    return int(base * math.ceil(float(x)/base))",Round float to next multiple of base.,
"def analyze(self):
        """"""Run complete anaylysis and return results.""""""
        self.calculate_cache_access()
        self.calculate_cycles()
        self.results['flops per iteration'] = sum(self.kernel._flops.values())

        return self.results",Run complete anaylysis and return results.,
"def strip_and_uncomment(asm_lines):
    """"""Strip whitespaces and comments from asm lines.""""""
    asm_stripped = []
    for line in asm_lines:
        # Strip comments and whitespaces
        asm_stripped.append(line.split('#')[0].strip())
    return asm_stripped",Strip whitespaces and comments from asm lines.,
"def insert_markers(asm_lines, start_line, end_line):
    """"""Insert IACA marker into list of ASM instructions at given indices.""""""
    asm_lines = (asm_lines[:start_line] + START_MARKER +
                 asm_lines[start_line:end_line + 1] + END_MARKER +
                 asm_lines[end_line + 1:])
    return asm_lines",Insert IACA marker into list of ASM instructions at given indices.,
"def main():
    """"""Initialize and run command line interface.""""""
    # Create and populate parser
    parser = create_parser()

    # Parse given arguments
    args = parser.parse_args()

    # Checking arguments
    check_arguments(args, parser)

    # BUSINESS LOGIC IS FOLLOWING
    run(parser, args)",Initialize and run command line interface.,
"def symbol_pos_int(*args, **kwargs):
    """"""Create a sympy.Symbol with positive and integer assumptions.""""""
    kwargs.update({'positive': True,
                   'integer': True})
    return sympy.Symbol(*args, **kwargs)",Create a sympy.Symbol with positive and integer assumptions.,
"def force_iterable(f):
    """"""Will make any functions return an iterable objects by wrapping its result in a list.""""""
    def wrapper(*args, **kwargs):
        r = f(*args, **kwargs)
        if hasattr(r, '__iter__'):
            return r
        else:
            return [r]
    return wrapper",Will make any functions return an iterable objects by wrapping its result in a list.,
"def reduce_path(path):
    """"""Reduce absolute path to relative (if shorter) for easier readability.""""""
    relative_path = os.path.relpath(path)
    if len(relative_path) < len(path):
        return relative_path
    else:
        return path",Reduce absolute path to relative (if shorter) for easier readability.,
"def check(self):
        """"""Check that information about kernel makes sens and is valid.""""""
        datatypes = [v[0] for v in self.variables.values()]
        assert len(set(datatypes)) <= 1, 'mixing of datatypes within a kernel is not supported.'",Check that information about kernel makes sens and is valid.,
"def subs_consts(self, expr):
        """"""Substitute constants in expression unless it is already a number.""""""
        if isinstance(expr, numbers.Number):
            return expr
        else:
            return expr.subs(self.constants)",Substitute constants in expression unless it is already a number.,
"def _remove_duplicate_accesses(self):
        """"""
        Remove duplicate source and destination accesses
        """"""
        self.destinations = {var_name: set(acs) for var_name, acs in self.destinations.items()}
        self.sources = {var_name: set(acs) for var_name, acs in self.sources.items()}",Remove duplicate source and destination accesses,
"def indices_to_global_iterator(self, indices):
        """"""
        Transform a dictionary of indices to a global iterator integer.

        Inverse of global_iterator_to_indices().
        """"""
        global_iterator = self.subs_consts(self.global_iterator().subs(indices))
        return global_iterator","Transform a dictionary of indices to a global iterator integer.

        Inverse of global_iterator_to_indices().",
"def max_global_iteration(self):
        """"""Return global iterator with last iteration number""""""
        return self.indices_to_global_iterator({
            symbol_pos_int(var_name): end-1 for var_name, start, end, incr in self._loop_stack
        })",Return global iterator with last iteration number,
"def print_constants_info(self, output_file=sys.stdout):
        """"""Print constants information in human readble format.""""""
        table = ('    name | value     \n' +
                 '---------+-----------\n')
        for name, value in list(self.constants.items()):
            table += '{!s:>8} | {:<10}\n'.format(name, value)
        print(prefix_indent('constants: ', table), file=output_file)",Print constants information in human readble format.,
"def print_kernel_code(self, output_file=sys.stdout):
        """"""Print source code of kernel.""""""
        print(self.kernel_code, file=output_file)",Print source code of kernel.,
"def _get_basename(cls, aref):
        """"""
        Return base name of ArrayRef object.

        e.g. c[i+1][j-2] -> 'c'
        """"""
        if isinstance(aref.name, c_ast.ArrayRef):
            return cls._get_basename(aref.name)
        elif isinstance(aref.name, str):
            return aref.name
        else:
            return aref.name.name","Return base name of ArrayRef object.

        e.g. c[i+1][j-2] -> 'c'",
"def get_array_declarations(self):
        """"""Return array declarations.""""""
        return [d for d in self.kernel_ast.block_items
                if type(d) is c_ast.Decl and type(d.type) is c_ast.ArrayDecl]",Return array declarations.,
"def get_kernel_loop_nest(self):
        """"""Return kernel loop nest including any preceding pragmas and following swaps.""""""
        loop_nest = [s for s in self.kernel_ast.block_items
                     if type(s) in [c_ast.For, c_ast.Pragma, c_ast.FuncCall]]
        assert len(loop_nest) >= 1, ""Found to few for statements in kernel""
        return loop_nest",Return kernel loop nest including any preceding pragmas and following swaps.,
"def _find_inner_most_loop(self, loop_nest):
        """"""Return inner most for loop in loop nest""""""
        r = None
        for s in loop_nest:
            if type(s) is c_ast.For:
                return self._find_inner_most_loop(s) or s
            else:
                r = r or self._find_inner_most_loop(s)
        return r",Return inner most for loop in loop nest,
"def _build_kernel_call(self, name='kernel'):
        """"""Generate and return kernel call ast.""""""
        return c_ast.FuncCall(name=c_ast.ID(name=name), args=c_ast.ExprList(exprs=[
            c_ast.ID(name=d.name) for d in (
                    self._build_array_declarations()[0] +
                    self._build_scalar_declarations() +
                    self._build_const_declartions())]))",Generate and return kernel call ast.,
"def get_identifier(self):
        """"""Return identifier which is either the machine file name or sha256 checksum of data.""""""
        if self._path:
            return os.path.basename(self._path)
        else:
            return hashlib.sha256(hashlib.sha256(repr(self._data).encode())).hexdigest()",Return identifier which is either the machine file name or sha256 checksum of data.,
"def get_last_modified_datetime(self):
        """"""Return datetime object of modified time of machine file. Return now if not a file.""""""
        if self._path:
            statbuf = os.stat(self._path)
            return datetime.utcfromtimestamp(statbuf.st_mtime)
        else:
            return datetime.now()",Return datetime object of modified time of machine file. Return now if not a file.,
"def get_header_path() -> str:
    """"""Return local folder path of header files.""""""
    import os
    return os.path.abspath(os.path.dirname(os.path.realpath(__file__))) + '/headers/'",Return local folder path of header files.,
"def get_loads(self):
        """"""Return a list with number of loaded cache lines per memory hierarchy level.""""""
        return [self.stats[cache_level]['LOAD_count'] / self.first_dim_factor
                for cache_level in range(len(self.machine['memory hierarchy']))]",Return a list with number of loaded cache lines per memory hierarchy level.,
"def get_hits(self):
        """"""Return a list with number of hit cache lines per memory hierarchy level.""""""
        return [self.stats[cache_level]['HIT_count']/self.first_dim_factor
                for cache_level in range(len(self.machine['memory hierarchy']))]",Return a list with number of hit cache lines per memory hierarchy level.,
"def get_misses(self):
        """"""Return a list with number of missed cache lines per memory hierarchy level.""""""
        return [self.stats[cache_level]['MISS_count']/self.first_dim_factor
                for cache_level in range(len(self.machine['memory hierarchy']))]",Return a list with number of missed cache lines per memory hierarchy level.,
"def get_stores(self):
        """"""Return a list with number of stored cache lines per memory hierarchy level.""""""
        return [self.stats[cache_level]['STORE_count']/self.first_dim_factor
                for cache_level in range(len(self.machine['memory hierarchy']))]",Return a list with number of stored cache lines per memory hierarchy level.,
"def get_evicts(self):
        """"""Return a list with number of evicted cache lines per memory hierarchy level.""""""
        return [self.stats[cache_level]['EVICT_count']/self.first_dim_factor
                for cache_level in range(len(self.machine['memory hierarchy']))]",Return a list with number of evicted cache lines per memory hierarchy level.,
"def schedule_retry(self, config):
    """"""Schedule a retry""""""
    raise self.retry(countdown=config.get('SAILTHRU_RETRY_SECONDS'),
                     max_retries=config.get('SAILTHRU_RETRY_ATTEMPTS'))",Schedule a retry,
"def set(self, key, value, duration):
        """"""Save an object in the cache

        Arguments:
            key (str): Cache key
            value (object): object to cache
            duration (int): time in seconds to keep object in cache

        """"""
        lock.acquire()
        try:
            self[key] = CacheObject(value, duration)
        finally:
            lock.release()","Save an object in the cache

        Arguments:
            key (str): Cache key
            value (object): object to cache
            duration (int): time in seconds to keep object in cache",
"def get_overrides_filename(variable):
    """"""
    Get the name of the file containing configuration overrides
    from the provided environment variable.
    """"""
    filename = os.environ.get(variable)

    if filename is None:
        msg = 'Please set the {} environment variable.'.format(variable)
        raise EnvironmentError(msg)

    return filename","Get the name of the file containing configuration overrides
    from the provided environment variable.",
"def from_epw(cls, buffer_or_path):
        """"""
        Parameters
        ----------
        buffer_or_path: buffer or path containing epw format.

        Returns
        -------
        WeatherData instance.
        """"""
        from .epw_parse import parse_epw
        _, buffer = to_buffer(buffer_or_path)
        with buffer as f:
            return parse_epw(f)","Parameters
        ----------
        buffer_or_path: buffer or path containing epw format.

        Returns
        -------
        WeatherData instance.",
"def default_external_files_dir_name(model_name):
    """"""
    Parameters
    ----------
    model_name: with or without extension
    """"""
    name, ext = os.path.splitext(model_name)
    return name + CONF.external_files_suffix","Parameters
    ----------
    model_name: with or without extension",
"def get_external_files(self):
        """"""
        An external file manages file paths.
        """"""
        external_files = []
        for table in self._tables.values():
            for r in table:
                external_files.extend([ef for ef in r.get_external_files()])
        return external_files",An external file manages file paths.,
"def set_defaults(self):
        """"""
        All fields of Epm with a default value and that are null will be set to their default value.
        """"""
        for table in self._tables.values():
            for r in table:
                r.set_defaults()",All fields of Epm with a default value and that are null will be set to their default value.,
"def get_simulated_epw_path():
    """"""
    Returns
    -------
    None if epw can be anywhere
    """"""
    from oplus import CONF  # touchy imports

    if OS_NAME == ""windows"":
        return os.path.join(CONF.eplus_base_dir_path, ""WeatherData"", ""%s.epw"" % CONF.default_model_name)","Returns
    -------
    None if epw can be anywhere",
"def get_external_files(self):
        """"""
        Returns
        -------
        List of ExternalFiles instances contained by record.
        """"""
        return [v for v in self._data.values() if isinstance(v, ExternalFile)]","Returns
        -------
        List of ExternalFiles instances contained by record.",
"def str(cls, value):
        '''Convert status (id) to its string name.'''
        for k, v in cls.__dict__.items():
            if k[0] in string.ascii_uppercase and v == value:
                return k.lower().replace('_', ' ')",Convert status (id) to its string name.,
"def remaining_duration(self, time):
        '''Returns the remaining duration for a recording.
        '''
        return max(0, self.end - max(self.start, time))",Returns the remaining duration for a recording.,
"def unix_ts(dtval):
    '''Convert datetime into a unix timestamp.
    This is the equivalent to Python 3's int(datetime.timestamp()).

    :param dt: datetime to convert
    '''
    epoch = datetime(1970, 1, 1, 0, 0, tzinfo=tzutc())
    delta = (dtval - epoch)
    return delta.days * 24 * 3600 + delta.seconds","Convert datetime into a unix timestamp.
    This is the equivalent to Python 3's int(datetime.timestamp()).

    :param dt: datetime to convert",
"def try_mkdir(directory):
    '''Try to create a directory. Pass without error if it already exists.
    '''
    try:
        os.mkdir(directory)
    except OSError as err:
        if err.errno != errno.EEXIST:
            raise err",Try to create a directory. Pass without error if it already exists.,
"def update_event_status(event, status):
    '''Update the status of a particular event in the database.
    '''
    dbs = db.get_session()
    dbs.query(db.RecordedEvent).filter(db.RecordedEvent.start == event.start)\
                               .update({'status': status})
    event.status = status
    dbs.commit()",Update the status of a particular event in the database.,
"def set_service_status(service, status):
    '''Update the status of a particular service in the database.
    '''
    srv = db.ServiceStates()
    srv.type = service
    srv.status = status

    dbs = db.get_session()
    dbs.merge(srv)
    dbs.commit()
    dbs.close()",Update the status of a particular service in the database.,
"def get_service_status(service):
    '''Update the status of a particular service in the database.
    '''
    dbs = db.get_session()
    srvs = dbs.query(db.ServiceStates).filter(db.ServiceStates.type == service)

    if srvs.count():
        return srvs[0].status

    return db.ServiceStatus.STOPPED",Update the status of a particular service in the database.,
"def configuration_file(cfgfile):
    '''Find the best match for the configuration file.
    '''
    if cfgfile is not None:
        return cfgfile
    # If no file is explicitely specified, probe for the configuration file
    # location.
    cfg = './etc/pyca.conf'
    if not os.path.isfile(cfg):
        return '/etc/pyca.conf'
    return cfg",Find the best match for the configuration file.,
"def sigterm_handler(signum, frame):
    '''Intercept sigterm and terminate all processes.
    '''
    sigint_handler(signum, frame)
    for process in multiprocessing.active_children():
        process.terminate()
    sys.exit(0)",Intercept sigterm and terminate all processes.,
"def run_all(*modules):
    '''Start all services.
    '''
    processes = [multiprocessing.Process(target=mod.run) for mod in modules]
    for p in processes:
        p.start()
    for p in processes:
        p.join()",Start all services.,
"def make_error_response(error, status=500):
    ''' Return a response with a jsonapi error object
    '''
    content = {
        'errors': [{
            'status': status,
            'title': error
        }]
    }
    return make_response(jsonify(content), status)",Return a response with a jsonapi error object,
"def make_data_response(data, status=200):
    ''' Return a response with a list of jsonapi data objects
    '''
    content = {'data': ensurelist(data)}
    return make_response(jsonify(content), status)",Return a response with a list of jsonapi data objects,
"def event(uid):
    '''Return a specific events JSON
    '''
    db = get_session()
    event = db.query(RecordedEvent).filter(RecordedEvent.uid == uid).first() \
        or db.query(UpcomingEvent).filter(UpcomingEvent.uid == uid).first()

    if event:
        return make_data_response(event.serialize())
    return make_error_response('No event with specified uid', 404)",Return a specific events JSON,
"def sigterm_handler(signum, frame):
    '''Intercept sigterm and terminate all processes.
    '''
    if captureproc and captureproc.poll() is None:
        captureproc.terminate()
    terminate(True)
    sys.exit(0)",Intercept sigterm and terminate all processes.,
"def render_to_fragment(self, request, **kwargs):
        """"""
        Returns a simple fragment
        """"""
        fragment = Fragment(TEST_HTML)
        fragment.add_javascript(TEST_JS)
        fragment.add_css(TEST_CSS)
        return fragment",Returns a simple fragment,
"def add_content(self, content):
        """"""
        Add content to this fragment.

        `content` is a Unicode string, HTML to append to the body of the
        fragment.  It must not contain a ``<body>`` tag, or otherwise assume
        that it is the only content on the page.
        """"""
        assert isinstance(content, six.text_type)
        self.content += content","Add content to this fragment.

        `content` is a Unicode string, HTML to append to the body of the
        fragment.  It must not contain a ``<body>`` tag, or otherwise assume
        that it is the only content on the page.",
"def render_standalone_response(self, request, fragment, **kwargs):  # pylint: disable=unused-argument
        """"""
        Renders a standalone page as a response for the specified fragment.
        """"""
        if fragment is None:
            return HttpResponse(status=204)

        html = self.render_to_standalone_html(request, fragment, **kwargs)
        return HttpResponse(html)",Renders a standalone page as a response for the specified fragment.,
"def unwrap_self_for_multiprocessing(arg):
    """""" You can not call methods with multiprocessing, but free functions,
        If you want to call  inst.method(arg0, arg1),

            unwrap_self_for_multiprocessing(inst, ""method"", (arg0, arg1))

        does the trick.
    """"""
    (inst, method_name, args) = arg
    return getattr(inst, method_name)(*args)","You can not call methods with multiprocessing, but free functions,
        If you want to call  inst.method(arg0, arg1),

            unwrap_self_for_multiprocessing(inst, ""method"", (arg0, arg1))

        does the trick.",
"def lookup_values_from_error_table(scores, err_df):
    """""" Find matching q-value for each score in 'scores' """"""
    ix = find_nearest_matches(np.float32(err_df.cutoff.values), np.float32(scores))
    return err_df.pvalue.iloc[ix].values, err_df.svalue.iloc[ix].values, err_df.pep.iloc[ix].values, err_df.qvalue.iloc[ix].values",Find matching q-value for each score in 'scores',
"def pnorm(stat, stat0):
    """""" [P(X>pi, mu, sigma) for pi in pvalues] for normal distributed stat with
    expectation value mu and std deviation sigma """"""

    mu, sigma = mean_and_std_dev(stat0)

    stat = to_one_dim_array(stat, np.float64)
    args = (stat - mu) / sigma
    return 1-(0.5 * (1.0 + scipy.special.erf(args / np.sqrt(2.0))))","[P(X>pi, mu, sigma) for pi in pvalues] for normal distributed stat with
    expectation value mu and std deviation sigma",
"def subsample(infile, outfile, subsample_ratio, test):
    """"""
    Subsample OpenSWATH file to minimum for integrated scoring
    """"""

    if outfile is None:
        outfile = infile
    else:
        outfile = outfile

    subsample_osw(infile, outfile, subsample_ratio, test)",Subsample OpenSWATH file to minimum for integrated scoring,
"def reduce(infile, outfile):
    """"""
    Reduce scored PyProphet file to minimum for global scoring
    """"""

    if outfile is None:
        outfile = infile
    else:
        outfile = outfile

    reduce_osw(infile, outfile)",Reduce scored PyProphet file to minimum for global scoring,
"def merge(infiles, outfile, same_run, templatefile):
    """"""
    Merge multiple OSW files and (for large experiments, it is recommended to subsample first).
    """"""

    if len(infiles) < 1:
        raise click.ClickException(""At least one PyProphet input file needs to be provided."")

    merge_osw(infiles, outfile, templatefile, same_run)","Merge multiple OSW files and (for large experiments, it is recommended to subsample first).",
"def backpropagate(infile, outfile, apply_scores):
    """"""
    Backpropagate multi-run peptide and protein scores to single files
    """"""

    if outfile is None:
        outfile = infile
    else:
        outfile = outfile

    backpropagate_oswr(infile, outfile, apply_scores)",Backpropagate multi-run peptide and protein scores to single files,
"def filter(sqmassfiles, infile, max_precursor_pep, max_peakgroup_pep, max_transition_pep):
    """"""
    Filter sqMass files
    """"""

    filter_sqmass(sqmassfiles, infile, max_precursor_pep, max_peakgroup_pep, max_transition_pep)",Filter sqMass files,
"def get_group_by_id(self, group_id):
        """"""
        Returns a restclients.Group object for the group identified by the
        passed group ID.
        """"""
        self._valid_group_id(group_id)

        url = ""{}/group/{}"".format(self.API, group_id)

        data = self._get_resource(url)

        return self._group_from_json(data.get(""data""))","Returns a restclients.Group object for the group identified by the
        passed group ID.",
"def create_group(self, group):
        """"""
        Creates a group from the passed restclients.Group object.
        """"""
        self._valid_group_id(group.id)

        body = {""data"": group.json_data()}
        url = ""{}/group/{}"".format(self.API, group.name)

        data = self._put_resource(url, headers={}, body=body)

        return self._group_from_json(data.get(""data""))",Creates a group from the passed restclients.Group object.,
"def delete_group(self, group_id):
        """"""
        Deletes the group identified by the passed group ID.
        """"""
        self._valid_group_id(group_id)

        url = ""{}/group/{}"".format(self.API, group_id)

        self._delete_resource(url)

        return True",Deletes the group identified by the passed group ID.,
"def error(self, msg, file=None):
        """"""
        Outputs the error msg to the file if specified, or to the
        io_manager's stderr if available, or to sys.stderr.
        """"""
        self.error_encountered = True
        file.write(self.error_prefix)
        file.write(msg)
        file.write('\n')
        file.flush()","Outputs the error msg to the file if specified, or to the
        io_manager's stderr if available, or to sys.stderr.",
"def exit(self, status=0, msg=None):
        """"""
        Immediately exits Python with the given status (or 0) as the
        exit code and optionally outputs the msg using self.error.
        """"""
        if msg:
            self.error(msg)
        sys.exit(status)","Immediately exits Python with the given status (or 0) as the
        exit code and optionally outputs the msg using self.error.",
"def print_help(self, file=None):
        """"""
        Outputs help information to the file if specified, or to the
        io_manager's stdout if available, or to sys.stdout.
        """"""
        optparse.OptionParser.print_help(self, file)
        if self.raw_epilog:
            file.write(self.raw_epilog)
        file.flush()","Outputs help information to the file if specified, or to the
        io_manager's stdout if available, or to sys.stdout.",
"def print_usage(self, file=None):
        """"""
        Outputs usage information to the file if specified, or to the
        io_manager's stdout if available, or to sys.stdout.
        """"""
        optparse.OptionParser.print_usage(self, file)
        file.flush()","Outputs usage information to the file if specified, or to the
        io_manager's stdout if available, or to sys.stdout.",
"def print_version(self, file=None):
        """"""
        Outputs version information to the file if specified, or to
        the io_manager's stdout if available, or to sys.stdout.
        """"""
        optparse.OptionParser.print_version(self, file)
        file.flush()","Outputs version information to the file if specified, or to
        the io_manager's stdout if available, or to sys.stdout.",
"def copy(self):
        """"""
        Returns a new CLIContext instance that is a shallow copy of
        the original, much like dict's copy method.
        """"""
        context = CLIContext()
        for item in dir(self):
            if item[0] != '_' and item not in ('copy', 'write_headers'):
                setattr(context, item, getattr(self, item))
        return context","Returns a new CLIContext instance that is a shallow copy of
        the original, much like dict's copy method.",
"def reset(self):
        """"""
        See :py:func:`swiftly.client.client.Client.reset`
        """"""
        for conn in (self.storage_conn, self.cdn_conn):
            if conn:
                try:
                    conn.close()
                except Exception:
                    pass
        self.storage_conn = None
        self.cdn_conn = None",See :py:func:`swiftly.client.client.Client.reset`,
"def get_account_hash(self):
        """"""
        See :py:func:`swiftly.client.client.Client.get_account_hash`
        """"""
        if not(self.storage_url or self.storage_path):
            self.auth()
        return (self.storage_url or self.storage_path).rsplit('/', 1)[1]",See :py:func:`swiftly.client.client.Client.get_account_hash`,
"def is_empty(self):
        """"""
        Check whether the ""file"" is empty reading the single byte.
        """"""
        something = self.read(1)
        if something:
            if self.buf:
                self.buf = something + self.buf
            else:
                self.buf = something
            return False
        else:
            return True","Check whether the ""file"" is empty reading the single byte.",
"def forwards(self, orm):
        ""Write your forwards methods here.""
        # Note: Remember to use orm['appname.ModelName'] rather than ""from appname.models...""
        for title in orm['hero_slider.SliderItemTitle'].objects.all():
            title.is_published = True
            title.save()",Write your forwards methods here.,
"def get_slider_items(context, amount=None):
    """"""Returns the published slider items.""""""
    req = context.get('request')
    qs = SliderItem.objects.published(req).order_by('position')
    if amount:
        qs = qs[:amount]
    return qs",Returns the published slider items.,
"def render_hero_slider(context):
    """"""
    Renders the hero slider.

    """"""
    req = context.get('request')
    qs = SliderItem.objects.published(req).order_by('position')
    return {
        'slider_items': qs,
    }",Renders the hero slider.,
"def reader_acquire(self):
        """"""Acquire the lock to read""""""

        self._order_mutex.acquire()
        self._readers_mutex.acquire()

        if self._readers == 0:
            self._access_mutex.acquire()
        self._readers += 1

        self._order_mutex.release()
        self._readers_mutex.release()",Acquire the lock to read,
"def reader_release(self):
        """"""Release the lock after reading""""""

        self._readers_mutex.acquire()

        self._readers -= 1
        if self._readers == 0:
            self._access_mutex.release()

        self._readers_mutex.release()",Release the lock after reading,
"def writer_acquire(self):
        """"""Acquire the lock to write""""""

        self._order_mutex.acquire()
        self._access_mutex.acquire()
        self._order_mutex.release()",Acquire the lock to write,
"def tasks(self):
        """"""Get the list of tasks""""""

        self._rwlock.reader_acquire()
        tl = [v for v in self._tasks.values()]
        tl.sort(key=lambda x: x.task_id)
        self._rwlock.reader_release()

        return tl",Get the list of tasks,
"def to_dict(self):
        """"""Returns a dict with the representation of this task configuration object.""""""

        properties = find_class_properties(self.__class__)
        config = {
            name: self.__getattribute__(name) for name, _ in properties
        }
        return config",Returns a dict with the representation of this task configuration object.,
"def initialize_archive_manager(self, archive_path):
        """"""Initialize the archive manager.

        :param archive_path: path where the archive manager is located
        """"""
        if archive_path == """":
            raise ValueError(""Archive manager path cannot be empty"")

        if archive_path:
            self.archive_manager = perceval.archive.ArchiveManager(archive_path)","Initialize the archive manager.

        :param archive_path: path where the archive manager is located",
"def json_encoder(*args, **kwargs):
    """"""Custom JSON encoder handler""""""

    obj = cherrypy.serving.request._json_inner_handler(*args, **kwargs)

    for chunk in JSONEncoder().iterencode(obj):
        yield chunk.encode('utf-8')",Custom JSON encoder handler,
"def write_items(cls, writer, items_generator):
        """"""Write items to the queue

        :param writer: the writer object
        :param items_generator: items to be written in the queue
        """"""
        while True:
            items = items_generator()
            writer.write(items)
            time.sleep(1)","Write items to the queue

        :param writer: the writer object
        :param items_generator: items to be written in the queue",
"def remove(self):
        """"""Remove tasks""""""

        payload = cherrypy.request.json
        logger.debug(""Reading tasks to remove..."")

        task_ids = {}

        for task_data in payload['tasks']:
            task_id = task_data['task_id']
            removed = super().remove_task(task_id)
            task_ids[task_id] = removed

        result = {'tasks': task_ids}

        return result",Remove tasks,
"def tasks(self):
        """"""List tasks""""""

        logger.debug(""API 'tasks' method called"")

        result = [task.to_dict() for task in self._tasks.tasks]
        result = {'tasks': result}

        logger.debug(""Tasks registry read"")

        return result",List tasks,
"def items(self):
        """"""Get the items fetched by the jobs.""""""

        # Get and remove queued items in an atomic transaction
        pipe = self.conn.pipeline()
        pipe.lrange(Q_STORAGE_ITEMS, 0, -1)
        pipe.ltrim(Q_STORAGE_ITEMS, 1, 0)
        items = pipe.execute()[0]

        for item in items:
            item = pickle.loads(item)
            yield item",Get the items fetched by the jobs.,
"def run(self):
        """"""Run thread to listen for jobs and reschedule successful ones.""""""

        try:
            self.listen()
        except Exception as e:
            logger.critical(""JobListener instence crashed. Error: %s"", str(e))
            logger.critical(traceback.format_exc())",Run thread to listen for jobs and reschedule successful ones.,
"def schedule(self):
        """"""Start scheduling jobs.""""""

        if self.async_mode:
            self._scheduler.start()
            self._listener.start()
        else:
            self._scheduler.schedule()",Start scheduling jobs.,
"def cancel_task(self, task_id):
        """"""Cancel or 'un-schedule' a task.

        :param task_id: identifier of the task to cancel

        :raises NotFoundError: raised when the requested task is not
            found in the registry
        """"""
        self.registry.remove(task_id)
        self._scheduler.cancel_job_task(task_id)

        logger.info(""Task %s canceled"", task_id)","Cancel or 'un-schedule' a task.

        :param task_id: identifier of the task to cancel

        :raises NotFoundError: raised when the requested task is not
            found in the registry",
"def _handle_failed_job(self, job):
        """"""Handle failed jobs""""""

        task_id = job.kwargs['task_id']
        logger.error(""Job #%s (task: %s) failed; cancelled"",
                     job.id, task_id)",Handle failed jobs,
"def register(view):  # Type[BananasAPI]
    """"""
    Register the API view class in the bananas router.

    :param BananasAPI view:
    """"""
    meta = view.get_admin_meta()
    prefix = meta.basename.replace(""."", ""/"")
    router.register(prefix, view, meta.basename)","Register the API view class in the bananas router.

    :param BananasAPI view:",
"def reverse_action(self, url_name, *args, **kwargs):
        """"""
        Extended DRF with fallback to requested namespace if request.version is missing
        """"""
        if self.request and not self.request.version:
            return reverse(self.get_url_name(url_name), *args, **kwargs)

        return super().reverse_action(url_name, *args, **kwargs)",Extended DRF with fallback to requested namespace if request.version is missing,
"def get_url_name(self, action_url_name=""list""):
        """"""
        Get full namespaced url name to use for reverse()
        """"""
        url_name = ""{}-{}"".format(self.basename, action_url_name)

        namespace = self.request.resolver_match.namespace
        if namespace:
            url_name = ""{}:{}"".format(namespace, url_name)

        return url_name",Get full namespaced url name to use for reverse(),
"def get_summary_and_description(self):
        """"""
        Compat: drf-yasg 1.12+
        """"""
        summary = self.get_summary()
        _, description = super().get_summary_and_description()
        return summary, description",Compat: drf-yasg 1.12+,
"def get_versioned_viewname(self, viewname, request):
        """"""
        Prefix viewname with full namespace bananas:vX.Y:
        """"""
        namespace = request.resolver_match.namespace
        if namespace:
            viewname = ""{}:{}"".format(namespace, viewname)

        return viewname",Prefix viewname with full namespace bananas:vX.Y:,
"def list(self, request):
        """"""
        Retrieve logged in user info
        """"""
        serializer = self.get_serializer(request.user)
        return Response(serializer.data, status=status.HTTP_200_OK)",Retrieve logged in user info,
"def parse_int(value):
    """"""
    Parse numeric string to int. Supports oct formatted string.

    :param str value: String value to parse as int
    :return int:
    """"""
    value = parse_str(value=value)
    if value.startswith(""0""):
        return int(value.lstrip(""0o""), 8)
    else:
        return int(value)","Parse numeric string to int. Supports oct formatted string.

    :param str value: String value to parse as int
    :return int:",
"def create_field(field_info):
    """"""
    Create a field by field info dict.
    """"""
    field_type = field_info.get('type')
    if field_type not in FIELDS_NAME_MAP:
        raise ValueError(_('not support this field: {}').format(field_type))
    field_class = FIELDS_NAME_MAP.get(field_type)
    params = dict(field_info)
    params.pop('type')
    return field_class.from_dict(params)",Create a field by field info dict.,
"def get_strings(args):
    """"""Returns all valid python strings inside a given argument string.""""""
    string_list = []
    for elem in ast.walk(ast.parse(args)):
        if isinstance(elem, ast.Str):
            string_list.append(elem.s)
    return string_list",Returns all valid python strings inside a given argument string.,
"def _set_logger(self, name=None):
        """"""Adds a logger with a given `name`.

        If no name is given, name is constructed as
        `type(self).__name__`.

        """"""
        if name is None:
            cls = self.__class__
            name = '%s.%s' % (cls.__module__, cls.__name__)
        self._logger = logging.getLogger(name)","Adds a logger with a given `name`.

        If no name is given, name is constructed as
        `type(self).__name__`.",
"def extract_replacements(self, trajectory):
        """"""Extracts the wildcards and file replacements from the `trajectory`""""""
        self.env_name = trajectory.v_environment_name
        self.traj_name = trajectory.v_name
        self.set_name =  trajectory.f_wildcard('$set')
        self.run_name = trajectory.f_wildcard('$')",Extracts the wildcards and file replacements from the `trajectory`,
"def _parser_to_string_io(parser):
        """"""Turns a ConfigParser into a StringIO stream.""""""
        memory_file = StringIO()
        parser.write(memory_file)
        memory_file.flush()
        memory_file.seek(0)
        return memory_file",Turns a ConfigParser into a StringIO stream.,
"def start(self):
        """"""Starts redirection of `stdout`""""""
        if sys.stdout is not self:
            self._original_steam = sys.stdout
            sys.stdout = self
            self._redirection = True
        if self._redirection:
            print('Established redirection of `stdout`.')",Starts redirection of `stdout`,
"def finalize(self):
        """"""Disables redirection""""""
        if self._original_steam is not None and self._redirection:
            sys.stdout = self._original_steam
            print('Disabled redirection of `stdout`.')
            self._redirection = False
            self._original_steam = None",Disables redirection,
"def _prfx_getattr_(obj, item):
    """"""Replacement of __getattr__""""""
    if item.startswith('f_') or item.startswith('v_'):
        return getattr(obj, item[2:])
    raise AttributeError('`%s` object has no attribute `%s`' % (obj.__class__.__name__, item))",Replacement of __getattr__,
"def _prfx_setattr_(obj, item, value):
    """"""Replacement of __setattr__""""""
    if item.startswith('v_'):
        return setattr(obj, item[2:], value)
    else:
        return super(obj.__class__, obj).__setattr__(item, value)",Replacement of __setattr__,
"def prefix_naming(cls):
    """"""Decorate that adds the prefix naming scheme""""""
    if hasattr(cls, '__getattr__'):
        raise TypeError('__getattr__ already defined')
    cls.__getattr__ = _prfx_getattr_
    cls.__setattr__ = _prfx_setattr_
    return cls",Decorate that adds the prefix naming scheme,
"def get_batch():
    """"""Function that parses the batch id from the command line arguments""""""
    optlist, args = getopt.getopt(sys.argv[1:], '', longopts='batch=')
    batch = 0
    for o, a in optlist:
        if o == '--batch':
            batch = int(a)
            print('Found batch %d' % batch)

    return batch",Function that parses the batch id from the command line arguments,
"def explore_batch(traj, batch):
    """"""Chooses exploration according to `batch`""""""
    explore_dict = {}
    explore_dict['sigma'] = np.arange(10.0 * batch, 10.0*(batch+1), 1.0).tolist()
    # for batch = 0 explores sigma in [0.0, 1.0, 2.0, ..., 9.0],
    # for batch = 1 explores sigma in [10.0, 11.0, 12.0, ..., 19.0]
    # and so on
    traj.f_explore(explore_dict)",Chooses exploration according to `batch`,
"def vars(self):
        """"""Alternative naming, you can use `node.vars.name` instead of `node.v_name`""""""
        if self._vars is None:
            self._vars = NNTreeNodeVars(self)
        return self._vars","Alternative naming, you can use `node.vars.name` instead of `node.v_name`",
"def func(self):
        """"""Alternative naming, you can use `node.func.name` instead of `node.f_func`""""""
        if self._func is None:
            self._func = NNTreeNodeFunc(self)
        return self._func","Alternative naming, you can use `node.func.name` instead of `node.f_func`",
"def _rename(self, full_name):
        """"""Renames the tree node""""""
        self._full_name = full_name
        if full_name:
            self._name = full_name.rsplit('.', 1)[-1]",Renames the tree node,
"def _set_details(self, depth, branch, run_branch):
        """"""Sets some details for internal handling.""""""
        self._depth = depth
        self._branch = branch
        self._run_branch = run_branch",Sets some details for internal handling.,
"def _replace_wildcards(self, name, run_idx=None):
        """"""Replaces the $ wildcards and returns True/False in case it was replaced""""""
        if self._root_instance.f_is_wildcard(name):
            return True, self._root_instance.f_wildcard(name, run_idx)
        else:
            return False, name",Replaces the $ wildcards and returns True/False in case it was replaced,
"def kids(self):
        """"""Alternative naming, you can use `node.kids.name` instead of `node.name`
        for easier tab completion.""""""
        if self._kids is None:
            self._kids = NNTreeNodeKids(self)
        return self._kids","Alternative naming, you can use `node.kids.name` instead of `node.name`
        for easier tab completion.",
"def f_get_parent(self):
        """"""Returns the parent of the node.

        Raises a TypeError if current node is root.

        """"""
        if self.v_is_root:
            raise TypeError('Root does not have a parent')
        elif self.v_location == '':
            return self.v_root
        else:
            return self.v_root.f_get(self.v_location, fast_access=False, shortcuts=False)","Returns the parent of the node.

        Raises a TypeError if current node is root.",
"def eval_one_max(traj, individual):
    """"""The fitness function""""""
    traj.f_add_result('$set.$.individual', list(individual))
    fitness = sum(individual)
    traj.f_add_result('$set.$.fitness', fitness)
    traj.f_store()
    return (fitness,)",The fitness function,
"def f_supports(self, data):
        """""" Simply checks if data is supported """"""
        if isinstance(data, Quantity):
            return True
        elif super(Brian2Parameter, self).f_supports(data):
            return True
        return False",Simply checks if data is supported,
"def _supports(self, data):
        """""" Simply checks if data is supported """"""
        if isinstance(data, Quantity):
            return True
        elif super(Brian2Result, self)._supports(data):
            return True
        return False",Simply checks if data is supported,
"def get_matching_kwargs(func, kwargs):
    """"""Takes a function and keyword arguments and returns the ones that can be passed.""""""
    args, uses_startstar = _get_argspec(func)
    if uses_startstar:
        return kwargs.copy()
    else:
        matching_kwargs = dict((k, kwargs[k]) for k in args if k in kwargs)
        return matching_kwargs",Takes a function and keyword arguments and returns the ones that can be passed.,
"def format_time(timestamp):
    """"""Formats timestamp to human readable format""""""
    format_string = '%Y_%m_%d_%Hh%Mm%Ss'
    formatted_time = datetime.datetime.fromtimestamp(timestamp).strftime(format_string)
    return formatted_time",Formats timestamp to human readable format,
"def f_to_dict(self, copy=True):
        """"""Returns annotations as dictionary.

        :param copy: Whether to return a shallow copy or the real thing (aka _dict).

        """"""
        if copy:
            return self._dict.copy()
        else:
            return self._dict","Returns annotations as dictionary.

        :param copy: Whether to return a shallow copy or the real thing (aka _dict).",
"def f_remove(self, key):
        """"""Removes `key` from annotations""""""
        key = self._translate_key(key)
        try:
            del self._dict[key]
        except KeyError:
            raise AttributeError('Your annotations do not contain %s' % key)",Removes `key` from annotations,
"def f_ann_to_str(self):
        """"""Returns all annotations lexicographically sorted as a concatenated string.""""""
        resstr = ''
        for key in sorted(self._dict.keys()):
            resstr += '%s=%s; ' % (key, str(self._dict[key]))
        return resstr[:-2]",Returns all annotations lexicographically sorted as a concatenated string.,
"def _supports(self, item):
        """"""Checks if outer data structure is supported.""""""
        result = super(SharedResult, self)._supports(item)
        result = result or type(item) in SharedResult.SUPPORTED_DATA
        return result",Checks if outer data structure is supported.,
"def create_shared_data(self, name=None, **kwargs):
        """"""Calls the corresponding function of the shared data item""""""
        if name is None:
            item = self.f_get()
        else:
            item = self.f_get(name)
        return item.create_shared_data(**kwargs)",Calls the corresponding function of the shared data item,
"def send_done(self):
        """"""Notifies the Server to shutdown""""""
        self.start(test_connection=False)
        self._logger.debug('Sending shutdown signal')
        self._req_rep(ZMQServer.DONE)",Notifies the Server to shutdown,
"def finalize(self):
        """"""Closes socket and terminates context

        NO-OP if already closed.

        """"""
        if self._context is not None:
            if self._socket is not None:
                self._close_socket(confused=False)
            self._context.term()
            self._context = None
            self._poll = None","Closes socket and terminates context

        NO-OP if already closed.",
"def start(self, test_connection=True):
        """"""Checks for forking and starts/restarts if desired""""""
        self._detect_fork()
        super(ForkAwareLockerClient, self).start(test_connection)",Checks for forking and starts/restarts if desired,
"def _put_on_queue(self, to_put):
        """"""Puts data on queue""""""
        old = self.pickle_queue
        self.pickle_queue = False
        try:
            self.queue.put(to_put, block=True)
        finally:
            self.pickle_queue = old",Puts data on queue,
"def _put_on_pipe(self, to_put):
        """"""Puts data on queue""""""
        self.acquire_lock()
        self._send_chunks(to_put)
        self.release_lock()",Puts data on queue,
"def _receive_data(self):
        """"""Gets data from queue""""""
        result = self.queue.get(block=True)
        if hasattr(self.queue, 'task_done'):
            self.queue.task_done()
        return result",Gets data from queue,
"def _receive_data(self):
        """"""Gets data from pipe""""""
        while True:
            while len(self._buffer) < self.max_size and self.conn.poll():
                data = self._read_chunks()
                if data is not None:
                    self._buffer.append(data)
            if len(self._buffer) > 0:
                return self._buffer.popleft()",Gets data from pipe,
"def store(self, msg, stuff_to_store, *args, **kwargs):
        """"""Simply keeps a reference to the stored data """"""
        trajectory_name = kwargs['trajectory_name']
        if trajectory_name not in self.references:
            self.references[trajectory_name] = []
        self.references[trajectory_name].append((msg, cp.copy(stuff_to_store), args, kwargs))",Simply keeps a reference to the stored data,
"def store_references(self, references):
        """"""Stores references to disk and may collect garbage.""""""
        for trajectory_name in references:
            self._storage_service.store(pypetconstants.LIST, references[trajectory_name], trajectory_name=trajectory_name)
        self._check_and_collect_garbage()",Stores references to disk and may collect garbage.,
"def _collect_config(self):
        """"""Collects all info from three sections""""""
        kwargs = {}
        sections = ('storage_service', 'trajectory', 'environment')
        for section in sections:
            kwargs.update(self._collect_section(section))
        return kwargs",Collects all info from three sections,
"def _overview_group(self):
        """"""Direct link to the overview group""""""
        if self._overview_group_ is None:
            self._overview_group_ = self._all_create_or_get_groups('overview')[0]
        return self._overview_group_",Direct link to the overview group,
"def _all_get_node_by_name(self, name):
        """"""Returns an HDF5 node by the path specified in `name`""""""
        path_name = name.replace('.', '/')
        where = '/%s/%s' % (self._trajectory_name, path_name)
        return self._hdf5file.get_node(where=where)",Returns an HDF5 node by the path specified in `name`,
"def _all_insert_into_row(self, row, insert_dict):
        """"""Copies data from `insert_dict` into a pytables `row`.""""""
        for key, val in insert_dict.items():
            try:
                row[key] = val
            except KeyError as ke:
                self._logger.warning('Could not write `%s` into a table, ' % key + repr(ke))",Copies data from `insert_dict` into a pytables `row`.,
"def _lnk_delete_link(self, link_name):
        """"""Removes a link from disk""""""
        translated_name = '/' + self._trajectory_name + '/' + link_name.replace('.','/')
        link = self._hdf5file.get_node(where=translated_name)
        link._f_remove()",Removes a link from disk,
"def make_set_name(idx):
    """"""Creates a run set name based on ``idx``""""""
    GROUPSIZE = 1000
    set_idx = idx // GROUPSIZE
    if set_idx >= 0:
        return pypetconstants.FORMATTED_SET_NAME % set_idx
    else:
        return pypetconstants.SET_NAME_DUMMY",Creates a run set name based on ``idx``,
"def v_full_copy(self, val):
        """""" Sets full copy mode of trajectory and (!) ALL explored parameters!""""""
        self._full_copy = bool(val)
        for param in self._explored_parameters.values():
            if param is not None:
                param.v_full_copy = bool(val)",Sets full copy mode of trajectory and (!) ALL explored parameters!,
"def f_preset_config(self, config_name, *args, **kwargs):
        """"""Similar to func:`~pypet.trajectory.Trajectory.f_preset_parameter`""""""

        if not config_name.startswith('config.'):
            config_name = 'config.' + config_name

        self._preset(config_name, args, kwargs)",Similar to func:`~pypet.trajectory.Trajectory.f_preset_parameter`,
"def _is_completed(self, name_or_id=None):
        """"""Private function such that it can still be called by the environment during
        a single run""""""

        if name_or_id is None:
            return all(
                (runinfo['completed'] for runinfo in self._run_information.values()))
        else:
            return self.f_get_run_information(name_or_id, copy=False)['completed']","Private function such that it can still be called by the environment during
        a single run",
"def _update_run_information(self, run_information_dict):
        """"""Overwrites the run information of a particular run""""""
        idx = run_information_dict['idx']
        name = run_information_dict['name']
        self._run_information[name] = run_information_dict
        self._updated_run_information.add(idx)",Overwrites the run information of a particular run,
"def f_lock_parameters(self):
        """"""Locks all non-empty parameters""""""
        for par in self._parameters.values():
            if not par.f_is_empty():
                par.f_lock()",Locks all non-empty parameters,
"def f_lock_derived_parameters(self):
        """"""Locks all non-empty derived parameters""""""
        for par in self._derived_parameters.values():
            if not par.f_is_empty():
                par.f_lock()",Locks all non-empty derived parameters,
"def f_is_empty(self):
        """""" Whether no results nor parameters have been added yet to the trajectory
        (ignores config).""""""
        return (len(self._parameters) == 0 and
                len(self._derived_parameters) == 0 and
                len(self._results) == 0 and
                len(self._other_leaves) == 0)","Whether no results nor parameters have been added yet to the trajectory
        (ignores config).",
"def f_restore_default(self):
        """""" Restores the default value in all explored parameters and sets the
        v_idx property back to -1 and v_crun to None.""""""
        self._idx = -1
        self._crun = None
        for param in self._explored_parameters.values():
            if param is not None:
                param._restore_default()","Restores the default value in all explored parameters and sets the
        v_idx property back to -1 and v_crun to None.",
"def _set_explored_parameters_to_idx(self, idx):
        """""" Notifies the explored parameters what current point in the parameter space
        they should represent.

        """"""
        for param in self._explored_parameters.values():
            if param is not None:
                param._set_parameter_access(idx)","Notifies the explored parameters what current point in the parameter space
        they should represent.",
"def _make_single_run(self):
        """""" Modifies the trajectory for single runs executed by the environment """"""
        self._is_run = False # to be able to use f_set_crun
        self._new_nodes = OrderedDict()
        self._new_links = OrderedDict()
        self._is_run = True
        return self",Modifies the trajectory for single runs executed by the environment,
"def f_store_item(self, item, *args, **kwargs):
        """"""Stores a single item, see also :func:`~pypet.trajectory.Trajectory.f_store_items`.""""""
        self.f_store_items([item], *args, **kwargs)","Stores a single item, see also :func:`~pypet.trajectory.Trajectory.f_store_items`.",
"def f_load_item(self, item, *args, **kwargs):
        """"""Loads a single item, see also :func:`~pypet.trajectory.Trajectory.f_load_items`""""""
        self.f_load_items([item], *args, **kwargs)","Loads a single item, see also :func:`~pypet.trajectory.Trajectory.f_load_items`",
"def f_remove_item(self, item, recursive=False):
        """"""Removes a single item, see :func:`~pypet.trajectory.Trajectory.f_remove_items`""""""
        self.f_remove_items([item], recursive=recursive)","Removes a single item, see :func:`~pypet.trajectory.Trajectory.f_remove_items`",
"def f_delete_item(self, item, *args, **kwargs):
        """"""Deletes a single item, see :func:`~pypet.trajectory.Trajectory.f_delete_items`""""""
        self.f_delete_items([item], *args, **kwargs)","Deletes a single item, see :func:`~pypet.trajectory.Trajectory.f_delete_items`",
"def _configure_pool(kwargs):
    """"""Configures the pool and keeps the storage service""""""
    _pool_single_run.storage_service = kwargs['storage_service']
    _configure_niceness(kwargs)
    _configure_logging(kwargs, extract=False)",Configures the pool and keeps the storage service,
"def _configure_frozen_pool(kwargs):
    """"""Configures the frozen pool and keeps all kwargs""""""
    _frozen_pool_single_run.kwargs = kwargs
    _configure_niceness(kwargs)
    _configure_logging(kwargs, extract=False)
    # Reset full copy to it's old value
    traj = kwargs['traj']
    traj.v_full_copy = kwargs['full_copy']",Configures the frozen pool and keeps all kwargs,
"def _process_single_run(kwargs):
    """"""Wrapper function that first configures logging and starts a single run afterwards.""""""
    _configure_niceness(kwargs)
    _configure_logging(kwargs)
    result_queue = kwargs['result_queue']
    result = _sigint_handling_single_run(kwargs)
    result_queue.put(result)
    result_queue.close()",Wrapper function that first configures logging and starts a single run afterwards.,
"def _is_supported_matrix(data):
        """"""Checks if a data is csr, csc, bsr, or dia Scipy sparse matrix""""""
        return (spsp.isspmatrix_csc(data) or
                spsp.isspmatrix_csr(data) or
                spsp.isspmatrix_bsr(data) or
                spsp.isspmatrix_dia(data))","Checks if a data is csr, csc, bsr, or dia Scipy sparse matrix",
"def f_supports(self, data):
        """"""Sparse matrices support Scipy csr, csc, bsr and dia matrices and everything their parent
        class the :class:`~pypet.parameter.ArrayParameter` supports.

        """"""
        if self._is_supported_matrix(data):
            return True
        else:
            return super(SparseParameter, self).f_supports(data)","Sparse matrices support Scipy csr, csc, bsr and dia matrices and everything their parent
        class the :class:`~pypet.parameter.ArrayParameter` supports.",
"def f_translate_key(self, key):
        """"""Translates integer indices into the appropriate names""""""
        if isinstance(key, int):
            if key == 0:
                key = self.v_name
            else:
                key = self.v_name + '_%d' % key
        return key",Translates integer indices into the appropriate names,
"def f_to_dict(self, copy=True):
        """"""Returns all handled data as a dictionary.

        :param copy:

            Whether the original dictionary or a shallow copy is returned.

        :return: Data dictionary

        """"""
        if copy:
            return self._data.copy()
        else:
            return self._data","Returns all handled data as a dictionary.

        :param copy:

            Whether the original dictionary or a shallow copy is returned.

        :return: Data dictionary",
"def f_remove(self, *args):
        """"""Removes `*args` from the result""""""
        for arg in args:
            arg = self.f_translate_key(arg)
            if arg in self._data:
                del self._data[arg]
            else:
                raise AttributeError('Your result `%s` does not contain %s.' % (self.name_, arg))",Removes `*args` from the result,
"def _supports(self, item):
        """"""Supports everything of parent class and csr, csc, bsr, and dia sparse matrices.""""""
        if SparseParameter._is_supported_matrix(item):
            return True
        else:
            return super(SparseResult, self)._supports(item)","Supports everything of parent class and csr, csc, bsr, and dia sparse matrices.",
"def _store(self):
        """"""Returns a dictionary containing pickle dumps""""""
        store_dict = {}
        for key, val in self._data.items():
            store_dict[key] = pickle.dumps(val, protocol=self.v_protocol)
        store_dict[PickleResult.PROTOCOL] = self.v_protocol
        return store_dict",Returns a dictionary containing pickle dumps,
"def main():
    """"""Simply merge all trajectories in the working directory""""""
    folder = os.getcwd()
    print('Merging all files')
    merge_all_in_folder(folder,
                        delete_other_files=True,  # We will only keep one trajectory
                        dynamic_imports=FunctionParameter,
                        backup=False)
    print('Done')",Simply merge all trajectories in the working directory,
"def upload_file(filename, session):
    """""" Uploads a file """"""
    print('Uploading file %s' % filename)
    outfilesource = os.path.join(os.getcwd(), filename)
    outfiletarget = 'sftp://' + ADDRESS + WORKING_DIR
    out = saga.filesystem.File(outfilesource, session=session, flags=OVERWRITE)
    out.copy(outfiletarget)
    print('Transfer of `%s` to `%s` successful' % (filename, outfiletarget))",Uploads a file,
"def create_session():
    """""" Creates and returns a new SAGA session """"""
    ctx = saga.Context(""UserPass"")
    ctx.user_id = USER
    ctx.user_pass = PASSWORD

    session = saga.Session()
    session.add_context(ctx)

    return session",Creates and returns a new SAGA session,
"def multiply(traj):
    """"""Sophisticated simulation of multiplication""""""
    z=traj.x*traj.y
    traj.f_add_result('z',z=z, comment='I am the product of two reals!')",Sophisticated simulation of multiplication,
"def make_filename(traj):
    """""" Function to create generic filenames based on what has been explored """"""
    explored_parameters = traj.f_get_explored_parameters()
    filename = ''
    for param in explored_parameters.values():
        short_name = param.v_name
        val = param.f_get()
        filename += '%s_%s__' % (short_name, str(val))

    return filename[:-2] + '.png'",Function to create generic filenames based on what has been explored,
"def future_dt_str(dt, td):
    """""".""""""
    if isinstance(td, str):
        td = float(td)
    td = timedelta(seconds=td)
    future_dt = dt + td
    return future_dt.strftime(DT_PRINT_FORMAT)",.,
"def gen_timeout_request_rebind(lease):
    """""".""""""
    time_left = (lease.lease_time - lease.rebinding_time) * RENEW_PERC
    if time_left < 60:
        time_left = 60
    logger.debug('Next request on rebinding will happen on %s',
                 future_dt_str(nowutc(), time_left))
    return time_left",.,
"def dict_self(self):
        """"""Return the self object attributes not inherited as dict.""""""
        return {k: v for k, v in self.__dict__.items() if k in FSM_ATTRS}",Return the self object attributes not inherited as dict.,
"def process_received_nak(self, pkt):
        """"""Process a received NAK packet.""""""
        if isnak(pkt):
            logger.info('DHCPNAK of %s from %s',
                        self.client.client_ip, self.client.server_ip)
            return True
        return False",Process a received NAK packet.,
"def RENEWING(self):
        """"""RENEWING state.""""""
        logger.debug('In state: RENEWING')
        self.current_state = STATE_RENEWING
        if self.script is not None:
            self.script.script_init(self.client.lease, self.current_state)
            self.script.script_go()
        else:
            set_net(self.client.lease)",RENEWING state.,
"def REBINDING(self):
        """"""REBINDING state.""""""
        logger.debug('In state: REBINDING')
        self.current_state = STATE_REBINDING
        if self.script is not None:
            self.script.script_init(self.client.lease, self.current_state)
            self.script.script_go()
        else:
            set_net(self.client.lease)",REBINDING state.,
"def END(self):
        """"""END state.""""""
        logger.debug('In state: END')
        self.current_state = STATE_END
        if self.script is not None:
            self.script.script_init(self.client.lease, self.current_state)
            self.script.script_go()
        else:
            set_net(self.client.lease)
        return",END state.,
"def ERROR(self):
        """"""ERROR state.""""""
        logger.debug('In state: ERROR')
        self.current_state = STATE_ERROR
        if self.script is not None:
            self.script.script_init(self.client.lease, self.current_state)
            self.script.script_go()
        set_net(self.client.lease)
        raise self.INIT()",ERROR state.,
"def receive_ack_requesting(self, pkt):
        """"""Receive ACK in REQUESTING state.""""""
        logger.debug(""C3. Received ACK?, in REQUESTING state."")
        if self.process_received_ack(pkt):
            logger.debug(""C3: T. Received ACK, in REQUESTING state, ""
                         ""raise BOUND."")
            raise self.BOUND()",Receive ACK in REQUESTING state.,
"def receive_nak_requesting(self, pkt):
        """"""Receive NAK in REQUESTING state.""""""
        logger.debug(""C3.1. Received NAK?, in REQUESTING state."")
        if self.process_received_nak(pkt):
            logger.debug(""C3.1: T. Received NAK, in REQUESTING state, ""
                         ""raise INIT."")
            raise self.INIT()",Receive NAK in REQUESTING state.,
"def receive_ack_renewing(self, pkt):
        """"""Receive ACK in RENEWING state.""""""
        logger.debug(""C3. Received ACK?, in RENEWING state."")
        if self.process_received_ack(pkt):
            logger.debug(""C3: T. Received ACK, in RENEWING state, ""
                         ""raise BOUND."")
            raise self.BOUND()",Receive ACK in RENEWING state.,
"def receive_nak_renewing(self, pkt):
        """"""Receive NAK in RENEWING state.""""""
        logger.debug(""C3.1. Received NAK?, in RENEWING state."")
        if self.process_received_nak(pkt):
            logger.debug(""C3.1: T. Received NAK, in RENEWING state, ""
                         "" raise INIT."")
            raise self.INIT()",Receive NAK in RENEWING state.,
"def receive_ack_rebinding(self, pkt):
        """"""Receive ACK in REBINDING state.""""""
        logger.debug(""C3. Received ACK?, in REBINDING state."")
        if self.process_received_ack(pkt):
            logger.debug(""C3: T. Received ACK, in REBINDING state, ""
                         ""raise BOUND."")
            raise self.BOUND()",Receive ACK in REBINDING state.,
"def receive_nak_rebinding(self, pkt):
        """"""Receive NAK in REBINDING state.""""""
        logger.debug(""C3.1. Received NAK?, in RENEWING state."")
        if self.process_received_nak(pkt):
            logger.debug(""C3.1: T. Received NAK, in RENEWING state, ""
                         ""raise INIT."")
            raise self.INIT()",Receive NAK in REBINDING state.,
"def on_renewing(self):
        """"""Action on renewing on RENEWING state.

        Not recording lease, but restarting timers.

        """"""
        self.client.lease.sanitize_net_values()
        self.client.lease.set_times(self.time_sent_request)
        self.set_timers()","Action on renewing on RENEWING state.

        Not recording lease, but restarting timers.",
"def isoffer(packet):
    """""".""""""
    if DHCP in packet and (DHCPTypes.get(packet[DHCP].options[0][1]) ==
                           'offer' or packet[DHCP].options[0][1] == ""offer""):
        logger.debug('Packet is Offer.')
        return True
    return False",.,
"def set(self, name, value):
        """""" Assign a value, remove if it's None """"""
        clone = self._clone()
        if django.VERSION[0] <= 1 and django.VERSION[1] <= 4:
            value = value or None
        clone._qsl = [(q, v) for (q, v) in self._qsl if q != name]
        if value is not None:
            clone._qsl.append((name, value))
        return clone","Assign a value, remove if it's None",
"def add(self, name, value):
        """""" Append a value to multiple value parameter. """"""
        clone = self._clone()
        clone._qsl = [p for p in self._qsl
                      if not(p[0] == name and p[1] == value)]
        clone._qsl.append((name, value,))
        return clone",Append a value to multiple value parameter.,
"def remove(self, name, value):
        """""" Remove a value from multiple value parameter. """"""
        clone = self._clone()
        clone._qsl = [qb for qb in self._qsl if qb != (name, str(value))]
        return clone",Remove a value from multiple value parameter.,
"def inc(self, name, value=1):
        """""" Increment value """"""
        clone = self._clone()
        clone._qsl = [(q, v) if q != name else (q, int(v) + value)
                      for (q, v) in self._qsl]
        if name not in dict(clone._qsl).keys():
            clone._qsl.append((name, value))
        return clone",Increment value,
"def main():
    """"""
    Program main.
    """"""

    options = parse_options()
    output, code = create_output(get_status(options), options)
    sys.stdout.write(output)
    sys.exit(code)",Program main.,
"def tdms2fcs(tdms_file):
    """"""Creates an fcs file for a given tdms file""""""
    fcs_file = tdms_file[:-4]+""fcs""
    chn_names, data = read_tdms(tdms_file)
    chn_names, data = add_deformation(chn_names, data)
    fcswrite.write_fcs(filename=fcs_file,
                       chn_names=chn_names,
                       data=np.array(data).transpose())",Creates an fcs file for a given tdms file,
"def _backup_file(self, file, patch):
        """""" Creates a backup of file """"""
        dest_dir = self.quilt_pc + patch.get_name()
        file_dir = file.get_directory()
        if file_dir:
            #TODO get relative path
            dest_dir = dest_dir + file_dir
        backup = Backup()
        backup.backup_file(file, dest_dir, copy_empty=True)",Creates a backup of file,
"def create(self):
        """""" Creates the directory and all its parent directories if it does not
        exist yet
        """"""
        if self.dirname and not os.path.exists(self.dirname):
            os.makedirs(self.dirname)","Creates the directory and all its parent directories if it does not
        exist yet",
"def link(self, link):
        """""" Create hard link as link to this file """"""
        if isinstance(link, File):
            link = link.filename
        os.link(self.filename, link)",Create hard link as link to this file,
"def copy(self, dest):
        """""" Copy file to destination """"""
        if isinstance(dest, File):
            dest_dir = dest.get_directory()
            dest_dir.create()
            dest = dest.filename
        elif isinstance(dest, Directory):
            dest = dest.dirname

        shutil.copy2(self.filename, dest)",Copy file to destination,
"def get_directory(self):
        """""" Returns the directory where the file is placed in or None if the
        path to the file doesn't contain a directory
        """"""
        dirname = os.path.dirname(self.filename)
        if dirname:
            return Directory(dirname)
        else:
            return None","Returns the directory where the file is placed in or None if the
        path to the file doesn't contain a directory",
"def unapply_patch(self, patch_name, force=False):
        """""" Unapply patches up to patch_name. patch_name will end up as top
            patch """"""
        self._check(force)

        patches = self.db.patches_after(Patch(patch_name))
        for patch in reversed(patches):
            self._unapply_patch(patch)

        self.db.save()

        self.unapplied(self.db.top_patch())","Unapply patches up to patch_name. patch_name will end up as top
            patch",
"def unapply_top_patch(self, force=False):
        """""" Unapply top patch """"""
        self._check(force)

        patch = self.db.top_patch()
        self._unapply_patch(patch)

        self.db.save()

        self.unapplied(self.db.top_patch())",Unapply top patch,
"def unapply_all(self, force=False):
        """""" Unapply all patches """"""
        self._check(force)

        for patch in reversed(self.db.applied_patches()):
            self._unapply_patch(patch)

        self.db.save()

        self.unapplied(self.db.top_patch())",Unapply all patches,
"def read(self):
        """""" Reads all patches from the series file """"""
        self.patchlines = []
        self.patch2line = dict()
        if self.exists():
            with open(self.series_file, ""r"") as f:
                for line in f:
                    self.add_patch(line)",Reads all patches from the series file,
"def save(self):
        """""" Saves current patches list in the series file """"""
        with open(self.series_file, ""wb"") as f:
            for patchline in self.patchlines:
                f.write(_encode_str(str(patchline)))
                f.write(b""\n"")",Saves current patches list in the series file,
"def add_patch(self, patch):
        """""" Add a patch to the patches list """"""
        patchline = PatchLine(patch)
        patch = patchline.get_patch()
        if patch:
            self.patch2line[patch] = patchline
        self.patchlines.append(patchline)",Add a patch to the patches list,
"def remove_patch(self, patch):
        """""" Remove a patch from the patches list """"""
        self._check_patch(patch)
        patchline = self.patch2line[patch]
        del self.patch2line[patch]
        self.patchlines.remove(patchline)",Remove a patch from the patches list,
"def patches_after(self, patch):
        """""" Returns a list of patches after patch from the patches list """"""
        return [line.get_patch() for line in self._patchlines_after(patch) if
                line.get_patch()]",Returns a list of patches after patch from the patches list,
"def patches_before(self, patch):
        """""" Returns a list of patches before patch from the patches list """"""
        return [line.get_patch() for line in self._patchlines_before(patch)
                if line.get_patch()]",Returns a list of patches before patch from the patches list,
"def patches_until(self, patch):
        """""" Returns a list of patches before patch from the patches list
        including the provided patch
        """"""
        return [line.get_patch() for line in self._patchlines_until(patch) if
                line.get_patch()]","Returns a list of patches before patch from the patches list
        including the provided patch",
"def create(self):
        """""" Creates the dirname and inserts a .version file """"""
        if not os.path.exists(self.dirname):
            os.makedirs(self.dirname)
        self._create_version(self.version_file)",Creates the dirname and inserts a .version file,
"def add_to_parser(self, parser):
        """"""
        Adds the group and its arguments to a argparse.ArgumentParser instance

        @param parser A argparse.ArgumentParser instance
        """"""
        self.group = parser.add_argument_group(self.title, self.description)
        for arg in self.arguments:
            arg.add_to_parser(self.group)","Adds the group and its arguments to a argparse.ArgumentParser instance

        @param parser A argparse.ArgumentParser instance",
"def add_to_parser(self, parser):
        """"""
        Adds the argument to an argparse.ArgumentParser instance

        @param parser An argparse.ArgumentParser instance
        """"""
        kwargs = self._get_kwargs()
        args = self._get_args()
        parser.add_argument(*args, **kwargs)","Adds the argument to an argparse.ArgumentParser instance

        @param parser An argparse.ArgumentParser instance",
"def set_subparsers_args(self, *args, **kwargs):
        """"""
        Sets args and kwargs that are passed when creating a subparsers group
        in an argparse.ArgumentParser i.e. when calling
        argparser.ArgumentParser.add_subparsers
        """"""
        self.subparsers_args = args
        self.subparsers_kwargs = kwargs","Sets args and kwargs that are passed when creating a subparsers group
        in an argparse.ArgumentParser i.e. when calling
        argparser.ArgumentParser.add_subparsers",
"def missing_node_ids(self):
        """"""Get a list of nodes not found in OSM data.""""""
        present_node_ids = self.nodes.keys()
        for nid in self.node_ids:
            if nid not in present_node_ids:
                yield nid",Get a list of nodes not found in OSM data.,
"def get_agency_id(relation):
    """"""Construct an id for agency using its tags.""""""
    op = relation.tags.get('operator')
    if op:
        return int(hashlib.sha256(op.encode('utf-8')).hexdigest(), 16) % 10**8
    return -1",Construct an id for agency using its tags.,
"def u2str(data):
    """"""Recursively converts unicode objects to UTF-8 encoded byte strings.""""""
    if isinstance(data, dict):
        return {u2str(k): u2str(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [u2str(x) for x in data]
    elif isinstance(data, text_type):
        return data.encode('utf-8')
    else:
        return data",Recursively converts unicode objects to UTF-8 encoded byte strings.,
"def _matches_filepath_pattern(self, filepath):
        '''Given a filepath, and a list of regex patterns, this function returns true
        if filepath matches any one of those patterns'''
        if not self.only_blame_patterns:
            return True

        for pattern in self.only_blame_patterns:
            if pattern.match(filepath):
                return True
        return False","Given a filepath, and a list of regex patterns, this function returns true
        if filepath matches any one of those patterns",
"def _get_entry(self, entry, entry_tree):
        '''Helper function for retrieving a particular entry from the prefix trees'''
        for e in entry_tree[entry.filename]:
            if entry == e:
                return e",Helper function for retrieving a particular entry from the prefix trees,
"def url_to_image(url):
    """"""
    Fetch an image from url and convert it into a Pillow Image object
    """"""
    r = requests.get(url)
    image = StringIO(r.content)
    return image",Fetch an image from url and convert it into a Pillow Image object,
"def string_to_image(image_string):
    """"""
    Convert string datas into a Pillow Image object
    """"""
    image_filelike = StringIO(image_string)
    image = Image.open(image_filelike)
    return image",Convert string datas into a Pillow Image object,
"def _is_big_enough(image, size):
    """"""Check that the image's size superior to `size`""""""
    if (size[0] > image.size[0]) and (size[1] > image.size[1]):
        raise ImageSizeError(image.size, size)",Check that the image's size superior to `size`,
"def _width_is_big_enough(image, width):
    """"""Check that the image width is superior to `width`""""""
    if width > image.size[0]:
        raise ImageSizeError(image.size[0], width)",Check that the image width is superior to `width`,
"def _height_is_big_enough(image, height):
    """"""Check that the image height is superior to `height`""""""
    if height > image.size[1]:
        raise ImageSizeError(image.size[1], height)",Check that the image height is superior to `height`,
"def resize_thumbnail(image, size, resample=Image.LANCZOS):
    """"""
    Resize image according to size.
    image:      a Pillow image instance
    size:       a list of two integers [width, height]
    """"""

    img_format = image.format
    img = image.copy()
    img.thumbnail((size[0], size[1]), resample)
    img.format = img_format
    return img","Resize image according to size.
    image:      a Pillow image instance
    size:       a list of two integers [width, height]",
"def parse_totals(self, item, field_name, source_name):
        """"""
        Parse numeric fields.
        """"""
        val = self.get_value(item, source_name)
        try:
            return int(val)
        except:
            return 0",Parse numeric fields.,
"def get_items(self):
        """"""
        Iterator of the list of items in the XML source.
        """"""
        # Use `iterparse`, it's more efficient, specially for big files
        for event, item in ElementTree.iterparse(self.source):
            if item.tag == self.item_tag_name:
                yield item
                # Releases the item from memory
                item.clear()",Iterator of the list of items in the XML source.,
"def get_value(self, item, source_name):
        """"""
        This method receives an item from the source and a source name,
        and returns the text content for the `source_name` node.
        """"""
        return force_text(smart_str(item.findtext(source_name))).strip()","This method receives an item from the source and a source name,
        and returns the text content for the `source_name` node.",
"def save_error(self, data, exception_info):
        """"""
        Saves an error in the error list. 
        """"""
        # TODO: what to do with errors? Let it flow? Write to a log file?
        self.errors.append({'data': data,
                            'exception': ''.join(format_exception(*exception_info)),
                            })",Saves an error in the error list.,
"def feed_instance(self, data, instance):
        """"""
        Feeds a model instance using parsed data (usually from `parse_item`).
        """"""
        for prop, val in data.items():
            setattr(instance, prop, val)
        return instance",Feeds a model instance using parsed data (usually from `parse_item`).,
"def save_item(self, item, data, instance, commit=True):
        """"""
        Saves a model instance to the database.
        """"""
        if commit:
            instance.save()
        return instance",Saves a model instance to the database.,
"def load(self, source):
        """"""
        Opens the source file.
        """"""
        self.source = open(self.source, 'rb')    
        self.loaded = True",Opens the source file.,
"def get_value(self, item, source_name):
        """"""
        This method receives an item from the source and a source name,
        and returns the text content for the `source_name` node.
        """"""
        val = item.get(source_name.encode('utf-8'), None)
        if val is not None:
            val = convert_string(val)
        return val","This method receives an item from the source and a source name,
        and returns the text content for the `source_name` node.",
"def get_package_meta(meta_name):
    """"""Return value of variable set in the package where said variable is
    named in the Python meta format `__<meta_name>__`.
    """"""
    regex = ""__{0}__ = ['\""]([^'\""]+)['\""]"".format(meta_name)
    return re.search(regex, package_file).group(1)","Return value of variable set in the package where said variable is
    named in the Python meta format `__<meta_name>__`.",
"def allow_network_access(self, value: bool):
        """"""
        Raises ValueError if this sandbox instance is currently running.
        """"""
        if self._is_running:
            raise ValueError(
                ""Cannot change network access settings on a running sandbox"")

        self._allow_network_access = value",Raises ValueError if this sandbox instance is currently running.,
"def get_enrollments_for_course_by_sis_id(self, sis_course_id, params={}):
        """"""
        Return a list of all enrollments for the passed course sis id.
        """"""
        return self.get_enrollments_for_course(
            self._sis_id(sis_course_id, sis_field=""course""), params)",Return a list of all enrollments for the passed course sis id.,
"def get_enrollments_for_section_by_sis_id(self, sis_section_id, params={}):
        """"""
        Return a list of all enrollments for the passed section sis id.
        """"""
        return self.get_enrollments_for_section(
            self._sis_id(sis_section_id, sis_field=""section""), params)",Return a list of all enrollments for the passed section sis id.,
"def get_roles_by_account_sis_id(self, account_sis_id, params={}):
        """"""
        List the roles for an account, for the passed account SIS ID.
        """"""
        return self.get_roles_in_account(self._sis_id(account_sis_id,
                                                      sis_field=""account""),
                                         params)","List the roles for an account, for the passed account SIS ID.",
"def get_role(self, account_id, role_id):
        """"""
        Get information about a single role, for the passed Canvas account ID.

        https://canvas.instructure.com/doc/api/roles.html#method.role_overrides.show
        """"""
        url = ACCOUNTS_API.format(account_id) + ""/roles/{}"".format(role_id)
        return CanvasRole(data=self._get_resource(url))","Get information about a single role, for the passed Canvas account ID.

        https://canvas.instructure.com/doc/api/roles.html#method.role_overrides.show",
"def get_role_by_account_sis_id(self, account_sis_id, role_id):
        """"""
        Get information about a single role, for the passed account SIS ID.
        """"""
        return self.get_role(self._sis_id(account_sis_id, sis_field=""account""),
                             role_id)","Get information about a single role, for the passed account SIS ID.",
"def get_course_by_sis_id(self, sis_course_id, params={}):
        """"""
        Return course resource for given sis id.
        """"""
        return self.get_course(self._sis_id(sis_course_id, sis_field=""course""),
                               params)",Return course resource for given sis id.,
"def get_courses_in_account_by_sis_id(self, sis_account_id, params={}):
        """"""
        Return a list of courses for the passed account SIS ID.
        """"""
        return self.get_courses_in_account(
            self._sis_id(sis_account_id, sis_field=""account""), params)",Return a list of courses for the passed account SIS ID.,
"def get_published_courses_in_account(self, account_id, params={}):
        """"""
        Return a list of published courses for the passed account ID.
        """"""
        params[""published""] = True
        return self.get_courses_in_account(account_id, params)",Return a list of published courses for the passed account ID.,
"def get_published_courses_in_account_by_sis_id(self, sis_account_id,
                                                   params={}):
        """"""
        Return a list of published courses for the passed account SIS ID.
        """"""

        return self.get_published_courses_in_account(
            self._sis_id(sis_account_id, sis_field=""account""), params)",Return a list of published courses for the passed account SIS ID.,
"def get_user(self, user_id):
        """"""
        Returns user profile data.

        https://canvas.instructure.com/doc/api/users.html#method.profile.settings
        """"""
        url = USERS_API.format(user_id) + ""/profile""
        return CanvasUser(data=self._get_resource(url))","Returns user profile data.

        https://canvas.instructure.com/doc/api/users.html#method.profile.settings",
"def get_users_for_course(self, course_id, params={}):
        """"""
        Returns a list of users for the given course id.
        """"""
        url = COURSES_API.format(course_id) + ""/users""
        data = self._get_paged_resource(url, params=params)
        users = []
        for datum in data:
            users.append(CanvasUser(data=datum))
        return users",Returns a list of users for the given course id.,
"def get_users_for_sis_course_id(self, sis_course_id, params={}):
        """"""
        Returns a list of users for the given sis course id.
        """"""
        return self.get_users_for_course(
            self._sis_id(sis_course_id, sis_field=""course""), params)",Returns a list of users for the given sis course id.,
"def _next_page(self, response):
        """"""
        return url path to next page of paginated data
        """"""
        for link in response.getheader(""link"", """").split("",""):
            try:
                (url, rel) = link.split("";"")
                if ""next"" in rel:
                    return url.lstrip(""<"").rstrip("">"")
            except Exception:
                return",return url path to next page of paginated data,
"def _get_resource(self, url, params=None, data_key=None):
        """"""
        Canvas GET method. Return representation of the requested resource.
        """"""
        if not params:
            params = {}

        self._set_as_user(params)

        full_url = url + self._params(params)

        return self._get_resource_url(full_url, True, data_key)",Canvas GET method. Return representation of the requested resource.,
"def create_admin_by_sis_id(self, sis_account_id, user_id, role):
        """"""
        Flag an existing user as an admin within the account sis id.
        """"""
        return self.create_admin(self._sis_id(sis_account_id), user_id, role)",Flag an existing user as an admin within the account sis id.,
"def delete_admin(self, account_id, user_id, role):
        """"""
        Remove an account admin role from a user.

        https://canvas.instructure.com/doc/api/admins.html#method.admins.destroy
        """"""
        url = ADMINS_API.format(account_id) + ""/{}?role={}"".format(
            user_id, quote(role))

        response = self._delete_resource(url)
        return True","Remove an account admin role from a user.

        https://canvas.instructure.com/doc/api/admins.html#method.admins.destroy",
"def delete_admin_by_sis_id(self, sis_account_id, user_id, role):
        """"""
        Remove an account admin role from a user for the account sis id.
        """"""
        return self.delete_admin(self._sis_id(sis_account_id), user_id, role)",Remove an account admin role from a user for the account sis id.,
"def get_section(self, section_id, params={}):
        """"""
        Return section resource for given canvas section id.

        https://canvas.instructure.com/doc/api/sections.html#method.sections.show
        """"""
        url = SECTIONS_API.format(section_id)
        return CanvasSection(data=self._get_resource(url, params=params))","Return section resource for given canvas section id.

        https://canvas.instructure.com/doc/api/sections.html#method.sections.show",
"def get_section_by_sis_id(self, sis_section_id, params={}):
        """"""
        Return section resource for given sis id.
        """"""
        return self.get_section(
            self._sis_id(sis_section_id, sis_field=""section""), params)",Return section resource for given sis id.,
"def get_sections_in_course_by_sis_id(self, sis_course_id, params={}):
        """"""
        Return list of sections for the passed course SIS ID.
        """"""
        return self.get_sections_in_course(
            self._sis_id(sis_course_id, sis_field=""course""), params)",Return list of sections for the passed course SIS ID.,
"def get_sections_with_students_in_course(self, course_id, params={}):
        """"""
        Return list of sections including students for the passed course ID.
        """"""
        include = params.get(""include"", [])
        if ""students"" not in include:
            include.append(""students"")
        params[""include""] = include

        return self.get_sections_in_course(course_id, params)",Return list of sections including students for the passed course ID.,
"def get_sections_with_students_in_course_by_sis_id(self, sis_course_id,
                                                       params={}):
        """"""
        Return list of sections including students for the passed sis ID.
        """"""
        return self.get_sections_with_students_in_course(
            self._sis_id(sis_course_id, sis_field=""course""), params)",Return list of sections including students for the passed sis ID.,
"def get_quizzes(self, course_id):
        """"""
        List quizzes for a given course

        https://canvas.instructure.com/doc/api/quizzes.html#method.quizzes_api.index
        """"""
        url = QUIZZES_API.format(course_id)
        data = self._get_resource(url)
        quizzes = []
        for datum in data:
            quizzes.append(Quiz(data=datum))
        return quizzes","List quizzes for a given course

        https://canvas.instructure.com/doc/api/quizzes.html#method.quizzes_api.index",
"def get_account(self, account_id):
        """"""
        Return account resource for given canvas account id.

        https://canvas.instructure.com/doc/api/accounts.html#method.accounts.show
        """"""
        url = ACCOUNTS_API.format(account_id)
        return CanvasAccount(data=self._get_resource(url))","Return account resource for given canvas account id.

        https://canvas.instructure.com/doc/api/accounts.html#method.accounts.show",
"def update_account(self, account):
        """"""
        Update the passed account. Returns the updated account.

        https://canvas.instructure.com/doc/api/accounts.html#method.accounts.update
        """"""
        url = ACCOUNTS_API.format(account.account_id)
        body = {""account"": {""name"": account.name}}

        return CanvasAccount(data=self._put_resource(url, body))","Update the passed account. Returns the updated account.

        https://canvas.instructure.com/doc/api/accounts.html#method.accounts.update",
"def get_auth_settings(self, account_id):
        """"""
        Return the authentication settings for the passed account_id.

        https://canvas.instructure.com/doc/api/authentication_providers.html#method.account_authorization_configs.show_sso_settings
        """"""
        url = ACCOUNTS_API.format(account_id) + ""/sso_settings""
        return CanvasSSOSettings(data=self._get_resource(url))","Return the authentication settings for the passed account_id.

        https://canvas.instructure.com/doc/api/authentication_providers.html#method.account_authorization_configs.show_sso_settings",
"def get_term_by_sis_id(self, sis_term_id):
        """"""
        Return a term resource for the passed SIS ID.
        """"""
        for term in self.get_all_terms():
            if term.sis_term_id == sis_term_id:
                return term",Return a term resource for the passed SIS ID.,
"def log(out_str, o2="""", o3="""", o4=""""):
    """"""
    Produces console output.
    :param out_str: Output string
    :param o2: Additional output string
    :param o3: Additional output string
    :param o4: Additional output string
    :return: None
    """"""
    print(out_str, o2, o3, o4)","Produces console output.
    :param out_str: Output string
    :param o2: Additional output string
    :param o3: Additional output string
    :param o4: Additional output string
    :return: None",
"def create_course_provisioning_report(self, account_id, term_id=None,
                                          params={}):
        """"""
        Convenience method for create_report, for creating a course
        provisioning report.
        """"""
        params[""courses""] = True
        return self.create_report(ReportType.PROVISIONING, account_id, term_id,
                                  params)","Convenience method for create_report, for creating a course
        provisioning report.",
"def create_course_sis_export_report(self, account_id, term_id=None,
                                        params={}):
        """"""
        Convenience method for create_report, for creating a course sis export
        report.
        """"""
        params[""courses""] = True
        return self.create_report(ReportType.SIS_EXPORT, account_id, term_id,
                                  params)","Convenience method for create_report, for creating a course sis export
        report.",
"def create_unused_courses_report(self, account_id, term_id=None):
        """"""
        Convenience method for create_report, for creating an unused courses
        report.
        """"""
        return self.create_report(ReportType.UNUSED_COURSES, account_id,
                                  term_id)","Convenience method for create_report, for creating an unused courses
        report.",
"def delete_report(self, report):
        """"""
        Deletes a generated report instance.

        https://canvas.instructure.com/doc/api/account_reports.html#method.account_reports.destroy
        """"""
        url = ACCOUNTS_API.format(report.account_id) + ""/reports/{}/{}"".format(
            report.type, report.report_id)

        response = self._delete_resource(url)
        return True","Deletes a generated report instance.

        https://canvas.instructure.com/doc/api/account_reports.html#method.account_reports.destroy",
"def crop_image(img, start_y, start_x, h, w):
    """"""
    Crop an image given the top left corner.
    :param img: The image
    :param start_y: The top left corner y coord
    :param start_x: The top left corner x coord
    :param h: The result height
    :param w: The result width
    :return: The cropped image.
    """"""
    return img[start_y:start_y + h, start_x:start_x + w, :].copy()","Crop an image given the top left corner.
    :param img: The image
    :param start_y: The top left corner y coord
    :param start_x: The top left corner x coord
    :param h: The result height
    :param w: The result width
    :return: The cropped image.",
"def empty_value(self):
        '''
        Get the text to display when the field is empty.
        '''
        edit_empty_value = self.config.get('edit_empty_value', False)
        if edit_empty_value:
            return edit_empty_value
        else:
            return unicode(inplace_settings.INPLACEEDIT_EDIT_EMPTY_VALUE)",Get the text to display when the field is empty.,
"def do_eval(parser, token):
    ""Usage: {% eval %}1 + 1{% endeval %}""

    nodelist = parser.parse(('endeval',))

    class EvalNode(template.Node):
        def render(self, context):
            return template.Template(nodelist.render(context)).render(template.Context(context))
    parser.delete_first_token()
    return EvalNode()",Usage: {% eval %}1 + 1{% endeval %},
"def create_metrics(
            self, metric_configs: Iterable[MetricConfig]) -> Dict[str, Metric]:
        """"""Create and register metrics from a list of MetricConfigs.""""""
        return self.registry.create_metrics(metric_configs)",Create and register metrics from a list of MetricConfigs.,
"def _setup_logging(self, log_level: str):
        """"""Setup logging for the application and aiohttp.""""""
        level = getattr(logging, log_level)
        names = (
            'aiohttp.access', 'aiohttp.internal', 'aiohttp.server',
            'aiohttp.web', self.name)
        for name in names:
            setup_logger(name=name, stream=sys.stderr, level=level)",Setup logging for the application and aiohttp.,
"def _configure_registry(self, include_process_stats: bool = False):
        """"""Configure the MetricRegistry.""""""
        if include_process_stats:
            self.registry.register_additional_collector(
                ProcessCollector(registry=None))",Configure the MetricRegistry.,
"def create_metrics(self,
                       configs: Iterable[MetricConfig]) -> Dict[str, Metric]:
        """"""Create Prometheus metrics from a list of MetricConfigs.""""""
        metrics: Dict[str, Metric] = {
            config.name: self._register_metric(config)
            for config in configs
        }
        self._metrics.update(metrics)
        return metrics",Create Prometheus metrics from a list of MetricConfigs.,
"def get_metric(
            self, name: str,
            labels: Union[Dict[str, str], None] = None) -> Metric:
        """"""Return a metric, optionally configured with labels.""""""
        metric = self._metrics[name]
        if labels:
            return metric.labels(**labels)

        return metric","Return a metric, optionally configured with labels.",
"def run(self):
        """"""Run the :class:`aiohttp.web.Application` for the exporter.""""""
        run_app(
            self.app,
            host=self.host,
            port=self.port,
            print=lambda *args, **kargs: None,
            access_log_format='%a ""%r"" %s %b ""%{Referrer}i"" ""%{User-Agent}i""')",Run the :class:`aiohttp.web.Application` for the exporter.,
"def _make_application(self) -> Application:
        """"""Setup an :class:`aiohttp.web.Application`.""""""
        app = Application()
        app['exporter'] = self
        app.router.add_get('/', self._handle_home)
        app.router.add_get('/metrics', self._handle_metrics)
        app.on_startup.append(self._log_startup_message)
        return app",Setup an :class:`aiohttp.web.Application`.,
"async def _handle_metrics(self, request: Request) -> Response:
        """"""Handler for metrics.""""""
        if self._update_handler:
            await self._update_handler(self.registry.get_metrics())
        response = Response(body=self.registry.generate_metrics())
        response.content_type = CONTENT_TYPE_LATEST
        return response",Handler for metrics.,
"def wa(client, event, channel, nick, rest):
	""""""
	A free-text query resolver by Wolfram|Alpha. Returns the first
	result, if available.
	""""""
	client = wolframalpha.Client(pmxbot.config['Wolfram|Alpha API key'])
	res = client.query(rest)
	return next(res.results).text","A free-text query resolver by Wolfram|Alpha. Returns the first
	result, if available.",
"def fix_HTTPMessage():
	""""""
	Python 2 uses a deprecated method signature and doesn't provide the
	forward compatibility.
	Add it.
	""""""
	if six.PY3:
		return

	http_client.HTTPMessage.get_content_type = http_client.HTTPMessage.gettype
	http_client.HTTPMessage.get_param = http_client.HTTPMessage.getparam","Python 2 uses a deprecated method signature and doesn't provide the
	forward compatibility.
	Add it.",
"def info(self):
        """"""
        The pods, assumptions, and warnings of this result.
        """"""
        return itertools.chain(self.pods, self.assumptions, self.warnings)","The pods, assumptions, and warnings of this result.",
"def results(self):
        """"""
        The pods that hold the response to a simple, discrete query.
        """"""
        return (
            pod
            for pod in self.pods
            if pod.primary
            or pod.title == 'Result'
        )","The pods that hold the response to a simple, discrete query.",
"def queue(celery_arguments):
    """"""[]""""""

    if not app.celery:
        return click.echo(
            click.style('No celery config foundskip start...', fg='yellow'))

    celery = app.celery
    celery.autodiscover_tasks()

    argv = celery_arguments.split()
    argv.insert(0, 'worker')
    argv.insert(0, 'Queue')
    celery.worker_main(argv)
    pass",[],
"def smart_database(app):
    """"""""""""

    from sqlalchemy.engine.url import make_url
    from sqlalchemy_utils import database_exists, create_database

    # 
    dsn = make_url(app.config['SQLALCHEMY_DATABASE_URI'])
    if not database_exists(dsn):
        create_database(dsn)
        pass
    pass",,
"def random_str(length=16, only_digits=False):
    """"""
    
    :return:
    """"""

    choices = string.digits
    if not only_digits:
        choices += string.ascii_uppercase

    return ''.join(random.SystemRandom().choice(choices)
                   for _ in range(length))","
    :return:",
"def vector(members: Iterable[T], meta: Optional[IPersistentMap] = None) -> Vector[T]:
    """"""Creates a new vector.""""""
    return Vector(pvector(members), meta=meta)",Creates a new vector.,
"def v(*members: T, meta: Optional[IPersistentMap] = None) -> Vector[T]:
    """"""Creates a new vector from members.""""""
    return Vector(pvector(members), meta=meta)",Creates a new vector from members.,
"def eval_file(filename: str, ctx: compiler.CompilerContext, module: types.ModuleType):
    """"""Evaluate a file with the given name into a Python module AST node.""""""
    last = None
    for form in reader.read_file(filename, resolver=runtime.resolve_alias):
        last = compiler.compile_and_exec_form(form, ctx, module)
    return last",Evaluate a file with the given name into a Python module AST node.,
"def eval_stream(stream, ctx: compiler.CompilerContext, module: types.ModuleType):
    """"""Evaluate the forms in stdin into a Python module AST node.""""""
    last = None
    for form in reader.read(stream, resolver=runtime.resolve_alias):
        last = compiler.compile_and_exec_form(form, ctx, module)
    return last",Evaluate the forms in stdin into a Python module AST node.,
"def eval_str(s: str, ctx: compiler.CompilerContext, module: types.ModuleType, eof: Any):
    """"""Evaluate the forms in a string into a Python module AST node.""""""
    last = eof
    for form in reader.read_str(s, resolver=runtime.resolve_alias, eof=eof):
        last = compiler.compile_and_exec_form(form, ctx, module)
    return last",Evaluate the forms in a string into a Python module AST node.,
"def multifn(dispatch: DispatchFunction, default=None) -> MultiFunction[T]:
    """"""Decorator function which can be used to make Python multi functions.""""""
    name = sym.symbol(dispatch.__qualname__, ns=dispatch.__module__)
    return MultiFunction(name, dispatch, default)",Decorator function which can be used to make Python multi functions.,
"def __add_method(m: lmap.Map, key: T, method: Method) -> lmap.Map:
        """"""Swap the methods atom to include method with key.""""""
        return m.assoc(key, method)",Swap the methods atom to include method with key.,
"def add_method(self, key: T, method: Method) -> None:
        """"""Add a new method to this function which will respond for
        key returned from the dispatch function.""""""
        self._methods.swap(MultiFunction.__add_method, key, method)","Add a new method to this function which will respond for
        key returned from the dispatch function.",
"def __remove_method(m: lmap.Map, key: T) -> lmap.Map:
        """"""Swap the methods atom to remove method with key.""""""
        return m.dissoc(key)",Swap the methods atom to remove method with key.,
"def remove_method(self, key: T) -> Optional[Method]:
        """"""Remove the method defined for this key and return it.""""""
        method = self.methods.entry(key, None)
        if method:
            self._methods.swap(MultiFunction.__remove_method, key)
        return method",Remove the method defined for this key and return it.,
"def _is_async(o: IMeta) -> bool:
    """"""Return True if the meta contains :async keyword.""""""
    return (  # type: ignore
        Maybe(o.meta)
        .map(lambda m: m.entry(SYM_ASYNC_META_KEY, None))
        .or_else_get(False)
    )",Return True if the meta contains :async keyword.,
"def _is_macro(v: Var) -> bool:
    """"""Return True if the Var holds a macro function.""""""
    return (
        Maybe(v.meta)
        .map(lambda m: m.entry(SYM_MACRO_META_KEY, None))  # type: ignore
        .or_else_get(False)
    )",Return True if the Var holds a macro function.,
"def _clean_meta(meta: Optional[lmap.Map]) -> Optional[lmap.Map]:
    """"""Remove reader metadata from the form's meta map.""""""
    if meta is None:
        return None
    else:
        new_meta = meta.dissoc(reader.READER_LINE_KW, reader.READER_COL_KW)
        return None if len(new_meta) == 0 else new_meta",Remove reader metadata from the form's meta map.,
"def _assert_no_recur(node: Node) -> None:
    """"""Assert that `recur` forms do not appear in any position of this or
    child AST nodes.""""""
    if node.op == NodeOp.RECUR:
        raise ParserException(
            ""recur must appear in tail position"", form=node.form, lisp_ast=node
        )
    elif node.op in {NodeOp.FN, NodeOp.LOOP}:
        pass
    else:
        node.visit(_assert_no_recur)","Assert that `recur` forms do not appear in any position of this or
    child AST nodes.",
"def parse_ast(ctx: ParserContext, form: ReaderForm) -> Node:
    """"""Take a Lisp form as an argument and produce a Basilisp syntax
    tree matching the clojure.tools.analyzer AST spec.""""""
    return _parse_ast(ctx, form).assoc(top_level=True)","Take a Lisp form as an argument and produce a Basilisp syntax
    tree matching the clojure.tools.analyzer AST spec.",
"def warn_on_shadowed_var(self) -> bool:
        """"""If True, warn when a def'ed Var name is shadowed in an inner scope.

        Implied by warn_on_shadowed_name. The value of warn_on_shadowed_name
        supersedes the value of this flag.""""""
        return self.warn_on_shadowed_name or self._opts.entry(
            WARN_ON_SHADOWED_VAR, False
        )","If True, warn when a def'ed Var name is shadowed in an inner scope.

        Implied by warn_on_shadowed_name. The value of warn_on_shadowed_name
        supersedes the value of this flag.",
"def sequence(s: Iterable) -> ISeq[Any]:
    """"""Create a Sequence from Iterable s.""""""
    try:
        i = iter(s)
        return _Sequence(i, next(i))
    except StopIteration:
        return EMPTY",Create a Sequence from Iterable s.,
"def fraction(numerator: int, denominator: int) -> Fraction:
    """"""Create a Fraction from a numerator and denominator.""""""
    return Fraction(numerator=numerator, denominator=denominator)",Create a Fraction from a numerator and denominator.,
"def get_handler(level: str, fmt: str) -> logging.Handler:
    """"""Get the default logging handler for Basilisp.""""""
    handler: logging.Handler = logging.NullHandler()
    if os.getenv(""BASILISP_USE_DEV_LOGGER"") == ""true"":
        handler = logging.StreamHandler()

    handler.setFormatter(logging.Formatter(fmt))
    handler.setLevel(level)
    return handler",Get the default logging handler for Basilisp.,
"def map(kvs: Mapping[K, V], meta=None) -> Map[K, V]:  # pylint:disable=redefined-builtin
    """"""Creates a new map.""""""
    return Map(pmap(initial=kvs), meta=meta)",Creates a new map.,
"def timed(f: Optional[Callable[[int], None]] = None):
    """"""Time the execution of code in the with-block, calling the function
    f (if it is given) with the resulting time in nanoseconds.""""""
    start = time.perf_counter()
    yield
    end = time.perf_counter()
    if f:
        ns = int((end - start) * 1_000_000_000)
        f(ns)","Time the execution of code in the with-block, calling the function
    f (if it is given) with the resulting time in nanoseconds.",
"def partition(coll, n: int):
    """"""Partition coll into groups of size n.""""""
    assert n > 0
    start = 0
    stop = n
    while stop <= len(coll):
        yield tuple(e for e in coll[start:stop])
        start += n
        stop += n
    if start < len(coll) < stop:
        stop = len(coll)
        yield tuple(e for e in coll[start:stop])",Partition coll into groups of size n.,
"def _read_list(ctx: ReaderContext) -> llist.List:
    """"""Read a list element from the input stream.""""""
    start = ctx.reader.advance()
    assert start == ""(""
    return _read_coll(ctx, llist.list, "")"", ""list"")",Read a list element from the input stream.,
"def _read_vector(ctx: ReaderContext) -> vector.Vector:
    """"""Read a vector element from the input stream.""""""
    start = ctx.reader.advance()
    assert start == ""[""
    return _read_coll(ctx, vector.vector, ""]"", ""vector"")",Read a vector element from the input stream.,
"def _read_set(ctx: ReaderContext) -> lset.Set:
    """"""Return a set from the input stream.""""""
    start = ctx.reader.advance()
    assert start == ""{""

    def set_if_valid(s: Collection) -> lset.Set:
        if len(s) != len(set(s)):
            raise SyntaxError(""Duplicated values in set"")
        return lset.set(s)

    return _read_coll(ctx, set_if_valid, ""}"", ""set"")",Return a set from the input stream.,
"def _read_kw(ctx: ReaderContext) -> keyword.Keyword:
    """"""Return a keyword from the input stream.""""""
    start = ctx.reader.advance()
    assert start == "":""
    ns, name = _read_namespaced(ctx)
    if ""."" in name:
        raise SyntaxError(""Found '.' in keyword name"")
    return keyword.keyword(name, ns=ns)",Return a keyword from the input stream.,
"def _read_quoted(ctx: ReaderContext) -> llist.List:
    """"""Read a quoted form from the input stream.""""""
    start = ctx.reader.advance()
    assert start == ""'""
    next_form = _read_next_consuming_comment(ctx)
    return llist.l(_QUOTE, next_form)",Read a quoted form from the input stream.,
"def _read_syntax_quoted(ctx: ReaderContext) -> ReaderForm:
    """"""Read a syntax-quote and set the syntax-quoting state in the reader.""""""
    start = ctx.reader.advance()
    assert start == ""`""

    with ctx.syntax_quoted():
        return _process_syntax_quoted_form(ctx, _read_next_consuming_comment(ctx))",Read a syntax-quote and set the syntax-quoting state in the reader.,
"def _read_deref(ctx: ReaderContext) -> LispForm:
    """"""Read a derefed form from the input stream.""""""
    start = ctx.reader.advance()
    assert start == ""@""
    next_form = _read_next_consuming_comment(ctx)
    return llist.l(_DEREF, next_form)",Read a derefed form from the input stream.,
"def _read_regex(ctx: ReaderContext) -> Pattern:
    """"""Read a regex reader macro from the input stream.""""""
    s = _read_str(ctx, allow_arbitrary_escapes=True)
    try:
        return langutil.regex_from_str(s)
    except re.error:
        raise SyntaxError(f""Unrecognized regex pattern syntax: {s}"")",Read a regex reader macro from the input stream.,
"def _read_next_consuming_comment(ctx: ReaderContext) -> ReaderForm:
    """"""Read the next full form from the input stream, consuming any
    reader comments completely.""""""
    while True:
        v = _read_next(ctx)
        if v is ctx.eof:
            return ctx.eof
        if v is COMMENT or isinstance(v, Comment):
            continue
        return v","Read the next full form from the input stream, consuming any
    reader comments completely.",
"def pushback(self) -> None:
        """"""Push one character back onto the stream, allowing it to be
        read again.""""""
        if abs(self._idx - 1) > self._pushback_depth:
            raise IndexError(""Exceeded pushback depth"")
        self._idx -= 1","Push one character back onto the stream, allowing it to be
        read again.",
"def next_token(self) -> str:
        """"""Advance the stream forward by one character and return the
        next token in the stream.""""""
        if self._idx < StreamReader.DEFAULT_INDEX:
            self._idx += 1
        else:
            c = self._stream.read(1)
            self._update_loc(c)
            self._buffer.append(c)
        return self.peek()","Advance the stream forward by one character and return the
        next token in the stream.",
"def _basilisp_bytecode(
    mtime: int, source_size: int, code: List[types.CodeType]
) -> bytes:
    """"""Return the bytes for a Basilisp bytecode cache file.""""""
    data = bytearray(MAGIC_NUMBER)
    data.extend(_w_long(mtime))
    data.extend(_w_long(source_size))
    data.extend(marshal.dumps(code))  # type: ignore
    return data",Return the bytes for a Basilisp bytecode cache file.,
"def _cache_from_source(path: str) -> str:
    """"""Return the path to the cached file for the given path. The original path
    does not have to exist.""""""
    cache_path, cache_file = os.path.split(importlib.util.cache_from_source(path))
    filename, _ = os.path.splitext(cache_file)
    return os.path.join(cache_path, filename + "".lpyc"")","Return the path to the cached file for the given path. The original path
    does not have to exist.",
"def symbol(name: str, ns: Optional[str] = None, meta=None) -> Symbol:
    """"""Create a new symbol.""""""
    return Symbol(name, ns=ns, meta=meta)",Create a new symbol.,
"def __get_or_create(
    kw_cache: ""PMap[int, Keyword]"", h: int, name: str, ns: Optional[str]
) -> PMap:
    """"""Private swap function used to either get the interned keyword
    instance from the input string.""""""
    if h in kw_cache:
        return kw_cache
    kw = Keyword(name, ns=ns)
    return kw_cache.set(h, kw)","Private swap function used to either get the interned keyword
    instance from the input string.",
"def keyword(
    name: str,
    ns: Optional[str] = None,
    kw_cache: atom.Atom[""PMap[int, Keyword]""] = __INTERN,
) -> Keyword:
    """"""Create a new keyword.""""""
    h = hash((name, ns))
    return kw_cache.swap(__get_or_create, h, name, ns)[h]",Create a new keyword.,
"def _chain_py_ast(*genned: GeneratedPyAST,) -> Tuple[PyASTStream, PyASTStream]:
    """"""Chain a sequence of generated Python ASTs into a tuple of dependency nodes""""""
    deps = chain.from_iterable(map(lambda n: n.dependencies, genned))
    nodes = map(lambda n: n.node, genned)
    return deps, nodes",Chain a sequence of generated Python ASTs into a tuple of dependency nodes,
"def _simple_ast_generator(gen_ast):
    """"""Wrap simpler AST generators to return a GeneratedPyAST.""""""

    @wraps(gen_ast)
    def wrapped_ast_generator(ctx: GeneratorContext, form: LispForm) -> GeneratedPyAST:
        return GeneratedPyAST(node=gen_ast(ctx, form))

    return wrapped_ast_generator",Wrap simpler AST generators to return a GeneratedPyAST.,
"def _collection_ast(
    ctx: GeneratorContext, form: Iterable[Node]
) -> Tuple[PyASTStream, PyASTStream]:
    """"""Turn a collection of Lisp forms into Python AST nodes.""""""
    return _chain_py_ast(*map(partial(gen_py_ast, ctx), form))",Turn a collection of Lisp forms into Python AST nodes.,
"def _clean_meta(form: IMeta) -> LispForm:
    """"""Remove reader metadata from the form's meta map.""""""
    assert form.meta is not None, ""Form must have non-null 'meta' attribute""
    meta = form.meta.dissoc(reader.READER_LINE_KW, reader.READER_COL_KW)
    if len(meta) == 0:
        return None
    return cast(lmap.Map, meta)",Remove reader metadata from the form's meta map.,
"def _is_dynamic(v: Var) -> bool:
    """"""Return True if the Var holds a value which should be compiled to a dynamic
    Var access.""""""
    return (
        Maybe(v.meta)
        .map(lambda m: m.get(SYM_DYNAMIC_META_KEY, None))  # type: ignore
        .or_else_get(False)
    )","Return True if the Var holds a value which should be compiled to a dynamic
    Var access.",
"def _is_redefable(v: Var) -> bool:
    """"""Return True if the Var can be redefined.""""""
    return (
        Maybe(v.meta)
        .map(lambda m: m.get(SYM_REDEF_META_KEY, None))  # type: ignore
        .or_else_get(False)
    )",Return True if the Var can be redefined.,
"def __fn_name(s: Optional[str]) -> str:
    """"""Generate a safe Python function name from a function name symbol.
    If no symbol is provided, generate a name with a default prefix.""""""
    return genname(""__"" + munge(Maybe(s).or_else_get(_FN_PREFIX)))","Generate a safe Python function name from a function name symbol.
    If no symbol is provided, generate a name with a default prefix.",
"def _quote_to_py_ast(ctx: GeneratorContext, node: Quote) -> GeneratedPyAST:
    """"""Return a Python AST Node for a `quote` expression.""""""
    assert node.op == NodeOp.QUOTE
    return _const_node_to_py_ast(ctx, node.expr)",Return a Python AST Node for a `quote` expression.,
"def _maybe_class_to_py_ast(_: GeneratorContext, node: MaybeClass) -> GeneratedPyAST:
    """"""Generate a Python AST node for accessing a potential Python module
    variable name.""""""
    assert node.op == NodeOp.MAYBE_CLASS
    return GeneratedPyAST(
        node=ast.Name(
            id=Maybe(_MODULE_ALIASES.get(node.class_)).or_else_get(node.class_),
            ctx=ast.Load(),
        )
    )","Generate a Python AST node for accessing a potential Python module
    variable name.",
"def _from_module_import() -> ast.ImportFrom:
    """"""Generate the Python From ... Import AST node for importing
    language support modules.""""""
    return ast.ImportFrom(
        module=""basilisp.lang.runtime"",
        names=[ast.alias(name=""Var"", asname=_VAR_ALIAS)],
        level=0,
    )","Generate the Python From ... Import AST node for importing
    language support modules.",
"def py_module_preamble(ctx: GeneratorContext,) -> GeneratedPyAST:
    """"""Bootstrap a new module with imports and other boilerplate.""""""
    preamble: List[ast.AST] = []
    preamble.extend(_module_imports(ctx))
    preamble.append(_from_module_import())
    preamble.append(_ns_var())
    return GeneratedPyAST(node=ast.NameConstant(None), dependencies=preamble)",Bootstrap a new module with imports and other boilerplate.,
"def warn_on_var_indirection(self) -> bool:
        """"""If True, warn when a Var reference cannot be direct linked (iff
        use_var_indirection is False)..""""""
        return not self.use_var_indirection and self._opts.entry(
            WARN_ON_VAR_INDIRECTION, True
        )","If True, warn when a Var reference cannot be direct linked (iff
        use_var_indirection is False)..",
"def set(members: Iterable[T], meta=None) -> Set[T]:  # pylint:disable=redefined-builtin
    """"""Creates a new set.""""""
    return Set(pset(members), meta=meta)",Creates a new set.,
"def s(*members: T, meta=None) -> Set[T]:
    """"""Creates a new set from members.""""""
    return Set(pset(members), meta=meta)",Creates a new set from members.,
"def _new_module(name: str, doc=None) -> types.ModuleType:
    """"""Create a new empty Basilisp Python module.
    Modules are created for each Namespace when it is created.""""""
    mod = types.ModuleType(name, doc=doc)
    mod.__loader__ = None
    mod.__package__ = None
    mod.__spec__ = None
    mod.__basilisp_bootstrapped__ = False  # type: ignore
    return mod","Create a new empty Basilisp Python module.
    Modules are created for each Namespace when it is created.",
"def first(o):
    """"""If o is a ISeq, return the first element from o. If o is None, return
    None. Otherwise, coerces o to a Seq and returns the first.""""""
    if o is None:
        return None
    if isinstance(o, ISeq):
        return o.first
    s = to_seq(o)
    if s is None:
        return None
    return s.first","If o is a ISeq, return the first element from o. If o is None, return
    None. Otherwise, coerces o to a Seq and returns the first.",
"def nthrest(coll, i: int):
    """"""Returns the nth rest sequence of coll, or coll if i is 0.""""""
    while True:
        if coll is None:
            return None
        if i == 0:
            return coll
        i -= 1
        coll = rest(coll)","Returns the nth rest sequence of coll, or coll if i is 0.",
"def nthnext(coll, i: int) -> Optional[ISeq]:
    """"""Returns the nth next sequence of coll.""""""
    while True:
        if coll is None:
            return None
        if i == 0:
            return to_seq(coll)
        i -= 1
        coll = next_(coll)",Returns the nth next sequence of coll.,
"def to_seq(o) -> Optional[ISeq]:
    """"""Coerce the argument o to a ISeq. If o is None, return None.""""""
    if o is None:
        return None
    if isinstance(o, ISeq):
        return _seq_or_nil(o)
    if isinstance(o, ISeqable):
        return _seq_or_nil(o.seq())
    return _seq_or_nil(lseq.sequence(o))","Coerce the argument o to a ISeq. If o is None, return None.",
"def concat(*seqs) -> ISeq:
    """"""Concatenate the sequences given by seqs into a single ISeq.""""""
    allseqs = lseq.sequence(itertools.chain(*filter(None, map(to_seq, seqs))))
    if allseqs is None:
        return lseq.EMPTY
    return allseqs",Concatenate the sequences given by seqs into a single ISeq.,
"def assoc(m, *kvs):
    """"""Associate keys to values in associative data structure m. If m is None,
    returns a new Map with key-values kvs.""""""
    if m is None:
        return lmap.Map.empty().assoc(*kvs)
    if isinstance(m, IAssociative):
        return m.assoc(*kvs)
    raise TypeError(
        f""Object of type {type(m)} does not implement Associative interface""
    )","Associate keys to values in associative data structure m. If m is None,
    returns a new Map with key-values kvs.",
"def partial(f, *args):
    """"""Return a function which is the partial application of f with args.""""""

    @functools.wraps(f)
    def partial_f(*inner_args):
        return f(*itertools.chain(args, inner_args))

    return partial_f",Return a function which is the partial application of f with args.,
"def equals(v1, v2) -> bool:
    """"""Compare two objects by value. Unlike the standard Python equality operator,
    this function does not consider 1 == True or 0 == False. All other equality
    operations are the same and performed using Python's equality operator.""""""
    if isinstance(v1, (bool, type(None))) or isinstance(v2, (bool, type(None))):
        return v1 is v2
    return v1 == v2","Compare two objects by value. Unlike the standard Python equality operator,
    this function does not consider 1 == True or 0 == False. All other equality
    operations are the same and performed using Python's equality operator.",
"def divide(x: LispNumber, y: LispNumber) -> LispNumber:
    """"""Division reducer. If both arguments are integers, return a Fraction.
    Otherwise, return the true division of x and y.""""""
    if isinstance(x, int) and isinstance(y, int):
        return Fraction(x, y)
    return x / y","Division reducer. If both arguments are integers, return a Fraction.
    Otherwise, return the true division of x and y.",
"def sort(coll, f=None) -> Optional[ISeq]:
    """"""Return a sorted sequence of the elements in coll. If a comparator
    function f is provided, compare elements in coll using f.""""""
    return to_seq(sorted(coll, key=Maybe(f).map(functools.cmp_to_key).value))","Return a sorted sequence of the elements in coll. If a comparator
    function f is provided, compare elements in coll using f.",
"def contains(coll, k):
    """"""Return true if o contains the key k.""""""
    if isinstance(coll, IAssociative):
        return coll.contains(k)
    return k in coll",Return true if o contains the key k.,
"def get(m, k, default=None):
    """"""Return the value of k in m. Return default if k not found in m.""""""
    if isinstance(m, IAssociative):
        return m.entry(k, default=default)

    try:
        return m[k]
    except (KeyError, IndexError, TypeError) as e:
        logger.debug(""Ignored %s: %s"", type(e).__name__, e)
        return default",Return the value of k in m. Return default if k not found in m.,
"def to_lisp(o, keywordize_keys: bool = True):
    """"""Recursively convert Python collections into Lisp collections.""""""
    if not isinstance(o, (dict, frozenset, list, set, tuple)):
        return o
    else:  # pragma: no cover
        return _to_lisp_backup(o, keywordize_keys=keywordize_keys)",Recursively convert Python collections into Lisp collections.,
"def _collect_args(args) -> ISeq:
    """"""Collect Python starred arguments into a Basilisp list.""""""
    if isinstance(args, tuple):
        return llist.list(args)
    raise TypeError(""Python variadic arguments should always be a tuple"")",Collect Python starred arguments into a Basilisp list.,
"def _with_attrs(**kwargs):
    """"""Decorator to set attributes on a function. Returns the original
    function after setting the attributes named by the keyword arguments.""""""

    def decorator(f):
        for k, v in kwargs.items():
            setattr(f, k, v)
        return f

    return decorator","Decorator to set attributes on a function. Returns the original
    function after setting the attributes named by the keyword arguments.",
"def _basilisp_fn(f):
    """"""Create a Basilisp function, setting meta and supplying a with_meta
    method implementation.""""""
    assert not hasattr(f, ""meta"")
    f._basilisp_fn = True
    f.meta = None
    f.with_meta = partial(_fn_with_meta, f)
    return f","Create a Basilisp function, setting meta and supplying a with_meta
    method implementation.",
"def get_current_ns(
    ns_var_name: str = NS_VAR_NAME, ns_var_ns: str = NS_VAR_NS
) -> Namespace:
    """"""Get the value of the dynamic variable `*ns*` in the current thread.""""""
    ns_sym = sym.Symbol(ns_var_name, ns=ns_var_ns)
    ns: Namespace = Maybe(Var.find(ns_sym)).map(lambda v: v.value).or_else_raise(
        lambda: RuntimeException(f""Dynamic Var {ns_sym} not bound!"")
    )
    return ns",Get the value of the dynamic variable `*ns*` in the current thread.,
"def resolve_var(s: sym.Symbol, ns: Optional[Namespace] = None) -> Optional[Var]:
    """"""Resolve the aliased symbol to a Var from the specified
    namespace, or the current namespace if none is specified.""""""
    return Var.find(resolve_alias(s, ns))","Resolve the aliased symbol to a Var from the specified
    namespace, or the current namespace if none is specified.",
"def intern(
        ns: sym.Symbol, name: sym.Symbol, val, dynamic: bool = False, meta=None
    ) -> ""Var"":
        """"""Intern the value bound to the symbol `name` in namespace `ns`.""""""
        var_ns = Namespace.get_or_create(ns)
        var = var_ns.intern(name, Var(var_ns, name, dynamic=dynamic, meta=meta))
        var.root = val
        return var",Intern the value bound to the symbol `name` in namespace `ns`.,
"def intern_unbound(
        ns: sym.Symbol, name: sym.Symbol, dynamic: bool = False, meta=None
    ) -> ""Var"":
        """"""Create a new unbound `Var` instance to the symbol `name` in namespace `ns`.""""""
        var_ns = Namespace.get_or_create(ns)
        return var_ns.intern(name, Var(var_ns, name, dynamic=dynamic, meta=meta))",Create a new unbound `Var` instance to the symbol `name` in namespace `ns`.,
"def find_in_ns(ns_sym: sym.Symbol, name_sym: sym.Symbol) -> ""Optional[Var]"":
        """"""Return the value current bound to the name `name_sym` in the namespace
        specified by `ns_sym`.""""""
        ns = Namespace.get(ns_sym)
        if ns:
            return ns.find(name_sym)
        return None","Return the value current bound to the name `name_sym` in the namespace
        specified by `ns_sym`.",
"def add_default_import(cls, module: str):
        """"""Add a gated default import to the default imports.

        In particular, we need to avoid importing 'basilisp.core' before we have
        finished macro-expanding.""""""
        if module in cls.GATED_IMPORTS:
            cls.DEFAULT_IMPORTS.swap(lambda s: s.cons(sym.symbol(module)))","Add a gated default import to the default imports.

        In particular, we need to avoid importing 'basilisp.core' before we have
        finished macro-expanding.",
"def add_alias(self, alias: sym.Symbol, namespace: ""Namespace"") -> None:
        """"""Add a Symbol alias for the given Namespace.""""""
        self._aliases.swap(lambda m: m.assoc(alias, namespace))",Add a Symbol alias for the given Namespace.,
"def _intern(
        m: lmap.Map, sym: sym.Symbol, new_var: Var, force: bool = False
    ) -> lmap.Map:
        """"""Swap function used by intern to atomically intern a new variable in
        the symbol mapping for this Namespace.""""""
        var = m.entry(sym, None)
        if var is None or force:
            return m.assoc(sym, new_var)
        return m","Swap function used by intern to atomically intern a new variable in
        the symbol mapping for this Namespace.",
"def find(self, sym: sym.Symbol) -> Optional[Var]:
        """"""Find Vars mapped by the given Symbol input or None if no Vars are
        mapped by that Symbol.""""""
        v = self.interns.entry(sym, None)
        if v is None:
            return self.refers.entry(sym, None)
        return v","Find Vars mapped by the given Symbol input or None if no Vars are
        mapped by that Symbol.",
"def add_refer(self, sym: sym.Symbol, var: Var) -> None:
        """"""Refer var in this namespace under the name sym.""""""
        if not var.is_private:
            self._refers.swap(lambda s: s.assoc(sym, var))",Refer var in this namespace under the name sym.,
"def get_refer(self, sym: sym.Symbol) -> Optional[Var]:
        """"""Get the Var referred by Symbol or None if it does not exist.""""""
        return self.refers.entry(sym, None)",Get the Var referred by Symbol or None if it does not exist.,
"def refer_all(self, other_ns: ""Namespace""):
        """"""Refer all the Vars in the other namespace.""""""
        self._refers.swap(Namespace.__refer_all, other_ns.interns)",Refer all the Vars in the other namespace.,
"def get_or_create(
        cls, name: sym.Symbol, module: types.ModuleType = None
    ) -> ""Namespace"":
        """"""Get the namespace bound to the symbol `name` in the global namespace
        cache, creating it if it does not exist.
        Return the namespace.""""""
        return cls._NAMESPACES.swap(Namespace.__get_or_create, name, module=module)[
            name
        ]","Get the namespace bound to the symbol `name` in the global namespace
        cache, creating it if it does not exist.
        Return the namespace.",
"def get(cls, name: sym.Symbol) -> ""Optional[Namespace]"":
        """"""Get the namespace bound to the symbol `name` in the global namespace
        cache. Return the namespace if it exists or None otherwise..""""""
        return cls._NAMESPACES.deref().entry(name, None)","Get the namespace bound to the symbol `name` in the global namespace
        cache. Return the namespace if it exists or None otherwise..",
"def __completion_matcher(text: str) -> CompletionMatcher:
        """"""Return a function which matches any symbol keys from map entries
        against the given text.""""""

        def is_match(entry: Tuple[sym.Symbol, Any]) -> bool:
            return entry[0].name.startswith(text)

        return is_match","Return a function which matches any symbol keys from map entries
        against the given text.",
"def __complete_refers(self, value: str) -> Iterable[str]:
        """"""Return an iterable of possible completions matching the given
        prefix from the list of referred Vars.""""""
        return map(
            lambda entry: f""{entry[0].name}"",
            filter(
                Namespace.__completion_matcher(value), [(s, v) for s, v in self.refers]
            ),
        )","Return an iterable of possible completions matching the given
        prefix from the list of referred Vars.",
"def list(members, meta=None) -> List:  # pylint:disable=redefined-builtin
    """"""Creates a new list.""""""
    return List(  # pylint: disable=abstract-class-instantiated
        plist(iterable=members), meta=meta
    )",Creates a new list.,
"def l(*members, meta=None) -> List:
    """"""Creates a new list from members.""""""
    return List(  # pylint: disable=abstract-class-instantiated
        plist(iterable=members), meta=meta
    )",Creates a new list from members.,
"def change_style(style, representer):
    """"""
    This function is used to format the key value as a multi-line string maintaining the line breaks
    """"""

    def new_representer(dumper, data):
        scalar = representer(dumper, data)
        scalar.style = style
        return scalar

    return new_representer",This function is used to format the key value as a multi-line string maintaining the line breaks,
"def get_default_args(func):
    """"""
    returns a dictionary of arg_name:default_values for the input function
    """"""
    args, _, _, defaults, *rest = inspect.getfullargspec(func)
    return dict(zip(reversed(args), reversed(defaults)))",returns a dictionary of arg_name:default_values for the input function,
"def delete(self, *args):
        """"""Remove the key from the request cache and from memcache.""""""
        cache = get_cache()
        key = self.get_cache_key(*args)
        if key in cache:
            del cache[key]",Remove the key from the request cache and from memcache.,
"def get_dot_target_name(version=None, module=None):
  """"""Returns the current version/module in -dot- notation which is used by `target:` parameters.""""""
  version = version or get_current_version_name()
  module = module or get_current_module_name()
  return '-dot-'.join((version, module))",Returns the current version/module in -dot- notation which is used by `target:` parameters.,
"def _get_os_environ_dict(keys):
  """"""Return a dictionary of key/values from os.environ.""""""
  return {k: os.environ.get(k, _UNDEFINED) for k in keys}",Return a dictionary of key/values from os.environ.,
"def to_python(self):
        """"""Deconstruct the ``Constraint`` instance to a tuple.

        Returns:
            tuple: The deconstructed ``Constraint``.
        """"""
        return (
            self.selector,
            COMPARISON_MAP.get(self.comparison, self.comparison),
            self.argument
        )","Deconstruct the ``Constraint`` instance to a tuple.

        Returns:
            tuple: The deconstructed ``Constraint``.",
"async def connect(self):
        """"""Connect to LASAF through a CAM-socket.""""""
        self.reader, self.writer = await asyncio.open_connection(
            self.host, self.port, loop=self.loop)
        self.welcome_msg = await self.reader.read(self.buffer_size)",Connect to LASAF through a CAM-socket.,
"async def receive(self):
        """"""Receive message from socket interface as list of OrderedDict.""""""
        try:
            incomming = await self.reader.read(self.buffer_size)
        except OSError:
            return []

        return _parse_receive(incomming)",Receive message from socket interface as list of OrderedDict.,
"def close(self):
        """"""Close stream.""""""
        if self.writer.can_write_eof():
            self.writer.write_eof()
        self.writer.close()",Close stream.,
"def encode_model(obj):
  """"""Encode objects like ndb.Model which have a `.to_dict()` method.""""""
  obj_dict = obj.to_dict()
  for key, val in obj_dict.iteritems():
    if isinstance(val, types.StringType):
      try:
        unicode(val)
      except UnicodeDecodeError:
        # Encode binary strings (blobs) to base64.
        obj_dict[key] = base64.b64encode(val)
  return obj_dict",Encode objects like ndb.Model which have a `.to_dict()` method.,
"def dump(ndb_model, fp, **kwargs):
  """"""Custom json dump using the custom encoder above.""""""
  for chunk in NdbEncoder(**kwargs).iterencode(ndb_model):
    fp.write(chunk)",Custom json dump using the custom encoder above.,
"def object_hook_handler(self, val):
    """"""Handles decoding of nested date strings.""""""
    return {k: self.decode_date(v) for k, v in val.iteritems()}",Handles decoding of nested date strings.,
"def decode(self, val):
    """"""Override of the default decode method that also uses decode_date.""""""
    # First try the date decoder.
    new_val = self.decode_date(val)
    if val != new_val:
      return new_val
    # Fall back to the default decoder.
    return json.JSONDecoder.decode(self, val)",Override of the default decode method that also uses decode_date.,
"def run():
    """"""Run client.""""""
    cam = CAM()
    print(cam.welcome_msg)
    print(cam.send(b'/cmd:deletelist'))
    sleep(0.1)
    print(cam.receive())
    print(cam.send(b'/cmd:deletelist'))
    sleep(0.1)
    print(cam.wait_for(cmd='cmd', timeout=0.1))
    cam.close()",Run client.,
"def connect(self):
        """"""Connect to LASAF through a CAM-socket.""""""
        self.socket = socket.socket()
        self.socket.connect((self.host, self.port))
        self.socket.settimeout(False)  # non-blocking
        sleep(self.delay)  # wait for response
        self.welcome_msg = self.socket.recv(
            self.buffer_size)",Connect to LASAF through a CAM-socket.,
"def flush(self):
        """"""Flush incomming socket messages.""""""
        debug('flushing incomming socket messages')
        try:
            while True:
                msg = self.socket.recv(self.buffer_size)
                debug(b'< ' + msg)
        except socket.error:
            pass",Flush incomming socket messages.,
"def receive(self):
        """"""Receive message from socket interface as list of OrderedDict.""""""
        try:
            incomming = self.socket.recv(self.buffer_size)
        except socket.error:
            return []

        return _parse_receive(incomming)",Receive message from socket interface as list of OrderedDict.,
"def save_template(self, filename=""{ScanningTemplate}leicacam.xml""):
        """"""Save scanning template to filename.""""""
        cmd = [
            ('sys', '0'),
            ('cmd', 'save'),
            ('fil', str(filename))
        ]
        self.send(cmd)
        return self.wait_for(*cmd[0])",Save scanning template to filename.,
"def get_information(self, about='stage'):
        """"""Get information about given keyword. Defaults to stage.""""""
        cmd = [
            ('cmd', 'getinfo'),
            ('dev', str(about))
        ]
        self.send(cmd)
        return self.wait_for(*cmd[1])",Get information about given keyword. Defaults to stage.,
"def parse_package_json():
    """"""
    Extract the JSPM configuration from package.json.
    """"""
    with open(locate_package_json()) as pjson:
        data = json.loads(pjson.read())
    return data",Extract the JSPM configuration from package.json.,
"def log(self, msg, level=2):
        """"""
        Small log helper
        """"""
        if self.verbosity >= level:
            self.stdout.write(msg)",Small log helper,
"def chunkiter(iterable, chunksize):
    """"""break an iterable into chunks and yield those chunks as lists
    until there's nothing left to yeild.
    """"""
    iterator = iter(iterable)
    for chunk in iter(lambda: list(itertools.islice(iterator, chunksize)), []):
        yield chunk","break an iterable into chunks and yield those chunks as lists
    until there's nothing left to yeild.",
"def flatten(iterable, map2iter=None):
    """"""recursively flatten nested objects""""""
    if map2iter and isinstance(iterable):
        iterable = map2iter(iterable)

    for item in iterable:
        if isinstance(item, str) or not isinstance(item, abc.Iterable):
            yield item
        else:
            yield from flatten(item, map2iter)",recursively flatten nested objects,
"def quietinterrupt(msg=None):
    """"""add a handler for SIGINT that optionally prints a given message.
    For stopping scripts without having to see the stacktrace.
    """"""

    def handler():
        if msg:
            print(msg, file=sys.stderr)
        sys.exit(1)

    signal.signal(signal.SIGINT, handler)","add a handler for SIGINT that optionally prints a given message.
    For stopping scripts without having to see the stacktrace.",
"def printtsv(table, sep=""\t"", file=sys.stdout):
    """"""stupidly print an iterable of iterables in TSV format""""""
    for record in table:
        print(*record, sep=sep, file=file)",stupidly print an iterable of iterables in TSV format,
"def mkdummy(name, **attrs):
    """"""Make a placeholder object that uses its own name for its repr""""""
    return type(
        name, (), dict(__repr__=(lambda self: ""<%s>"" % name), **attrs)
    )()",Make a placeholder object that uses its own name for its repr,
"def pipe(value, *functions, funcs=None):
    """"""pipe(value, f, g, h) == h(g(f(value)))""""""
    if funcs:
        functions = funcs
    for function in functions:
        value = function(value)
    return value","pipe(value, f, g, h) == h(g(f(value)))",
"def pipeline(*functions, funcs=None):
    """"""like pipe, but curried:

        pipline(f, g, h)(*args, **kwargs) == h(g(f(*args, **kwargs)))
    """"""
    if funcs:
        functions = funcs
    head, *tail = functions
    return lambda *args, **kwargs: pipe(head(*args, **kwargs), funcs=tail)","like pipe, but curried:

        pipline(f, g, h)(*args, **kwargs) == h(g(f(*args, **kwargs)))",
"def trace_module(no_print=True):
    """"""Trace eng wave module exceptions.""""""
    mname = ""wave_core""
    fname = ""peng""
    module_prefix = ""peng.{0}.Waveform."".format(mname)
    callable_names = (""__init__"",)
    return docs.support.trace_support.run_trace(
        mname, fname, module_prefix, callable_names, no_print
    )",Trace eng wave module exceptions.,
"def make_common_entry(plist, pyver, suffix, req_ver):
    """"""Generate Python interpreter version entries for 2.x or 3.x series.""""""
    prefix = ""Python {pyver}.x{suffix}"".format(pyver=pyver, suffix=suffix)
    plist.append(""{prefix}{ver}"".format(prefix=prefix, ver=ops_to_words(req_ver)))",Generate Python interpreter version entries for 2.x or 3.x series.,
"def make_multi_entry(plist, pkg_pyvers, ver_dict):
    """"""Generate Python interpreter version entries.""""""
    for pyver in pkg_pyvers:
        pver = pyver[2] + ""."" + pyver[3:]
        plist.append(""Python {0}: {1}"".format(pver, ops_to_words(ver_dict[pyver])))",Generate Python interpreter version entries.,
"def _chunk_noise(noise):
    """"""Chunk input noise data into valid Touchstone file rows.""""""
    data = zip(
        noise[""freq""],
        noise[""nf""],
        np.abs(noise[""rc""]),
        np.angle(noise[""rc""]),
        noise[""res""],
    )
    for freq, nf, rcmag, rcangle, res in data:
        yield freq, nf, rcmag, rcangle, res",Chunk input noise data into valid Touchstone file rows.,
"def _operation(wave, desc, units, fpointer):
    """"""Perform generic operation on a waveform object.""""""
    ret = copy.copy(wave)
    ret.dep_units = units
    ret.dep_name = ""{0}({1})"".format(desc, ret.dep_name)
    ret._dep_vector = fpointer(ret._dep_vector)
    return ret",Perform generic operation on a waveform object.,
"def _next_rdelim(items, pos):
    """"""Return position of next matching closing delimiter.""""""
    for num, item in enumerate(items):
        if item > pos:
            break
    else:
        raise RuntimeError(""Mismatched delimiters"")
    del items[num]
    return item",Return position of next matching closing delimiter.,
"def _pair_delims(expr, ldelim=""("", rdelim="")""):
    """"""Pair delimiters.""""""
    # Find where remaining delimiters are
    lindex = reversed([num for num, item in enumerate(expr) if item == ldelim])
    rindex = [num for num, item in enumerate(expr) if item == rdelim]
    # Pair remaining delimiters
    return [(lpos, _next_rdelim(rindex, lpos)) for lpos in lindex][::-1]",Pair delimiters.,
"def get_paths(self):
        """"""
        Return a tuple with the absolute path and relative path (relative to STATIC_URL)
        """"""
        outfile = self.get_outfile()
        rel_path = os.path.relpath(outfile, settings.STATIC_ROOT)
        return outfile, rel_path",Return a tuple with the absolute path and relative path (relative to STATIC_URL),
"def needs_ext(self):
        """"""
        Check whether `self.app` is missing the '.js' extension and if it needs it.
        """"""
        if settings.SYSTEMJS_DEFAULT_JS_EXTENSIONS:
            name, ext = posixpath.splitext(self.app)
            if not ext:
                return True
        return False",Check whether `self.app` is missing the '.js' extension and if it needs it.,
"def hashes_match(self, dep_tree):
        """"""
        Compares the app deptree file hashes with the hashes stored in the
        cache.
        """"""
        hashes = self.get_hashes()
        for module, info in dep_tree.items():
            md5 = self.get_hash(info['path'])
            if md5 != hashes[info['path']]:
                return False
        return True","Compares the app deptree file hashes with the hashes stored in the
        cache.",
"def valid_identifiers(self):
        """"""Get a list of all valid identifiers for the current context.

        Returns:
            list(str): A list of all of the valid identifiers for this context
        """"""

        funcs = list(utils.find_all(self.contexts[-1])) + list(self.builtins)
        return funcs","Get a list of all valid identifiers for the current context.

        Returns:
            list(str): A list of all of the valid identifiers for this context",
"def _split_line(self, line):
        """"""Split a line into arguments using shlex and a dequoting routine.""""""

        parts = shlex.split(line, posix=self.posix_lex)
        if not self.posix_lex:
            parts = [self._remove_quotes(x) for x in parts]

        return parts",Split a line into arguments using shlex and a dequoting routine.,
"def get_type_size(self, type):
        """"""
        Get the size of this type for converting a hex string to the
        type. Return 0 if the size is not known.
        """"""

        typeobj = self.get_type(type)

        if hasattr(typeobj, 'size'):
            return typeobj.size()

        return 0","Get the size of this type for converting a hex string to the
        type. Return 0 if the size is not known.",
"def is_known_type(self, type_name):
        """"""Check if type is known to the type system.

        Returns:
            bool: True if the type is a known instantiated simple type, False otherwise
        """"""

        type_name = str(type_name)
        if type_name in self.known_types:
            return True

        return False","Check if type is known to the type system.

        Returns:
            bool: True if the type is a known instantiated simple type, False otherwise",
"def is_known_format(self, type, format):
        """"""
        Check if format is known for given type.

        Returns boolean indicating if format is valid for the specified type.
        """"""

        typeobj = self.get_type(type)

        formatter = ""format_%s"" % str(format)
        if not hasattr(typeobj, formatter):
            return False

        return True","Check if format is known for given type.

        Returns boolean indicating if format is valid for the specified type.",
"def custom_returnvalue(self, printer, desc=None):
        """"""Use a custom function to print the return value.

        Args:
            printer (callable): A function that should take in the return
                value and convert it to a string.
            desc (str): An optional description of the return value.
        """"""
        self.return_info = ReturnInfo(None, printer, True, desc)","Use a custom function to print the return value.

        Args:
            printer (callable): A function that should take in the return
                value and convert it to a string.
            desc (str): An optional description of the return value.",
"def to_dict(self):
        """"""Convert this exception to a dictionary.

        Returns:
            dist: A dictionary of information about this exception,
                Has a 'reason' key, a 'type' key  and a dictionary of params
        """"""

        out = {}
        out['reason'] = self.msg
        out['type'] = self.__class__.__name__
        out['params'] = self.params

        return out","Convert this exception to a dictionary.

        Returns:
            dist: A dictionary of information about this exception,
                Has a 'reason' key, a 'type' key  and a dictionary of params",
"def short_description(func):
    """"""
    Given an object with a docstring, return the first line of the docstring
    """"""

    doc = inspect.getdoc(func)
    if doc is not None:
        doc = inspect.cleandoc(doc)
        lines = doc.splitlines()
        return lines[0]

    return """"","Given an object with a docstring, return the first line of the docstring",
"def install():
    """"""
    Register tasks with cron.
    """"""
    load()
    tab = crontab.CronTab(user=True)
    for task in registry:
        tab.new(task.command, KRONOS_BREADCRUMB).setall(task.schedule)
    tab.write()
    return len(registry)",Register tasks with cron.,
"def printtasks():
    """"""
    Print the tasks that would be installed in the
    crontab, for debugging purposes.
    """"""
    load()

    tab = crontab.CronTab('')
    for task in registry:
        tab.new(task.command, KRONOS_BREADCRUMB).setall(task.schedule)
    print(tab.render())","Print the tasks that would be installed in the
    crontab, for debugging purposes.",
"def uninstall():
    """"""
    Uninstall tasks from cron.
    """"""
    tab = crontab.CronTab(user=True)
    count = len(list(tab.find_comment(KRONOS_BREADCRUMB)))
    tab.remove_all(comment=KRONOS_BREADCRUMB)
    tab.write()
    return count",Uninstall tasks from cron.,
"def set(self, newvalue):
        # type: (B) -> Callable[[S], T]
        '''Set the focus to `newvalue`.

            >>> from lenses import lens
            >>> set_item_one_to_four = lens[1].set(4)
            >>> set_item_one_to_four([1, 2, 3])
            [1, 4, 3]
        '''

        def setter(state):
            return self._optic.set(state, newvalue)

        return setter","Set the focus to `newvalue`.

            >>> from lenses import lens
            >>> set_item_one_to_four = lens[1].set(4)
            >>> set_item_one_to_four([1, 2, 3])
            [1, 4, 3]",
"def func(self, f, state):
        '''Intended to be overridden by subclasses. Raises
        NotImplementedError.'''
        message = 'Tried to use unimplemented lens {}.'
        raise NotImplementedError(message.format(type(self)))","Intended to be overridden by subclasses. Raises
        NotImplementedError.",
"def kind(self):
        '''Returns a class representing the 'kind' of optic.'''
        optics = [
            Equality,
            Isomorphism,
            Prism,
            Review,
            Lens,
            Traversal,
            Getter,
            Setter,
            Fold,
        ]
        for optic in optics:
            if self._is_kind(optic):
                return optic",Returns a class representing the 'kind' of optic.,
"def step_towards(self, other):
        '''returns the vector moved one step in the direction of the
        other, potentially diagonally.'''

        return self + Vector(
            (
                (self[0] < other[0]) - (self[0] > other[0]),
                (self[1] < other[1]) - (self[1] > other[1]),
            )
        )","returns the vector moved one step in the direction of the
        other, potentially diagonally.",
"def end_game(self, message=''):
        '''Returns a completed game state object, setting an optional
        message to display after the game is over.'''

        return lens.running.set(False)(lens.message.set(message)(self))","Returns a completed game state object, setting an optional
        message to display after the game is over.",
"def player_move(board):
    '''Shows the board to the player on the console and asks them to
    make a move.'''
    print(board, end='\n\n')
    x, y = input('Enter move (e.g. 2b): ')
    print()
    return int(x) - 1, ord(y) - ord('a')","Shows the board to the player on the console and asks them to
    make a move.",
"def play():
    'Play a game of naughts and crosses against the computer.'
    ai = {'X': player_move, 'O': random_move}
    board = Board()
    while not board.winner:
        x, y = ai[board.player](board)
        board = board.make_move(x, y)
    print(board, end='\n\n')
    print(board.winner)",Play a game of naughts and crosses against the computer.,
"def make_move(self, x, y):
        '''Return a board with a cell filled in by the current player. If
        the cell is already occupied then return the board unchanged.'''
        if self.board[y][x] == ' ':
            return lens.board[y][x].set(self.player)(self)
        return self","Return a board with a cell filled in by the current player. If
        the cell is already occupied then return the board unchanged.",
"def _potential_wins(self):
        '''Generates all the combinations of board positions that need
        to be checked for a win.'''
        yield from self.board
        yield from zip(*self.board)
        yield self.board[0][0], self.board[1][1], self.board[2][2]
        yield self.board[0][2], self.board[1][1], self.board[2][0]","Generates all the combinations of board positions that need
        to be checked for a win.",
"def process_item(self, item, spider):
        """"""
        Process single item. Add item to items and then upload to S3 if size of items
        >= max_chunk_size.
        """"""
        self.items.append(item)
        if len(self.items) >= self.max_chunk_size:
            self._upload_chunk(spider)

        return item","Process single item. Add item to items and then upload to S3 if size of items
        >= max_chunk_size.",
"def open_spider(self, spider):
        """"""
        Callback function when spider is open.
        """"""
        # Store timestamp to replace {time} in S3PIPELINE_URL
        self.ts = datetime.utcnow().replace(microsecond=0).isoformat().replace(':', '-')",Callback function when spider is open.,
"def send_raw_transaction(self, hextx, **kwargs):
        """""" Broadcasts a transaction over the NEO network and returns the result.

        :param hextx: hexadecimal string that has been serialized
        :type hextx: str
        :return: result of the transaction
        :rtype: bool

        """"""
        return self._call(JSONRPCMethods.SEND_RAW_TRANSACTION.value, [hextx, ], **kwargs)","Broadcasts a transaction over the NEO network and returns the result.

        :param hextx: hexadecimal string that has been serialized
        :type hextx: str
        :return: result of the transaction
        :rtype: bool",
"def validate_address(self, addr, **kwargs):
        """""" Validates if the considered string is a valid NEO address.

        :param hex: string containing a potential NEO address
        :type hex: str
        :return: dictionary containing the result of the verification
        :rtype: dictionary

        """"""
        return self._call(JSONRPCMethods.VALIDATE_ADDRESS.value, [addr, ], **kwargs)","Validates if the considered string is a valid NEO address.

        :param hex: string containing a potential NEO address
        :type hex: str
        :return: dictionary containing the result of the verification
        :rtype: dictionary",
"def is_hash256(s):
    """""" Returns True if the considered string is a valid SHA256 hash. """"""
    if not s or not isinstance(s, str):
        return False
    return re.match('^[0-9A-F]{64}$', s.strip(), re.IGNORECASE)",Returns True if the considered string is a valid SHA256 hash.,
"def is_hash160(s):
    """""" Returns True if the considered string is a valid RIPEMD160 hash. """"""
    if not s or not isinstance(s, str):
        return False
    if not len(s) == 40:
        return False
    for c in s:
        if (c < '0' or c > '9') and (c < 'A' or c > 'F') and (c < 'a' or c > 'f'):
            return False
    return True",Returns True if the considered string is a valid RIPEMD160 hash.,
"def decode_invocation_result(result):
    """""" Tries to decode the values embedded in an invocation result dictionary. """"""
    if 'stack' not in result:
        return result
    result = copy.deepcopy(result)
    result['stack'] = _decode_invocation_result_stack(result['stack'])
    return result",Tries to decode the values embedded in an invocation result dictionary.,
"def calculate_checksum(self):
        """"""Calculates the checksum for EAN13-Code.

        :returns: The checksum for `self.ean`.
        :rtype: Integer
        """"""
        def sum_(x, y):
            return int(x) + int(y)

        evensum = reduce(sum_, self.ean[::2])
        oddsum = reduce(sum_, self.ean[1::2])
        return (10 - ((evensum + oddsum * 3) % 10)) % 10","Calculates the checksum for EAN13-Code.

        :returns: The checksum for `self.ean`.
        :rtype: Integer",
"def to_df(self, **kwargs):
        """"""[pandas.read_sql]
        
        Arguments:
            Query {[type]} -- [description]
        
        Returns:
            [pd.DataFrame or generate] -- [description]
        """"""

        return pd.read_sql(sql=self.statement, con=self.session.bind, **kwargs)","[pandas.read_sql]
        
        Arguments:
            Query {[type]} -- [description]
        
        Returns:
            [pd.DataFrame or generate] -- [description]",
"def connect(cls, settings):
        """""" Call that method in the pyramid configuration phase.
        """"""
        server = serializer('json').loads(settings['kvs.perlsess'])
        server.setdefault('key_prefix', 'perlsess::')
        server.setdefault('codec', 'storable')
        cls.cookie_name = server.pop('cookie_name', 'session_id')
        cls.client = KVS(**server)",Call that method in the pyramid configuration phase.,
"def update(self, t_obj):
        """"""[update table]

        Arguments:
            t_obj {[objs of DeclarativeMeta]} -- [update the table]
        """"""

        if isinstance(t_obj, Iterable):
            self._session.add_all(t_obj)
        else:
            self._session.add(t_obj)","[update table]

        Arguments:
            t_obj {[objs of DeclarativeMeta]} -- [update the table]",
"def basic(username, password):
    """"""Add basic authentication to the requests of the clients.""""""
    none()
    _config.username = username
    _config.password = password",Add basic authentication to the requests of the clients.,
"def api_key(api_key):
    """"""Authenticate via an api key.""""""
    none()
    _config.api_key_prefix[""Authorization""] = ""api-key""
    _config.api_key[""Authorization""] = ""key="" + b64encode(api_key.encode()).decode()",Authenticate via an api key.,
"def get_schemas():
    """"""Return a dict of schema names mapping to a Schema.

    The schema is of type schul_cloud_resources_api_v1.schema.Schema
    """"""
    schemas = {}
    for name in os.listdir(JSON_PATH):
        if name not in NO_SCHEMA:
            schemas[name] = Schema(name)
    return schemas","Return a dict of schema names mapping to a Schema.

    The schema is of type schul_cloud_resources_api_v1.schema.Schema",
"def get_schema(self):
        """"""Return the schema.""""""
        path = os.path.join(self._get_schema_folder(), self._name + "".json"")
        with open(path, ""rb"") as file:
            schema = json.loads(file.read().decode(""UTF-8""))
        return schema",Return the schema.,
"def get_resolver(self):
        """"""Return a jsonschema.RefResolver for the schemas.

        All schemas returned be get_schemas() are resolved locally.
        """"""
        store = {}
        for schema in get_schemas().values():
            store[schema.get_uri()] = schema.get_schema()
        schema = self.get_schema()
        return jsonschema.RefResolver.from_schema(schema, store=store)","Return a jsonschema.RefResolver for the schemas.

        All schemas returned be get_schemas() are resolved locally.",
"def validate(self, object):
        """"""Validate an object against the schema.

        This function just passes if the schema matches the object.
        If the object does not match the schema, a ValidationException is raised.
        This error allows debugging.
        """"""
        resolver=self.get_resolver()
        jsonschema.validate(object, self.get_schema(), resolver=resolver)","Validate an object against the schema.

        This function just passes if the schema matches the object.
        If the object does not match the schema, a ValidationException is raised.
        This error allows debugging.",
"def get_valid_examples(self):
        """"""Return a list of valid examples for the given schema.""""""
        path = os.path.join(self._get_schema_folder(), ""examples"", ""valid"")
        return list(_get_json_content_from_folder(path))",Return a list of valid examples for the given schema.,
"def get_invalid_examples(self):
        """"""Return a list of examples which violate the schema.""""""
        path = os.path.join(self._get_schema_folder(), ""examples"", ""invalid"")
        return list(_get_json_content_from_folder(path))",Return a list of examples which violate the schema.,
"def auth_user_get_url(self, scope=None):
		'Build authorization URL for User Agent.'
		if not self.client_id: raise AuthMissingError('No client_id specified')
		return '{}?{}'.format(self.auth_url_user, urllib.urlencode(dict(
			client_id=self.client_id, scope=' '.join(scope or self.auth_scope),
			response_type='code', redirect_uri=self.auth_redirect_uri )))",Build authorization URL for User Agent.,
"def auth_get_token(self, check_scope=True):
		'Refresh or acquire access_token.'
		res = self.auth_access_data_raw = self._auth_token_request()
		return self._auth_token_process(res, check_scope=check_scope)",Refresh or acquire access_token.,
"def get_user_id(self):
		'Returns ""id"" of a OneDrive user.'
		if self._user_id is None:
			self._user_id = self.get_user_data()['id']
		return self._user_id","Returns ""id"" of a OneDrive user.",
"def listdir(self, folder_id='me/skydrive', limit=None, offset=None):
		'Get OneDrive object representing list of objects in a folder.'
		return self(self._api_url_join(folder_id, 'files'), dict(limit=limit, offset=offset))",Get OneDrive object representing list of objects in a folder.,
"def mkdir(self, name=None, folder_id='me/skydrive', metadata=dict()):
		'''Create a folder with a specified ""name"" attribute.
				folder_id allows to specify a parent folder.
				metadata mapping may contain additional folder properties to pass to an API.'''
		metadata = metadata.copy()
		if name: metadata['name'] = name
		return self(folder_id, data=metadata, method='post', auth_header=True)","Create a folder with a specified ""name"" attribute.
				folder_id allows to specify a parent folder.
				metadata mapping may contain additional folder properties to pass to an API.",
"def info_update(self, obj_id, data):
		'''Update metadata with of a specified object.
			See http://msdn.microsoft.com/en-us/library/live/hh243648.aspx
				for the list of RW keys for each object type.'''
		return self(obj_id, method='put', data=data, auth_header=True)","Update metadata with of a specified object.
			See http://msdn.microsoft.com/en-us/library/live/hh243648.aspx
				for the list of RW keys for each object type.",
"def copy(self, obj_id, folder_id, move=False):
		'''Copy specified file (object) to a folder with a given ID.
				Well-known folder names (like ""me/skydrive"")
				don't seem to work here.
			Folders cannot be copied; this is an API limitation.'''
		return self( obj_id,
			method='copy' if not move else 'move',
			data=dict(destination=folder_id), auth_header=True )","Copy specified file (object) to a folder with a given ID.
				Well-known folder names (like ""me/skydrive"")
				don't seem to work here.
			Folders cannot be copied; this is an API limitation.",
"def move(self, obj_id, folder_id):
		'''Move specified file (object) to a folder.
			Note that folders cannot be moved, this is an API limitation.'''
		return self.copy(obj_id, folder_id, move=True)","Move specified file (object) to a folder.
			Note that folders cannot be moved, this is an API limitation.",
"def comment_add(self, obj_id, message):
		'Add comment message to a specified object.'
		return self( self._api_url_join(obj_id, 'comments'),
			method='post', data=dict(message=message), auth_header=True )",Add comment message to a specified object.,
"def set_drop_target(obj, root, designer, inspector):
    ""Recursively create and set the drop target for obj and childs""
    if obj._meta.container:
        dt = ToolBoxDropTarget(obj, root, designer=designer, 
                                          inspector=inspector)
        obj.drop_target = dt
    for child in obj:
        set_drop_target(child, root, designer, inspector)",Recursively create and set the drop target for obj and childs,
"def set_default_tlw(self, tlw, designer, inspector):
        ""track default top level window for toolbox menu default action""
        self.designer = designer
        self.inspector = inspector",track default top level window for toolbox menu default action,
"def copy(self):
        ""Return a copy of the drop target (to avoid wx problems on rebuild)""
        return ToolBoxDropTarget(self.dv, self.root, 
                                 self.designer, self.inspector)",Return a copy of the drop target (to avoid wx problems on rebuild),
"def inspect(obj):
    ""Open the inspector windows for a given object""
    from gui.tools.inspector import InspectorTool
    inspector = InspectorTool()
    inspector.show(obj)
    return inspector",Open the inspector windows for a given object,
"def shell():
    ""Open a shell""
    from gui.tools.debug import Shell    
    shell = Shell()
    shell.show()
    return shell",Open a shell,
"def migrate_font(font):
    ""Convert PythonCard font description to gui2py style""
    if 'faceName' in font:
        font['face'] = font.pop('faceName')
    if 'family' in font and font['family'] == 'sansSerif':
        font['family'] = 'sans serif'
    return font",Convert PythonCard font description to gui2py style,
"def load_page(self, location):
        ""Loads HTML page from location and then displays it""
        if not location:
            self.wx_obj.SetPage("""")
        else:
            self.wx_obj.LoadPage(location)",Loads HTML page from location and then displays it,
"def GetParam(tag, param, default=__SENTINEL):
    """""" Convenience function for accessing tag parameters""""""
    if tag.HasParam(param):
        return tag.GetParam(param)
    else:
        if default == __SENTINEL:
            raise KeyError
        else:
            return default",Convenience function for accessing tag parameters,
"def send(evt):
    ""Process an outgoing communication""
    # get the text written by the user (input textbox control)
    msg = ctrl_input.value
    # send the message (replace with socket/queue/etc.)
    gui.alert(msg, ""Message"")
    # record the message (update the UI)
    log(msg)
    ctrl_input.value = """"
    ctrl_input.set_focus()",Process an outgoing communication,
"def delete(self, event):
        ""delete all of the selected objects""
        # get the selected objects (if any)
        for obj in self.selection:
            if obj:
                if DEBUG: print ""deleting"", obj.name
                obj.destroy()
        self.selection = []                         # clean selection
        self.inspector.load_object()",delete all of the selected objects,
"def update(self):
        ""Adjust facade with the dimensions of the original object (and repaint)""
        x, y = self.obj.wx_obj.GetPosition()
        w, h = self.obj.wx_obj.GetSize()
        self.Hide()
        self.Move((x, y))
        self.SetSize((w, h))
        # allow original control to repaint before taking the new snapshot image:
        wx.CallLater(200, self.refresh)",Adjust facade with the dimensions of the original object (and repaint),
"def refresh(self):
        ""Capture the new control superficial image after an update""
        self.bmp = self.obj.snapshot()
        # change z-order to overlap controls (windows) and show the image:
        self.Raise()
        self.Show()
        self.Refresh()",Capture the new control superficial image after an update,
"def GetPyData(self, item):
        ""Returns the pyth item data associated with the item""
        wx_data = self.GetItemData(item)
        py_data = self._py_data_map.get(wx_data)
        return py_data",Returns the pyth item data associated with the item,
"def DeleteItem(self, item):
        ""Remove the item from the list and unset the related data""
        wx_data = self.GetItemData(item)
        py_data = self._py_data_map[wx_data]
        del self._py_data_map[wx_data]
        del self._wx_data_map[py_data]
        wx.ListCtrl.DeleteItem(self, item)",Remove the item from the list and unset the related data,
"def DeleteAllItems(self):
        ""Remove all the item from the list and unset the related data""
        self._py_data_map.clear()
        self._wx_data_map.clear()
        wx.ListCtrl.DeleteAllItems(self)",Remove all the item from the list and unset the related data,
"def set_count(self, value):
        ""Set item (row) count -useful only in virtual mode-""
        if self.view == ""report"" and self.virtual and value is not None:
            self.wx_obj.SetItemCount(value)",Set item (row) count -useful only in virtual mode-,
"def delete(self, a_position):
        ""Deletes the item at the zero-based index 'n' from the control.""
        key = self.wx_obj.GetPyData(a_position)
        del self._items[key]",Deletes the item at the zero-based index 'n' from the control.,
"def clear_all(self):
        ""Remove all items and column headings""
        self.clear()
        for ch in reversed(self.columns):
            del self[ch.name]",Remove all items and column headings,
"def clear(self):
        ""Remove all items and reset internal structures""
        dict.clear(self)
        self._key = 0
        if hasattr(self._list_view, ""wx_obj""):
            self._list_view.wx_obj.DeleteAllItems()",Remove all items and reset internal structures,
"def _get_selection(self):
        ""Returns the index of the selected item (list for multiselect) or None""
        if self.multiselect:
            return self.wx_obj.GetSelections()
        else:
            sel = self.wx_obj.GetSelection()
            if sel == wx.NOT_FOUND:
                return None
            else:
                return sel",Returns the index of the selected item (list for multiselect) or None,
"def _get_string_selection(self):
        ""Returns the label of the selected item or an empty string if none""
        if self.multiselect:
            return [self.wx_obj.GetString(i) for i in 
                    self.wx_obj.GetSelections()]
        else:
            return self.wx_obj.GetStringSelection()",Returns the label of the selected item or an empty string if none,
"def set_data(self, n, data):
        ""Associate the given client data with the item at position n.""
        self.wx_obj.SetClientData(n, data)
        # reverse association:
        self._items_dict[data] = self.get_string(n)",Associate the given client data with the item at position n.,
"def append(self, a_string, data=None):
        ""Adds the item to the control, associating the given data if not None.""
        self.wx_obj.Append(a_string, data)
        # reverse association:
        self._items_dict[data] = a_string","Adds the item to the control, associating the given data if not None.",
"def delete(self, a_position):
        ""Deletes the item at the zero-based index 'n' from the control.""
        self.wx_obj.Delete(a_position)
        data = self.get_data()
        if data in self._items_dict:
            del self._items_dict[data]",Deletes the item at the zero-based index 'n' from the control.,
"def set_parent(self, new_parent, init=False):
        ""Store the gui/wx object parent for this component""
        # set init=True if this is called from the constructor
        self._parent = get(new_parent, init)",Store the gui/wx object parent for this component,
"def _get_fully_qualified_name(self):
        ""return full parents name + self name (useful as key)""
        parent_name = self._get_parent_name()
        if not parent_name:
            return self._name
        else:
            return ""%s.%s"" % (parent_name, self._name)",return full parents name + self name (useful as key),
"def set_parent(self, new_parent, init=False):
        ""Associate the component to the control (it could be recreated)""
        # store gui reference inside of wx object (this will enable rebuild...)
        self._parent = get(new_parent, init=False)    # store new parent
        if init:
            self._parent[self._name] = self",Associate the component to the control (it could be recreated),
"def rebuild(self, **kwargs):
        ""Update a property value with (used by the designer)""
        for name, value in kwargs.items():
            setattr(self, name, value)",Update a property value with (used by the designer),
"def _get_column_headings(self):
        ""Return a list of children sub-components that are column headings""
        # return it in the same order as inserted in the Grid
        headers = [ctrl for ctrl in self if isinstance(ctrl, GridColumn)]
        return sorted(headers, key=lambda ch: ch.index)",Return a list of children sub-components that are column headings,
"def _set_row_label(self, value):
        ""Set the row label format string (empty to hide)""
        if not value:
            self.wx_obj.SetRowLabelSize(0)
        else:
            self.wx_obj._table._row_label = value",Set the row label format string (empty to hide),
"def UpdateValues(self, grid):
        ""Update all displayed values""
        # This sends an event to the grid table to update all of the values
        msg = gridlib.GridTableMessage(self, 
                                    gridlib.GRIDTABLE_REQUEST_VIEW_GET_VALUES)
        grid.ProcessTableMessage(msg)",Update all displayed values,
"def SortColumn(self, col):
        ""col -> sort the data based on the column indexed by col""
        name = self.columns[col].name
        _data = []

        for row in self.data:
            rowname, entry = row
            _data.append((entry.get(name, None), row))

        _data.sort()
        self.data = []

        for sortvalue, row in _data:
            self.data.append(row)",col -> sort the data based on the column indexed by col,
"def insert(self, pos, values):
        ""Insert a number of rows into the grid (and associated table)""
        if isinstance(values, dict):
            row = GridRow(self, **values)
        else:
            row = GridRow(self, *values)
        list.insert(self, pos, row)
        self._grid_view.wx_obj.InsertRows(pos, numRows=1)",Insert a number of rows into the grid (and associated table),
"def append(self, values):
        ""Insert a number of rows into the grid (and associated table)""
        if isinstance(values, dict):
            row = GridRow(self, **values)
        else:
            row = GridRow(self, *values)
        list.append(self, row)
        self._grid_view.wx_obj.AppendRows(numRows=1)",Insert a number of rows into the grid (and associated table),
"def clear(self):
        ""Remove all rows and reset internal structures""
        ## list has no clear ... remove items in reverse order
        for i in range(len(self)-1, -1, -1):
            del self[i]
        self._key = 0
        if hasattr(self._grid_view, ""wx_obj""):
            self._grid_view.wx_obj.ClearGrid()",Remove all rows and reset internal structures,
"def Create(self, parent, id, evtHandler):
        ""Called to create the control, which must derive from wxControl.""        
        self._tc = wx.ComboBox(parent, id, """", (100, 50))
        self.SetControl(self._tc)
        # pushing a different event handler instead evtHandler:
        self._tc.PushEventHandler(wx.EvtHandler())
        self._tc.Bind(wx.EVT_COMBOBOX, self.OnChange)","Called to create the control, which must derive from wxControl.",
"def SetSize(self, rect):
        ""Called to position/size the edit control within the cell rectangle.""
        self._tc.SetDimensions(rect.x, rect.y, rect.width+2, rect.height+2,
                               wx.SIZE_ALLOW_MINUS_ONE)",Called to position/size the edit control within the cell rectangle.,
"def BeginEdit(self, row, col, grid):
        ""Fetch the value from the table and prepare the edit control""
        self.startValue = grid.GetTable().GetValue(row, col)
        choices = grid.GetTable().columns[col]._choices
        self._tc.Clear()
        self._tc.AppendItems(choices)
        self._tc.SetStringSelection(self.startValue)
        self._tc.SetFocus()",Fetch the value from the table and prepare the edit control,
"def IsAcceptedKey(self, evt):
        ""Return True to allow the given key to start editing""
        ## Oops, there's a bug here, we'll have to do it ourself..
        ##return self.base_IsAcceptedKey(evt)
        return (not (evt.ControlDown() or evt.AltDown()) and
                evt.GetKeyCode() != wx.WXK_SHIFT)",Return True to allow the given key to start editing,
"def TypeHandler(type_name):
    """""" A metaclass generator. Returns a metaclass which
    will register it's class as the class that handles input type=typeName
    """"""
    def metaclass(name, bases, dict):
        klass = type(name, bases, dict)
        form.FormTagHandler.register_type(type_name.upper(), klass)
        return klass
    return metaclass","A metaclass generator. Returns a metaclass which
    will register it's class as the class that handles input type=typeName",
"def Enable(self, value):
        ""enable or disable all menu items""
        for i in range(self.GetMenuItemCount()):
            it = self.FindItemByPosition(i) 
            it.Enable(value)",enable or disable all menu items,
"def IsEnabled(self, *args, **kwargs):
        ""check if all menu items are enabled""
        for i in range(self.GetMenuItemCount()):
            it = self.FindItemByPosition(i) 
            if not it.IsEnabled():
                return False
        return True",check if all menu items are enabled,
"def find(self, item_id=None):
        ""Recursively find a menu item by its id (useful for event handlers)""
        for it in self:
            if it.id == item_id:
                return it
            elif isinstance(it, Menu):
                found = it.find(item_id)
                if found:
                    return found",Recursively find a menu item by its id (useful for event handlers),
"def Enable(self, value):
        ""enable or disable all top menus""
        for i in range(self.GetMenuCount()):
            self.EnableTop(i, value)",enable or disable all top menus,
"def IsEnabled(self, *args, **kwargs):
        ""check if all top menus are enabled""
        for i in range(self.GetMenuCount()):
            if not self.IsEnabledTop(i):
                return False
        return True",check if all top menus are enabled,
"def RemoveItem(self, menu):
        ""Helper method to remove a menu avoiding using its position""
        menus = self.GetMenus()     # get the list of (menu, title)
        menus = [submenu for submenu in menus if submenu[0] != menu]
        self.SetMenus(menus)",Helper method to remove a menu avoiding using its position,
"def find(self, item_id=None):
        ""Recursively find a menu item by its id (useful for event handlers)""
        for it in self:
            found = it.find(item_id)
            if found:
                return found",Recursively find a menu item by its id (useful for event handlers),
"def submit(self, btn=None):
        ""Process form submission""
        data = self.build_data_set()
        if btn and btn.name:
            data[btn.name] = btn.name
        evt = FormSubmitEvent(self, data)
        self.container.ProcessEvent(evt)",Process form submission,
"def setObjectTag(self, object, tag):
        """""" Add a tag attribute to the wx window """"""
        object._attributes = {}
        object._name = tag.GetName().lower()
        for name in self.attributes:
            object._attributes[""_%s"" % name] = tag.GetParam(name)
            if object._attributes[""_%s"" % name] == """":
                object._attributes[""_%s"" % name] = None",Add a tag attribute to the wx window,
"def select_color(message="""", title="""", color=None, parent=None):
    ""Show a dialog to pick a color""
    result = dialogs.colorDialog(parent, color=color)
    return result.accepted and result.color",Show a dialog to pick a color,
"def choose_directory(message='Choose a directory', path="""", parent=None):
    ""Show a dialog to choose a directory""
    result = dialogs.directoryDialog(parent, message, path)
    return result.path",Show a dialog to choose a directory,
"def find(default='', whole_words=0, case_sensitive=0, parent=None):
    ""Shows a find text dialog""
    result = dialogs.findDialog(parent, default, whole_words, case_sensitive)
    return {'text': result.searchText, 'whole_words': result.wholeWordsOnly,
            'case_sensitive': result.caseSensitive}",Shows a find text dialog,
"def clear(self):
        ""Remove all items and reset internal structures""
        dict.clear(self)
        self._key = 0
        if hasattr(self._tree_view, ""wx_obj""):
            self._tree_view.wx_obj.DeleteAllItems()",Remove all items and reset internal structures,
"def _set_icon(self, icon=None):
        """"""Set icon based on resource values""""""
        if icon is not None:
            try:
                wx_icon = wx.Icon(icon, wx.BITMAP_TYPE_ICO)
                self.wx_obj.SetIcon(wx_icon)
            except:
                pass",Set icon based on resource values,
"def resize(self, evt=None):
        ""automatically adjust relative pos and size of children controls""
        for child in self:
            if isinstance(child, Control):
                child.resize(evt)
        # call original handler (wx.HtmlWindow)
        if evt:
            evt.Skip()",automatically adjust relative pos and size of children controls,
"def parse(filename=""""):
    ""Open, read and eval the resource from the source file""
    # use the provided resource file:
    s = open(filename).read()
    ##s.decode(""latin1"").encode(""utf8"")
    import datetime, decimal
    rsrc = eval(s)
    return rsrc","Open, read and eval the resource from the source file",
"def save(filename, rsrc):
    ""Save the resource to the source file""
    s = pprint.pformat(rsrc)
    ## s = s.encode(""utf8"")
    open(filename, ""w"").write(s)",Save the resource to the source file,
"def convert(self, name):
        ""translate gui2py attribute name from pythoncard legacy code""
        new_name = PYTHONCARD_PROPERTY_MAP.get(name)
        if new_name:
            print ""WARNING: property %s should be %s (%s)"" % (name, new_name, self.obj.name)
            return new_name
        else:
            return name",translate gui2py attribute name from pythoncard legacy code,
"def find_autosummary_in_files(filenames):
    """"""Find out what items are documented in source/*.rst.

    See `find_autosummary_in_lines`.
    """"""
    documented = []
    for filename in filenames:
        f = open(filename, 'r')
        lines = f.read().splitlines()
        documented.extend(find_autosummary_in_lines(lines, filename=filename))
        f.close()
    return documented","Find out what items are documented in source/*.rst.

    See `find_autosummary_in_lines`.",
"def set_parent(self, new_parent, init=False):
        ""Re-parent a child control with the new wx_obj parent (owner)""
        ##SubComponent.set_parent(self, new_parent, init)
        self.wx_obj.SetOwner(new_parent.wx_obj.GetEventHandler())",Re-parent a child control with the new wx_obj parent (owner),
"def add_selector(name):
    """"""
    Builds and registers a :class:`Selector` object with the given name and configuration.

    Args:
        name (str): The name of the selector.

    Yields:
        SelectorFactory: The factory that will build the :class:`Selector`.
    """"""

    factory = SelectorFactory(name)
    yield factory
    selectors[name] = factory.build_selector()","Builds and registers a :class:`Selector` object with the given name and configuration.

    Args:
        name (str): The name of the selector.

    Yields:
        SelectorFactory: The factory that will build the :class:`Selector`.",
"def expression_filters(self):
        """""" Dict[str, ExpressionFilter]: Returns the expression filters for this selector. """"""

        return {
            name: filter for name, filter in iter(self.filters.items())
            if isinstance(filter, ExpressionFilter)}","Dict[str, ExpressionFilter]: Returns the expression filters for this selector.",
"def node_filters(self):
        """""" Dict[str, NodeFilter]: Returns the node filters for this selector. """"""

        return {
            name: filter for name, filter in iter(self.filters.items())
            if isinstance(filter, NodeFilter)}","Dict[str, NodeFilter]: Returns the node filters for this selector.",
"def failure_message(self):
        """""" str: A message describing the query failure. """"""
        return (
            ""Expected node to have styles {expected}. ""
            ""Actual styles were {actual}"").format(
                expected=desc(self.expected_styles),
                actual=desc(self.actual_styles))",str: A message describing the query failure.,
"def select_option(self):
        """""" Select this node if it is an option element inside a select tag. """"""
        if self.disabled:
            warn(""Attempt to select disabled option: {}"".format(self.value or self.text))
        self.base.select_option()",Select this node if it is an option element inside a select tag.,
"def kwargs(self):
        """""" Dict[str, Any]: The keyword arguments with which this query was initialized. """"""
        kwargs = {}
        kwargs.update(self.options)
        kwargs.update(self.filter_options)
        return kwargs","Dict[str, Any]: The keyword arguments with which this query was initialized.",
"def current_scope(self):
        """""" node.Base: The current node relative to which all interaction will be scoped. """"""
        scope = self._scopes[-1]
        if scope in [None, ""frame""]:
            scope = self.document
        return scope",node.Base: The current node relative to which all interaction will be scoped.,
"def current_path(self):
        """""" str: Path of the current page, without any domain information. """"""

        if not self.current_url:
            return

        path = urlparse(self.current_url).path
        return path if path else None","str: Path of the current page, without any domain information.",
"def current_host(self):
        """""" str: Host of the current page. """"""

        if not self.current_url:
            return

        result = urlparse(self.current_url)
        scheme, netloc = result.scheme, result.netloc
        host = netloc.split("":"")[0] if netloc else None
        return ""{0}://{1}"".format(scheme, host) if host else None",str: Host of the current page.,
"def raise_server_error(self):
        """""" Raise errors encountered by the server. """"""
        if self.server and self.server.error:
            try:
                if capybara.raise_server_errors:
                    raise self.server.error
            finally:
                self.server.reset_error()",Raise errors encountered by the server.,
"def get_version():
    """""" str: The package version. """"""

    global_vars = {}

    # Compile and execute the individual file to prevent
    # the package from being automatically loaded.
    source = read(os.path.join(""capybara"", ""version.py""))
    code = compile(source, ""version.py"", ""exec"")
    exec(code, global_vars)

    return global_vars['__version__']",str: The package version.,
"def resolves_for(self, node):
        """"""
        Resolves this query relative to the given node.

        Args:
            node (node.Document): The node to be evaluated.

        Returns:
            bool: Whether the given node matches this query.
        """"""

        self.actual_title = normalize_text(node.title)
        return bool(self.search_regexp.search(self.actual_title))","Resolves this query relative to the given node.

        Args:
            node (node.Document): The node to be evaluated.

        Returns:
            bool: Whether the given node matches this query.",
"def frame_title(self):
        """""" str: The title for the current frame. """"""
        elements = self._find_xpath(""/html/head/title"")
        titles = [element.all_text for element in elements]
        return titles[0] if len(titles) else """"",str: The title for the current frame.,
"def add_filter_set(name):
    """"""
    Builds and registers a global :class:`FilterSet`.

    Args:
        name (str): The name of the set.

    Yields:
        FilterSetFactory: A configurable factory for building a :class:`FilterSet`.
    """"""

    factory = FilterSetFactory(name)
    yield factory
    filter_sets[name] = factory.build_filter_set()","Builds and registers a global :class:`FilterSet`.

    Args:
        name (str): The name of the set.

    Yields:
        FilterSetFactory: A configurable factory for building a :class:`FilterSet`.",
"def _valid_value(self, value):
        """""" bool: Whether the given value is valid. """"""

        if not self.valid_values:
            return True

        valid_values = (self.valid_values if isinstance(self.valid_values, list)
                        else list(self.valid_values))
        return value in valid_values",bool: Whether the given value is valid.,
"def synchronize(func):
    """""" Decorator for :meth:`synchronize`. """"""

    @wraps(func)
    def outer(self, *args, **kwargs):
        @self.synchronize
        def inner(self, *args, **kwargs):
            return func(self, *args, **kwargs)

        return inner(self, *args, **kwargs)

    return outer",Decorator for :meth:`synchronize`.,
"def normalize_whitespace(text):
    """"""
    Returns the given text with outer whitespace removed and inner whitespace collapsed.

    Args:
        text (str): The text to normalize.

    Returns:
        str: The normalized text.
    """"""

    return re.sub(r""\s+"", "" "", text, flags=re.UNICODE).strip()","Returns the given text with outer whitespace removed and inner whitespace collapsed.

    Args:
        text (str): The text to normalize.

    Returns:
        str: The normalized text.",
"def current(self):
        """""" bool: Whether this window is the window in which commands are being executed. """"""
        try:
            return self.driver.current_window_handle == self.handle
        except self.driver.no_such_window_error:
            return False",bool: Whether this window is the window in which commands are being executed.,
"def instance_method(self, imeth: typing.Optional[typing.Callable[..., typing.Any]]) -> ""SeparateClassMethod"":
        """"""Descriptor to change instance method.

        :param imeth: New instance method.
        :type imeth: typing.Optional[typing.Callable]
        :return: SeparateClassMethod
        :rtype: SeparateClassMethod
        """"""
        self.__instance_method = imeth
        return self","Descriptor to change instance method.

        :param imeth: New instance method.
        :type imeth: typing.Optional[typing.Callable]
        :return: SeparateClassMethod
        :rtype: SeparateClassMethod",
"def class_method(self, cmeth: typing.Optional[typing.Callable[..., typing.Any]]) -> ""SeparateClassMethod"":
        """"""Descriptor to change class method.

        :param cmeth: New class method.
        :type cmeth: typing.Optional[typing.Callable]
        :return: SeparateClassMethod
        :rtype: SeparateClassMethod
        """"""
        self.__class_method = cmeth
        return self","Descriptor to change class method.

        :param cmeth: New class method.
        :type cmeth: typing.Optional[typing.Callable]
        :return: SeparateClassMethod
        :rtype: SeparateClassMethod",
"def __get_obj_source(self, instance: typing.Any, owner: typing.Optional[type] = None) -> str:
        """"""Get object repr block.""""""
        if self.log_object_repr:
            return f""{instance!r}""
        return f""<{owner.__name__ if owner is not None else instance.__class__.__name__}() at 0x{id(instance):X}>""",Get object repr block.,
"def logger(self, logger: typing.Union[logging.Logger, str, None]) -> None:
        """"""Logger instance to use as override.""""""
        if logger is None or isinstance(logger, logging.Logger):
            self.__logger = logger
        else:
            self.__logger = logging.getLogger(logger)",Logger instance to use as override.,
"def channels(self):
        """"""
        List of channels of this slack team
        """"""
        if not self._channels:
            self._channels = self._call_api('channels.list')['channels']
        return self._channels",List of channels of this slack team,
"def users(self):
        """"""
        List of users of this slack team
        """"""
        if not self._users:
            self._users = self._call_api('users.list')['members']
        return self._users",List of users of this slack team,
"def channel_from_name(self, name):
        """"""
        Return the channel dict given by human-readable {name}
        """"""
        try:
            channel = [channel for channel in self.channels
                       if channel['name'] == name][0]
        except IndexError:
            raise ValueError('Unknown channel for name: ""{}""'.format(name))
        return channel",Return the channel dict given by human-readable {name},
"def sendSlack(self, message):
        """"""
        Send message to Slack
        """"""
        channel = message.get('channel', 'general')
        self.sendMessage(self.make_message(message['text'], channel))",Send message to Slack,
"def read_channel(self):
        """"""
        Get available messages and send through to the protocol
        """"""
        channel, message = self.protocol.channel_layer.receive_many([u'slack.send'], block=False)
        delay = 0.1
        if channel:
            self.protocols[0].sendSlack(message)
        reactor.callLater(delay, self.read_channel)",Get available messages and send through to the protocol,
"def dict_diff(prv, nxt):
    """"""Return a dict of keys that differ with another config object.""""""
    keys = set(prv.keys() + nxt.keys())
    result = {}
    for k in keys:
        if prv.get(k) != nxt.get(k):
            result[k] = (prv.get(k), nxt.get(k))
    return result",Return a dict of keys that differ with another config object.,
"def colorize(msg, color):
    """"""Given a string add necessary codes to format the string.""""""
    if DONT_COLORIZE:
        return msg
    else:
        return ""{}{}{}"".format(COLORS[color], msg, COLORS[""endc""])",Given a string add necessary codes to format the string.,
"def v2_playbook_on_task_start(self, task, **kwargs):
        """"""Run when a task starts.""""""
        self.last_task_name = task.get_name()
        self.printed_last_task = False",Run when a task starts.,
"def load_filters():
    """"""
    Loads and returns all filters.
    """"""
    all_filters = {}
    for m in JINJA_FILTERS:
        if hasattr(m, ""filters""):
            all_filters.update(m.filters())
    return all_filters",Loads and returns all filters.,
"def url_query_params(url):
    """"""Return query parameters as a dict from the specified URL.

    :param url: URL.
    :type url: str
    :rtype: dict
    """"""
    return dict(urlparse.parse_qsl(urlparse.urlparse(url).query, True))","Return query parameters as a dict from the specified URL.

    :param url: URL.
    :type url: str
    :rtype: dict",
"def _handle_exception(self, exc):
        """"""Handle an internal exception that was caught and suppressed.

        :param exc: Exception to process.
        :type exc: Exception
        """"""
        logger = logging.getLogger(__name__)
        logger.exception(exc)","Handle an internal exception that was caught and suppressed.

        :param exc: Exception to process.
        :type exc: Exception",
"def read_byte(self, addr):
        """"""Read a single byte from the specified device.""""""
        assert self._device is not None, 'Bus must be opened before operations are made against it!'
        self._select_device(addr)
        return ord(self._device.read(1))",Read a single byte from the specified device.,
"def read_bytes(self, addr, number):
        """"""Read many bytes from the specified device.""""""
        assert self._device is not None, 'Bus must be opened before operations are made against it!'
        self._select_device(addr)
        return self._device.read(number)",Read many bytes from the specified device.,
"def write_byte(self, addr, val):
        """"""Write a single byte to the specified device.""""""
        assert self._device is not None, 'Bus must be opened before operations are made against it!'
        self._select_device(addr)
        data = bytearray(1)
        data[0] = val & 0xFF
        self._device.write(data)",Write a single byte to the specified device.,
"def write_bytes(self, addr, buf):
        """"""Write many bytes to the specified device. buf is a bytearray""""""
        assert self._device is not None, 'Bus must be opened before operations are made against it!'
        self._select_device(addr)
        self._device.write(buf)",Write many bytes to the specified device. buf is a bytearray,
"def datetime_stored(self):
        """"""Returns file's store aware *datetime* in UTC format.

        It might do API request once because it depends on ``info()``.

        """"""
        if self.info().get('datetime_stored'):
            return dateutil.parser.parse(self.info()['datetime_stored'])","Returns file's store aware *datetime* in UTC format.

        It might do API request once because it depends on ``info()``.",
"def datetime_removed(self):
        """"""Returns file's remove aware *datetime* in UTC format.

        It might do API request once because it depends on ``info()``.

        """"""
        if self.info().get('datetime_removed'):
            return dateutil.parser.parse(self.info()['datetime_removed'])","Returns file's remove aware *datetime* in UTC format.

        It might do API request once because it depends on ``info()``.",
"def datetime_uploaded(self):
        """"""Returns file's upload aware *datetime* in UTC format.

        It might do API request once because it depends on ``info()``.

        """"""
        if self.info().get('datetime_uploaded'):
            return dateutil.parser.parse(self.info()['datetime_uploaded'])","Returns file's upload aware *datetime* in UTC format.

        It might do API request once because it depends on ``info()``.",
"def datetime_created(self):
        """"""Returns file group's create aware *datetime* in UTC format.""""""
        if self.info().get('datetime_created'):
            return dateutil.parser.parse(self.info()['datetime_created'])",Returns file group's create aware *datetime* in UTC format.,
"def construct_from(cls, group_info):
        """"""Constructs ``FileGroup`` instance from group information.""""""
        group = cls(group_info['id'])
        group._info_cache = group_info
        return group",Constructs ``FileGroup`` instance from group information.,
"def _base_opration(self, method):
        """""" Base method for storage operations.
        """"""
        uuids = self.uuids()

        while True:
            chunk = list(islice(uuids, 0, self.chunk_size))

            if not chunk:
                return

            rest_request(method, self.storage_url, chunk)",Base method for storage operations.,
"def uuids(self):
        """""" Extract uuid from each item of specified ``seq``.
        """"""
        for f in self._seq:
            if isinstance(f, File):
                yield f.uuid
            elif isinstance(f, six.string_types):
                yield f
            else:
                raise ValueError(
                    'Invalid type for sequence item: {0}'.format(type(f)))",Extract uuid from each item of specified ``seq``.,
"def set_home_mode(self, state):
        """"""Set the state of Home Mode""""""
        state_parameter = HOME_MODE_OFF
        if state:
            state_parameter = HOME_MODE_ON
        return self._api.home_mode_set_state(state_parameter)",Set the state of Home Mode,
"def get_ilvl(li, w_namespace):
    """"""
    The ilvl on an li tag tells the li tag at what level of indentation this
    tag is at. This is used to determine if the li tag needs to be nested or
    not.
    """"""
    ilvls = li.xpath('.//w:ilvl', namespaces=li.nsmap)
    if len(ilvls) == 0:
        return -1
    return int(ilvls[0].get('%sval' % w_namespace))","The ilvl on an li tag tells the li tag at what level of indentation this
    tag is at. This is used to determine if the li tag needs to be nested or
    not.",
"def get_numId(li, w_namespace):
    """"""
    The numId on an li tag maps to the numbering dictionary along side the ilvl
    to determine what the list should look like (unordered, digits, lower
    alpha, etc)
    """"""
    numIds = li.xpath('.//w:numId', namespaces=li.nsmap)
    if len(numIds) == 0:
        return -1
    return numIds[0].get('%sval' % w_namespace)","The numId on an li tag maps to the numbering dictionary along side the ilvl
    to determine what the list should look like (unordered, digits, lower
    alpha, etc)",
"def style_is_false(style):
    """"""
    For bold, italics and underline. Simply checking to see if the various tags
    are present will not suffice. If the tag is present and set to False then
    the style should not be present.
    """"""
    if style is None:
        return False
    w_namespace = get_namespace(style, 'w')
    return style.get('%sval' % w_namespace) != 'false'","For bold, italics and underline. Simply checking to see if the various tags
    are present will not suffice. If the tag is present and set to False then
    the style should not be present.",
"def is_bold(r):
    """"""
    The function will return True if the r tag passed in is considered bold.
    """"""
    w_namespace = get_namespace(r, 'w')
    rpr = r.find('%srPr' % w_namespace)
    if rpr is None:
        return False
    bold = rpr.find('%sb' % w_namespace)
    return style_is_false(bold)",The function will return True if the r tag passed in is considered bold.,
"def is_italics(r):
    """"""
    The function will return True if the r tag passed in is considered
    italicized.
    """"""
    w_namespace = get_namespace(r, 'w')
    rpr = r.find('%srPr' % w_namespace)
    if rpr is None:
        return False
    italics = rpr.find('%si' % w_namespace)
    return style_is_false(italics)","The function will return True if the r tag passed in is considered
    italicized.",
"def is_underlined(r):
    """"""
    The function will return True if the r tag passed in is considered
    underlined.
    """"""
    w_namespace = get_namespace(r, 'w')
    rpr = r.find('%srPr' % w_namespace)
    if rpr is None:
        return False
    underline = rpr.find('%su' % w_namespace)
    return style_is_false(underline)","The function will return True if the r tag passed in is considered
    underlined.",
"def is_title(p):
    """"""
    Certain p tags are denoted as ``Title`` tags. This function will return
    True if the passed in p tag is considered a title.
    """"""
    w_namespace = get_namespace(p, 'w')
    styles = p.xpath('.//w:pStyle', namespaces=p.nsmap)
    if len(styles) == 0:
        return False
    style = styles[0]
    return style.get('%sval' % w_namespace) == 'Title'","Certain p tags are denoted as ``Title`` tags. This function will return
    True if the passed in p tag is considered a title.",
"def _strip_tag(tree, tag):
    """"""
    Remove all tags that have the tag name ``tag``
    """"""
    for el in tree.iter():
        if el.tag == tag:
            el.getparent().remove(el)",Remove all tags that have the tag name ``tag``,
"def variables(self):
        '''A list of Theano variables used in this loss.'''
        result = [self._target]
        if self._weights is not None:
            result.append(self._weights)
        return result",A list of Theano variables used in this loss.,
"def set_loss(self, *args, **kwargs):
        '''Clear the current loss functions from the network and add a new one.

        All parameters and keyword arguments are passed to :func:`add_loss`
        after clearing the current losses.
        '''
        self.losses = []
        self.add_loss(*args, **kwargs)","Clear the current loss functions from the network and add a new one.

        All parameters and keyword arguments are passed to :func:`add_loss`
        after clearing the current losses.",
"def inputs(self):
        '''A list of Theano variables for feedforward computations.'''
        return [l.input for l in self.layers if isinstance(l, layers.Input)]",A list of Theano variables for feedforward computations.,
"def variables(self):
        '''A list of Theano variables for loss computations.'''
        result = self.inputs
        seen = set(i.name for i in result)
        for loss in self.losses:
            for v in loss.variables:
                if v.name not in seen:
                    result.append(v)
                    seen.add(v.name)
        return result",A list of Theano variables for loss computations.,
"def updates(self, **kwargs):
        '''Return expressions to run as updates during network training.

        Returns
        -------
        updates : list of (parameter, expression) pairs
            A list of named parameter update expressions for this network.
        '''
        regs = regularizers.from_kwargs(self, **kwargs)
        _, updates = self.build_graph(regs)
        return updates","Return expressions to run as updates during network training.

        Returns
        -------
        updates : list of (parameter, expression) pairs
            A list of named parameter update expressions for this network.",
"def input_name(self):
        '''Name of layer input (for layers with one input).'''
        if len(self._input_shapes) != 1:
            raise util.ConfigurationError(
                'expected one input for layer ""{}"", got {}'
                .format(self.name, self._input_shapes))
        return list(self._input_shapes)[0]",Name of layer input (for layers with one input).,
"def input_size(self):
        '''Size of layer input (for layers with one input).'''
        shape = self.input_shape
        if shape is None:
            raise util.ConfigurationError(
                'undefined input size for layer ""{}""'.format(self.name))
        return shape[-1]",Size of layer input (for layers with one input).,
"def output_size(self):
        '''Number of ""neurons"" in this layer's default output.'''
        shape = self.output_shape
        if shape is None:
            raise util.ConfigurationError(
                'undefined output size for layer ""{}""'.format(self.name))
        return shape[-1]","Number of ""neurons"" in this layer's default output.",
"def log(self):
        '''Log some information about this layer.'''
        inputs = ', '.join('""{0}"" {1}'.format(*ns) for ns in self._input_shapes.items())
        util.log('layer {0.__class__.__name__} ""{0.name}"" {0.output_shape} {1} from {2}',
                 self, getattr(self.activate, 'name', self.activate), inputs)
        util.log('learnable parameters: {}', self.log_params())",Log some information about this layer.,
"def log_params(self):
        '''Log information about this layer's parameters.'''
        total = 0
        for p in self.params:
            shape = p.get_value().shape
            util.log('parameter ""{}"" {}', p.name, shape)
            total += np.prod(shape)
        return total",Log information about this layer's parameters.,
"def _fmt(self, string):
        '''Helper method to format our name into a string.'''
        if '{' not in string:
            string = '{}.' + string
        return string.format(self.name)",Helper method to format our name into a string.,
"def argmax(self, C):
        """"""
        Returns the ArgMax from C by returning the
        (x_pos, y_pos, theta, scale)  tuple

        >>> C = np.random.randn(10, 10, 5, 4)
        >>> x_pos, y_pos, theta, scale = mp.argmax(C)
        >>> C[x_pos][y_pos][theta][scale] = C.max()

        """"""
        ind = np.absolute(C).argmax()
        return np.unravel_index(ind, C.shape)","Returns the ArgMax from C by returning the
        (x_pos, y_pos, theta, scale)  tuple

        >>> C = np.random.randn(10, 10, 5, 4)
        >>> x_pos, y_pos, theta, scale = mp.argmax(C)
        >>> C[x_pos][y_pos][theta][scale] = C.max()",
"def remove_point(self, time):
        """"""Remove a point, if no point is found nothing happens.

        :param int time: Time of the point.
        :raises TierTypeException: If the tier is not a TextTier.
        """"""
        if self.tier_type != 'TextTier':
            raise Exception('Tiertype must be TextTier.')
        self.intervals = [i for i in self.intervals if i[0] != time]","Remove a point, if no point is found nothing happens.

        :param int time: Time of the point.
        :raises TierTypeException: If the tier is not a TextTier.",
"def get_intervals(self, sort=False):
        """"""Give all the intervals or points.

        :param bool sort: Flag for yielding the intervals or points sorted.
        :yields: All the intervals
        """"""
        for i in sorted(self.intervals) if sort else self.intervals:
            yield i","Give all the intervals or points.

        :param bool sort: Flag for yielding the intervals or points sorted.
        :yields: All the intervals",
"def add_language(self, lang_id, lang_def=None, lang_label=None):
        """"""Add a language.

        :param str lang_id: ID of the language.
        :param str lang_def: Definition of the language(preferably ISO-639-3).
        :param str lang_label: Label of the language.
        """"""
        self.languages[lang_id] = (lang_def, lang_label)","Add a language.

        :param str lang_id: ID of the language.
        :param str lang_def: Definition of the language(preferably ISO-639-3).
        :param str lang_label: Label of the language.",
"def add_locale(self, language_code, country_code=None, variant=None):
        """"""Add a locale.

        :param str language_code: The language code of the locale.
        :param str country_code: The country code of the locale.
        :param str variant: The variant of the locale.
        """"""
        self.locales[language_code] = (country_code, variant)","Add a locale.

        :param str language_code: The language code of the locale.
        :param str country_code: The country code of the locale.
        :param str variant: The variant of the locale.",
"def get_full_time_interval(self):
        """"""Give the full time interval of the file. Note that the real interval
        can be longer because the sound file attached can be longer.

        :returns: Tuple of the form: ``(min_time, max_time)``.
        """"""
        return (0, 0) if not self.timeslots else\
            (min(self.timeslots.values()), max(self.timeslots.values()))","Give the full time interval of the file. Note that the real interval
        can be longer because the sound file attached can be longer.

        :returns: Tuple of the form: ``(min_time, max_time)``.",
"def insert_annotation(self, id_tier, start, end, value='', svg_ref=None):
        """""".. deprecated:: 1.2

        Use :func:`add_annotation` instead.
        """"""
        return self.add_annotation(id_tier, start, end, value, svg_ref)",".. deprecated:: 1.2

        Use :func:`add_annotation` instead.",
"def insert_ref_annotation(self, id_tier, tier2, time, value='',
                              prev=None, svg=None):
        """""".. deprecated:: 1.2

        Use :func:`add_ref_annotation` instead.
        """"""
        return self.add_ref_annotation(id_tier, tier2, time, value, prev, svg)",".. deprecated:: 1.2

        Use :func:`add_ref_annotation` instead.",
"def remove_license(self, name=None, url=None):
        """"""Remove all licenses matching both key and value.

        :param str name: Name of the license.
        :param str url: URL of the license.
        """"""
        for k, v in self.licenses[:]:
            if (name is None or name == k) and (url is None or url == v):
                del(self.licenses[self.licenses.index((k, v))])","Remove all licenses matching both key and value.

        :param str name: Name of the license.
        :param str url: URL of the license.",
"def remove_tier(self, id_tier, clean=True):
        """"""Remove a tier.

        :param str id_tier: Name of the tier.
        :param bool clean: Flag to also clean the timeslots.
        :raises KeyError: If tier is non existent.
        """"""
        del(self.tiers[id_tier])
        if clean:
            self.clean_time_slots()","Remove a tier.

        :param str id_tier: Name of the tier.
        :param bool clean: Flag to also clean the timeslots.
        :raises KeyError: If tier is non existent.",
"def _add(object, name, value):
    """"""Append to self, accessible via Qt.QtCompat""""""
    self.__added__.append(name)
    setattr(object, name, value)","Append to self, accessible via Qt.QtCompat",
"def _discover_gui():
    """"""Return the most desirable of the currently registered GUIs""""""

    # Prefer last registered
    guis = reversed(pyblish.api.registered_guis())

    for gui in guis:
        try:
            gui = __import__(gui).show
        except (ImportError, AttributeError):
            continue
        else:
            return gui",Return the most desirable of the currently registered GUIs,
"def teardown():
    """"""Remove integration""""""
    if not self._has_been_setup:
        return

    deregister_plugins()
    deregister_host()

    if self._has_menu:
        remove_from_filemenu()
        self._has_menu = False

    self._has_been_setup = False
    print(""pyblish: Integration torn down successfully"")",Remove integration,
"def deregister_host():
    """"""Register supported hosts""""""
    pyblish.api.deregister_host(""mayabatch"")
    pyblish.api.deregister_host(""mayapy"")
    pyblish.api.deregister_host(""maya"")",Register supported hosts,
"def maintained_time():
    """"""Maintain current time during context

    Example:
        >>> with maintained_time():
        ...    cmds.playblast()
        >>> # Time restored

    """"""

    ct = cmds.currentTime(query=True)
    try:
        yield
    finally:
        cmds.currentTime(ct, edit=True)","Maintain current time during context

    Example:
        >>> with maintained_time():
        ...    cmds.playblast()
        >>> # Time restored",
"def get_cumulative_data(self):
		""""""Get the data as it will be charted.  The first set will be
		the actual first data set.  The second will be the sum of the
		first and the second, etc.""""""
		sets = map(itemgetter('data'), self.data)
		if not sets:
			return
		sum = sets.pop(0)
		yield sum
		while sets:
			sum = map(add, sets.pop(0))
			yield sum","Get the data as it will be charted.  The first set will be
		the actual first data set.  The second will be the sum of the
		first and the second, etc.",
"def get_single_axis_values(self, axis, dataset):
		""""""
		Return all the values for a single axis of the data.
		""""""
		data_index = getattr(self, '%s_data_index' % axis)
		return [p[data_index] for p in dataset['data']]",Return all the values for a single axis of the data.,
"def reverse_mapping(mapping):
	""""""
	For every key, value pair, return the mapping for the
	equivalent value, key pair

	>>> reverse_mapping({'a': 'b'}) == {'b': 'a'}
	True
	""""""
	keys, values = zip(*mapping.items())
	return dict(zip(values, keys))","For every key, value pair, return the mapping for the
	equivalent value, key pair

	>>> reverse_mapping({'a': 'b'}) == {'b': 'a'}
	True",
"def flatten_mapping(mapping):
	""""""
	For every key that has an __iter__ method, assign the values
	to a key for each.

	>>> flatten_mapping({'ab': 3, ('c','d'): 4}) == {'ab': 3, 'c': 4, 'd': 4}
	True
	""""""
	return {
		key: value
		for keys, value in mapping.items()
		for key in always_iterable(keys)
	}","For every key that has an __iter__ method, assign the values
	to a key for each.

	>>> flatten_mapping({'ab': 3, ('c','d'): 4}) == {'ab': 3, 'c': 4, 'd': 4}
	True",
"def float_range(start=0, stop=None, step=1):
	""""""
	Much like the built-in function range, but accepts floats

	>>> tuple(float_range(0, 9, 1.5))
	(0.0, 1.5, 3.0, 4.5, 6.0, 7.5)
	""""""
	start = float(start)
	while start < stop:
		yield start
		start += step","Much like the built-in function range, but accepts floats

	>>> tuple(float_range(0, 9, 1.5))
	(0.0, 1.5, 3.0, 4.5, 6.0, 7.5)",
"def add_defs(self, defs):
		""Add svg definitions""
		etree.SubElement(
			defs,
			'filter',
			id='dropshadow',
			width='1.2',
			height='1.2',
		)
		etree.SubElement(
			defs,
			'feGaussianBlur',
			stdDeviation='4',
			result='blur',
		)",Add svg definitions,
"def add_data(self, conf):
		""""""
		Add data to the graph object. May be called several times to add
		additional data sets.

		conf should be a dictionary including 'data' and 'title' keys
		""""""
		self.validate_data(conf)
		self.process_data(conf)
		self.data.append(conf)","Add data to the graph object. May be called several times to add
		additional data sets.

		conf should be a dictionary including 'data' and 'title' keys",
"def calculate_right_margin(self):
		""""""
		Calculate the margin in pixels to the right of the plot area,
		setting border_right.
		""""""
		br = 7
		if self.key and self.key_position == 'right':
			max_key_len = max(map(len, self.keys()))
			br += max_key_len * self.key_font_size * 0.6
			br += self.KEY_BOX_SIZE
			br += 10		# Some padding around the box
		self.border_right = br","Calculate the margin in pixels to the right of the plot area,
		setting border_right.",
"def calculate_top_margin(self):
		""""""
		Calculate the margin in pixels above the plot area, setting
		border_top.
		""""""
		self.border_top = 5
		if self.show_graph_title:
			self.border_top += self.title_font_size
		self.border_top += 5
		if self.show_graph_subtitle:
			self.border_top += self.subtitle_font_size","Calculate the margin in pixels above the plot area, setting
		border_top.",
"def draw_x_labels(self):
		""Draw the X axis labels""
		if self.show_x_labels:
			labels = self.get_x_labels()
			count = len(labels)

			labels = enumerate(iter(labels))
			start = int(not self.step_include_first_x_label)
			labels = itertools.islice(labels, start, None, self.step_x_labels)
			list(map(self.draw_x_label, labels))
			self.draw_x_guidelines(self.field_width(), count)",Draw the X axis labels,
"def draw_x_guidelines(self, label_height, count):
		""Draw the X-axis guidelines""
		if not self.show_x_guidelines:
			return
		# skip the first one
		for count in range(1, count):
			move = 'M {start} 0 v{stop}'.format(
				start=label_height * count,
				stop=self.graph_height,
			)
			path = {'d': move, 'class': 'guideLines'}
			etree.SubElement(self.graph, 'path', path)",Draw the X-axis guidelines,
"def draw_y_guidelines(self, label_height, count):
		""Draw the Y-axis guidelines""
		if not self.show_y_guidelines:
			return
		for count in range(1, count):
			move = 'M 0 {start} h{stop}'.format(
				start=self.graph_height - label_height * count,
				stop=self.graph_width,
			)
			path = {'d': move, 'class': 'guideLines'}
			etree.SubElement(self.graph, 'path', path)",Draw the Y-axis guidelines,
"def draw_titles(self):
		""Draws the graph title and subtitle""
		if self.show_graph_title:
			self.draw_graph_title()
		if self.show_graph_subtitle:
			self.draw_graph_subtitle()
		if self.show_x_title:
			self.draw_x_title()
		if self.show_y_title:
			self.draw_y_title()",Draws the graph title and subtitle,
"def parse_css(self):
		""""""
		Take a .css file (classes only please) and parse it into a dictionary
		of class/style pairs.
		""""""
		# todo: save the prefs for use later
		# orig_prefs = cssutils.ser.prefs
		cssutils.ser.prefs.useMinified()
		pairs = (
			(r.selectorText, r.style.cssText)
			for r in self.get_stylesheet()
			if not isinstance(r, cssutils.css.CSSComment)
		)
		return dict(pairs)","Take a .css file (classes only please) and parse it into a dictionary
		of class/style pairs.",
"def get_stylesheet_resources(self):
		""Get the stylesheets for this instance""
		# allow css to include class variables
		class_vars = class_dict(self)
		loader = functools.partial(
			self.load_resource_stylesheet,
			subs=class_vars)
		sheets = list(map(loader, self.stylesheet_names))
		return sheets",Get the stylesheets for this instance,
"def new_nick(self):
        """"""\
        Generates a new nickname based on original nickname followed by a
        random number
        """"""
        old = self.nick
        self.nick = '%s_%s' % (self.base_nick, random.randint(1, 1000))
        self.logger.warn('Nick %s already taken, trying %s' % (old, self.nick))
        self.register_nick()
        self.handle_nick_change(old, self.nick)","\
        Generates a new nickname based on original nickname followed by a
        random number",
"def handle_ping(self, payload):
        """"""\
        Respond to periodic PING messages from server
        """"""
        self.logger.info('server ping: %s' % payload)
        self.send('PONG %s' % payload, True)","\
        Respond to periodic PING messages from server",
"def handle_registered(self, server):
        """"""\
        When the connection to the server is registered, send all pending
        data.
        """"""
        if not self._registered:
            self.logger.info('Registered')
            self._registered = True
            for data in self._out_buffer:
                self.send(data)
            self._out_buffer = []","\
        When the connection to the server is registered, send all pending
        data.",
"def register_callbacks(self):
        """"""\
        Hook for registering callbacks with connection -- handled by __init__()
        """"""
        self.conn.register_callbacks((
            (re.compile(pattern), callback) \
                for pattern, callback in self.command_patterns()
        ))","\
        Hook for registering callbacks with connection -- handled by __init__()",
"def respond(self, message, channel=None, nick=None):
        """"""\
        Wraps the connection object's respond() method
        """"""
        self.conn.respond(message, channel, nick)","\
        Wraps the connection object's respond() method",
"def register_with_boss(self):
        """"""\
        Register the worker with the boss
        """"""
        gevent.sleep(10) # wait for things to connect, etc
        
        while not self.registered.is_set():
            self.respond('!register {%s}' % platform.node(), nick=self.boss)
            gevent.sleep(30)","\
        Register the worker with the boss",
"def require_boss(self, callback):
        """"""\
        Decorator to ensure that commands only can come from the boss
        """"""
        def inner(nick, message, channel, *args, **kwargs):
            if nick != self.boss:
                return
            
            return callback(nick, message, channel, *args, **kwargs)
        return inner","\
        Decorator to ensure that commands only can come from the boss",
"def add(self, nick):
        """"""\
        Indicate that the worker with given nick is performing this task
        """"""
        self.data[nick] = ''
        self.workers.add(nick)","\
        Indicate that the worker with given nick is performing this task",
"def send_validation_email(self):
        """"""Send a validation email to the user's email address.""""""
        if self.email_verified:
            raise ValueError(_('Cannot validate already active user.'))

        site = Site.objects.get_current()
        self.validation_notification(user=self, site=site).notify()",Send a validation email to the user's email address.,
"def send_password_reset(self):
        """"""Send a password reset to the user's email address.""""""
        site = Site.objects.get_current()
        self.password_reset_notification(user=self, site=site).notify()",Send a password reset to the user's email address.,
"def delete(self, request, *args, **kwargs):
        """"""
        Delete the user's avatar.

        We set `user.avatar = None` instead of calling `user.avatar.delete()`
        to avoid test errors with `django.inmemorystorage`.
        """"""
        user = self.get_object()
        user.avatar = None
        user.save()
        return response.Response(status=HTTP_204_NO_CONTENT)","Delete the user's avatar.

        We set `user.avatar = None` instead of calling `user.avatar.delete()`
        to avoid test errors with `django.inmemorystorage`.",
"def allow_request(self, request, view):
        """"""
        Throttle POST requests only.
        """"""
        if request.method != 'POST':
            return True

        return super(PostRequestThrottleMixin, self).allow_request(request, view)",Throttle POST requests only.,
"def executor(self, max_workers=1):
        """"""single global executor""""""
        cls = self.__class__
        if cls._executor is None:
            cls._executor = ThreadPoolExecutor(max_workers)
        return cls._executor",single global executor,
"def tls_client(self):
        """"""A tuple consisting of the TLS client certificate and key if they
        have been provided, otherwise None.

        """"""
        if self.tls_cert and self.tls_key:
            return (self.tls_cert, self.tls_key)
        return None","A tuple consisting of the TLS client certificate and key if they
        have been provided, otherwise None.",
"def _docker(self, method, *args, **kwargs):
        """"""wrapper for calling docker methods

        to be passed to ThreadPoolExecutor
        """"""
        m = getattr(self.client, method)
        return m(*args, **kwargs)","wrapper for calling docker methods

        to be passed to ThreadPoolExecutor",
"def docker(self, method, *args, **kwargs):
        """"""Call a docker method in a background thread

        returns a Future
        """"""
        return self.executor.submit(self._docker, method, *args, **kwargs)","Call a docker method in a background thread

        returns a Future",
"def filter_queryset(self, value, queryset):
        """"""Check lower-cased email is unique.""""""
        return super(UniqueEmailValidator, self).filter_queryset(
            value.lower(),
            queryset,
        )",Check lower-cased email is unique.,
"def update(self, instance, validated_data):
        """"""Set the new password for the user.""""""
        instance.set_password(validated_data['new_password'])
        instance.save()
        return instance",Set the new password for the user.,
"def update_expiry(self, commit=True):
        """"""Update token's expiration datetime on every auth action.""""""
        self.expires = update_expiry(self.created)
        if commit:
            self.save()",Update token's expiration datetime on every auth action.,
"def password_reset_email_context(notification):
    """"""Email context to reset a user password.""""""
    return {
        'protocol': 'https',
        'uid': notification.user.generate_uid(),
        'token': notification.user.generate_token(),
        'site': notification.site,
    }",Email context to reset a user password.,
"def password_reset_email_handler(notification):
    """"""Password reset email handler.""""""
    base_subject = _('{domain} password reset').format(domain=notification.site.domain)
    subject = getattr(settings, 'DUM_PASSWORD_RESET_SUBJECT', base_subject)
    notification.email_subject = subject
    email_handler(notification, password_reset_email_context)",Password reset email handler.,
"def validation_email_handler(notification):
    """"""Validation email handler.""""""
    base_subject = _('{domain} account validate').format(domain=notification.site.domain)
    subject = getattr(settings, 'DUM_VALIDATE_EMAIL_SUBJECT', base_subject)
    notification.email_subject = subject
    email_handler(notification, validation_email_context)",Validation email handler.,
"def widget(self, param_name):
        """"""Get widget for param_name""""""
        if param_name not in self._widgets:
            self._widgets[param_name] = self._make_widget(param_name)
        return self._widgets[param_name]",Get widget for param_name,
"def TextWidget(*args, **kw):
    """"""Forces a parameter value to be text""""""
    kw['value'] = str(kw['value'])
    kw.pop('options', None)
    return TextInput(*args,**kw)",Forces a parameter value to be text,
"def named_objs(objlist):
    """"""
    Given a list of objects, returns a dictionary mapping from
    string name for the object to the object itself.
    """"""
    objs = []
    for k, obj in objlist:
        if hasattr(k, '__name__'):
            k = k.__name__
        else:
            k = as_unicode(k)
        objs.append((k, obj))
    return objs","Given a list of objects, returns a dictionary mapping from
    string name for the object to the object itself.",
"def get_method_owner(meth):
    """"""
    Returns the instance owning the supplied instancemethod or
    the class owning the supplied classmethod.
    """"""
    if inspect.ismethod(meth):
        if sys.version_info < (3,0):
            return meth.im_class if meth.im_self is None else meth.im_self
        else:
            return meth.__self__","Returns the instance owning the supplied instancemethod or
    the class owning the supplied classmethod.",
"def ping(self, params=None):
        """""" Returns True if the cluster is up, False otherwise. """"""
        try:
            self.transport.perform_request('HEAD', '/', params=params)
        except TransportError:
            raise gen.Return(False)
        raise gen.Return(True)","Returns True if the cluster is up, False otherwise.",
"def info(self, params=None):
        """"""Get the basic info from the current cluster.

        :rtype: dict

        """"""
        _, data = yield self.transport.perform_request('GET', '/',
                                                       params=params)
        raise gen.Return(data)","Get the basic info from the current cluster.

        :rtype: dict",
"def cpu_total_load(self):
        """"""Total CPU load for Synology DSM""""""
        system_load = self.cpu_system_load
        user_load = self.cpu_user_load
        other_load = self.cpu_other_load

        if system_load is not None and \
           user_load is not None and \
           other_load is not None:
            return system_load + user_load + other_load",Total CPU load for Synology DSM,
"def _get_network(self, network_id):
        """"""Function to get specific network (eth0, total, etc)""""""
        if self._data is not None:
            for network in self._data[""network""]:
                if network[""device""] == network_id:
                    return network","Function to get specific network (eth0, total, etc)",
"def network_up(self, human_readable=True):
        """"""Total upload speed being used""""""
        network = self._get_network(""total"")
        if network is not None:
            return_data = int(network[""tx""])
            if human_readable:
                return SynoFormatHelper.bytes_to_readable(
                    return_data)
            else:
                return return_data",Total upload speed being used,
"def volumes(self):
        """"""Returns all available volumes""""""
        if self._data is not None:
            volumes = []
            for volume in self._data[""volumes""]:
                volumes.append(volume[""id""])
            return volumes",Returns all available volumes,
"def _get_volume(self, volume_id):
        """"""Returns a specific volume""""""
        if self._data is not None:
            for volume in self._data[""volumes""]:
                if volume[""id""] == volume_id:
                    return volume",Returns a specific volume,
"def disks(self):
        """"""Returns all available (internal) disks""""""
        if self._data is not None:
            disks = []
            for disk in self._data[""disks""]:
                disks.append(disk[""id""])
            return disks",Returns all available (internal) disks,
"def _get_disk(self, disk_id):
        """"""Returns a specific disk""""""
        if self._data is not None:
            for disk in self._data[""disks""]:
                if disk[""id""] == disk_id:
                    return disk",Returns a specific disk,
"def utilisation(self):
        """"""Getter for various Utilisation variables""""""
        if self._utilisation is None:
            api = ""SYNO.Core.System.Utilization""
            url = ""%s/entry.cgi?api=%s&version=1&method=get"" % (
                self.base_url,
                api)
            self._utilisation = SynoUtilization(self._get_url(url))
        return self._utilisation",Getter for various Utilisation variables,
"def storage(self):
        """"""Getter for various Storage variables""""""
        if self._storage is None:
            api = ""SYNO.Storage.CGI.Storage""
            url = ""%s/entry.cgi?api=%s&version=1&method=load_info"" % (
                self.base_url,
                api)
            self._storage = SynoStorage(self._get_url(url))
        return self._storage",Getter for various Storage variables,
"def tenant_token(self):
        """"""The cached token of the current tenant.""""""
        rv = getattr(self, '_tenant_token', None)
        if rv is None:
            rv = self._tenant_token = self.tenant.get_token()
        return rv",The cached token of the current tenant.,
"def build_attrs(self, extra_attrs=None, **kwargs):
        ""Helper function for building an attribute dictionary.""
        self.attrs = self.widget.build_attrs(extra_attrs=None, **kwargs)
        return self.attrs",Helper function for building an attribute dictionary.,
"def with_apps(*apps):
    """"""
    Class decorator that makes sure the passed apps are present in
    INSTALLED_APPS.
    """"""
    apps_set = set(settings.INSTALLED_APPS)
    apps_set.update(apps)
    return override_settings(INSTALLED_APPS=list(apps_set))","Class decorator that makes sure the passed apps are present in
    INSTALLED_APPS.",
"def without_apps(*apps):
    """"""
    Class decorator that makes sure the passed apps are not present in
    INSTALLED_APPS.
    """"""
    apps_list = [a for a in settings.INSTALLED_APPS if a not in apps]
    return override_settings(INSTALLED_APPS=apps_list)","Class decorator that makes sure the passed apps are not present in
    INSTALLED_APPS.",
"def get_global_settings(self):
        """"""
        Return a dictionary of all global_settings values.
        """"""
        return dict((key, getattr(global_settings, key)) for key in dir(global_settings)
                    if key.isupper())",Return a dictionary of all global_settings values.,
"def _set_app_info(self):
		""""""
		Set the app info (id & secret) read from the config file on the Reddit object
		""""""
		redirect_url = ""http://{0}:{1}/{2}"".format(SERVER_URL, SERVER_PORT,
												   SERVER_REDIRECT_PATH)
		self.r.set_oauth_app_info(self._get_value(CONFIGKEY_APP_KEY),
								  self._get_value(CONFIGKEY_APP_SECRET),
								  redirect_url)",Set the app info (id & secret) read from the config file on the Reddit object,
"def _change_value(self, key, value):
		""""""
		Change the value of the given key in the given file to the given value
		""""""
		if not self.config.has_section(key[0]):
			self.config.add_section(key[0])

		self.config.set(key[0], key[1], str(value))

		with open(self.configfile, ""w"") as f:
			self.config.write(f)",Change the value of the given key in the given file to the given value,
"def _start_webserver(self, authorize_url=None):
		""""""
		Start the webserver that will receive the code
		""""""
		server_address = (SERVER_URL, SERVER_PORT)
		self.server = HTTPServer(server_address, OAuth2UtilRequestHandler)
		self.server.response_code = None
		self.server.authorize_url = authorize_url
		t = Thread(target=self.server.serve_forever)
		t.daemon = True
		t.start()",Start the webserver that will receive the code,
"def _wait_for_response(self):
		""""""
		Wait until the user accepted or rejected the request
		""""""
		while not self.server.response_code:
			time.sleep(2)
		time.sleep(5)
		self.server.shutdown()",Wait until the user accepted or rejected the request,
"def _check_token_present(self):
		""""""
		Check whether the tokens are set and request new ones if not
		""""""
		try:
			self._get_value(CONFIGKEY_TOKEN)
			self._get_value(CONFIGKEY_REFRESH_TOKEN)
			self._get_value(CONFIGKEY_REFRESHABLE)
		except KeyError:
			self._log(""Request new Token (CTP)"")
			self._get_new_access_information()",Check whether the tokens are set and request new ones if not,
"def clean_dict(dict):
    """"""Remove all keys with Nones as values

    >>> clean_dict({'key': None})
    {}
    >>> clean_dict({'empty_s': ''})
    {'empty_s': ''}
    """"""
    if sys.version_info[0] < 3:
        return {k: v for k, v in dict.iteritems() if v is not None}
    else:
        return {k: v for k, v in dict.items() if v is not None}","Remove all keys with Nones as values

    >>> clean_dict({'key': None})
    {}
    >>> clean_dict({'empty_s': ''})
    {'empty_s': ''}",
"def transform(line, known_fields=ENRICHED_EVENT_FIELD_TYPES, add_geolocation_data=True):
    """"""
    Convert a Snowplow enriched event TSV into a JSON
    """"""
    return jsonify_good_event(line.split('\t'), known_fields, add_geolocation_data)",Convert a Snowplow enriched event TSV into a JSON,
"def pformat_sql_html(sql):
    """"""
    Highlight common SQL words in a string.
    """"""
    sql = escape(sql)
    sql = RE_SQL_NL.sub(u'<br>\n\\1', sql)
    sql = RE_SQL.sub(u'<strong>\\1</strong>', sql)
    return sql",Highlight common SQL words in a string.,
"def pformat_dict_summary_html(dict):
    """"""
    Briefly print the dictionary keys.
    """"""
    if not dict:
        return '   {}'

    html = []
    for key, value in sorted(six.iteritems(dict)):
        if not isinstance(value, DICT_EXPANDED_TYPES):
            value = '...'

        html.append(_format_dict_item(key, value))

    return mark_safe(u'<br/>'.join(html))",Briefly print the dictionary keys.,
"def format(self, object, context, maxlevels, level):
        """"""
        Format an item in the result.
        Could be a dictionary key, value, etc..
        """"""
        try:
            return PrettyPrinter.format(self, object, context, maxlevels, level)
        except HANDLED_EXCEPTIONS as e:
            return _format_exception(e), True, False","Format an item in the result.
        Could be a dictionary key, value, etc..",
"def _format(self, object, stream, indent, allowance, context, level):
        """"""
        Recursive part of the formatting
        """"""
        try:
            PrettyPrinter._format(self, object, stream, indent, allowance, context, level)
        except Exception as e:
            stream.write(_format_exception(e))",Recursive part of the formatting,
"def get_latex_maybe_optional_arg(s, pos, **parse_flags):
    """"""
    Attempts to parse an optional argument. Returns a tuple `(groupnode, pos, len)` if
    success, otherwise returns None.

    .. deprecated:: 1.0
       Please use :py:meth:`LatexWalker.get_latex_maybe_optional_arg()` instead.
    """"""

    return LatexWalker(s, **parse_flags).get_latex_maybe_optional_arg(pos=pos)","Attempts to parse an optional argument. Returns a tuple `(groupnode, pos, len)` if
    success, otherwise returns None.

    .. deprecated:: 1.0
       Please use :py:meth:`LatexWalker.get_latex_maybe_optional_arg()` instead.",
"def latex_to_text(self, latex, **parse_flags):
        """"""
        Parses the given `latex` code and returns its textual representation.

        The `parse_flags` are the flags to give on to the
        :py:class:`pylatexenc.latexwalker.LatexWalker` constructor.
        """"""
        return self.nodelist_to_text(latexwalker.LatexWalker(latex, **parse_flags).get_latex_nodes()[0])","Parses the given `latex` code and returns its textual representation.

        The `parse_flags` are the flags to give on to the
        :py:class:`pylatexenc.latexwalker.LatexWalker` constructor.",
"def get_organisation_information(self, query_params=None):
        '''
        Get information fot this organisation. Returns a dictionary of values.
        '''
        return self.fetch_json(
            uri_path=self.base_uri,
            query_params=query_params or {}
        )",Get information fot this organisation. Returns a dictionary of values.,
"def update_organisation(self, query_params=None):
        '''
        Update this organisations information. Returns a new organisation
        object.
        '''
        organisation_json = self.fetch_json(
            uri_path=self.base_uri,
            http_method='PUT',
            query_params=query_params or {}
        )

        return self.create_organisation(organisation_json)","Update this organisations information. Returns a new organisation
        object.",
"def remove_member(self, member_id):
        '''
        Remove a member from the organisation.Returns JSON of all members if
        successful or raises an Unauthorised exception if not.
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/members/%s' % member_id,
            http_method='DELETE'
        )","Remove a member from the organisation.Returns JSON of all members if
        successful or raises an Unauthorised exception if not.",
"def get_list_information(self, query_params=None):
        '''
        Get information for this list. Returns a dictionary of values.
        '''
        return self.fetch_json(
            uri_path=self.base_uri,
            query_params=query_params or {}
        )",Get information for this list. Returns a dictionary of values.,
"def add_card(self, query_params=None):
        '''
        Create a card for this list. Returns a Card object.
        '''
        card_json = self.fetch_json(
            uri_path=self.base_uri + '/cards',
            http_method='POST',
            query_params=query_params or {}
        )

        return self.create_card(card_json)",Create a card for this list. Returns a Card object.,
"def get_label_information(self, query_params=None):
        '''
        Get all information for this Label. Returns a dictionary of values.
        '''
        return self.fetch_json(
            uri_path=self.base_uri,
            query_params=query_params or {}
        )",Get all information for this Label. Returns a dictionary of values.,
"def get_items(self, query_params=None):
        '''
        Get all the items for this label. Returns a list of dictionaries.
        Each dictionary has the values for an item.
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/checkItems',
            query_params=query_params or {}
        )","Get all the items for this label. Returns a list of dictionaries.
        Each dictionary has the values for an item.",
"def _update_label_name(self, name):
        '''
        Update the current label's name. Returns a new Label object.
        '''
        label_json = self.fetch_json(
            uri_path=self.base_uri,
            http_method='PUT',
            query_params={'name': name}
        )

        return self.create_label(label_json)",Update the current label's name. Returns a new Label object.,
"def _update_label_dict(self, query_params={}):
        '''
        Update the current label. Returns a new Label object.
        '''
        label_json = self.fetch_json(
            uri_path=self.base_uri,
            http_method='PUT',
            query_params=query_params
        )

        return self.create_label(label_json)",Update the current label. Returns a new Label object.,
"def get_card_information(self, query_params=None):
        '''
        Get information for this card. Returns a dictionary of values.
        '''
        return self.fetch_json(
            uri_path=self.base_uri,
            query_params=query_params or {}
        )",Get information for this card. Returns a dictionary of values.,
"def get_board(self, **query_params):
        '''
        Get board information for this card. Returns a Board object.

        Returns:
            Board: The board this card is attached to
        '''
        board_json = self.get_board_json(self.base_uri,
                                         query_params=query_params)
        return self.create_board(board_json)","Get board information for this card. Returns a Board object.

        Returns:
            Board: The board this card is attached to",
"def get_list(self, **query_params):
        '''
        Get list information for this card. Returns a List object.

        Returns:
            List: The list this card is attached to
        '''
        list_json = self.get_list_json(self.base_uri,
                                       query_params=query_params)
        return self.create_list(list_json)","Get list information for this card. Returns a List object.

        Returns:
            List: The list this card is attached to",
"def add_comment(self, comment_text):
        '''
        Adds a comment to this card by the current user.
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/actions/comments',
            http_method='POST',
            query_params={'text': comment_text}
        )",Adds a comment to this card by the current user.,
"def add_checklist(self, query_params=None):
        '''
        Add a checklist to this card. Returns a Checklist object.
        '''
        checklist_json = self.fetch_json(
            uri_path=self.base_uri + '/checklists',
            http_method='POST',
            query_params=query_params or {}
        )

        return self.create_checklist(checklist_json)",Add a checklist to this card. Returns a Checklist object.,
"def _add_label_from_dict(self, query_params=None):
        '''
        Add a label to this card, from a dictionary.
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/labels',
            http_method='POST',
            query_params=query_params or {}
        )","Add a label to this card, from a dictionary.",
"def _add_label_from_class(self, label=None):
        '''
        Add an existing label to this card.
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/idLabels',
            http_method='POST',
            query_params={'value': label.id}
        )",Add an existing label to this card.,
"def get_member_information(self, query_params=None):
        '''
        Get Information for a member. Returns a dictionary of values.

        Returns:
            dict
        '''
        return self.fetch_json(
            uri_path=self.base_uri,
            query_params=query_params or {}
        )","Get Information for a member. Returns a dictionary of values.

        Returns:
            dict",
"def singledispatchmethod(method):
    '''
    Enable singledispatch for class methods.

    See http://stackoverflow.com/a/24602374/274318
    '''
    dispatcher = singledispatch(method)
    def wrapper(*args, **kw):
        return dispatcher.dispatch(args[1].__class__)(*args, **kw)
    wrapper.register = dispatcher.register
    update_wrapper(wrapper, dispatcher)
    return wrapper","Enable singledispatch for class methods.

    See http://stackoverflow.com/a/24602374/274318",
"def create_checklist_item(self, card_id, checklist_id, checklistitem_json, **kwargs):
        '''
        Create a ChecklistItem object from JSON object
        '''
        return self.client.create_checklist_item(card_id, checklist_id, checklistitem_json, **kwargs)",Create a ChecklistItem object from JSON object,
"def get_board_information(self, query_params=None):
        '''
        Get all information for this board. Returns a dictionary of values.
        '''
        return self.fetch_json(
            uri_path='/boards/' + self.id,
            query_params=query_params or {}
        )",Get all information for this board. Returns a dictionary of values.,
"def get_card(self, card_id, **query_params):
        '''
        Get a Card for a given card id. Returns a Card object.

        Returns:
            Card: The card with the given card_id
        '''
        card_json = self.fetch_json(
            uri_path=self.base_uri + '/cards/' + card_id
        )

        return self.create_card(card_json)","Get a Card for a given card id. Returns a Card object.

        Returns:
            Card: The card with the given card_id",
"def get_checklists( self ):
        """"""
        Get the checklists for this board. Returns a list of Checklist objects.
        """"""
        checklists = self.getChecklistsJson( self.base_uri )

        checklists_list = []
        for checklist_json in checklists:
            checklists_list.append( self.createChecklist( checklist_json ) )

        return checklists_list",Get the checklists for this board. Returns a list of Checklist objects.,
"def update_board(self, query_params=None):
        '''
        Update this board's information. Returns a new board.
        '''
        board_json = self.fetch_json(
            uri_path=self.base_uri,
            http_method='PUT',
            query_params=query_params or {}
        )

        return self.create_board(board_json)",Update this board's information. Returns a new board.,
"def add_list(self, query_params=None):
        '''
        Create a list for a board. Returns a new List object.
        '''
        list_json = self.fetch_json(
            uri_path=self.base_uri + '/lists',
            http_method='POST',
            query_params=query_params or {}
        )

        return self.create_list(list_json)",Create a list for a board. Returns a new List object.,
"def add_label(self, query_params=None):
        '''
        Create a label for a board. Returns a new Label object.
        '''
        list_json = self.fetch_json(
            uri_path=self.base_uri + '/labels',
            http_method='POST',
            query_params=query_params or {}
        )

        return self.create_label(list_json)",Create a label for a board. Returns a new Label object.,
"def get_card(self):
        '''
        Get card this checklist is on.
        '''
        card_id = self.get_checklist_information().get('idCard', None)
        if card_id:
            return self.client.get_card(card_id)",Get card this checklist is on.,
"def update_checklist(self, name):
        '''
        Update the current checklist. Returns a new Checklist object.
        '''
        checklist_json = self.fetch_json(
            uri_path=self.base_uri,
            http_method='PUT',
            query_params={'name': name}
        )

        return self.create_checklist(checklist_json)",Update the current checklist. Returns a new Checklist object.,
"def add_item(self, query_params=None):
        '''
        Add an item to this checklist. Returns a dictionary of values of new
        item.
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/checkItems',
            http_method='POST',
            query_params=query_params or {}
        )","Add an item to this checklist. Returns a dictionary of values of new
        item.",
"def remove_item(self, item_id):
        '''
        Deletes an item from this checklist.
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/checkItems/' + item_id,
            http_method='DELETE'
        )",Deletes an item from this checklist.,
"def add_authorisation(self, query_params):
        '''
        Adds the API key and user auth token to the query parameters
        '''
        query_params['key'] = self.api_key

        if self.user_auth_token:
            query_params['token'] = self.user_auth_token

        return query_params",Adds the API key and user auth token to the query parameters,
"def check_errors(self, uri, response):
        '''
        Check HTTP reponse for known errors
        '''
        if response.status == 401:
            raise trolly.Unauthorised(uri, response)

        if response.status != 200:
            raise trolly.ResourceUnavailable(uri, response)",Check HTTP reponse for known errors,
"def build_uri(self, path, query_params):
        '''
        Build the URI for the API call.
        '''
        url = 'https://api.trello.com/1' + self.clean_path(path)
        url += '?' + urlencode(query_params)

        return url",Build the URI for the API call.,
"def create_board(self, board_json):
        '''
        Create Board object from a JSON object

        Returns:
            Board: The board from the given `board_json`.
        '''
        return trolly.board.Board(
            trello_client=self,
            board_id=board_json['id'],
            name=board_json['name'],
            data=board_json,
        )","Create Board object from a JSON object

        Returns:
            Board: The board from the given `board_json`.",
"def create_label(self, label_json):
        '''
        Create Label object from JSON object

        Returns:
            Label: The label from the given `label_json`.
        '''
        return trolly.label.Label(
            trello_client=self,
            label_id=label_json['id'],
            name=label_json['name'],
            data=label_json,
        )","Create Label object from JSON object

        Returns:
            Label: The label from the given `label_json`.",
"def create_list(self, list_json):
        '''
        Create List object from JSON object

        Returns:
            List: The list from the given `list_json`.
        '''
        return trolly.list.List(
            trello_client=self,
            list_id=list_json['id'],
            name=list_json['name'],
            data=list_json,
        )","Create List object from JSON object

        Returns:
            List: The list from the given `list_json`.",
"def create_card(self, card_json):
        '''
        Create a Card object from JSON object

        Returns:
            Card: The card from the given `card_json`.
        '''
        return trolly.card.Card(
            trello_client=self,
            card_id=card_json['id'],
            name=card_json['name'],
            data=card_json,
        )","Create a Card object from JSON object

        Returns:
            Card: The card from the given `card_json`.",
"def create_member(self, member_json):
        '''
        Create a Member object from JSON object

        Returns:
            Member: The member from the given `member_json`.
        '''
        return trolly.member.Member(
            trello_client=self,
            member_id=member_json['id'],
            name=member_json['fullName'],
            data=member_json,
        )","Create a Member object from JSON object

        Returns:
            Member: The member from the given `member_json`.",
"def get_organisation(self, id, name=None):
        '''
        Get an organisation

        Returns:
            Organisation: The organisation with the given `id`
        '''
        return self.create_organisation(dict(id=id, name=name))","Get an organisation

        Returns:
            Organisation: The organisation with the given `id`",
"def get_board(self, id, name=None):
        '''
        Get a board

        Returns:
            Board: The board with the given `id`
        '''
        return self.create_board(dict(id=id, name=name))","Get a board

        Returns:
            Board: The board with the given `id`",
"def get_list(self, id, name=None):
        '''
        Get a list

        Returns:
            List: The list with the given `id`
        '''
        return self.create_list(dict(id=id, name=name))","Get a list

        Returns:
            List: The list with the given `id`",
"def get_card(self, id, name=None):
        '''
        Get a card

        Returns:
            Card: The card with the given `id`
        '''
        return self.create_card(dict(id=id, name=name))","Get a card

        Returns:
            Card: The card with the given `id`",
"def get_checklist(self, id, name=None):
        '''
        Get a checklist

        Returns:
            Checklist: The checklist with the given `id`
        '''
        return self.create_checklist(dict(id=id, name=name))","Get a checklist

        Returns:
            Checklist: The checklist with the given `id`",
"def get_member(self, id='me', name=None):
        '''
        Get a member or your current member if `id` wasn't given.

        Returns:
            Member: The member with the given `id`, defaults to the
            logged in member.
        '''
        return self.create_member(dict(id=id, fullName=name))","Get a member or your current member if `id` wasn't given.

        Returns:
            Member: The member with the given `id`, defaults to the
            logged in member.",
"def domain_from_url(url):
    """"""
    Get root domain from url.
    Will prune away query strings, url paths, protocol prefix and sub-domains
    Exceptions will be raised on invalid urls
    """"""
    ext = tldextract.extract(url)
    if not ext.suffix:
        raise InvalidURLException()
    new_url = ext.domain + ""."" + ext.suffix
    return new_url","Get root domain from url.
    Will prune away query strings, url paths, protocol prefix and sub-domains
    Exceptions will be raised on invalid urls",
"def main(argv=None):
    """"""Main command line interface.""""""
    if argv is None:
        argv = sys.argv[1:]

    cli = CommandLineTool()
    try:
        return cli.run(argv)
    except KeyboardInterrupt:
        print('Canceled')
        return 3",Main command line interface.,
"def setLogLevel(namespace=None, levelStr='info'):
    '''
    Set a new log level for a given namespace
    LevelStr is: 'critical', 'error', 'warn', 'info', 'debug'
    '''
    level = LogLevel.levelWithName(levelStr)
    logLevelFilterPredicate.setLogLevelForNamespace(namespace=namespace, level=level)","Set a new log level for a given namespace
    LevelStr is: 'critical', 'error', 'warn', 'info', 'debug'",
"def onPublish(self, topic, payload, qos, dup, retain, msgId):
        '''
        Callback Receiving messages from publisher
        '''
        log.debug(""msg={payload}"", payload=payload)",Callback Receiving messages from publisher,
"def onDisconnection(self, reason):
        '''
        get notfied of disconnections
        and get a deferred for a new protocol object (next retry)
        '''
        log.debug(""<Connection was lost !> <reason={r}>"", r=reason)
        self.whenConnected().addCallback(self.connectToBroker)","get notfied of disconnections
        and get a deferred for a new protocol object (next retry)",
"def makeId(self):
        '''Produce ids for Protocol packets, outliving their sessions'''
        self.id = (self.id + 1) % 65536
        self.id = self.id or 1   # avoid id 0
        return self.id","Produce ids for Protocol packets, outliving their sessions",
"def connect(self, request):
        '''
        Send a CONNECT control packet.
        '''
        state = self.__class__.__name__
        return defer.fail(MQTTStateError(""Unexpected connect() operation"", state))",Send a CONNECT control packet.,
"def handleCONNACK(self, response):
        '''
        Handles CONNACK packet from the server
        '''
        state = self.__class__.__name__
        log.error(""Unexpected {packet:7} packet received in {log_source}"", packet=""CONNACK"")",Handles CONNACK packet from the server,
"def encodeString(string):
    '''
    Encode an UTF-8 string into MQTT format. 
    Returns a bytearray
    '''
    encoded = bytearray(2)
    encoded.extend(bytearray(string, encoding='utf-8'))
    l = len(encoded)-2
    if(l > 65535):
        raise StringValueError(l)
    encoded[0] = l >> 8
    encoded[1] = l & 0xFF
    return encoded","Encode an UTF-8 string into MQTT format. 
    Returns a bytearray",
"def decodeString(encoded):
    '''
    Decodes an UTF-8 string from an encoded MQTT bytearray.
    Returns the decoded string and renaining bytearray to be parsed
    '''
    length = encoded[0]*256 + encoded[1]
    return (encoded[2:2+length].decode('utf-8'), encoded[2+length:])","Decodes an UTF-8 string from an encoded MQTT bytearray.
    Returns the decoded string and renaining bytearray to be parsed",
"def encode16Int(value):
    '''
    Encodes a 16 bit unsigned integer into MQTT format.
    Returns a bytearray
    '''
    value      = int(value)
    encoded    = bytearray(2)
    encoded[0] = value >> 8
    encoded[1] = value & 0xFF
    return encoded","Encodes a 16 bit unsigned integer into MQTT format.
    Returns a bytearray",
"def encodeLength(value):
    '''
    Encodes value into a multibyte sequence defined by MQTT protocol.
    Used to encode packet length fields.
    '''
    encoded = bytearray()
    while True:
        digit = value % 128
        value //= 128
        if value > 0:
            digit |= 128
        encoded.append(digit)
        if value <= 0:
            break
    return encoded","Encodes value into a multibyte sequence defined by MQTT protocol.
    Used to encode packet length fields.",
"def decodeLength(encoded):
    '''
    Decodes a variable length value defined in the MQTT protocol.
    This value typically represents remaining field lengths
    '''
    value      = 0
    multiplier = 1
    for i in encoded:
        value += (i & 0x7F) * multiplier
        multiplier *= 0x80
        if (i & 0x80) != 0x80:
            break
    return value","Decodes a variable length value defined in the MQTT protocol.
    This value typically represents remaining field lengths",
"def encode(self):
        '''
        Encode and store a DISCONNECT control packet.
        '''
        header    = bytearray(2)
        header[0] = 0xE0
        self.encoded = header
        return str(header) if PY2 else bytes(header)",Encode and store a DISCONNECT control packet.,
"def encode(self):
        '''
        Encode and store an UNSUBACK control packet
        '''
        header    = bytearray(1)
        varHeader = encode16Int(self.msgId)
        header[0] = 0xB0 
        header.extend(encodeLength(len(varHeader)))
        header.extend(varHeader)
        self.encoded = header
        return str(header) if PY2 else bytes(header)",Encode and store an UNSUBACK control packet,
"def decode(self, packet):
        '''
        Decode a PUBREL control packet. 
        '''
        self.encoded = packet
        lenLen = 1
        while packet[lenLen] & 0x80:
            lenLen += 1
        packet_remaining = packet[lenLen+1:]
        self.msgId  = decode16Int(packet_remaining)
        self.dup = (packet[0] & 0x08) == 0x08",Decode a PUBREL control packet.,
"def request(self, method, **kwargs):
        """"""
        Send request to API.

        :param method: `str` method name.
        :returns: `dict` response.
        """"""
        kwargs.setdefault('v', self.__version)

        if self.__token is not None:
            kwargs.setdefault('access_token', self.__token)

        return requests.get(self.get_url(method, **kwargs)).json()","Send request to API.

        :param method: `str` method name.
        :returns: `dict` response.",
"def refresh(self):
        """""" Refresh the list of blocks to the disk, collectively """"""
        if self.comm.rank == 0:
            self._blocks = self.list_blocks()
        else:
            self._blocks = None
        self._blocks = self.comm.bcast(self._blocks)","Refresh the list of blocks to the disk, collectively",
"def get_total_n_points(d):
    """"""
    Returns the total number of data points in values of dict.

    Paramters
    ---------
    d : dict
    """"""
    n = 0
    for di in d.values():
        n += len(di)
    return n","Returns the total number of data points in values of dict.

    Paramters
    ---------
    d : dict",
"def get_total_time_span(d):
    """"""
    Returns total length of analysis.
    """"""

    tmax = 0
    for di in d.values():
        if di.uTime.max() > tmax:
            tmax = di.uTime.max()
    
    return tmax",Returns total length of analysis.,
"def pretty_element(s):
    """"""
    Returns formatted element name.

    Parameters
    ----------
    s : str
        of format [A-Z][a-z]?[0-9]+

    Returns
    -------
    str
        LaTeX formatted string with superscript numbers.
    """"""
    el = re.match('.*?([A-z]{1,3}).*?', s).groups()[0]
    m = re.match('.*?([0-9]{1,3}).*?', s).groups()[0]

    return '$^{' + m + '}$' + el","Returns formatted element name.

    Parameters
    ----------
    s : str
        of format [A-Z][a-z]?[0-9]+

    Returns
    -------
    str
        LaTeX formatted string with superscript numbers.",
"def analyte_2_namemass(s):
    """"""
    Converts analytes in format '27Al' to 'Al27'.

    Parameters
    ----------
    s : str
        of format [A-z]{1,3}[0-9]{1,3}

    Returns
    -------
    str
        Name in format [0-9]{1,3}[A-z]{1,3}
    """"""
    el = re.match('.*?([A-z]{1,3}).*?', s).groups()[0]
    m = re.match('.*?([0-9]{1,3}).*?', s).groups()[0]

    return el + m","Converts analytes in format '27Al' to 'Al27'.

    Parameters
    ----------
    s : str
        of format [A-z]{1,3}[0-9]{1,3}

    Returns
    -------
    str
        Name in format [0-9]{1,3}[A-z]{1,3}",
"def analyte_2_massname(s):
    """"""
    Converts analytes in format 'Al27' to '27Al'.

    Parameters
    ----------
    s : str
        of format [0-9]{1,3}[A-z]{1,3}

    Returns
    -------
    str
        Name in format [A-z]{1,3}[0-9]{1,3}
    """"""
    el = re.match('.*?([A-z]{1,3}).*?', s).groups()[0]
    m = re.match('.*?([0-9]{1,3}).*?', s).groups()[0]

    return m + el","Converts analytes in format 'Al27' to '27Al'.

    Parameters
    ----------
    s : str
        of format [0-9]{1,3}[A-z]{1,3}

    Returns
    -------
    str
        Name in format [A-z]{1,3}[0-9]{1,3}",
"def findmins(x, y):
    """""" Function to find local minima.

    Parameters
    ----------
    x, y : array_like
        1D arrays of the independent (x) and dependent (y) variables.

    Returns
    -------
    array_like
        Array of points in x where y has a local minimum.
    """"""
    return x[np.r_[False, y[1:] < y[:-1]] & np.r_[y[:-1] < y[1:], False]]","Function to find local minima.

    Parameters
    ----------
    x, y : array_like
        1D arrays of the independent (x) and dependent (y) variables.

    Returns
    -------
    array_like
        Array of points in x where y has a local minimum.",
"def get_defined_srms(srm_file):
    """"""
    Returns list of SRMS defined in the SRM database
    """"""
    srms = read_table(srm_file)
    return np.asanyarray(srms.index.unique())",Returns list of SRMS defined in the SRM database,
"def read_latoolscfg():
    """"""
    Reads configuration, returns a ConfigParser object.

    Distinct from read_configuration, which returns a dict.
    """"""
    config_file = pkgrs.resource_filename('latools', 'latools.cfg')
    cf = configparser.ConfigParser()
    cf.read(config_file)
    return config_file, cf","Reads configuration, returns a ConfigParser object.

    Distinct from read_configuration, which returns a dict.",
"def threshold(values, threshold):
    """"""
    Return boolean arrays where a >= and < threshold.

    Parameters
    ----------
    values : array-like
        Array of real values.
    threshold : float
        Threshold value
    
    Returns
    -------
    (below, above) : tuple or boolean arrays
    """"""
    values = nominal_values(values)
    return (values < threshold, values >= threshold)","Return boolean arrays where a >= and < threshold.

    Parameters
    ----------
    values : array-like
        Array of real values.
    threshold : float
        Threshold value
    
    Returns
    -------
    (below, above) : tuple or boolean arrays",
"def ablation_times(self):
        """"""
        Function for calculating the ablation time for each
        ablation.

        Returns
        -------
            dict of times for each ablation.
        """"""
        ats = {}
        for n in np.arange(self.n) + 1:
            t = self.Time[self.ns == n]
            ats[n - 1] = t.max() - t.min()
        return ats","Function for calculating the ablation time for each
        ablation.

        Returns
        -------
            dict of times for each ablation.",
"def rangecalc(x, y=None, pad=0.05):
    """"""
    Calculate padded range limits for axes.
    """"""        
    mn = np.nanmin([np.nanmin(x), np.nanmin(y)])
    mx = np.nanmax([np.nanmax(x), np.nanmax(y)])
    rn = mx - mn
    
    return (mn - pad * rn, mx + pad * rn)",Calculate padded range limits for axes.,
"def rangecalcx(x, pad=0.05):
    """"""
    Calculate padded range limits for axes.
    """"""        
    mn = np.nanmin(x)
    mx = np.nanmax(x)
    rn = mx - mn

    return (mn - pad * rn, mx + pad * rn)",Calculate padded range limits for axes.,
"def zero_break(stack: tuple) -> tuple:
    '''Handle Resets in input stack.
    Breaks the input stack if a Reset operator (zero) is encountered.
    '''
    reducer = lambda x, y: tuple() if y == 0 else x + (y,)
    return reduce(reducer, stack, tuple())","Handle Resets in input stack.
    Breaks the input stack if a Reset operator (zero) is encountered.",
"def dedup(stack: tuple) -> tuple:
    '''Remove duplicates from the stack in first-seen order.'''
    # Initializes with an accumulator and then reduces the stack with first match
    # deduplication.
    reducer = lambda x, y: x if y in x else x + (y,)
    return reduce(reducer, stack, tuple())",Remove duplicates from the stack in first-seen order.,
"def gauss(x, *p):
    """""" Gaussian function.

    Parameters
    ----------
    x : array_like
        Independent variable.
    *p : parameters unpacked to A, mu, sigma
        A = amplitude, mu = centre, sigma = width

    Return
    ------
    array_like
        gaussian descriped by *p.
    """"""
    A, mu, sigma = p
    return A * np.exp(-0.5 * (-mu + x)**2 / sigma**2)","Gaussian function.

    Parameters
    ----------
    x : array_like
        Independent variable.
    *p : parameters unpacked to A, mu, sigma
        A = amplitude, mu = centre, sigma = width

    Return
    ------
    array_like
        gaussian descriped by *p.",
"def stderr(a):
    """"""
    Calculate the standard error of a.
    """"""
    return np.nanstd(a) / np.sqrt(sum(np.isfinite(a)))",Calculate the standard error of a.,
"def H15_se(x):
    """"""
    Calculate the Huber (H15) Robust standard deviation of x.

    For details, see:
        http://www.cscjp.co.jp/fera/document/ANALYSTVol114Decpgs1693-97_1989.pdf
        http://www.rsc.org/images/robust-statistics-technical-brief-6_tcm18-214850.pdf
    """"""
    sd = H15_std(x)
    return sd / np.sqrt(sum(np.isfinite(x)))","Calculate the Huber (H15) Robust standard deviation of x.

    For details, see:
        http://www.cscjp.co.jp/fera/document/ANALYSTVol114Decpgs1693-97_1989.pdf
        http://www.rsc.org/images/robust-statistics-technical-brief-6_tcm18-214850.pdf",
"def filter_clear(self, samples=None, subset=None):
        """"""
        Clears (deletes) all data filters.
        """"""
        if samples is not None:
            subset = self.make_subset(samples)

        samples = self._get_samples(subset)

        for s in samples:
            self.data[s].filt.clear()",Clears (deletes) all data filters.,
"def fold_map(self, fa: F[A], z: B, f: Callable[[A], B], g: Callable[[Z, B], Z]=operator.add) -> Z:
        ''' map `f` over the traversable, then fold over the result
        using the supplied initial element `z` and operation `g`,
        defaulting to addition for the latter.
        '''
        mapped = Functor.fatal(type(fa)).map(fa, f)
        return self.fold_left(mapped)(z)(g)","map `f` over the traversable, then fold over the result
        using the supplied initial element `z` and operation `g`,
        defaulting to addition for the latter.",
"def bayes_scale(s):
    """"""
    Remove mean and divide by standard deviation, using bayes_kvm statistics.
    """"""
    if sum(~np.isnan(s)) > 1:
        bm, bv, bs = bayes_mvs(s[~np.isnan(s)])
        return (s - bm.statistic) / bs.statistic
    else:
        return np.full(s.shape, np.nan)","Remove mean and divide by standard deviation, using bayes_kvm statistics.",
"def median_scaler(s):
    """"""
    Remove median, divide by IQR.
    """"""
    if sum(~np.isnan(s)) > 2:
        ss = s[~np.isnan(s)]
        median = np.median(ss)
        IQR = np.diff(np.percentile(ss, [25, 75]))
        return (s - median) / IQR
    else:
        return np.full(s.shape, np.nan)","Remove median, divide by IQR.",
"def clear(self):
        """"""
        Clear all filters.
        """"""
        self.components = {}
        self.info = {}
        self.params = {}
        self.switches = {}
        self.keys = {}
        self.index = {}
        self.sets = {}
        self.maxset = -1
        self.n = 0
        for a in self.analytes:
            self.switches[a] = {}
        return",Clear all filters.,
"def clean(self):
        """"""
        Remove unused filters.
        """"""
        for f in sorted(self.components.keys()):
            unused = not any(self.switches[a][f] for a in self.analytes)
            if unused:
                self.remove(f)",Remove unused filters.,
"def get_info(self):
        """"""
        Get info for all filters.
        """"""
        out = ''
        for k in sorted(self.components.keys()):
            out += '{:s}: {:s}'.format(k, self.info[k]) + '\n'
        return(out)",Get info for all filters.,
"def _log(func):
    """"""
    Function for logging method calls and parameters
    """"""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        a = func(self, *args, **kwargs)
        self.log.append(func.__name__ + ' :: args={} kwargs={}'.format(args, kwargs))
        return a
    return wrapper",Function for logging method calls and parameters,
"async def send_message():
    """"""Example of sending a message.""""""
    jar = aiohttp.CookieJar(unsafe=True)
    websession = aiohttp.ClientSession(cookie_jar=jar)

    modem = eternalegypt.Modem(hostname=sys.argv[1], websession=websession)
    await modem.login(password=sys.argv[2])

    await modem.sms(phone=sys.argv[3], message=sys.argv[4])

    await modem.logout()
    await websession.close()",Example of sending a message.,
"def nbviewer_link(url):
    """"""Return the link to the Jupyter nbviewer for the given notebook url""""""
    if six.PY2:
        from urlparse import urlparse as urlsplit
    else:
        from urllib.parse import urlsplit
    info = urlsplit(url)
    domain = info.netloc
    url_type = 'github' if domain == 'github.com' else 'url'
    return 'https://nbviewer.jupyter.org/%s%s' % (url_type, info.path)",Return the link to the Jupyter nbviewer for the given notebook url,
"def thumbnail_div(self):
        """"""The string for creating the thumbnail of this example""""""
        return self.THUMBNAIL_TEMPLATE.format(
            snippet=self.get_description()[1], thumbnail=self.thumb_file,
            ref_name=self.reference)",The string for creating the thumbnail of this example,
"def code_div(self):
        """"""The string for creating a code example for the gallery""""""
        code_example = self.code_example
        if code_example is None:
            return None
        return self.CODE_TEMPLATE.format(
            snippet=self.get_description()[1], code=code_example,
            ref_name=self.reference)",The string for creating a code example for the gallery,
"def code_example(self):
        """"""The code example out of the notebook metadata""""""
        if self._code_example is not None:
            return self._code_example
        return getattr(self.nb.metadata, 'code_example', None)",The code example out of the notebook metadata,
"def supplementary_files(self):
        """"""The supplementary files of this notebook""""""
        if self._supplementary_files is not None:
            return self._supplementary_files
        return getattr(self.nb.metadata, 'supplementary_files', None)",The supplementary files of this notebook,
"def other_supplementary_files(self):
        """"""The supplementary files of this notebook""""""
        if self._other_supplementary_files is not None:
            return self._other_supplementary_files
        return getattr(self.nb.metadata, 'other_supplementary_files', None)",The supplementary files of this notebook,
"def url(self):
        """"""The url on jupyter nbviewer for this notebook or None if unknown""""""
        if self._url is not None:
            url = self._url
        else:
            url = getattr(self.nb.metadata, 'url', None)
        if url is not None:
            return nbviewer_link(url)",The url on jupyter nbviewer for this notebook or None if unknown,
"def get_out_file(self, ending='rst'):
        """"""get the output file with the specified `ending`""""""
        return os.path.splitext(self.outfile)[0] + os.path.extsep + ending",get the output file with the specified `ending`,
"def data_download(self, files):
        """"""Create the rst string to download supplementary data""""""
        if len(files) > 1:
            return self.DATA_DOWNLOAD % (
                ('\n\n' + ' '*8) + ('\n' + ' '*8).join(
                    '* :download:`%s`' % f for f in files))
        return self.DATA_DOWNLOAD % ':download:`%s`' % files[0]",Create the rst string to download supplementary data,
"def process_directories(self):
        """"""Create the rst files from the input directories in the
        :attr:`in_dir` attribute""""""
        for i, (base_dir, target_dir, paths) in enumerate(zip(
                self.in_dir, self.out_dir, map(os.walk, self.in_dir))):
            self._in_dir_count = i
            self.recursive_processing(base_dir, target_dir, paths)","Create the rst files from the input directories in the
        :attr:`in_dir` attribute",
"def process(thumbnail_file, size, **kwargs):
    """"""
    Post processors are functions that receive file objects,
    performs necessary operations and return the results as file objects.
    """"""
    from . import conf

    size_dict = conf.SIZES[size]
    for processor in size_dict['POST_PROCESSORS']:
        processor['processor'](thumbnail_file, **processor['kwargs'])

    return thumbnail_file","Post processors are functions that receive file objects,
    performs necessary operations and return the results as file objects.",
"def import_attribute(name):
    """"""
    Return an attribute from a dotted path name (e.g. ""path.to.func"").
    Copied from nvie's rq https://github.com/nvie/rq/blob/master/rq/utils.py
    """"""
    if hasattr(name, '__call__'):
        return name
    module_name, attribute = name.rsplit('.', 1)
    module = importlib.import_module(module_name)
    return getattr(module, attribute)","Return an attribute from a dotted path name (e.g. ""path.to.func"").
    Copied from nvie's rq https://github.com/nvie/rq/blob/master/rq/utils.py",
"def _refresh_cache(self):
        """"""Populate self._thumbnails.""""""
        self._thumbnails = {}
        metadatas = self.metadata_backend.get_thumbnails(self.source_image.name)
        for metadata in metadatas:
            self._thumbnails[metadata.size] = Thumbnail(metadata=metadata, storage=self.storage)",Populate self._thumbnails.,
"def all(self):
        """"""
        Return all thumbnails in a dict format.
        """"""
        if self._thumbnails is not None:
            return self._thumbnails
        self._refresh_cache()
        return self._thumbnails",Return all thumbnails in a dict format.,
"def create(self, size):
        """"""
        Creates and return a thumbnail of a given size.
        """"""
        thumbnail = images.create(self.source_image.name, size,
                                  self.metadata_backend, self.storage)
        return thumbnail",Creates and return a thumbnail of a given size.,
"def delete(self, size):
        """"""
        Deletes a thumbnail of a given size
        """"""
        images.delete(self.source_image.name, size,
                      self.metadata_backend, self.storage)
        del(self._thumbnails[size])",Deletes a thumbnail of a given size,
"def im():
    """""" Incoming message handler: forwarded by ForwardServerProvider """"""
    req = jsonex_loads(request.get_data())
    message = g.provider._receive_message(req['message'])
    return {'message': message}",Incoming message handler: forwarded by ForwardServerProvider,
"def status():
    """""" Incoming status handler: forwarded by ForwardServerProvider """"""
    req = jsonex_loads(request.get_data())
    status = g.provider._receive_status(req['status'])
    return {'status': status}",Incoming status handler: forwarded by ForwardServerProvider,
"def jsonex_loads(s):
    """""" Unserialize with JsonEx
    :rtype: dict
    """"""
    return json.loads(s.decode('utf-8'), cls=JsonExDecoder, classes=classes, exceptions=exceptions)","Unserialize with JsonEx
    :rtype: dict",
"def get_balance(self, address: str, erc20_address: str) -> int:
        """"""
        Get balance of address for `erc20_address`
        :param address: owner address
        :param erc20_address: erc20 token address
        :return: balance
        """"""
        return get_erc20_contract(self.w3, erc20_address).functions.balanceOf(address).call()","Get balance of address for `erc20_address`
        :param address: owner address
        :param erc20_address: erc20 token address
        :return: balance",
"def get_erc20_contract(w3: Web3, address=None):
    """"""
    Get ERC20 interface
    :param w3: Web3 instance
    :param address: address of the proxy contract
    :return: ERC 20 contract
    """"""
    return w3.eth.contract(address,
                           abi=ERC20_INTERFACE['abi'],
                           bytecode=ERC20_INTERFACE['bytecode'])","Get ERC20 interface
    :param w3: Web3 instance
    :param address: address of the proxy contract
    :return: ERC 20 contract",
"def signature_to_bytes(vrs: Tuple[int, int, int]) -> bytes:
    """"""
    Convert signature to bytes
    :param vrs: tuple of v, r, s
    :return: signature in form of {bytes32 r}{bytes32 s}{uint8 v}
    """"""

    byte_order = 'big'
    v, r, s = vrs

    return (r.to_bytes(32, byteorder=byte_order) +
            s.to_bytes(32, byteorder=byte_order) +
            v.to_bytes(1, byteorder=byte_order))","Convert signature to bytes
    :param vrs: tuple of v, r, s
    :return: signature in form of {bytes32 r}{bytes32 s}{uint8 v}",
"def signatures_to_bytes(signatures: List[Tuple[int, int, int]]) -> bytes:
    """"""
    Convert signatures to bytes
    :param signatures: list of tuples(v, r, s)
    :return: 65 bytes per signature
    """"""
    return b''.join([signature_to_bytes(vrs) for vrs in signatures])","Convert signatures to bytes
    :param signatures: list of tuples(v, r, s)
    :return: 65 bytes per signature",
"def estimate_tx_gas_with_web3(self, safe_address: str, to: str, value: int, data: bytes) -> int:
        """"""
        Estimate tx gas using web3
        """"""
        return self.ethereum_client.estimate_gas(safe_address, to, value, data, block_identifier='pending')",Estimate tx gas using web3,
"async def read(self, num_bytes=0) -> bytes:
        """"""
        Reads a given number of bytes

        :param bytecount: How many bytes to read, leave it at default
                          to read everything that is available
        :returns: incoming bytes
        """"""
        if num_bytes < 1:
            num_bytes = self.in_waiting or 1

        return await self._read(num_bytes)","Reads a given number of bytes

        :param bytecount: How many bytes to read, leave it at default
                          to read everything that is available
        :returns: incoming bytes",
"def _mimetext(self, text, subtype='plain'):
        """"""Creates a MIMEText object with the given subtype (default: 'plain')
        If the text is unicode, the utf-8 charset is used.
        """"""
        charset = self.charset or 'utf-8'
        return MIMEText(text, _subtype=subtype, _charset=charset)","Creates a MIMEText object with the given subtype (default: 'plain')
        If the text is unicode, the utf-8 charset is used.",
"def register_context_middleware(self, *middleware):
        """"""
        :param middleware: Middleware in order of execution
        """"""
        for m in middleware:
            if not is_generator(m):
                raise Exception('Middleware {} must be a Python generator callable.'.format(m))

        self._middleware.extend(middleware)",:param middleware: Middleware in order of execution,
"def from_module(module_name):
    """"""
    Load a configuration module and return a Config
    """"""
    d = importlib.import_module(module_name)
    config = {}
    for key in dir(d):
        if key.isupper():
            config[key] = getattr(d, key)
    return Config(config)",Load a configuration module and return a Config,
"def register_resources(self, **resources):
        """"""
        Register resources with the ResourceManager.
        """"""
        for key, resource in resources.items():
            if key in self._resources:
                raise AlreadyExistsException('A Service for {} is already registered.'.format(key))

            self._init_resource(key, resource)",Register resources with the ResourceManager.,
"def require(self, key):
        """"""
        Raises an exception if value for ``key`` is empty.
        """"""
        value = self.get(key)
        if not value:
            raise ValueError('""{}"" is empty.'.format(key))
        return value",Raises an exception if value for ``key`` is empty.,
"def ng(self, wavelength):
        '''
        The group index with respect to wavelength.

        Args:
            wavelength (float, list, None): The wavelength(s) the group
                index will be evaluated at.

        Returns:
            float, list: The group index at the target wavelength(s).
        '''
        return self.n(wavelength) - (wavelength*1.e-9)*self.nDer1(wavelength)","The group index with respect to wavelength.

        Args:
            wavelength (float, list, None): The wavelength(s) the group
                index will be evaluated at.

        Returns:
            float, list: The group index at the target wavelength(s).",
"def error(self, message):
        '''Suppress default exit behavior'''
        message = self._remessage_invalid_subparser(message)
        raise utils.UsageError(message)",Suppress default exit behavior,
"def read(*paths):
    """"""Build a file path from *paths* and return the contents.""""""
    with open(os.path.join(*paths), 'r') as filename:
        return filename.read()",Build a file path from *paths* and return the contents.,
"def _get_dependent_value(tag_values, dependent_tag_id):
        '''Extract (float) value of dependent tag or None if absent.'''
        try:
            values = tag_values[dependent_tag_id].split("","")
            return max([float(value) for value in values])
        except KeyError:
            return None
        except ValueError:
            return None",Extract (float) value of dependent tag or None if absent.,
"def splitlines(self, data):
        """"""
        Split data into lines where lines are separated by LINE_TERMINATORS.

        :param data: Any chunk of binary data.
        :return: List of lines without any characters at LINE_TERMINATORS.
        """"""
        return re.split(b'|'.join(self.LINE_TERMINATORS), data)","Split data into lines where lines are separated by LINE_TERMINATORS.

        :param data: Any chunk of binary data.
        :return: List of lines without any characters at LINE_TERMINATORS.",
"def read(self, read_size=-1):
        """"""
        Read given number of bytes from file.
        :param read_size: Number of bytes to read. -1 to read all.
        :return: Number of bytes read and data that was read.
        """"""
        read_str = self.file.read(read_size)
        return len(read_str), read_str","Read given number of bytes from file.
        :param read_size: Number of bytes to read. -1 to read all.
        :return: Number of bytes read and data that was read.",
"def prefix_line_terminator(self, data):
        """"""
        Return line terminator data begins with or None.
        """"""
        for t in self.LINE_TERMINATORS:
            if data.startswith(t):
                return t

        return None",Return line terminator data begins with or None.,
"def suffix_line_terminator(self, data):
        """"""
        Return line terminator data ends with or None.
        """"""
        for t in self.LINE_TERMINATORS:
            if data.endswith(t):
                return t

        return None",Return line terminator data ends with or None.,
"def format_tags(self):
        """"""Returns set of format tags.""""""
        tags = VcfRecord._EMPTY_SET
        if self.sample_tag_values:
            first_sample = list(self.sample_tag_values.keys())[0]
            tags = set(self.sample_tag_values[first_sample].keys())
        return tags",Returns set of format tags.,
"def _format_field(self):
        """"""Returns string representation of format field.""""""
        format_field = "".""
        if self.sample_tag_values:
            first_sample = list(self.sample_tag_values.keys())[0]
            tag_names = self.sample_tag_values[first_sample].keys()
            if tag_names:
                format_field = "":"".join(tag_names)
        return format_field",Returns string representation of format field.,
"def _sample_field(self, sample):
        """"""Returns string representation of sample-format values.

        Raises:
            KeyError: if requested sample is not defined.
        """"""
        tag_values = self.sample_tag_values[sample].values()
        if tag_values:
            return "":"".join(tag_values)
        else:
            return "".""","Returns string representation of sample-format values.

        Raises:
            KeyError: if requested sample is not defined.",
"def add_or_replace_filter(self, new_filter):
        """"""Replaces null or blank filter or adds filter to existing list.""""""
        if self.filter.lower() in self._FILTERS_TO_REPLACE:
            self.filter = new_filter
        elif new_filter not in self.filter.split("";""):
            self.filter = "";"".join([self.filter,
                                    new_filter])",Replaces null or blank filter or adds filter to existing list.,
"def add_product_error(self, product, error):
        ''' Adds an error to the given product's field '''

        ''' if product in field_names:
            field = field_names[product]
        elif isinstance(product, inventory.Product):
            return
        else:
            field = None '''

        self.add_error(self.field_name(product), error)",Adds an error to the given product's field,
"def items_pending_or_purchased(self):
        ''' Returns the items that this user has purchased or has pending. '''
        status = [commerce.Cart.STATUS_PAID, commerce.Cart.STATUS_ACTIVE]
        return self._items(status)",Returns the items that this user has purchased or has pending.,
"def passes_filter(self, user):
        ''' Returns true if the condition passes the filter '''

        cls = type(self.condition)
        qs = cls.objects.filter(pk=self.condition.id)
        return self.condition in self.pre_filter(qs, user)",Returns true if the condition passes the filter,
"def is_met(self, user, filtered=False):
        ''' Returns True if this flag condition is met, otherwise returns
        False. It determines if the condition is met by calling pre_filter
        with a queryset containing only self.condition. '''

        if filtered:
            return True  # Why query again?

        return self.passes_filter(user)","Returns True if this flag condition is met, otherwise returns
        False. It determines if the condition is met by calling pre_filter
        with a queryset containing only self.condition.",
"def pre_filter(self, conditions, user):
        ''' Returns all of the items from conditions which are enabled by a
        user being member of a Django Auth Group. '''

        return conditions.filter(group__in=user.groups.all())","Returns all of the items from conditions which are enabled by a
        user being member of a Django Auth Group.",
"def rows(self, content_type):
        ''' Returns the data rows for the table. '''

        for row in self._data:
            yield [
                self.cell_text(content_type, i, cell)
                for i, cell in enumerate(row)
            ]",Returns the data rows for the table.,
"def get_form(self, request):

        ''' Creates an instance of self.form_type using request.GET '''

        # Create a form instance
        if self.form_type is not None:
            form = self.form_type(request.GET)

            # Pre-validate it
            form.is_valid()
        else:
            form = None

        return form",Creates an instance of self.form_type using request.GET,
"def wrap_reports(cls, reports, content_type):
        ''' Wraps the reports in a _ReportTemplateWrapper for the given
        content_type -- this allows data to be returned as HTML links, for
        instance. '''

        reports = [
            _ReportTemplateWrapper(content_type, report)
            for report in reports
        ]

        return reports","Wraps the reports in a _ReportTemplateWrapper for the given
        content_type -- this allows data to be returned as HTML links, for
        instance.",
"def payments():
    ''' Shows the history of payments into the system '''

    payments = commerce.PaymentBase.objects.all()
    return QuerysetReport(
        ""Payments"",
        [""invoice__id"", ""id"", ""reference"", ""amount""],
        payments,
        link_view=views.invoice,
    )",Shows the history of payments into the system,
"def credit_note_refunds():
    ''' Shows all of the credit notes that have been generated. '''
    notes_refunded = commerce.CreditNote.refunded()
    return QuerysetReport(
        ""Credit note refunds"",
        [""id"", ""creditnoterefund__reference"", ""amount""],
        notes_refunded,
        link_view=views.credit_note,
    )",Shows all of the credit notes that have been generated.,
"def invoices(request, form):
    ''' Shows all of the invoices in the system. '''

    invoices = commerce.Invoice.objects.all().order_by(""status"", ""id"")

    return QuerysetReport(
        ""Invoices"",
        [""id"", ""recipient"", ""value"", ""get_status_display""],
        invoices,
        headings=[""id"", ""Recipient"", ""Value"", ""Status""],
        link_view=views.invoice,
    )",Shows all of the invoices in the system.,
"def total_items_purchased(context, category=None):
    ''' Returns the number of items purchased for this user (sum of quantities).

    The user will be either `context.user`, and `context.request.user` if
    the former is not defined.
    '''

    return sum(i.quantity for i in items_purchased(context, category))","Returns the number of items purchased for this user (sum of quantities).

    The user will be either `context.user`, and `context.request.user` if
    the former is not defined.",
"def extend_reservation(request, user_id, days=7):
    ''' Allows staff to extend the reservation on a given user's cart.
    '''

    user = User.objects.get(id=int(user_id))
    cart = CartController.for_user(user)
    cart.extend_reservation(datetime.timedelta(days=days))

    return redirect(request.META[""HTTP_REFERER""])",Allows staff to extend the reservation on a given user's cart.,
"def badge(request, user_id):
    ''' Renders a single user's badge (SVG). '''

    user_id = int(user_id)
    user = User.objects.get(pk=user_id)

    rendered = render_badge(user)
    response = HttpResponse(rendered)

    response[""Content-Type""] = ""image/svg+xml""
    response[""Content-Disposition""] = 'inline; filename=""badge.svg""'
    return response",Renders a single user's badge (SVG).,
"def render_badge(user):
    ''' Renders a single user's badge. '''

    data = {
        ""user"": user,
    }

    t = loader.get_template('registrasion/badge.svg')
    return t.render(data)",Renders a single user's badge.,
"def _refresh(self):
        ''' Refreshes the underlying invoice and cart objects. '''
        self.invoice.refresh_from_db()
        if self.invoice.cart:
            self.invoice.cart.refresh_from_db()",Refreshes the underlying invoice and cart objects.,
"def _mark_paid(self):
        ''' Marks the invoice as paid, and updates the attached cart if
        necessary. '''
        cart = self.invoice.cart
        if cart:
            cart.status = commerce.Cart.STATUS_PAID
            cart.save()
        self.invoice.status = commerce.Invoice.STATUS_PAID
        self.invoice.save()","Marks the invoice as paid, and updates the attached cart if
        necessary.",
"def _mark_refunded(self):
        ''' Marks the invoice as refunded, and updates the attached cart if
        necessary. '''
        self._release_cart()
        self.invoice.status = commerce.Invoice.STATUS_REFUNDED
        self.invoice.save()","Marks the invoice as refunded, and updates the attached cart if
        necessary.",
"def _mark_void(self):
        ''' Marks the invoice as refunded, and updates the attached cart if
        necessary. '''
        self.invoice.status = commerce.Invoice.STATUS_VOID
        self.invoice.save()","Marks the invoice as refunded, and updates the attached cart if
        necessary.",
"def _invoice_matches_cart(self):
        ''' Returns true if there is no cart, or if the revision of this
        invoice matches the current revision of the cart. '''

        self._refresh()

        cart = self.invoice.cart
        if not cart:
            return True

        return cart.revision == self.invoice.cart_revision","Returns true if there is no cart, or if the revision of this
        invoice matches the current revision of the cart.",
"def email(cls, invoice, kind):
        ''' Sends out an e-mail notifying the user about something to do
        with that invoice. '''

        context = {
            ""invoice"": invoice,
        }

        send_email([invoice.user.email], kind, context=context)","Sends out an e-mail notifying the user about something to do
        with that invoice.",
"def print_annotation(self):
        """"""Print annotation ""key: value"" pairs to standard output.""""""
        for path, ann in self.annotation.items():
            print(""{}: {}"".format(path, ann['value']))","Print annotation ""key: value"" pairs to standard output.",
"def print_downloads(self):
        """"""Print file fields to standard output.""""""
        for path, ann in self.annotation.items():
            if path.startswith('output') and ann['type'] == 'basic:file:':
                print(""{}: {}"".format(path, ann['value']['file']))",Print file fields to standard output.,
"def projects(self):
        """"""Return a list :obj:`GenProject` projects.

        :rtype: list of :obj:`GenProject` projects

        """"""
        if not ('projects' in self.cache and self.cache['projects']):
            self.cache['projects'] = {c['id']: GenProject(c, self) for c in self.api.case.get()['objects']}

        return self.cache['projects']","Return a list :obj:`GenProject` projects.

        :rtype: list of :obj:`GenProject` projects",
"def rundata(self, strjson):
        """"""POST JSON data object to server""""""

        d = json.loads(strjson)
        return self.api.data.post(d)",POST JSON data object to server,
"def get_subclasses(c):
    """"""Gets the subclasses of a class.""""""
    subclasses = c.__subclasses__()
    for d in list(subclasses):
        subclasses.extend(get_subclasses(d))
    return subclasses",Gets the subclasses of a class.,
"def uniqify(cls, seq):
        """"""Returns a unique list of seq""""""
        seen = set()
        seen_add = seen.add
        return [ x for x in seq if x not in seen and not seen_add(x)]",Returns a unique list of seq,
"def _list_select(cls, lst, prompt, offset=0):
        """"""Given a list of values and names, accepts the index value or name.""""""

        inp = raw_input(""select %s: "" % prompt)
        assert inp, ""value required.""

        try:
            return lst[int(inp)+offset]
        except ValueError:
            return inp
        except IndexError:
            assert False, ""bad value.""","Given a list of values and names, accepts the index value or name.",
"def get_asana_task(self, asana_task_id):
        """"""Retrieves a task from asana.""""""

        try:
            return self.asana.tasks.find_by_id(asana_task_id)
        except asana_errors.NotFoundError:
            return None
        except asana_errors.ForbiddenError:
            return None",Retrieves a task from asana.,
"def save(self):
        """"""Save data.""""""

        with open(self.filename, 'wb') as file:
            self.prune()
            self.data['version'] = self.version
            json.dump(self.data,
                file,
                sort_keys=True, indent=2)",Save data.,
"def flush(callback=None):
    """"""Waits until queue is empty.""""""

    while True:
        if shutdown_event.is_set():
            return

        if callable(callback):
            callback()

        try:
            item = queue.get(timeout=1)
            queue.put(item)  # put it back, we're just peeking.
        except Queue.Empty:
            return",Waits until queue is empty.,
"def task_create(asana_workspace_id, name, notes, assignee, projects,
                completed, **kwargs):
    """"""Creates a task""""""
    put(""task_create"",
        asana_workspace_id=asana_workspace_id,
        name=name,
        notes=notes,
        assignee=assignee,
        projects=projects,
        completed=completed,
        **kwargs)",Creates a task,
"def data_types(self):
        """"""Return a list of data types.""""""
        data = self.gencloud.project_data(self.id)
        return sorted(set(d.type for d in data))",Return a list of data types.,
"def data(self, **query):
        """"""Query for Data object annotation.""""""
        data = self.gencloud.project_data(self.id)
        query['case_ids__contains'] = self.id
        ids = set(d['id'] for d in self.gencloud.api.dataid.get(**query)['objects'])
        return [d for d in data if d.id in ids]",Query for Data object annotation.,
"def setPollingValues(self, max_waits, wait_sleep):
        """""" Optional polling loop control

        Args:
            max_waits (int):   waits
            wait_sleep (int):  ms per wait
        """"""
        self.m_max_waits = max_waits
        self.m_wait_sleep = wait_sleep","Optional polling loop control

        Args:
            max_waits (int):   waits
            wait_sleep (int):  ms per wait",
"def sqlCreate(self):
        """""" Reasonably portable SQL CREATE for defined fields.
        Returns:
            string: Portable as possible SQL Create for all-reads table.
        """"""
        count = 0
        qry_str = ""CREATE TABLE Meter_Reads ( \n\r""
        qry_str = self.fillCreate(qry_str)
        ekm_log(qry_str, 4)
        return qry_str","Reasonably portable SQL CREATE for defined fields.
        Returns:
            string: Portable as possible SQL Create for all-reads table.",
"def dbInsert(self, def_buf, raw_a, raw_b):
        """""" Call overridden dbExec() with built insert statement.
        Args:
            def_buf (SerialBlock): Block of read buffer fields to write.
            raw_a (str): Hex string of raw A read.
            raw_b (str): Hex string of raw B read or empty.
        """"""
        self.dbExec(self.sqlInsert(def_buf, raw_a, raw_b))","Call overridden dbExec() with built insert statement.
        Args:
            def_buf (SerialBlock): Block of read buffer fields to write.
            raw_a (str): Hex string of raw A read.
            raw_b (str): Hex string of raw B read or empty.",
"def setContext(self, context_str):
        """""" Set context string for serial command.  Private setter.

        Args:
            context_str (str): Command specific string.
        """"""
        if (len(self.m_context) == 0) and (len(context_str) >= 7):
            if context_str[0:7] != ""request"":
                ekm_log(""Context: "" + context_str)
        self.m_context = context_str","Set context string for serial command.  Private setter.

        Args:
            context_str (str): Command specific string.",
"def unregisterObserver(self, observer):
        """""" Remove an observer from the meter update() chain.

        Args:
            observer (MeterObserver): Subclassed MeterObserver.
        """"""
        if observer in self.m_observers:
            self.m_observers.remove(observer)
        pass","Remove an observer from the meter update() chain.

        Args:
            observer (MeterObserver): Subclassed MeterObserver.",
"def writeCmdMsg(self, msg):
        """""" Internal method to set the command result string.

        Args:
            msg (str): Message built during command.
        """"""
        ekm_log(""(writeCmdMsg | "" + self.getContext() + "") "" + msg)
        self.m_command_msg = msg","Internal method to set the command result string.

        Args:
            msg (str): Message built during command.",
"def makeReturnFormat(self):
        """""" Strip reserved and CRC for m_req :class:`~ekmmeters.SerialBlock`. """"""
        for fld in self.m_blk_a:
            compare_fld = fld.upper()
            if not ""RESERVED"" in compare_fld and not ""CRC"" in compare_fld:
                self.m_req[fld] = self.m_blk_a[fld]
        pass",Strip reserved and CRC for m_req :class:`~ekmmeters.SerialBlock`.,
"def updateObservers(self):
        """""" Fire update method in all attached observers in order of attachment. """"""
        for observer in self.m_observers:
            try:
                observer.update(self.m_req)
            except:
                ekm_log(traceback.format_exc(sys.exc_info()))",Fire update method in all attached observers in order of attachment.,
"def serialPostEnd(self):
        """""" Send termination string to implicit current meter.""""""
        ekm_log(""Termination string sent ("" + self.m_context + "")"")

        try:
            self.m_serial_port.write(""0142300375"".decode(""hex""))
        except:
            ekm_log(traceback.format_exc(sys.exc_info()))

        pass",Send termination string to implicit current meter.,
"def statistics(self, elapsed, result):
        """"""
        Return output for the combined time and result summary statistics.

        """"""

        return ""\n"".join((self.timing(elapsed), self.result_summary(result)))",Return output for the combined time and result summary statistics.,
"def color(self, color, text):
        """"""
        Color some text in the given ANSI color.

        """"""

        return ""{escape}{text}{reset}"".format(
            escape=self.ANSI[color], text=text, reset=self.ANSI[""reset""],
        )",Color some text in the given ANSI color.,
"def show(self, text):
        """"""
        Write the text to the stream and flush immediately.

        """"""

        self.stream.write(text)
        self.stream.flush()",Write the text to the stream and flush immediately.,
"def result_summary(self, result):
        """"""
        Return a summary of the results.

        """"""

        return ""{} examples, {} errors, {} failures\n"".format(
            result.testsRun, len(result.errors), len(result.failures),
        )",Return a summary of the results.,
"def parse(argv=None):
    """"""
    Parse some arguments using the parser.

    """"""

    if argv is None:
        argv = sys.argv[1:]

    # Evade http://bugs.python.org/issue9253
    if not argv or argv[0] not in {""run"", ""transform""}:
        argv = [""run""] + argv

    arguments = _clean(_parser.parse_args(argv))
    return arguments",Parse some arguments using the parser.,
"def setup(config):
    """"""
    Setup the environment for an example run.

    """"""

    formatter = config.Formatter()

    if config.verbose:
        formatter = result.Verbose(formatter)
    if config.color:
        formatter = result.Colored(formatter)

    current_result = result.ExampleResult(formatter)

    ivoire.current_result = ivoire._manager.result = current_result",Setup the environment for an example run.,
"def transform(config):
    """"""
    Run in transform mode.

    """"""

    if transform_possible:
        ExampleLoader.register()

        args, sys.argv[1:] = sys.argv[1:], config.args
        try:
            return runpy.run_path(config.runner, run_name=""__main__"")
        finally:
            sys.argv[1:] = args",Run in transform mode.,
"def takes_only_self(self):
        """"""
        Return an argument list node that takes only ``self``.

        """"""

        return ast.arguments(
            args=[ast.arg(arg=""self"")],
            defaults=[],
            kw_defaults=[],
            kwonlyargs=[],
        )",Return an argument list node that takes only ``self``.,
"def register(cls):
        """"""
        Register the path hook.

        """"""

        cls._finder = FileFinder.path_hook((cls, [cls.suffix]))
        sys.path_hooks.append(cls._finder)",Register the path hook.,
"def source_to_code(self, source_bytes, source_path):
        """"""
        Transform the source code, then return the code object.

        """"""

        node = ast.parse(source_bytes)
        transformed = ExampleTransformer().transform(node)
        return compile(transformed, source_path, ""exec"", dont_inherit=True)","Transform the source code, then return the code object.",
"def apply_argument_parser(argumentsParser, options=None):
    """""" Apply the argument parser. """"""
    if options is not None:
        args = argumentsParser.parse_args(options)
    else:
        args = argumentsParser.parse_args()
    return args",Apply the argument parser.,
"def load_by_name(name):
    """"""
    Load a spec from either a file path or a fully qualified name.

    """"""

    if os.path.exists(name):
        load_from_path(name)
    else:
        __import__(name)",Load a spec from either a file path or a fully qualified name.,
"def load_from_path(path):
    """"""
    Load a spec from a given path, discovering specs if a directory is given.

    """"""

    if os.path.isdir(path):
        paths = discover(path)
    else:
        paths = [path]

    for path in paths:
        name = os.path.basename(os.path.splitext(path)[0])
        imp.load_source(name, path)","Load a spec from a given path, discovering specs if a directory is given.",
"def discover(path, filter_specs=filter_specs):
    """"""
    Discover all of the specs recursively inside ``path``.

    Successively yields the (full) relative paths to each spec.

    """"""

    for dirpath, _, filenames in os.walk(path):
        for spec in filter_specs(filenames):
            yield os.path.join(dirpath, spec)","Discover all of the specs recursively inside ``path``.

    Successively yields the (full) relative paths to each spec.",
"def remove(places, name):
    """"""Remove a process

    :params places: a Places instance
    :params name: string, the logical name of the process
    :returns: None
    """"""
    config = filepath.FilePath(places.config)
    fle = config.child(name)
    fle.remove()","Remove a process

    :params places: a Places instance
    :params name: string, the logical name of the process
    :returns: None",
"def restart(places, name):
    """"""Restart a process

    :params places: a Places instance
    :params name: string, the logical name of the process
    :returns: None
    """"""
    content = _dumps(dict(type='RESTART', name=name))
    _addMessage(places, content)","Restart a process

    :params places: a Places instance
    :params name: string, the logical name of the process
    :returns: None",
"def call(results):
    """"""Call results.func on the attributes of results

    :params result: dictionary-like object
    :returns: None
    """"""
    results = vars(results)
    places = Places(config=results.pop('config'),
                    messages=results.pop('messages'))
    func = results.pop('func')
    func(places, **results)","Call results.func on the attributes of results

    :params result: dictionary-like object
    :returns: None",
"def remove_node(self, node_id=None):
        """"""
        Removes a particular node from the nodelist.

        :param string node_id: optional, the process id of the node to remove
        """"""
        if not node_id:
            node_id = self.conn.id

        self.conn.client.hdel(self.nodelist_key, node_id)","Removes a particular node from the nodelist.

        :param string node_id: optional, the process id of the node to remove",
"def get_all_nodes(self):
        """"""
        Returns all nodes in the hash with the time they were last refreshed
        as a dictionary.

        :rtype: dict(string, int)
        :returns: A dictionary of strings and corresponding timestamps

        """"""
        nodes = self.conn.client.hgetall(self.nodelist_key)
        return {node_id: int(dt) for (node_id, dt) in nodes.items()}","Returns all nodes in the hash with the time they were last refreshed
        as a dictionary.

        :rtype: dict(string, int)
        :returns: A dictionary of strings and corresponding timestamps",
"def increment_times_modified(self):
        """"""
        Increments the number of times this resource has been modified by all
        processes.
        """"""
        rc = self.conn.client.incr(self.times_modified_key)
        self.conn.client.pexpire(self.times_modified_key,
                                 phonon.s_to_ms(TTL))","Increments the number of times this resource has been modified by all
        processes.",
"def get_times_modified(self):
        """"""
        :returns: The total number of times increment_times_modified has been called for this resource by all processes.
        :rtype: int
        """"""
        times_modified = self.conn.client.get(self.times_modified_key)
        if times_modified is None:
            return 0
        return int(times_modified)",":returns: The total number of times increment_times_modified has been called for this resource by all processes.
        :rtype: int",
"def count(self):
        """"""
        :returns: The total number of elements in the reference list.
        :rtype: int
        """"""
        references = self.conn.client.get(self.refcount_key)
        if references is None:
            return 0
        return int(references)",":returns: The total number of elements in the reference list.
        :rtype: int",
"def check(path, start, now):
    """"""check which processes need to be restarted

    :params path: a twisted.python.filepath.FilePath with configurations
    :params start: when the checker started running
    :params now: current time
    :returns: list of strings
    """"""
    return [child.basename() for child in path.children()
            if _isbad(child, start, now)]","check which processes need to be restarted

    :params path: a twisted.python.filepath.FilePath with configurations
    :params start: when the checker started running
    :params now: current time
    :returns: list of strings",
"def parseConfig(opt):
    """"""Parse configuration

    :params opt: dict-like object with config and messages keys
    :returns: restarter, path
    """"""
    places = ctllib.Places(config=opt['config'], messages=opt['messages'])
    restarter = functools.partial(ctllib.restart, places)
    path = filepath.FilePath(opt['config'])
    return restarter, path","Parse configuration

    :params opt: dict-like object with config and messages keys
    :returns: restarter, path",
"def constant(x: A) -> Callable[..., A]:
    """"""Produce a function that always returns a supplied value.

    Args:
        x: Any object.

    Returns:
        A function that accepts any number of positional and keyword arguments, discards them, and returns ``x``.
    """"""

    def constanted(*args, **kwargs):
        return x

    return constanted","Produce a function that always returns a supplied value.

    Args:
        x: Any object.

    Returns:
        A function that accepts any number of positional and keyword arguments, discards them, and returns ``x``.",
"def close(self):
        """"""Discard data and cancel all calls.

        Instance cannot be reused after closing.
        """"""
        if self.closed:
            raise ValueError(""Cannot close a closed state"")
        if self.call is not None:
            self.call.cancel()
        self.closed = True","Discard data and cancel all calls.

        Instance cannot be reused after closing.",
"def check(self):
        """"""Check the state of HTTP""""""
        if self.closed:
            raise ValueError(""Cannot check a closed state"")
        self._maybeReset()
        if self.url is None:
            return False
        return self._maybeCheck()",Check the state of HTTP,
"def maybeAddHeart(master):
    """"""Add a heart to a service collection

    Add a heart to a service.IServiceCollector if
    the heart is not None.

    :params master: a service.IServiceCollector
    """"""
    heartSer = makeService()
    if heartSer is None:
        return
    heartSer.setName('heart')
    heartSer.setServiceParent(master)","Add a heart to a service collection

    Add a heart to a service.IServiceCollector if
    the heart is not None.

    :params master: a service.IServiceCollector",
"def wrapHeart(service):
    """"""Wrap a service in a MultiService with a heart""""""
    master = taservice.MultiService()
    service.setServiceParent(master)
    maybeAddHeart(master)
    return master",Wrap a service in a MultiService with a heart,
"def freeze(sess, output_file_path, output_node_names):
    """"""Freeze and shrink the graph based on a session and the output node names.""""""
    with TemporaryDirectory() as temp_dir_name:
        checkpoint_path = os.path.join(temp_dir_name, 'model.ckpt')
        tf.train.Saver().save(sess, checkpoint_path)

        freeze_from_checkpoint(checkpoint_path, output_file_path, output_node_names)",Freeze and shrink the graph based on a session and the output node names.,
"def restore_from_checkpoint(sess, input_checkpoint):
    """"""Return a TensorFlow saver from a checkpoint containing the metagraph.""""""
    saver = tf.train.import_meta_graph('{}.meta'.format(input_checkpoint))
    saver.restore(sess, input_checkpoint)
    return saver",Return a TensorFlow saver from a checkpoint containing the metagraph.,
"def render_tag(self, context, *tag_args, **tag_kwargs):
        """"""
        Render the tag, with all arguments resolved to their actual values.
        """"""
        raise NotImplementedError(""{0}.render_tag() is not implemented!"".format(self.__class__.__name__))","Render the tag, with all arguments resolved to their actual values.",
"def get_context_data(self, parent_context, *tag_args, **tag_kwargs):
        """"""
        Return the context data for the included template.
        """"""
        raise NotImplementedError(""{0}.get_context_data() is not implemented."".format(self.__class__.__name__))",Return the context data for the included template.,
"def render_tag(self, context, *tag_args, **tag_kwargs):
        """"""
        Rendering of the tag. It either assigns the value as variable, or renders it.
        """"""
        if self.as_var:
            # Assign the value in the parent context
            context[self.as_var] = self.get_value(context, *tag_args, **tag_kwargs)

        return u''","Rendering of the tag. It either assigns the value as variable, or renders it.",
"def flatten(subject, test=None):
	""""""
	*Deprecated*: Use more_itertools.collapse instead.
	""""""
	warnings.warn(
		""Use more_itertools.collapse instead"",
		DeprecationWarning,
		stacklevel=2)
	return list(more_itertools.collapse(subject, base_type=(bytes,)))",*Deprecated*: Use more_itertools.collapse instead.,
"def every_other(iterable):
	""""""
	Yield every other item from the iterable

	>>> ' '.join(every_other('abcdefg'))
	'a c e g'
	""""""
	items = iter(iterable)
	while True:
		try:
			yield next(items)
			next(items)
		except StopIteration:
			return","Yield every other item from the iterable

	>>> ' '.join(every_other('abcdefg'))
	'a c e g'",
"def peek(iterable):
	""""""
	Get the next value from an iterable, but also return an iterable
	that will subsequently return that value and the rest of the
	original iterable.

	>>> l = iter([1,2,3])
	>>> val, l = peek(l)
	>>> val
	1
	>>> list(l)
	[1, 2, 3]
	""""""
	peeker, original = itertools.tee(iterable)
	return next(peeker), original","Get the next value from an iterable, but also return an iterable
	that will subsequently return that value and the rest of the
	original iterable.

	>>> l = iter([1,2,3])
	>>> val, l = peek(l)
	>>> val
	1
	>>> list(l)
	[1, 2, 3]",
"def nwise(iter, n):
	""""""
	Like pairwise, except returns n-tuples of adjacent items.
	s -> (s0,s1,...,sn), (s1,s2,...,s(n+1)), ...
	""""""
	iterset = [iter]
	while len(iterset) < n:
		iterset[-1:] = itertools.tee(iterset[-1])
		next(iterset[-1], None)
	return six.moves.zip(*iterset)","Like pairwise, except returns n-tuples of adjacent items.
	s -> (s0,s1,...,sn), (s1,s2,...,s(n+1)), ...",
"def _mutable_iter(dict):
	""""""
	Iterate over items in the dict, yielding the first one, but allowing
	it to be mutated during the process.
	>>> d = dict(a=1)
	>>> it = _mutable_iter(d)
	>>> next(it)
	('a', 1)
	>>> d
	{}
	>>> d.update(b=2)
	>>> list(it)
	[('b', 2)]
	""""""
	while dict:
		prev_key = next(iter(dict))
		yield prev_key, dict.pop(prev_key)","Iterate over items in the dict, yielding the first one, but allowing
	it to be mutated during the process.
	>>> d = dict(a=1)
	>>> it = _mutable_iter(d)
	>>> next(it)
	('a', 1)
	>>> d
	{}
	>>> d.update(b=2)
	>>> list(it)
	[('b', 2)]",
"def _swap_on_miss(partition_result):
	""""""
	Given a partition_dict result, if the partition missed, swap
	the before and after.
	""""""
	before, item, after = partition_result
	return (before, item, after) if item else (after, item, before)","Given a partition_dict result, if the partition missed, swap
	the before and after.",
"def reset(self):
		""""""
		Resets the iterator to the start.

		Any remaining values in the current iteration are discarded.
		""""""
		self.__iterator, self.__saved = itertools.tee(self.__saved)","Resets the iterator to the start.

		Any remaining values in the current iteration are discarded.",
"def select(selector, obj):
    """"""Appy selector to obj and return matching nodes.

    If only one node is found, return it, otherwise return a list of matches.
    Returns False on syntax error. None if no results found.
    """"""

    parser = Parser(obj)
    try:
        return parser.parse(selector)
    except SelectorSyntaxError as e:
        log.exception(e)
        return False","Appy selector to obj and return matching nodes.

    If only one node is found, return it, otherwise return a list of matches.
    Returns False on syntax error. None if no results found.",
"def parents(self, lhs, rhs):
        """"""Find nodes in rhs which have parents in lhs.""""""

        return [node for node in rhs if node.parent in lhs]",Find nodes in rhs which have parents in lhs.,
"def ancestors(self, lhs, rhs):
        """"""Return nodes from rhs which have ancestors in lhs.""""""

        def _search(node):
            if node in lhs:
                return True
            if not node.parent:
                return False
            return _search(node.parent)

        return [node for node in rhs if _search(node)]",Return nodes from rhs which have ancestors in lhs.,
"def siblings(self, lhs, rhs):
        """"""Find nodes in rhs having common parents in lhs.""""""
        parents = [node.parent for node in lhs]

        return [node for node in rhs if node.parent in parents]",Find nodes in rhs having common parents in lhs.,
"def _match_nodes(self, validators, obj):
        """"""Apply each validator in validators to each node in obj.

        Return each node in obj which matches all validators.
        """"""

        results = []
        for node in object_iter(obj):
            if all([validate(node) for validate in validators]):
                results.append(node)
        return results","Apply each validator in validators to each node in obj.

        Return each node in obj which matches all validators.",
"def getBody(self, url, method='GET', headers={}, data=None, socket=None):
        """"""Make an HTTP request and return the body
        """"""

        if not 'User-Agent' in headers:
            headers['User-Agent'] = ['Tensor HTTP checker']

        return self.request(url, method, headers, data, socket)",Make an HTTP request and return the body,
"def set(self, k, v):
        """"""Set a key `k` to value `v`""""""
        self.store[k] = (time.time(), v)
        self._persist()",Set a key `k` to value `v`,
"def get(self, k):
        """"""Returns key contents, and modify time""""""
        if self._changed():
            self._read()

        if k in self.store:
            return tuple(self.store[k])
        else:
            return None","Returns key contents, and modify time",
"def contains(self, k):
        """"""Return True if key `k` exists""""""
        if self._changed():
            self._read()
        return k in self.store.keys()",Return True if key `k` exists,
"def get(self, max_lines=None):
        """"""Returns a big list of all log lines since the last run
        """"""
        rows = []

        self.get_fn(lambda row: rows.append(row), max_lines=max_lines)

        return rows",Returns a big list of all log lines since the last run,
"def create_token(self, obj_id, extra_data):
        """"""Create a token referencing the object id with extra data.

        Note random data is added to ensure that no two tokens are identical.
        """"""
        return self.dumps(
            dict(
                id=obj_id,
                data=extra_data,
                rnd=binascii.hexlify(os.urandom(4)).decode('utf-8')
            )
        )","Create a token referencing the object id with extra data.

        Note random data is added to ensure that no two tokens are identical.",
"def create_token(self, obj_id, extra_data):
        """"""Create a token referencing the object id with extra data.""""""
        return self.engine.encrypt(
            super(EncryptedTokenMixIn, self).create_token(obj_id, extra_data)
        )",Create a token referencing the object id with extra data.,
"def load_token(self, token, force=False):
        """"""Load data in a token.

        :param token: Token to load.
        :param force: Load token data even if signature expired.
                      Default: False.
        """"""
        return super(EncryptedTokenMixIn, self).load_token(
            self.engine.decrypt(token), force=force
        )","Load data in a token.

        :param token: Token to load.
        :param force: Load token data even if signature expired.
                      Default: False.",
"def compat_validate_token(cls, *args, **kwargs):
        """"""Multiple algorithm-compatible token validation.""""""
        data = None
        for algorithm in SUPPORTED_DIGEST_ALGORITHMS:
            data = cls(algorithm_name=algorithm).validate_token(
                *args, **kwargs)
            if not data:  # move to next algorithm
                continue
        return data",Multiple algorithm-compatible token validation.,
"def create_token(cls, obj_id, data, expires_at=None):
        """"""Create the secret link token.""""""
        if expires_at:
            s = TimedSecretLinkSerializer(expires_at=expires_at)
        else:
            s = SecretLinkSerializer()

        return s.create_token(obj_id, data)",Create the secret link token.,
"def Counter32(a, b, delta):
    """"""32bit counter aggregator with wrapping
    """"""
    if b < a:
        c = 4294967295 - a
        return (c + b) / float(delta)

    return (b - a) / float(delta)",32bit counter aggregator with wrapping,
"def Counter64(a, b, delta):
    """"""64bit counter aggregator with wrapping
    """"""
    if b < a:
        c = 18446744073709551615 - a
        return (c + b) / float(delta)

    return (b - a) / float(delta)",64bit counter aggregator with wrapping,
"def Counter(a, b, delta):
    """"""Counter derivative
    """"""
    if b < a:
        return None 

    return (b - a) / float(delta)",Counter derivative,
"def average_duration(total_duration, visits):
    """""" Method to calculate and format an average duration safely """"""
    if not visits:
        seconds = 0
    else:
        seconds = int(round(total_duration / Decimal(visits)))
    duration = timedelta(seconds=seconds)
    return str(duration)",Method to calculate and format an average duration safely,
"def setupSources(self, config):
        """"""Sets up source objects from the given config""""""
        sources = config.get('sources', [])

        for source in sources:
            src = self.createSource(source)
            self.setupTriggers(source, src)

            self.sources.append(src)",Sets up source objects from the given config,
"def validate_accept(form, field):
        """"""Validate that accept have not been set.""""""
        if field.data and form.reject.data:
            raise validators.ValidationError(
                _(""Both reject and accept cannot be set at the same time."")
            )",Validate that accept have not been set.,
"def validate_reject(form, field):
        """"""Validate that accept have not been set.""""""
        if field.data and form.accept.data:
            raise validators.ValidationError(
                _(""Both reject and accept cannot be set at the same time."")
            )",Validate that accept have not been set.,
"def validate_message(form, field):
        """"""Validate message.""""""
        if form.reject.data and not field.data.strip():
            raise validators.ValidationError(
                _(""You are required to provide message to the requester when""
                  "" you reject a request."")
            )",Validate message.,
"def verify_token():
    """"""Verify token and save in session if it's valid.""""""
    try:
        from .models import SecretLink
        token = request.args['token']
        # if the token is valid
        if token and SecretLink.validate_token(token, {}):
            # then save in session the token
            session['accessrequests-secret-token'] = token
    except KeyError:
        pass",Verify token and save in session if it's valid.,
"def init_app(self, app):
        """"""Flask application initialization.""""""
        app.before_request(verify_token)
        self.init_config(app)
        state = _AppState(app=app)
        app.extensions['zenodo-accessrequests'] = state",Flask application initialization.,
"def name(self):
        """""" Return a basic meaningful name based on device type """"""
        if (
            self.device_type and
            self.device_type.code in (DeviceType.MOBILE, DeviceType.TABLET)
        ):
            return self.device
        else:
            return self.browser",Return a basic meaningful name based on device type,
"def _warn_node(self, msg, *args, **kwargs):
    """"""Do not warn on external images.""""""
    if not msg.startswith('nonlocal image URI found:'):
        _warn_node_old(self, msg, *args, **kwargs)",Do not warn on external images.,
"def connect_receivers():
    """"""Connect receivers to signals.""""""
    request_created.connect(send_email_validation)
    request_confirmed.connect(send_confirmed_notifications)
    request_rejected.connect(send_reject_notification)
    # Order is important:
    request_accepted.connect(create_secret_link)
    request_accepted.connect(send_accept_notification)",Connect receivers to signals.,
"def _send_notification(to, subject, template, **ctx):
    """"""Render a template and send as email.""""""
    msg = Message(
        subject,
        sender=current_app.config.get('SUPPORT_EMAIL'),
        recipients=[to]
    )
    msg.body = render_template(template, **ctx)

    send_email.delay(msg.__dict__)",Render a template and send as email.,
"def extra_data(self):
        """"""Load token data stored in token (ignores expiry date of tokens).""""""
        if self.token:
            return SecretLinkFactory.load_token(self.token, force=True)[""data""]
        return None",Load token data stored in token (ignores expiry date of tokens).,
"def revoke(self):
        """"""Revoken a secret link.""""""
        if self.revoked_at is None:
            with db.session.begin_nested():
                self.revoked_at = datetime.utcnow()
            link_revoked.send(self)
            return True
        return False",Revoken a secret link.,
"def get_by_receiver(cls, request_id, user):
        """"""Get access request for a specific receiver.""""""
        return cls.query.filter_by(
            id=request_id,
            receiver_user_id=user.id
        ).first()",Get access request for a specific receiver.,
"def confirm_email(self):
        """"""Confirm that senders email is valid.""""""
        with db.session.begin_nested():
            if self.status != RequestStatus.EMAIL_VALIDATION:
                raise InvalidRequestStateError(RequestStatus.EMAIL_VALIDATION)

            self.status = RequestStatus.PENDING
        request_confirmed.send(self)",Confirm that senders email is valid.,
"def accept(self, message=None, expires_at=None):
        """"""Accept request.""""""
        with db.session.begin_nested():
            if self.status != RequestStatus.PENDING:
                raise InvalidRequestStateError(RequestStatus.PENDING)
            self.status = RequestStatus.ACCEPTED
        request_accepted.send(self, message=message, expires_at=expires_at)",Accept request.,
"def reject(self, message=None):
        """"""Reject request.""""""
        with db.session.begin_nested():
            if self.status != RequestStatus.PENDING:
                raise InvalidRequestStateError(RequestStatus.PENDING)
            self.status = RequestStatus.REJECTED
        request_rejected.send(self, message=message)",Reject request.,
"def create_secret_link(self, title, description=None, expires_at=None):
        """"""Create a secret link from request.""""""
        self.link = SecretLink.create(
            title,
            self.receiver,
            extra_data=dict(recid=self.recid),
            description=description,
            expires_at=expires_at,
        )
        return self.link",Create a secret link from request.,
"def is_embargoed(record):
    """"""Template filter to check if a record is embargoed.""""""
    return record.get('access_right') == 'embargoed' and \
        record.get('embargo_date') and \
        record.get('embargo_date') > datetime.utcnow().date()",Template filter to check if a record is embargoed.,
"def _get_endpoint(self):
        """""" Creates a generic endpoint connection that doesn't finish
        """"""
        return SSHCommandClientEndpoint.newConnection(
            reactor, b'/bin/cat', self.username, self.hostname,
            port=self.port, keys=self.keys, password=self.password,
            knownHosts = self.knownHosts)",Creates a generic endpoint connection that doesn't finish,
"def reverse(self, col):
        """"""Get reverse direction of ordering.""""""
        if col in self.options:
            if self.is_selected(col):
                return col if not self.asc else '-{0}'.format(col)
            else:
                return col
        return None",Get reverse direction of ordering.,
"def dir(self, col, asc='asc', desc='desc'):
        """"""Get direction (ascending/descending) of ordering.""""""
        if col == self._selected and self.asc is not None:
            return asc if self.asc else desc
        else:
            return None",Get direction (ascending/descending) of ordering.,
"def selected(self):
        """"""Get column which is being order by.""""""
        if self._selected:
            return self._selected if self.asc else \
                ""-{0}"".format(self._selected)
        return None",Get column which is being order by.,
"def items(self):
        """"""Get query with correct ordering.""""""
        if self.asc is not None:
            if self._selected and self.asc:
                return self.query.order_by(self._selected)
            elif self._selected and not self.asc:
                return self.query.order_by(desc(self._selected))
        return self.query",Get query with correct ordering.,
"def startTimer(self):
        """"""Starts the timer for this source""""""
        self.td = self.t.start(self.inter)

        if self.use_ssh and self.ssh_connector:
            self.ssh_client.connect()",Starts the timer for this source,
"def createLog(self, type, data, evtime=None, hostname=None):
        """"""Creates an Event object from the Source configuration""""""

        return Event(None, type, data, 0, self.ttl,
            hostname=hostname or self.hostname, evtime=evtime, tags=self.tags, type='log'
        )",Creates an Event object from the Source configuration,
"def stop(self):
        """"""Stop this client.
        """"""
        self.t.stop()
        self.factory.stopTrying()
        self.connector.disconnect()",Stop this client.,
"def eventsReceived(self, events):
        """"""Receives a list of events and transmits them to Riemann

        Arguments:
        events -- list of `tensor.objects.Event`
        """"""
        # Make sure queue isn't oversized
        if (self.maxsize < 1) or (len(self.events) < self.maxsize):
            self.events.extend(events)","Receives a list of events and transmits them to Riemann

        Arguments:
        events -- list of `tensor.objects.Event`",
"def createClient(self):
        """"""Sets up HTTP connector and starts queue timer
        """"""

        server = self.config.get('server', 'localhost')
        port = int(self.config.get('port', 9200))

        self.client = elasticsearch.ElasticSearch(self.url, self.user,
            self.password, self.index)

        self.t.start(self.inter)",Sets up HTTP connector and starts queue timer,
"def encodeMessage(self, events):
        """"""Encode a list of Tensor events with protobuf""""""

        message = proto_pb2.Msg(
            events=[self.encodeEvent(e) for e in events if e._type=='riemann']
        )

        return message.SerializeToString()",Encode a list of Tensor events with protobuf,
"def decodeMessage(self, data):
        """"""Decode a protobuf message into a list of Tensor events""""""
        message = proto_pb2.Msg()
        message.ParseFromString(data)

        return message",Decode a protobuf message into a list of Tensor events,
"def sendEvents(self, events):
        """"""Send a Tensor Event to Riemann""""""
        self.pressure += 1
        self.sendString(self.encodeMessage(events))",Send a Tensor Event to Riemann,
"def retrieve(ctx, preview_id, *args, **kwargs):
    """"""
    Retreive preview results for ID.
    """"""
    file_previews = ctx.obj['file_previews']
    results = file_previews.retrieve(preview_id)

    click.echo(results)",Retreive preview results for ID.,
"def log_time(self):
        """"""Return True if it's time to log""""""
        if self.hot_loop and self.time_delta >= self.log_interval:
            return True
        return False",Return True if it's time to log,
"def xor_bytes(a, b):
    """"""
    Calculate the byte wise exclusive of of two :class:`bytes` objects
    of the same length.
    """"""
    assert len(a) == len(b)
    return bytes(map(operator.xor, a, b))","Calculate the byte wise exclusive of of two :class:`bytes` objects
    of the same length.",
"def short_version(version=None):
    """"""
    Return short application version. For example: `1.0.0`.
    """"""
    v = version or __version__
    return '.'.join([str(x) for x in v[:3]])",Return short application version. For example: `1.0.0`.,
"def get_version(version=None):
    """"""
    Return full version nr, inc. rc, beta etc tags.

    For example: `2.0.0a1`
    :rtype: str
    """"""
    v = version or __version__
    if len(v) == 4:
        return '{0}{1}'.format(short_version(v), v[3])

    return short_version(v)","Return full version nr, inc. rc, beta etc tags.

    For example: `2.0.0a1`
    :rtype: str",
"def _configureShortcuts(self):
        '''Add keyboard shortcuts to navigate the filesystem.'''
        self._upShortcut = QtGui.QShortcut(
            QtGui.QKeySequence('Backspace'), self
        )
        self._upShortcut.setAutoRepeat(False)
        self._upShortcut.activated.connect(self._onNavigateUpButtonClicked)",Add keyboard shortcuts to navigate the filesystem.,
"def _onActivateItem(self, index):
        '''Handle activation of item in listing.'''
        item = self._filesystemWidget.model().item(index)
        if not isinstance(item, riffle.model.File):
            self._acceptButton.setDisabled(True)
            self.setLocation(item.path, interactive=True)",Handle activation of item in listing.,
"def _onSelectItem(self, selection, previousSelection):
        '''Handle selection of item in listing.'''
        self._acceptButton.setEnabled(True)
        del self._selected[:]
        item = self._filesystemWidget.model().item(selection)
        self._selected.append(item.path)",Handle selection of item in listing.,
"def _onNavigate(self, index):
        '''Handle selection of path segment.'''
        if index > 0:
            self.setLocation(
                self._locationWidget.itemData(index), interactive=True
            )",Handle selection of path segment.,
"def finalize_options(self):
        '''Finalize options to be used.'''
        self.resource_source_path = os.path.join(RESOURCE_PATH, 'resource.qrc')
        self.resource_target_path = RESOURCE_TARGET_PATH",Finalize options to be used.,
"def addChild(self, item):
        '''Add *item* as child of this item.'''
        if item.parent and item.parent != self:
            item.parent.removeChild(item)

        self.children.append(item)
        item.parent = self",Add *item* as child of this item.,
"def refetch(self):
        '''Reload children.'''
        # Reset children
        for child in self.children[:]:
            self.removeChild(child)

        # Enable children fetching
        self._fetched = False",Reload children.,
"def _fetchChildren(self):
        '''Fetch and return new child items.'''
        children = []
        for entry in QDir.drives():
            path = os.path.normpath(entry.canonicalFilePath())
            children.append(Mount(path))

        return children",Fetch and return new child items.,
"def _fetchChildren(self):
        '''Fetch and return new child items.'''
        children = []
        for path in self._collection:
            try:
                child = ItemFactory(path)
            except ValueError:
                pass
            else:
                children.append(child)

        return children",Fetch and return new child items.,
"def rowCount(self, parent):
        '''Return number of children *parent* index has.'''
        if parent.column() > 0:
            return 0

        if parent.isValid():
            item = parent.internalPointer()
        else:
            item = self.root

        return len(item.children)",Return number of children *parent* index has.,
"def parent(self, index):
        '''Return parent of *index*.'''
        if not index.isValid():
            return QModelIndex()

        item = index.internalPointer()
        if not item:
            return QModelIndex()

        parent = item.parent
        if not parent or parent == self.root:
            return QModelIndex()

        return self.createIndex(parent.row, 0, parent)",Return parent of *index*.,
"def headerData(self, section, orientation, role):
        '''Return label for *section* according to *orientation* and *role*.'''
        if orientation == Qt.Horizontal:
            if section < len(self.columns):
                column = self.columns[section]
                if role == Qt.DisplayRole:
                    return column

        return None",Return label for *section* according to *orientation* and *role*.,
"def hasChildren(self, index):
        '''Return if *index* has children.

        Optimised to avoid loading children at this stage.

        '''
        if not index.isValid():
            item = self.root
        else:
            item = index.internalPointer()
            if not item:
                return False

        return item.mayHaveChildren()","Return if *index* has children.

        Optimised to avoid loading children at this stage.",
"def canFetchMore(self, index):
        '''Return if more data available for *index*.'''
        if not index.isValid():
            item = self.root
        else:
            item = index.internalPointer()

        return item.canFetchMore()",Return if more data available for *index*.,
"def pathIndex(self, path):
        '''Return index of item with *path*.'''
        sourceModel = self.sourceModel()
        if not sourceModel:
            return QModelIndex()

        return self.mapFromSource(sourceModel.pathIndex(path))",Return index of item with *path*.,
"def item(self, index):
        '''Return item at *index*.'''
        sourceModel = self.sourceModel()

        if not sourceModel:
            return None

        return sourceModel.item(self.mapToSource(index))",Return item at *index*.,
"def icon(self, index):
        '''Return icon for index.'''
        sourceModel = self.sourceModel()
        if not sourceModel:
            return None

        return sourceModel.icon(self.mapToSource(index))",Return icon for index.,
"def hasChildren(self, index):
        '''Return if *index* has children.'''
        sourceModel = self.sourceModel()

        if not sourceModel:
            return False

        return sourceModel.hasChildren(self.mapToSource(index))",Return if *index* has children.,
"def canFetchMore(self, index):
        '''Return if more data available for *index*.'''
        sourceModel = self.sourceModel()

        if not sourceModel:
            return False

        return sourceModel.canFetchMore(self.mapToSource(index))",Return if more data available for *index*.,
"def fetchMore(self, index):
        '''Fetch additional data under *index*.'''
        sourceModel = self.sourceModel()

        if not sourceModel:
            return False

        return sourceModel.fetchMore(self.mapToSource(index))",Fetch additional data under *index*.,
"def _get_max_fd(self):
        """"""Return the maximum file descriptor value.""""""
        limits = resource.getrlimit(resource.RLIMIT_NOFILE)
        result = limits[1]
        if result == resource.RLIM_INFINITY:
            result = maxfd
        return result",Return the maximum file descriptor value.,
"def _close_fd(self, fd):
        """"""Close a file descriptor if it is open.""""""
        try:
            os.close(fd)
        except OSError, exc:
            if exc.errno != errno.EBADF:
                msg = ""Failed to close file descriptor {}: {}"".format(fd, exc)
                raise Error(msg)",Close a file descriptor if it is open.,
"def _close_open_fds(self):
        """"""Close open file descriptors.""""""
        maxfd = self._get_max_fd()
        for fd in reversed(range(maxfd)):
            if fd not in self.exclude_fds:
                self._close_fd(fd)",Close open file descriptors.,
"def _redirect(self, stream, target):
        """"""Redirect a system stream to the provided target.""""""
        if target is None:
            target_fd = os.open(os.devnull, os.O_RDWR)
        else:
            target_fd = target.fileno()
        os.dup2(target_fd, stream.fileno())",Redirect a system stream to the provided target.,
"def repositories(self):
        """"""
        Return a list of all repository objects in the repofiles in the repo folder specified
        :return:
        """"""
        for repo_path in self.path.glob('*.repo'):
            for id, repository in self._get_repo_file(repo_path).repositories:
                yield id, repository","Return a list of all repository objects in the repofiles in the repo folder specified
        :return:",
"def _get_repo_file(self, repo_path):
        """"""
        Lazy load RepoFile objects on demand.
        :param repo_path:
        :return:
        """"""
        if repo_path not in self._repo_files:
            self._repo_files[repo_path] = RepoFile(repo_path)
        return self._repo_files[repo_path]","Lazy load RepoFile objects on demand.
        :param repo_path:
        :return:",
"def from_url(url):
        """"""
        Given a URL, return a package
        :param url:
        :return:
        """"""
        package_data = HTTPClient().http_request(url=url, decode=None)
        return Package(raw_data=package_data)","Given a URL, return a package
        :param url:
        :return:",
"def dependencies(self):
        """"""
        Read the contents of the rpm itself
        :return:
        """"""
        cpio = self.rpm.gzip_file.read()
        content = cpio.read()
        return []","Read the contents of the rpm itself
        :return:",
"def gravatar_get_url(obj, size=65, default='identicon'):
    """"""Returns Gravatar image URL for a given string or UserModel.

    Example:

        {% load gravatar %}
        {% gravatar_get_url user_model %}

    :param UserModel, str obj:
    :param int size:
    :param str default:
    :return:
    """"""
    return get_gravatar_url(obj, size=size, default=default)","Returns Gravatar image URL for a given string or UserModel.

    Example:

        {% load gravatar %}
        {% gravatar_get_url user_model %}

    :param UserModel, str obj:
    :param int size:
    :param str default:
    :return:",
"def parse(cls, xml_path):
        """"""
        Parses an xml_path with the inherited xml parser
        :param xml_path:
        :return:
        """"""
        parser = etree.XMLParser(target=cls.xml_parse())
        return etree.parse(xml_path, parser)","Parses an xml_path with the inherited xml parser
        :param xml_path:
        :return:",
"def load(self):
        """"""
        Load the repo database from the remote source, and then parse it.
        :return:
        """"""
        data = self.http_request(self.location())
        self._parse(data)
        return self","Load the repo database from the remote source, and then parse it.
        :return:",
"def get_input_string_port(self, port_name, default=None):
        """"""
        Get input string port value
        :param port_name:
        :param default:
        :return: :rtype:
        """"""
        if self.__string_input_ports:
            return self.__string_input_ports.get(port_name, default)
        return default","Get input string port value
        :param port_name:
        :param default:
        :return: :rtype:",
"def set_output_string_port(self, port_name, value):
        """"""
        Set output string port value
        :param port_name:
        :param value:
        :return: :rtype:
        """"""
        if not self.__string_output_ports:
            self.__string_output_ports = {}

        self.__string_output_ports[port_name] = value","Set output string port value
        :param port_name:
        :param value:
        :return: :rtype:",
"def is_valid_filesys(path):
        """"""Checks if the path is correct and exists, must be abs-> a dir -> and not a file.""""""
        if os.path.isabs(path) and os.path.isdir(path) and \
                not os.path.isfile(path):
            return True
        else:
            raise LocalPortValidationError(
                'Port value %s is not a valid filesystem location' % path
            )","Checks if the path is correct and exists, must be abs-> a dir -> and not a file.",
"def invoke(self):
        """"""
        Execute the command from the arguments.
        :return: None or Error
        """"""
        for key in self.FUNCTION_KEYS.keys():
            if self._arguments[key] is True:
                self.FUNCTION_KEYS[key]()","Execute the command from the arguments.
        :return: None or Error",
"def _get_template_abs_path(filename):
        """"""
        Return a valid absolute path. filename can be relative or absolute.
        """"""
        if os.path.isabs(filename) and os.path.isfile(filename):
            return filename
        else:
            return os.path.join(os.getcwd(), filename)",Return a valid absolute path. filename can be relative or absolute.,
"def finalize(self, success_or_fail, message=''):
        """"""
        :param success_or_fail: string that is 'success' or 'fail'
        :param message:
        """"""
        if not self.__remote_run:
            return json.dumps({'status': success_or_fail, 'reason': message}, indent=4)
        else:
            super(TaskTemplate, self).finalize(success_or_fail, message)",":param success_or_fail: string that is 'success' or 'fail'
        :param message:",
"def archive(folder, dry_run=False):
    ""Move an active project to the archive.""
    # error handling on archive_dir already done in main()

    for f in folder:
        if not os.path.exists(f):
            bail('folder does not exist: ' + f)

    _archive_safe(folder, PROJ_ARCHIVE, dry_run=dry_run)",Move an active project to the archive.,
"def _mkdir(p):
    ""The equivalent of 'mkdir -p' in shell.""
    isdir = os.path.isdir

    stack = [os.path.abspath(p)]
    while not isdir(stack[-1]):
        parent_dir = os.path.dirname(stack[-1])
        stack.append(parent_dir)

    while stack:
        p = stack.pop()
        if not isdir(p):
            os.mkdir(p)",The equivalent of 'mkdir -p' in shell.,
"def new(cls, access_token, environment='prod'):
        '''Creates a new cross-service client.'''

        return cls(
            storage_client=StorageClient.new(access_token, environment=environment))",Creates a new cross-service client.,
"def _prep_params(params):
        '''Remove empty (None) valued keywords and self from function parameters'''

        return {k: v for (k, v) in params.items() if v is not None and k != 'self'}",Remove empty (None) valued keywords and self from function parameters,
"def emit(self, record):

        """""" pymongo expects a dict """"""
        msg = self.format(record)

        if not isinstance(msg, dict):
            msg = json.loads(msg)

        self.collection.insert(msg)",pymongo expects a dict,
"def with_headers(self, headers):
        '''Adds headers to the request

        Args:
            headers (dict): The headers to add the request headers

        Returns:
            The request builder instance in order to chain calls
        '''
        copy = headers.copy()
        copy.update(self._headers)
        return self.__copy_and_set('headers', copy)","Adds headers to the request

        Args:
            headers (dict): The headers to add the request headers

        Returns:
            The request builder instance in order to chain calls",
"def with_params(self, params):
        '''Adds parameters to the request params

        Args:
            params (dict): The parameters to add to the request params

        Returns:
            The request builder instance in order to chain calls
        '''
        copy = params.copy()
        copy.update(self._params)
        return self.__copy_and_set('params', copy)","Adds parameters to the request params

        Args:
            params (dict): The parameters to add to the request params

        Returns:
            The request builder instance in order to chain calls",
"def extract_source(bundle_path, source_path):
    """"""
    Extract the source bundle
    :param bundle_path: path to the aource bundle *.tar.gz
    :param source_path: path to location where to extractall
    """"""
    with tarfile.open(bundle_path, 'r:gz') as tf:
        tf.extractall(path=source_path)
    logger.debug(""Archive Files: %s"" % os.listdir(os.path.dirname(bundle_path)))","Extract the source bundle
    :param bundle_path: path to the aource bundle *.tar.gz
    :param source_path: path to location where to extractall",
"def sort(self, f=lambda d: d[""t""]):
        """"""Sort here works by sorting by timestamp by default""""""
        list.sort(self, key=f)
        return self",Sort here works by sorting by timestamp by default,
"def t(self):
        """"""Returns just the timestamp portion of the datapoints as a list.
        The timestamps are in python datetime's date format.""""""
        return list(map(lambda x: datetime.datetime.fromtimestamp(x[""t""]), self.raw()))","Returns just the timestamp portion of the datapoints as a list.
        The timestamps are in python datetime's date format.",
"def writeJSON(self, filename):
        """"""Writes the data to the given file::

            DatapointArray([{""t"": unix timestamp, ""d"": data}]).writeJSON(""myfile.json"")

        The data can later be loaded using loadJSON.
        """"""
        with open(filename, ""w"") as f:
            json.dump(self, f)","Writes the data to the given file::

            DatapointArray([{""t"": unix timestamp, ""d"": data}]).writeJSON(""myfile.json"")

        The data can later be loaded using loadJSON.",
"def loadJSON(self, filename):
        """"""Adds the data from a JSON file. The file is expected to be in datapoint format::

            d = DatapointArray().loadJSON(""myfile.json"")
        """"""
        with open(filename, ""r"") as f:
            self.merge(json.load(f))
        return self","Adds the data from a JSON file. The file is expected to be in datapoint format::

            d = DatapointArray().loadJSON(""myfile.json"")",
"def sum(self):
        """"""Gets the sum of the data portions of all datapoints within""""""
        raw = self.raw()
        s = 0
        for i in range(len(raw)):
            s += raw[i][""d""]
        return s",Gets the sum of the data portions of all datapoints within,
"def create_user(username):
    ""Create a new user.""
    password = prompt_pass(""Enter password"")
    user = User(username=username, password=password)
    db.session.add(user)
    db.session.commit()",Create a new user.,
"async def parse_vn_results(soup):
    """"""
    Parse Visual Novel search pages.

    :param soup: The BS4 class object
    :return:  A list of dictionaries containing a name and id.
    """"""
    soup = soup.find_all('td', class_='tc1')
    vns = []
    for item in soup[1:]:
        vns.append({'name': item.string, 'id': item.a.get('href')[1:]})
    return vns","Parse Visual Novel search pages.

    :param soup: The BS4 class object
    :return:  A list of dictionaries containing a name and id.",
"async def parse_prod_staff_results(soup):
    """"""
    Parse a page of producer or staff results

    :param soup: The BS4 class object
    :return: A list of dictionaries containing a name and nationality.
    """"""
    soup = soup.find_all('li')
    producers = []
    for item in soup:
        producers.append({'nationality': item.abbr.get('title'), 'name': item.a.string})
    return producers","Parse a page of producer or staff results

    :param soup: The BS4 class object
    :return: A list of dictionaries containing a name and nationality.",
"async def parse_tag_results(soup):
    """"""
    Parse a page of tag or trait results. Same format.

    :param soup: BS4 Class Object
    :return: A list of tags, Nothing else really useful there
    """"""
    soup = soup.find_all('td', class_='tc3')
    tags = []
    for item in soup:
        tags.append(item.a.string)
    return tags","Parse a page of tag or trait results. Same format.

    :param soup: BS4 Class Object
    :return: A list of tags, Nothing else really useful there",
"def refresh(self):
        """"""Refresh reloads data from the server. It raises an error if it fails to get the object's metadata""""""
        self.metadata = self.db.read(self.path).json()",Refresh reloads data from the server. It raises an error if it fails to get the object's metadata,
"def streams(self):
        """"""Returns the list of streams that belong to the device""""""
        result = self.db.read(self.path, {""q"": ""ls""})

        if result is None or result.json() is None:
            return []
        streams = []
        for s in result.json():
            strm = self[s[""name""]]
            strm.metadata = s
            streams.append(strm)
        return streams",Returns the list of streams that belong to the device,
"def reset_apikey(self):
        """"""invalidates the device's current api key, and generates a new one. Resets current auth to use the new apikey,
        since the change would have future queries fail if they use the old api key.""""""
        apikey = Device.reset_apikey(self)
        self.db.setauth(apikey)
        return apikey","invalidates the device's current api key, and generates a new one. Resets current auth to use the new apikey,
        since the change would have future queries fail if they use the old api key.",
"def users(self):
        """"""Returns the list of users in the database""""""
        result = self.db.read("""", {""q"": ""ls""})

        if result is None or result.json() is None:
            return []
        users = []
        for u in result.json():
            usr = self(u[""name""])
            usr.metadata = u
            users.append(usr)
        return users",Returns the list of users in the database,
"def connectordb(self):
        """"""Returns the ConnectorDB object that the logger uses. Raises an error if Logger isn't able to connect""""""
        if self.__cdb is None:
            logging.debug(""Logger: Connecting to "" + self.serverurl)
            self.__cdb = ConnectorDB(self.apikey, url=self.serverurl)
        return self.__cdb",Returns the ConnectorDB object that the logger uses. Raises an error if Logger isn't able to connect,
"def stop(self):
        """"""Stops the background synchronization thread""""""
        with self.synclock:
            if self.syncthread is not None:
                self.syncthread.cancel()
                self.syncthread = None",Stops the background synchronization thread,
"def read(*paths):
    """"""Build a file path from *paths* and return the contents.""""""
    filename = os.path.join(*paths)
    with codecs.open(filename, mode='r', encoding='utf-8') as handle:
        return handle.read()",Build a file path from *paths* and return the contents.,
"def download_url_job(job, url, name=None, s3_key_path=None, cghub_key_path=None):
    """"""Job version of `download_url`""""""
    work_dir = job.fileStore.getLocalTempDir()
    fpath = download_url(job=job, url=url, work_dir=work_dir, name=name,
                         s3_key_path=s3_key_path, cghub_key_path=cghub_key_path)
    return job.fileStore.writeGlobalFile(fpath)",Job version of `download_url`,
"def s3am_upload_job(job, file_id, file_name, s3_dir, s3_key_path=None):
    """"""Job version of s3am_upload""""""
    work_dir = job.fileStore.getLocalTempDir()
    fpath = job.fileStore.readGlobalFile(file_id, os.path.join(work_dir, file_name))
    s3am_upload(job=job, fpath=fpath, s3_dir=s3_dir, num_cores=job.cores, s3_key_path=s3_key_path)",Job version of s3am_upload,
"def labels(ontology, output, ols_base):
    """"""Output the names to the given file""""""
    for label in get_labels(ontology=ontology, ols_base=ols_base):
        click.echo(label, file=output)",Output the names to the given file,
"def tree(ontology, output, ols_base):
    """"""Output the parent-child relations to the given file""""""
    for parent, child in get_hierarchy(ontology=ontology, ols_base=ols_base):
        click.echo('{}\t{}'.format(parent, child), file=output)",Output the parent-child relations to the given file,
"def insert(self, data):
        """"""insert inserts one datapoint with the given data, and appends it to
        the end of the stream::

            s = cdb[""mystream""]

            s.create({""type"": ""string""})

            s.insert(""Hello World!"")

        """"""
        self.insert_array([{""d"": data, ""t"": time.time()}], restamp=True)","insert inserts one datapoint with the given data, and appends it to
        the end of the stream::

            s = cdb[""mystream""]

            s.create({""type"": ""string""})

            s.insert(""Hello World!"")",
"def device(self):
        """"""returns the device which owns the given stream""""""
        splitted_path = self.path.split(""/"")

        return Device(self.db,
                      splitted_path[0] + ""/"" + splitted_path[1])",returns the device which owns the given stream,
"def get_labels(ontology, ols_base=None):
    """"""Iterates over the labels of terms in the ontology

    :param str ontology: The name of the ontology
    :param str ols_base: An optional, custom OLS base url
    :rtype: iter[str]
    """"""
    client = OlsClient(ols_base=ols_base)
    return client.iter_labels(ontology)","Iterates over the labels of terms in the ontology

    :param str ontology: The name of the ontology
    :param str ols_base: An optional, custom OLS base url
    :rtype: iter[str]",
"def get_metadata(ontology, ols_base=None):
    """"""Gets the metadata for a given ontology

    :param str ontology: The name of the ontology
    :param str ols_base: An optional, custom OLS base url
    :return: The dictionary representing the JSON from the OLS
    :rtype: dict
    """"""
    client = OlsClient(ols_base=ols_base)
    return client.get_ontology(ontology)","Gets the metadata for a given ontology

    :param str ontology: The name of the ontology
    :param str ols_base: An optional, custom OLS base url
    :return: The dictionary representing the JSON from the OLS
    :rtype: dict",
"def get_hierarchy(ontology, ols_base=None):
    """"""Iterates over the parent-child relationships in an ontolog

    :param str ontology: The name of the ontology
    :param str ols_base: An optional, custom OLS base url
    :rtype: iter[tuple[str,str]]
    """"""
    client = OlsClient(ols_base=ols_base)
    return client.iter_hierarchy(ontology)","Iterates over the parent-child relationships in an ontolog

    :param str ontology: The name of the ontology
    :param str ols_base: An optional, custom OLS base url
    :rtype: iter[tuple[str,str]]",
"def __get_empty_config(self):
        """"""
        Returns the config file contents as a string. The config file is generated and then deleted.
        """"""
        self._generate_config()
        path = self._get_config_path()
        with open(path, 'r') as readable:
            contents = readable.read()
        os.remove(path)
        return contents",Returns the config file contents as a string. The config file is generated and then deleted.,
"def _add_option(self, arg_parser, name, *args, **kwargs):
        """"""
        Add an argument to the given arg_parser with the given name.

        :param argparse.ArgumentParser arg_parser:
        :param str name: The name of the option.
        """"""
        arg_parser.add_argument('--' + name, *args, **kwargs)","Add an argument to the given arg_parser with the given name.

        :param argparse.ArgumentParser arg_parser:
        :param str name: The name of the option.",
"def ping(self):
        """"""Attempts to ping the server using current credentials, and responds with the path of the currently
        authenticated device""""""
        return self.handleresult(self.r.get(self.url,
                                            params={""q"": ""this""})).text","Attempts to ping the server using current credentials, and responds with the path of the currently
        authenticated device",
"def query(self, query_type, query=None):
        """"""Run the given query on the connection (POST request to /query)""""""
        return self.handleresult(self.r.post(urljoin(self.url + ""query/"",
                                                     query_type),
                                             data=json.dumps(query))).json()",Run the given query on the connection (POST request to /query),
"def create(self, path, data=None):
        """"""Send a POST CRUD API request to the given path using the given data which will be converted
        to json""""""
        return self.handleresult(self.r.post(urljoin(self.url + CRUD_PATH,
                                                     path),
                                             data=json.dumps(data)))","Send a POST CRUD API request to the given path using the given data which will be converted
        to json",
"def read(self, path, params=None):
        """"""Read the result at the given path (GET) from the CRUD API, using the optional params dictionary
        as url parameters.""""""
        return self.handleresult(self.r.get(urljoin(self.url + CRUD_PATH,
                                                    path),
                                            params=params))","Read the result at the given path (GET) from the CRUD API, using the optional params dictionary
        as url parameters.",
"def update(self, path, data=None):
        """"""Send an update request to the given path of the CRUD API, with the given data dict, which will be converted
        into json""""""
        return self.handleresult(self.r.put(urljoin(self.url + CRUD_PATH,
                                                    path),
                                            data=json.dumps(data)))","Send an update request to the given path of the CRUD API, with the given data dict, which will be converted
        into json",
"def delete(self, path):
        """"""Send a delete request to the given path of the CRUD API. This deletes the object. Or at least tries to.""""""
        return self.handleresult(self.r.delete(urljoin(self.url + CRUD_PATH,
                                                       path)))",Send a delete request to the given path of the CRUD API. This deletes the object. Or at least tries to.,
"def subscribe(self, stream, callback, transform=""""):
        """"""Subscribe to the given stream with the callback""""""
        return self.ws.subscribe(stream, callback, transform)",Subscribe to the given stream with the callback,
"def devices(self):
        """"""Returns the list of devices that belong to the user""""""
        result = self.db.read(self.path, {""q"": ""ls""})

        if result is None or result.json() is None:
            return []
        devices = []
        for d in result.json():
            dev = self[d[""name""]]
            dev.metadata = d
            devices.append(dev)
        return devices",Returns the list of devices that belong to the user,
"def send(self, cmd):
        """"""Send the given command thru the websocket""""""
        with self.ws_sendlock:
            self.ws.send(json.dumps(cmd))",Send the given command thru the websocket,
"def __on_error(self, ws, err):
        """"""Called when there is an error in the websocket""""""
        logging.debug(""ConnectorDB:WS: Connection Error"")

        if self.status == ""connecting"":
            self.status = ""errored""
            self.ws_openlock.release()",Called when there is an error in the websocket,
"def write_config(configuration):
    """"""Helper to write the JSON configuration to a file""""""
    with open(CONFIG_PATH, 'w') as f:
        json.dump(configuration, f, indent=2, sort_keys=True)",Helper to write the JSON configuration to a file,
"def get_config():
    """"""Gets the configuration for this project from the default JSON file, or writes one if it doesn't exist

    :rtype: dict
    """"""
    if not os.path.exists(CONFIG_PATH):
        write_config({})

    with open(CONFIG_PATH) as f:
        return json.load(f)","Gets the configuration for this project from the default JSON file, or writes one if it doesn't exist

    :rtype: dict",
"def get_ontology(self, ontology):
        """"""Gets the metadata for a given ontology

        :param str ontology: The name of the ontology
        :return: The dictionary representing the JSON from the OLS
        :rtype: dict
        """"""
        url = self.ontology_metadata_fmt.format(ontology=ontology)
        response = requests.get(url)
        return response.json()","Gets the metadata for a given ontology

        :param str ontology: The name of the ontology
        :return: The dictionary representing the JSON from the OLS
        :rtype: dict",
"def get_term(self, ontology, iri):
        """"""Gets the data for a given term

        :param str ontology: The name of the ontology
        :param str iri: The IRI of a term
        :rtype: dict
        """"""
        url = self.ontology_term_fmt.format(ontology, iri)
        response = requests.get(url)

        return response.json()","Gets the data for a given term

        :param str ontology: The name of the ontology
        :param str iri: The IRI of a term
        :rtype: dict",
"def check(self):
        """"""
        Checks to see if Spark worker and HDFS datanode are still running.
        """"""

        status = _checkContainerStatus(self.sparkContainerID,
                                       self.hdfsContainerID,
                                       sparkNoun='worker',
                                       hdfsNoun='datanode')
        
        return status",Checks to see if Spark worker and HDFS datanode are still running.,
"def get_mint_tree(tokens_stream):
    '''
    This function is wrapper to normal parsers (tag_parser, block_parser, etc.).
    Returns mint tree.
    '''
    smart_stack = RecursiveStack()
    block_parser.parse(tokens_stream, smart_stack)
    return MintTemplate(body=smart_stack.stack)","This function is wrapper to normal parsers (tag_parser, block_parser, etc.).
    Returns mint tree.",
"def minimize_best_n(Members):
    '''
    Orders population members from lowest fitness to highest fitness

    Args:
        Members (list): list of PyGenetics Member objects

    Returns:
        lsit: ordered lsit of Members, from highest fitness to lowest fitness
    '''

    return(list(reversed(sorted(
        Members, key=lambda Member: Member.fitness_score
    ))))","Orders population members from lowest fitness to highest fitness

    Args:
        Members (list): list of PyGenetics Member objects

    Returns:
        lsit: ordered lsit of Members, from highest fitness to lowest fitness",
"def fitness(self):
        '''Population fitness == average member fitness score'''

        if len(self.__members) != 0:
            if self.__num_processes > 1:
                members = [m.get() for m in self.__members]
            else:
                members = self.__members
            return sum(m.fitness_score for m in members) / len(members)
        else:
            return None",Population fitness == average member fitness score,
"def med_cost_fn_val(self):
        '''Returns median cost function return value for all members'''

        if len(self.__members) != 0:
            if self.__num_processes > 1:
                members = [m.get() for m in self.__members]
            else:
                members = self.__members
            return median([m.cost_fn_val for m in members])
        else:
            return None",Returns median cost function return value for all members,
"def members(self):
        '''Returns Member objects of population'''

        if self.__num_processes > 1:
            return [m.get() for m in self.__members]
        else:
            return self.__members",Returns Member objects of population,
"def add_parameter(self, name, min_val, max_val):
        '''Adds a paramber to the Population

        Args:
            name (str): name of the parameter
            min_val (int or float): minimum value for the parameter
            max_val (int or float): maximum value for the parameter
        '''

        self.__parameters.append(Parameter(name, min_val, max_val))","Adds a paramber to the Population

        Args:
            name (str): name of the parameter
            min_val (int or float): minimum value for the parameter
            max_val (int or float): maximum value for the parameter",
"def get_environ_vars(self):
        """"""Returns a generator with all environmental vars with prefix PIP_""""""
        for key, val in os.environ.items():
            if _environ_prefix_re.search(key):
                yield (_environ_prefix_re.sub("""", key).lower(), val)",Returns a generator with all environmental vars with prefix PIP_,
"def throws_exception(callable, *exceptions):
	""""""
	Return True if the callable throws the specified exception

	>>> throws_exception(lambda: int('3'))
	False
	>>> throws_exception(lambda: int('a'))
	True
	>>> throws_exception(lambda: int('a'), KeyError)
	False
	""""""
	with context.ExceptionTrap():
		with context.ExceptionTrap(*exceptions) as exc:
			callable()
	return bool(exc)","Return True if the callable throws the specified exception

	>>> throws_exception(lambda: int('3'))
	False
	>>> throws_exception(lambda: int('a'))
	True
	>>> throws_exception(lambda: int('a'), KeyError)
	False",
"def _transform_result(typ, result):
    """"""Convert the result back into the input type.
    """"""
    if issubclass(typ, bytes):
        return tostring(result, encoding='utf-8')
    elif issubclass(typ, unicode):
        return tostring(result, encoding='unicode')
    else:
        return result",Convert the result back into the input type.,
"def html_to_xhtml(html):
    """"""Convert all tags in an HTML tree to XHTML by moving them to the
    XHTML namespace.
    """"""
    try:
        html = html.getroot()
    except AttributeError:
        pass
    prefix = ""{%s}"" % XHTML_NAMESPACE
    for el in html.iter(etree.Element):
        tag = el.tag
        if tag[0] != '{':
            el.tag = prefix + tag","Convert all tags in an HTML tree to XHTML by moving them to the
    XHTML namespace.",
"def xhtml_to_html(xhtml):
    """"""Convert all tags in an XHTML tree to HTML by removing their
    XHTML namespace.
    """"""
    try:
        xhtml = xhtml.getroot()
    except AttributeError:
        pass
    prefix = ""{%s}"" % XHTML_NAMESPACE
    prefix_len = len(prefix)
    for el in xhtml.iter(prefix + ""*""):
        el.tag = el.tag[prefix_len:]","Convert all tags in an XHTML tree to HTML by removing their
    XHTML namespace.",
"def _label__get(self):
        """"""
        Get or set any <label> element associated with this element.
        """"""
        id = self.get('id')
        if not id:
            return None
        result = _label_xpath(self, id=id)
        if not result:
            return None
        else:
            return result[0]",Get or set any <label> element associated with this element.,
"def find_rel_links(self, rel):
        """"""
        Find any links like ``<a rel=""{rel}"">...</a>``; returns a list of elements.
        """"""
        rel = rel.lower()
        return [el for el in _rel_links_xpath(self)
                if el.get('rel').lower() == rel]","Find any links like ``<a rel=""{rel}"">...</a>``; returns a list of elements.",
"def _action__get(self):
        """"""
        Get/set the form's ``action`` attribute.
        """"""
        base_url = self.base_url
        action = self.get('action')
        if base_url and action is not None:
            return urljoin(base_url, action)
        else:
            return action",Get/set the form's ``action`` attribute.,
"def _for_element__get(self):
        """"""
        Get/set the element this label points to.  Return None if it
        can't be found.
        """"""
        id = self.get('for')
        if not id:
            return None
        return self.body.get_element_by_id(id)","Get/set the element this label points to.  Return None if it
        can't be found.",
"def classpath(v):
    """"""given a class/instance return the full class path (eg, prefix.module.Classname)

    :param v: class or instance
    :returns: string, the full classpath of v
    """"""
    if isinstance(v, type):
        ret = strclass(v)
    else:
        ret = strclass(v.__class__)
    return ret","given a class/instance return the full class path (eg, prefix.module.Classname)

    :param v: class or instance
    :returns: string, the full classpath of v",
"def is_single_class():
    """"""Returns True if only a single class is being run or some tests within a single class""""""
    ret = False
    counts = get_counts()
    if counts[""classes""] < 1 and counts[""modules""] < 1:
        ret = counts[""tests""] > 0
    else:
        ret = counts[""classes""] <= 1 and counts[""modules""] <= 1
    return ret",Returns True if only a single class is being run or some tests within a single class,
"def is_single_module():
    """"""Returns True if only a module is being run""""""
    ret = False
    counts = get_counts()
    if counts[""modules""] == 1:
        ret = True

    elif counts[""modules""] < 1:
        ret = is_single_class()

    return ret",Returns True if only a module is being run,
"def validate_params(request):
    """"""Validate request params.""""""

    if 'params' in request:
        correct_params = isinstance(request['params'], (list, dict))
        error = 'Incorrect parameter values'
        assert correct_params, error",Validate request params.,
"def validate_id(request):
    """"""Validate request id.""""""

    if 'id' in request:
        correct_id = isinstance(
            request['id'],
            (string_types, int, None),
        )
        error = 'Incorrect identifier'
        assert correct_id, error",Validate request id.,
"def filesys_decode(path):
    """"""
    Ensure that the given path is decoded,
    NONE when no expected encoding works
    """"""

    fs_enc = sys.getfilesystemencoding()
    if isinstance(path, decoded_string):
        return path

    for enc in (fs_enc, ""utf-8""):
        try:
            return path.decode(enc)
        except UnicodeDecodeError:
            continue","Ensure that the given path is decoded,
    NONE when no expected encoding works",
"def _escape_argspec(obj, iterable, escape):
    """"""Helper for various string-wrapped functions.""""""
    for key, value in iterable:
        if hasattr(value, '__html__') or isinstance(value, string_types):
            obj[key] = escape(value)
    return obj",Helper for various string-wrapped functions.,
"def sub_symbols(pattern, code, symbol):
    """"""Substitutes symbols in CLDR number pattern.""""""
    return pattern.replace('', code).replace('', symbol)",Substitutes symbols in CLDR number pattern.,
"def amount_converter(obj):
    """"""Converts amount value from several types into Decimal.""""""
    if isinstance(obj, Decimal):
        return obj
    elif isinstance(obj, (str, int, float)):
        return Decimal(str(obj))
    else:
        raise ValueError('do not know how to convert: {}'.format(type(obj)))",Converts amount value from several types into Decimal.,
"def exception(self):
        """"""String representation of the exception.""""""
        buf = traceback.format_exception_only(self.exc_type, self.exc_value)
        rv = ''.join(buf).strip()
        return rv.decode('utf-8', 'replace') if PY2 else rv",String representation of the exception.,
"def render_source(self):
        """"""Render the sourcecode.""""""
        return SOURCE_TABLE_HTML % u'\n'.join(line.render() for line in
                                              self.get_annotated_lines())",Render the sourcecode.,
"def is_artifact(self):
        """"""
        Determines if this points to an actual artifact (e.g. a tarball) or if
        it points to an ""abstract"" thing like a path or a VCS location.
        """"""
        from pip.vcs import vcs

        if self.scheme in vcs.all_schemes:
            return False

        return True","Determines if this points to an actual artifact (e.g. a tarball) or if
        it points to an ""abstract"" thing like a path or a VCS location.",
"def join_lines(iterator):
    """"""
    Joins a line ending in '\' with the previous line.
    """"""
    lines = []
    for line in iterator:
        if not line.endswith('\\'):
            if lines:
                lines.append(line)
                yield ''.join(lines)
                lines = []
            else:
                yield line
        else:
            lines.append(line.strip('\\'))",Joins a line ending in '\' with the previous line.,
"def ignore_comments(iterator):
    """"""
    Strips and filters empty or commented lines.
    """"""
    for line in iterator:
        line = COMMENT_RE.sub('', line)
        line = line.strip()
        if line:
            yield line",Strips and filters empty or commented lines.,
"def skip_regex(lines, options):
    """"""
    Optionally exclude lines that match '--skip-requirements-regex'
    """"""
    skip_regex = options.skip_requirements_regex if options else None
    if skip_regex:
        lines = filterfalse(re.compile(skip_regex).search, lines)
    return lines",Optionally exclude lines that match '--skip-requirements-regex',
"def visit(self, node):
        """"""Ensure statement only contains allowed nodes.""""""
        if not isinstance(node, self.ALLOWED):
            raise SyntaxError('Not allowed in environment markers.\n%s\n%s' %
                               (self.statement,
                               (' ' * node.col_offset) + '^'))
        return ast.NodeTransformer.visit(self, node)",Ensure statement only contains allowed nodes.,
"def visit_Attribute(self, node):
        """"""Flatten one level of attribute access.""""""
        new_node = ast.Name(""%s.%s"" % (node.value.id, node.attr), node.ctx)
        return ast.copy_location(new_node, node)",Flatten one level of attribute access.,
"def push(self):
        """"""Binds the app context to the current context.""""""
        self._refcnt += 1
        _app_ctx_stack.push(self)
        appcontext_pushed.send(self.app)",Binds the app context to the current context.,
"def match_request(self):
        """"""Can be overridden by a subclass to hook into the matching
        of the request.
        """"""
        try:
            url_rule, self.request.view_args = \
                self.url_adapter.match(return_rule=True)
            self.request.url_rule = url_rule
        except HTTPException as e:
            self.request.routing_exception = e","Can be overridden by a subclass to hook into the matching
        of the request.",
"def backup_dir(dir, ext='.bak'):
    """"""Figure out the name of a directory to back up the given dir to
    (adding .bak, .bak2, etc)""""""
    n = 1
    extension = ext
    while os.path.exists(dir + extension):
        n += 1
        extension = ext + str(n)
    return dir + extension","Figure out the name of a directory to back up the given dir to
    (adding .bak, .bak2, etc)",
"def dist_in_usersite(dist):
    """"""
    Return True if given Distribution is installed in user site.
    """"""
    norm_path = normalize_path(dist_location(dist))
    return norm_path.startswith(normalize_path(user_site))",Return True if given Distribution is installed in user site.,
"def dist_is_editable(dist):
    """"""Is distribution an editable install?""""""
    # TODO: factor out determining editableness out of FrozenRequirement
    from pip import FrozenRequirement
    req = FrozenRequirement.from_dist(dist, [])
    return req.editable",Is distribution an editable install?,
"def make_setup_state(self, app, options, first_registration=False):
        """"""Creates an instance of :meth:`~flask.blueprints.BlueprintSetupState`
        object that is later passed to the register callback functions.
        Subclasses can override this to return a subclass of the setup state.
        """"""
        return BlueprintSetupState(self, app, options, first_registration)","Creates an instance of :meth:`~flask.blueprints.BlueprintSetupState`
        object that is later passed to the register callback functions.
        Subclasses can override this to return a subclass of the setup state.",
"def before_request(self, f):
        """"""Like :meth:`Flask.before_request` but for a blueprint.  This function
        is only executed before each request that is handled by a function of
        that blueprint.
        """"""
        self.record_once(lambda s: s.app.before_request_funcs
            .setdefault(self.name, []).append(f))
        return f","Like :meth:`Flask.before_request` but for a blueprint.  This function
        is only executed before each request that is handled by a function of
        that blueprint.",
"def before_app_request(self, f):
        """"""Like :meth:`Flask.before_request`.  Such a function is executed
        before each request, even if outside of a blueprint.
        """"""
        self.record_once(lambda s: s.app.before_request_funcs
            .setdefault(None, []).append(f))
        return f","Like :meth:`Flask.before_request`.  Such a function is executed
        before each request, even if outside of a blueprint.",
"def before_app_first_request(self, f):
        """"""Like :meth:`Flask.before_first_request`.  Such a function is
        executed before the first request to the application.
        """"""
        self.record_once(lambda s: s.app.before_first_request_funcs.append(f))
        return f","Like :meth:`Flask.before_first_request`.  Such a function is
        executed before the first request to the application.",
"def after_request(self, f):
        """"""Like :meth:`Flask.after_request` but for a blueprint.  This function
        is only executed after each request that is handled by a function of
        that blueprint.
        """"""
        self.record_once(lambda s: s.app.after_request_funcs
            .setdefault(self.name, []).append(f))
        return f","Like :meth:`Flask.after_request` but for a blueprint.  This function
        is only executed after each request that is handled by a function of
        that blueprint.",
"def after_app_request(self, f):
        """"""Like :meth:`Flask.after_request` but for a blueprint.  Such a function
        is executed after each request, even if outside of the blueprint.
        """"""
        self.record_once(lambda s: s.app.after_request_funcs
            .setdefault(None, []).append(f))
        return f","Like :meth:`Flask.after_request` but for a blueprint.  Such a function
        is executed after each request, even if outside of the blueprint.",
"def teardown_app_request(self, f):
        """"""Like :meth:`Flask.teardown_request` but for a blueprint.  Such a
        function is executed when tearing down each request, even if outside of
        the blueprint.
        """"""
        self.record_once(lambda s: s.app.teardown_request_funcs
            .setdefault(None, []).append(f))
        return f","Like :meth:`Flask.teardown_request` but for a blueprint.  Such a
        function is executed when tearing down each request, even if outside of
        the blueprint.",
"def context_processor(self, f):
        """"""Like :meth:`Flask.context_processor` but for a blueprint.  This
        function is only executed for requests handled by a blueprint.
        """"""
        self.record_once(lambda s: s.app.template_context_processors
            .setdefault(self.name, []).append(f))
        return f","Like :meth:`Flask.context_processor` but for a blueprint.  This
        function is only executed for requests handled by a blueprint.",
"def app_context_processor(self, f):
        """"""Like :meth:`Flask.context_processor` but for a blueprint.  Such a
        function is executed each request, even if outside of the blueprint.
        """"""
        self.record_once(lambda s: s.app.template_context_processors
            .setdefault(None, []).append(f))
        return f","Like :meth:`Flask.context_processor` but for a blueprint.  Such a
        function is executed each request, even if outside of the blueprint.",
"def app_errorhandler(self, code):
        """"""Like :meth:`Flask.errorhandler` but for a blueprint.  This
        handler is used for all requests, even if outside of the blueprint.
        """"""
        def decorator(f):
            self.record_once(lambda s: s.app.errorhandler(code)(f))
            return f
        return decorator","Like :meth:`Flask.errorhandler` but for a blueprint.  This
        handler is used for all requests, even if outside of the blueprint.",
"def url_value_preprocessor(self, f):
        """"""Registers a function as URL value preprocessor for this
        blueprint.  It's called before the view functions are called and
        can modify the url values provided.
        """"""
        self.record_once(lambda s: s.app.url_value_preprocessors
            .setdefault(self.name, []).append(f))
        return f","Registers a function as URL value preprocessor for this
        blueprint.  It's called before the view functions are called and
        can modify the url values provided.",
"def url_defaults(self, f):
        """"""Callback function for URL defaults for this blueprint.  It's called
        with the endpoint and values and should update the values passed
        in place.
        """"""
        self.record_once(lambda s: s.app.url_default_functions
            .setdefault(self.name, []).append(f))
        return f","Callback function for URL defaults for this blueprint.  It's called
        with the endpoint and values and should update the values passed
        in place.",
"def app_url_value_preprocessor(self, f):
        """"""Same as :meth:`url_value_preprocessor` but application wide.
        """"""
        self.record_once(lambda s: s.app.url_value_preprocessors
            .setdefault(None, []).append(f))
        return f",Same as :meth:`url_value_preprocessor` but application wide.,
"def app_url_defaults(self, f):
        """"""Same as :meth:`url_defaults` but application wide.
        """"""
        self.record_once(lambda s: s.app.url_default_functions
            .setdefault(None, []).append(f))
        return f",Same as :meth:`url_defaults` but application wide.,
"def jinja_loader(self):
        """"""The Jinja loader for this package bound object.

        .. versionadded:: 0.5
        """"""
        if self.template_folder is not None:
            return FileSystemLoader(os.path.join(self.root_path,
                                                 self.template_folder))","The Jinja loader for this package bound object.

        .. versionadded:: 0.5",
"def iter_symbols(code):
    """"""Yield names and strings used by `code` and its nested code objects""""""
    for name in code.co_names:
        yield name
    for const in code.co_consts:
        if isinstance(const, basestring):
            yield const
        elif isinstance(const, CodeType):
            for name in iter_symbols(const):
                yield name",Yield names and strings used by `code` and its nested code objects,
"def ensure_fresh_rates(func):
    """"""Decorator for Backend that ensures rates are fresh within last 5 mins""""""
    def wrapper(self, *args, **kwargs):
        if self.last_updated + timedelta(minutes=5) < zulu.now():
            self.refresh()
        return func(self, *args, **kwargs)
    return wrapper",Decorator for Backend that ensures rates are fresh within last 5 mins,
"def quotation(self, origin, target):
        """"""Return quotation between two currencies (origin, target)""""""
        a = self.rate(origin)
        b = self.rate(target)
        if a and b:
            return Decimal(b) / Decimal(a)
        return None","Return quotation between two currencies (origin, target)",
"def write_delete_marker_file(directory):
    """"""
    Write the pip delete marker file into this directory.
    """"""
    filepath = os.path.join(directory, PIP_DELETE_MARKER_FILENAME)
    with open(filepath, 'w') as marker_fp:
        marker_fp.write(DELETE_MARKER_MESSAGE)",Write the pip delete marker file into this directory.,
"def running_under_virtualenv():
    """"""
    Return True if we're running inside a virtualenv, False otherwise.

    """"""
    if hasattr(sys, 'real_prefix'):
        return True
    elif sys.prefix != getattr(sys, ""base_prefix"", sys.prefix):
        return True

    return False","Return True if we're running inside a virtualenv, False otherwise.",
"def __get_username():
    """""" Returns the effective username of the current process. """"""
    if WINDOWS:
        return getpass.getuser()
    import pwd
    return pwd.getpwuid(os.geteuid()).pw_name",Returns the effective username of the current process.,
"def add_filters(self, filterer, filters):
        """"""Add filters to a filterer from a list of names.""""""
        for f in filters:
            try:
                filterer.addFilter(self.config['filters'][f])
            except StandardError as e:
                raise ValueError('Unable to add filter %r: %s' % (f, e))",Add filters to a filterer from a list of names.,
"def add_handlers(self, logger, handlers):
        """"""Add handlers to a logger from a list of names.""""""
        for h in handlers:
            try:
                logger.addHandler(self.config['handlers'][h])
            except StandardError as e:
                raise ValueError('Unable to add handler %r: %s' % (h, e))",Add handlers to a logger from a list of names.,
"def override_temp(replacement):
    """"""
    Monkey-patch tempfile.tempdir with replacement, ensuring it exists
    """"""
    if not os.path.isdir(replacement):
        os.makedirs(replacement)

    saved = tempfile.tempdir

    tempfile.tempdir = replacement

    try:
        yield
    finally:
        tempfile.tempdir = saved","Monkey-patch tempfile.tempdir with replacement, ensuring it exists",
"def dump(cls, type, exc):
        """"""
        Always return a dumped (pickled) type and exc. If exc can't be pickled,
        wrap it in UnpickleableException first.
        """"""
        try:
            return pickle.dumps(type), pickle.dumps(exc)
        except Exception:
            return cls.dump(cls, cls(repr(exc)))","Always return a dumped (pickled) type and exc. If exc can't be pickled,
        wrap it in UnpickleableException first.",
"def _generate(self, source, name, filename, defer_init=False):
        """"""Internal hook that can be overridden to hook a different generate
        method in.

        .. versionadded:: 2.5
        """"""
        return generate(source, self, name, filename, defer_init=defer_init)","Internal hook that can be overridden to hook a different generate
        method in.

        .. versionadded:: 2.5",
"def yield_lines(strs):
    """"""Yield non-empty/non-comment lines of a string or sequence""""""
    if isinstance(strs, string_types):
        for s in strs.splitlines():
            s = s.strip()
            # skip blank lines/comments
            if s and not s.startswith('#'):
                yield s
    else:
        for ss in strs:
            for s in yield_lines(ss):
                yield s",Yield non-empty/non-comment lines of a string or sequence,
"def _get_mro(cls):
    """"""Get an mro for a type or classic class""""""
    if not isinstance(cls, type):
        class cls(cls, object): pass
        return cls.__mro__[1:]
    return cls.__mro__",Get an mro for a type or classic class,
"def _find_adapter(registry, ob):
    """"""Return an adapter factory for `ob` from `registry`""""""
    for t in _get_mro(getattr(ob, '__class__', type(ob))):
        if t in registry:
            return registry[t]",Return an adapter factory for `ob` from `registry`,
"def ensure_directory(path):
    """"""Ensure that the parent directory of `path` exists""""""
    dirname = os.path.dirname(path)
    if not os.path.isdir(dirname):
        os.makedirs(dirname)",Ensure that the parent directory of `path` exists,
"def subscribe(self, callback):
        """"""Invoke `callback` for all distributions (including existing ones)""""""
        if callback in self.callbacks:
            return
        self.callbacks.append(callback)
        for dist in self:
            callback(dist)",Invoke `callback` for all distributions (including existing ones),
"def is_invalid_marker(cls, text):
        """"""
        Validate text as a PEP 426 environment marker; return an exception
        if invalid or False otherwise.
        """"""
        try:
            cls.evaluate_marker(text)
        except SyntaxError as e:
            return cls.normalize_exception(e)
        return False","Validate text as a PEP 426 environment marker; return an exception
        if invalid or False otherwise.",
"def format(self, record):
        """"""
        Calls the standard formatter, but will indent all of the log messages
        by our current indentation level.
        """"""
        formatted = logging.Formatter.format(self, record)
        formatted = """".join([
            ("" "" * get_indentation()) + line
            for line in formatted.splitlines(True)
        ])
        return formatted","Calls the standard formatter, but will indent all of the log messages
        by our current indentation level.",
"def get_decimal_quantum(precision):
    """"""Return minimal quantum of a number, as defined by precision.""""""
    assert isinstance(precision, (int, decimal.Decimal))
    return decimal.Decimal(10) ** (-precision)","Return minimal quantum of a number, as defined by precision.",
"def total_seconds(td):
    """"""Python 2.6 compatability""""""
    if hasattr(td, 'total_seconds'):
        return td.total_seconds()

    ms = td.microseconds
    secs = (td.seconds + td.days * 24 * 3600)
    return (ms + secs * 10**6) / 10**6",Python 2.6 compatability,
"def _initialize(g=globals()):
    ""Set up global resource manager (deliberately not state-saved)""
    manager = ResourceManager()
    g['_manager'] = manager
    for name in dir(manager):
        if not name.startswith('_'):
            g[name] = getattr(manager, name)",Set up global resource manager (deliberately not state-saved),
"def do_dice_roll():
	""""""
	Roll n-sided dice and return each result and the total
	""""""
	options = get_options()
	dice = Dice(options.sides)
	rolls = [dice.roll() for n in range(options.number)]
	for roll in rolls:
		print('rolled', roll)
	if options.number > 1:
		print('total', sum(rolls))",Roll n-sided dice and return each result and the total,
"def price_converter(obj):
    """"""Ensures that string prices are converted into Price objects.""""""
    if isinstance(obj, str):
        obj = PriceClass.parse(obj)
    return obj",Ensures that string prices are converted into Price objects.,
"def validate(self, request):
        """"""Validate JSON-RPC request.

        :param request: RPC request object
        :type request: dict

        """"""

        try:
            validate_version(request)
            validate_method(request)
            validate_params(request)
            validate_id(request)
        except (AssertionError, KeyError) as error:
            invalid_request(error)","Validate JSON-RPC request.

        :param request: RPC request object
        :type request: dict",
"def get_method(self, args):
        """"""Get request method for service application.""""""

        try:
            method = self.app[args['method']]
        except KeyError:
            method_not_found(args['id'])
        else:
            return method",Get request method for service application.,
"def apply(self, method, args):
        """"""Apply application method.""""""

        try:
            params = args['params']
            if isinstance(params, dict):
                result = method(**params)
            else:
                result = method(*params)
        except Exception as error:
            server_error(args['id'], error)
        else:
            return result",Apply application method.,
"def blueprint(self):
        """"""The name of the current blueprint""""""
        if self.url_rule and '.' in self.url_rule.endpoint:
            return self.url_rule.endpoint.rsplit('.', 1)[0]",The name of the current blueprint,
"def prepare_files(self, finder):
        """"""
        Prepare process. Create temp directories, download and/or unpack files.
        """"""
        # make the wheelhouse
        if self.wheel_download_dir:
            ensure_dir(self.wheel_download_dir)

        self._walk_req_to_install(
            functools.partial(self._prepare_file, finder))","Prepare process. Create temp directories, download and/or unpack files.",
"def cleanup_files(self):
        """"""Clean up files, remove builds.""""""
        logger.debug('Cleaning up...')
        with indent_log():
            for req in self.reqs_to_cleanup:
                req.remove_temporary_source()","Clean up files, remove builds.",
"def _get_all_ns_packages(self):
        """"""Return sorted list of all package namespaces""""""
        nsp = set()
        for pkg in self.distribution.namespace_packages or []:
            pkg = pkg.split('.')
            while pkg:
                nsp.add('.'.join(pkg))
                pkg.pop()
        return sorted(nsp)",Return sorted list of all package namespaces,
"def default(self, obj):
        """"""
        Convert QuerySet objects to their list counter-parts
        """"""
        if isinstance(obj, models.Model):
            return self.encode(model_to_dict(obj))
        elif isinstance(obj, models.query.QuerySet):
            return serializers.serialize('json', obj)
        else:
            return super(JsonResponseEncoder, self).default(obj)",Convert QuerySet objects to their list counter-parts,
"def tokenize_annotated(doc, annotation): 
    """"""Tokenize a document and add an annotation attribute to each token
    """"""
    tokens = tokenize(doc, include_hrefs=False)
    for tok in tokens: 
        tok.annotation = annotation
    return tokens",Tokenize a document and add an annotation attribute to each token,
"def copy_annotations(src, dest): 
    """"""
    Copy annotations from the tokens listed in src to the tokens in dest
    """"""
    assert len(src) == len(dest)
    for src_tok, dest_tok in zip(src, dest): 
        dest_tok.annotation = src_tok.annotation",Copy annotations from the tokens listed in src to the tokens in dest,
"def merge_delete(del_chunks, doc):
    """""" Adds the text chunks in del_chunks to the document doc (another
    list of text chunks) with marker to show it is a delete.
    cleanup_delete later resolves these markers into <del> tags.""""""
    doc.append(DEL_START)
    doc.extend(del_chunks)
    doc.append(DEL_END)","Adds the text chunks in del_chunks to the document doc (another
    list of text chunks) with marker to show it is a delete.
    cleanup_delete later resolves these markers into <del> tags.",
"def split_trailing_whitespace(word):
    """"""
    This function takes a word, such as 'test\n\n' and returns ('test','\n\n')
    """"""
    stripped_length = len(word.rstrip())
    return word[0:stripped_length], word[stripped_length:]","This function takes a word, such as 'test\n\n' and returns ('test','\n\n')",
"def split_words(text):
    """""" Splits some text into words. Includes trailing whitespace
    on each word when appropriate.  """"""
    if not text or not text.strip():
        return []

    words = split_words_re.findall(text)
    return words","Splits some text into words. Includes trailing whitespace
    on each word when appropriate.",
"def start_tag(el):
    """"""
    The text representation of the start tag for a tag.
    """"""
    return '<%s%s>' % (
        el.tag, ''.join([' %s=""%s""' % (name, html_escape(value, True))
                         for name, value in el.attrib.items()]))",The text representation of the start tag for a tag.,
"def end_tag(el):
    """""" The text representation of an end tag for a tag.  Includes
    trailing whitespace when appropriate.  """"""
    if el.tail and start_whitespace_re.search(el.tail):
        extra = ' '
    else:
        extra = ''
    return '</%s>%s' % (el.tag, extra)","The text representation of an end tag for a tag.  Includes
    trailing whitespace when appropriate.",
"def fixup_ins_del_tags(html):
    """""" Given an html string, move any <ins> or <del> tags inside of any
    block-level elements, e.g. transform <ins><p>word</p></ins> to
    <p><ins>word</ins></p> """"""
    doc = parse_html(html, cleanup=False)
    _fixup_ins_del_tags(doc)
    html = serialize_html_fragment(doc, skip_outer=True)
    return html","Given an html string, move any <ins> or <del> tags inside of any
    block-level elements, e.g. transform <ins><p>word</p></ins> to
    <p><ins>word</ins></p>",
"def _fixup_ins_del_tags(doc):
    """"""fixup_ins_del_tags that works on an lxml document in-place
    """"""
    for tag in ['ins', 'del']:
        for el in doc.xpath('descendant-or-self::%s' % tag):
            if not _contains_block_level_tag(el):
                continue
            _move_el_inside_block(el, tag=tag)
            el.drop_tag()",fixup_ins_del_tags that works on an lxml document in-place,
"def _contains_block_level_tag(el):
    """"""True if the element contains any block-level elements, like <p>, <td>, etc.
    """"""
    if el.tag in block_level_tags or el.tag in block_level_container_tags:
        return True
    for child in el:
        if _contains_block_level_tag(child):
            return True
    return False","True if the element contains any block-level elements, like <p>, <td>, etc.",
"def document_fromstring(html, guess_charset=True, parser=None):
    """"""Parse a whole document into a string.""""""
    if not isinstance(html, _strings):
        raise TypeError('string required')

    if parser is None:
        parser = html_parser

    return parser.parse(html, useChardet=guess_charset).getroot()",Parse a whole document into a string.,
"def propagate_exceptions(self):
        """"""Returns the value of the `PROPAGATE_EXCEPTIONS` configuration
        value in case it's set, otherwise a sensible default is returned.

        .. versionadded:: 0.7
        """"""
        rv = self.config['PROPAGATE_EXCEPTIONS']
        if rv is not None:
            return rv
        return self.testing or self.debug","Returns the value of the `PROPAGATE_EXCEPTIONS` configuration
        value in case it's set, otherwise a sensible default is returned.

        .. versionadded:: 0.7",
"def endpoint(self, endpoint):
        """"""A decorator to register a function as an endpoint.
        Example::

            @app.endpoint('example.endpoint')
            def example():
                return ""example""

        :param endpoint: the name of the endpoint
        """"""
        def decorator(f):
            self.view_functions[endpoint] = f
            return f
        return decorator","A decorator to register a function as an endpoint.
        Example::

            @app.endpoint('example.endpoint')
            def example():
                return ""example""

        :param endpoint: the name of the endpoint",
"def add_template_filter(self, f, name=None):
        """"""Register a custom template filter.  Works exactly like the
        :meth:`template_filter` decorator.

        :param name: the optional name of the filter, otherwise the
                     function name will be used.
        """"""
        self.jinja_env.filters[name or f.__name__] = f","Register a custom template filter.  Works exactly like the
        :meth:`template_filter` decorator.

        :param name: the optional name of the filter, otherwise the
                     function name will be used.",
"def add_template_global(self, f, name=None):
        """"""Register a custom template global function. Works exactly like the
        :meth:`template_global` decorator.

        .. versionadded:: 0.10

        :param name: the optional name of the global function, otherwise the
                     function name will be used.
        """"""
        self.jinja_env.globals[name or f.__name__] = f","Register a custom template global function. Works exactly like the
        :meth:`template_global` decorator.

        .. versionadded:: 0.10

        :param name: the optional name of the global function, otherwise the
                     function name will be used.",
"def unique(iterable):
    """"""
    Yield unique values in iterable, preserving order.
    """"""
    seen = set()
    for value in iterable:
        if not value in seen:
            seen.add(value)
            yield value","Yield unique values in iterable, preserving order.",
"def requires_to_requires_dist(requirement):
    """"""Compose the version predicates for requirement in PEP 345 fashion.""""""
    requires_dist = []
    for op, ver in requirement.specs:
        requires_dist.append(op + ver)
    if not requires_dist:
        return ''
    return "" (%s)"" % ','.join(requires_dist)",Compose the version predicates for requirement in PEP 345 fashion.,
"def _find_prefix_path(self, basedir, prefix):
        """"""Similar to _find_prefix_paths() but only returns the first match""""""
        ret = """"
        for ret in self._find_prefix_paths(basedir, prefix):
            break

        if not ret:
            raise IOError(""Could not find prefix {} in path {}"".format(prefix, basedir))

        return ret",Similar to _find_prefix_paths() but only returns the first match,
"def commit(self):
        """"""Remove temporary save dir: rollback will no longer be possible.""""""
        if self.save_dir is not None:
            rmtree(self.save_dir)
            self.save_dir = None
            self._moved_paths = []",Remove temporary save dir: rollback will no longer be possible.,
"def _load_arg_defaults(kwargs):
    """"""Inject default arguments for load functions.""""""
    if current_app:
        kwargs.setdefault('cls', current_app.json_decoder)
    else:
        kwargs.setdefault('cls', JSONDecoder)",Inject default arguments for load functions.,
"def dump(obj, fp, **kwargs):
    """"""Like :func:`dumps` but writes into a file object.""""""
    _dump_arg_defaults(kwargs)
    encoding = kwargs.pop('encoding', None)
    if encoding is not None:
        fp = _wrap_writer_for_text(fp, encoding)
    _json.dump(obj, fp, **kwargs)",Like :func:`dumps` but writes into a file object.,
"def loads(s, **kwargs):
    """"""Unserialize a JSON object from a string ``s`` by using the application's
    configured decoder (:attr:`~flask.Flask.json_decoder`) if there is an
    application on the stack.
    """"""
    _load_arg_defaults(kwargs)
    if isinstance(s, bytes):
        s = s.decode(kwargs.pop('encoding', None) or 'utf-8')
    return _json.loads(s, **kwargs)","Unserialize a JSON object from a string ``s`` by using the application's
    configured decoder (:attr:`~flask.Flask.json_decoder`) if there is an
    application on the stack.",
"def load(fp, **kwargs):
    """"""Like :func:`loads` but reads from a file object.
    """"""
    _load_arg_defaults(kwargs)
    if not PY2:
        fp = _wrap_reader_for_text(fp, kwargs.pop('encoding', None) or 'utf-8')
    return _json.load(fp, **kwargs)",Like :func:`loads` but reads from a file object.,
"def htmlsafe_dump(obj, fp, **kwargs):
    """"""Like :func:`htmlsafe_dumps` but writes into a file object.""""""
    fp.write(unicode(htmlsafe_dumps(obj, **kwargs)))",Like :func:`htmlsafe_dumps` but writes into a file object.,
"def dump_object(self, value):
        """"""Dumps an object into a string for redis.  By default it serializes
        integers as regular string and pickle dumps everything else.
        """"""
        t = type(value)
        if t in integer_types:
            return str(value).encode('ascii')
        return b'!' + pickle.dumps(value)","Dumps an object into a string for redis.  By default it serializes
        integers as regular string and pickle dumps everything else.",
"def _strip_postfix(req):
    """"""
        Strip req postfix ( -dev, 0.2, etc )
    """"""
    # FIXME: use package_to_requirement?
    match = re.search(r'^(.*?)(?:-dev|-\d.*)$', req)
    if match:
        # Strip off -dev, -0.2, etc.
        req = match.group(1)
    return req","Strip req postfix ( -dev, 0.2, etc )",
"def populate_link(self, finder, upgrade):
        """"""Ensure that if a link can be found for this, that it is found.

        Note that self.link may still be None - if Upgrade is False and the
        requirement is already installed.
        """"""
        if self.link is None:
            self.link = finder.find_requirement(self, upgrade)","Ensure that if a link can be found for this, that it is found.

        Note that self.link may still be None - if Upgrade is False and the
        requirement is already installed.",
"def to_text(s, blank_if_none=True):
    """"""Wrapper around six.text_type to convert None to empty string""""""
    if s is None:
        if blank_if_none:
            return """"
        else:
            return None
    elif isinstance(s, text_type):
        return s
    else:
        return text_type(s)",Wrapper around six.text_type to convert None to empty string,
"def parse(doc, treebuilder=""etree"", encoding=None,
          namespaceHTMLElements=True):
    """"""Parse a string or file-like object into a tree""""""
    tb = treebuilders.getTreeBuilder(treebuilder)
    p = HTMLParser(tb, namespaceHTMLElements=namespaceHTMLElements)
    return p.parse(doc, encoding=encoding)",Parse a string or file-like object into a tree,
"def bind(self):
        """"""Bind and activate HTTP server.""""""

        HTTPServer.__init__(self, (self.host, self.port), HTTPRequestHandler)
        self.port = self.server_port",Bind and activate HTTP server.,
"def report(self):
        """"""Report startup info to stdout.""""""

        print(
            self.report_message.format(
                service=self.service,
                host=self.host,
                port=self.port,
            )
        )
        sys.stdout.flush()",Report startup info to stdout.,
"def _is_local_repository(self, repo):
        """"""
           posix absolute paths start with os.path.sep,
           win32 ones ones start with drive (like c:\\folder)
        """"""
        drive, tail = os.path.splitdrive(repo)
        return repo.startswith(os.path.sep) or drive","posix absolute paths start with os.path.sep,
           win32 ones ones start with drive (like c:\\folder)",
"def get_info(self, location):
        """"""
        Returns (url, revision), where both are strings
        """"""
        assert not location.rstrip('/').endswith(self.dirname), \
            'Bad directory: %s' % location
        return self.get_url(location), self.get_revision(location)","Returns (url, revision), where both are strings",
"def unpack(self, location):
        """"""
        Clean up current location and download the url repository
        (and vcs infos) into location
        """"""
        if os.path.exists(location):
            rmtree(location)
        self.obtain(location)","Clean up current location and download the url repository
        (and vcs infos) into location",
"def get_impl_ver():
    """"""Return implementation version.""""""
    impl_ver = sysconfig.get_config_var(""py_version_nodot"")
    if not impl_ver:
        impl_ver = ''.join(map(str, sys.version_info[:2]))
    return impl_ver",Return implementation version.,
"def from_url(cls, url):
        ""Construct a (possibly null) ContentChecker from a URL""
        fragment = urlparse(url)[-1]
        if not fragment:
            return ContentChecker()
        match = cls.pattern.search(fragment)
        if not match:
            return ContentChecker()
        return cls(**match.groupdict())",Construct a (possibly null) ContentChecker from a URL,
"def addbuilddir():
    """"""Append ./build/lib.<platform> in case we're running in the build dir
    (especially for Guido :-)""""""
    from distutils.util import get_platform
    s = ""build/lib.%s-%.3s"" % (get_platform(), sys.version)
    if hasattr(sys, 'gettotalrefcount'):
        s += '-pydebug'
    s = os.path.join(os.path.dirname(sys.path[-1]), s)
    sys.path.append(s)","Append ./build/lib.<platform> in case we're running in the build dir
    (especially for Guido :-)",
"def _init_pathinfo():
    """"""Return a set containing all existing directory entries from sys.path""""""
    d = set()
    for dir in sys.path:
        try:
            if os.path.isdir(dir):
                dir, dircase = makepath(dir)
                d.add(dircase)
        except TypeError:
            continue
    return d",Return a set containing all existing directory entries from sys.path,
"def is_url(name):
    """"""Returns true if the name looks like a URL""""""
    if ':' not in name:
        return False
    scheme = name.split(':', 1)[0].lower()
    return scheme in ['http', 'https', 'file', 'ftp'] + vcs.all_schemes",Returns true if the name looks like a URL,
"def exchange(_context, component, backend, base, name=''):
        """"""Handle exchange subdirectives.""""""
        _context.action(
            discriminator=('currency', 'exchange', component),
            callable=_register_exchange,
            args=(name, component, backend, base)
        )",Handle exchange subdirectives.,
"def _default_template_ctx_processor():
    """"""Default template context processor.  Injects `request`,
    `session` and `g`.
    """"""
    reqctx = _request_ctx_stack.top
    appctx = _app_ctx_stack.top
    rv = {}
    if appctx is not None:
        rv['g'] = appctx.g
    if reqctx is not None:
        rv['request'] = reqctx.request
        rv['session'] = reqctx.session
    return rv","Default template context processor.  Injects `request`,
    `session` and `g`.",
"def _render(template, context, app):
    """"""Renders the template and fires the signal""""""
    rv = template.render(context)
    template_rendered.send(app, template=template, context=context)
    return rv",Renders the template and fires the signal,
"def parse_version(version):
    """"""Use parse_version from pkg_resources or distutils as available.""""""
    global parse_version
    try:
        from pkg_resources import parse_version
    except ImportError:
        from distutils.version import LooseVersion as parse_version
    return parse_version(version)",Use parse_version from pkg_resources or distutils as available.,
"def is_declared(self, name):
        """"""Check if a name is declared in this or an outer scope.""""""
        if name in self.declared_locally or name in self.declared_parameter:
            return True
        return name in self.declared",Check if a name is declared in this or an outer scope.,
"def inspect(self, nodes):
        """"""Walk the node and check for identifiers.  If the scope is hard (eg:
        enforce on a python level) overrides from outer scopes are tracked
        differently.
        """"""
        visitor = FrameIdentifierVisitor(self.identifiers)
        for node in nodes:
            visitor.visit(node)","Walk the node and check for identifiers.  If the scope is hard (eg:
        enforce on a python level) overrides from outer scopes are tracked
        differently.",
"def atomize(f, lock=None):
	""""""
	Decorate a function with a reentrant lock to prevent multiple
	threads from calling said thread simultaneously.
	""""""
	lock = lock or threading.RLock()

	@functools.wraps(f)
	def exec_atomic(*args, **kwargs):
		lock.acquire()
		try:
			return f(*args, **kwargs)
		finally:
			lock.release()
	return exec_atomic","Decorate a function with a reentrant lock to prevent multiple
	threads from calling said thread simultaneously.",
"def ancestor(self):
        """"""This browse node's immediate ancestor in the browse node tree.

        :return:
            The ancestor as an :class:`~.AmazonBrowseNode`, or None.
        """"""
        ancestors = getattr(self.element, 'Ancestors', None)
        if hasattr(ancestors, 'BrowseNode'):
            return AmazonBrowseNode(ancestors['BrowseNode'])
        return None","This browse node's immediate ancestor in the browse node tree.

        :return:
            The ancestor as an :class:`~.AmazonBrowseNode`, or None.",
"def children(self):
        """"""This browse node's children in the browse node tree.

    :return:
    A list of this browse node's children in the browse node tree.
    """"""
        children = []
        child_nodes = getattr(self.element, 'Children')
        for child in getattr(child_nodes, 'BrowseNode', []):
                children.append(AmazonBrowseNode(child))
        return children","This browse node's children in the browse node tree.

    :return:
    A list of this browse node's children in the browse node tree.",
"def do_title(s):
    """"""Return a titlecased version of the value. I.e. words will start with
    uppercase letters, all remaining characters are lowercase.
    """"""
    rv = []
    for item in re.compile(r'([-\s]+)(?u)').split(s):
        if not item:
            continue
        rv.append(item[0].upper() + item[1:].lower())
    return ''.join(rv)","Return a titlecased version of the value. I.e. words will start with
    uppercase letters, all remaining characters are lowercase.",
"def base64_encode(string):
    """"""base64 encodes a single bytestring (and is tolerant to getting
    called with a unicode string).
    The resulting bytestring is safe for putting into URLs.
    """"""
    string = want_bytes(string)
    return base64.urlsafe_b64encode(string).strip(b'=')","base64 encodes a single bytestring (and is tolerant to getting
    called with a unicode string).
    The resulting bytestring is safe for putting into URLs.",
"def base64_decode(string):
    """"""base64 decodes a single bytestring (and is tolerant to getting
    called with a unicode string).
    The result is also a bytestring.
    """"""
    string = want_bytes(string, encoding='ascii', errors='ignore')
    return base64.urlsafe_b64decode(string + b'=' * (-len(string) % 4))","base64 decodes a single bytestring (and is tolerant to getting
    called with a unicode string).
    The result is also a bytestring.",
"def verify_signature(self, key, value, sig):
        """"""Verifies the given signature matches the expected signature""""""
        return constant_time_compare(sig, self.get_signature(key, value))",Verifies the given signature matches the expected signature,
"def get_signature(self, value):
        """"""Returns the signature for the given value""""""
        value = want_bytes(value)
        key = self.derive_key()
        sig = self.algorithm.get_signature(key, value)
        return base64_encode(sig)",Returns the signature for the given value,
"def sign(self, value):
        """"""Signs the given string.""""""
        return value + want_bytes(self.sep) + self.get_signature(value)",Signs the given string.,
"def verify_signature(self, value, sig):
        """"""Verifies the signature for the given value.""""""
        key = self.derive_key()
        try:
            sig = base64_decode(sig)
        except Exception:
            return False
        return self.algorithm.verify_signature(key, value, sig)",Verifies the signature for the given value.,
"def sign(self, value):
        """"""Signs the given string and also attaches a time information.""""""
        value = want_bytes(value)
        timestamp = base64_encode(int_to_bytes(self.get_timestamp()))
        sep = want_bytes(self.sep)
        value = value + sep + timestamp
        return value + sep + self.get_signature(value)",Signs the given string and also attaches a time information.,
"def validate(self, signed_value, max_age=None):
        """"""Just validates the given signed value.  Returns `True` if the
        signature exists and is valid, `False` otherwise.""""""
        try:
            self.unsign(signed_value, max_age=max_age)
            return True
        except BadSignature:
            return False","Just validates the given signed value.  Returns `True` if the
        signature exists and is valid, `False` otherwise.",
"def make_signer(self, salt=None):
        """"""A method that creates a new instance of the signer to be used.
        The default implementation uses the :class:`Signer` baseclass.
        """"""
        if salt is None:
            salt = self.salt
        return self.signer(self.secret_key, salt=salt, **self.signer_kwargs)","A method that creates a new instance of the signer to be used.
        The default implementation uses the :class:`Signer` baseclass.",
"def dump(self, obj, f, salt=None):
        """"""Like :meth:`dumps` but dumps into a file.  The file handle has
        to be compatible with what the internal serializer expects.
        """"""
        f.write(self.dumps(obj, salt))","Like :meth:`dumps` but dumps into a file.  The file handle has
        to be compatible with what the internal serializer expects.",
"def loads(self, s, salt=None):
        """"""Reverse of :meth:`dumps`, raises :exc:`BadSignature` if the
        signature validation fails.
        """"""
        s = want_bytes(s)
        return self.load_payload(self.make_signer(salt).unsign(s))","Reverse of :meth:`dumps`, raises :exc:`BadSignature` if the
        signature validation fails.",
"def load_unsafe(self, f, *args, **kwargs):
        """"""Like :meth:`loads_unsafe` but loads from a file.

        .. versionadded:: 0.15
        """"""
        return self.loads_unsafe(f.read(), *args, **kwargs)","Like :meth:`loads_unsafe` but loads from a file.

        .. versionadded:: 0.15",
"def _all_dirs(base_path):
        """"""
        Return all dirs in base_path, relative to base_path
        """"""
        for root, dirs, files in os.walk(base_path, followlinks=True):
            for dir in dirs:
                yield os.path.relpath(os.path.join(root, dir), base_path)","Return all dirs in base_path, relative to base_path",
"def _maxiter_default(self):
        """""" Trait initialiser.
        """"""
        mode = self.mode
        if mode == ""KK"":
            return 100 * len(self.nodes)
        elif mode == ""major"":
            return 200
        else:
            return 600",Trait initialiser.,
"def _directed_changed(self, new):
        """""" Sets the connection string for all edges.
        """"""
        if new:
            conn = ""->""
        else:
            conn = ""--""

        for edge in [e for g in self.all_graphs for e in g.edges]:
            edge.conn = conn",Sets the connection string for all edges.,
"def _on_nodes(self):
        """""" Maintains each branch's list of available nodes in order that they
            may move themselves (InstanceEditor values).
        """"""
        all_graphs = self.all_graphs
        all_nodes = [n for g in all_graphs for n in g.nodes]

        for graph in all_graphs:
            for edge in graph.edges:
                edge._nodes = all_nodes","Maintains each branch's list of available nodes in order that they
            may move themselves (InstanceEditor values).",
"def _viewport_default(self):
        """""" Trait initialiser """"""

        viewport = Viewport(component=self.canvas, enable_zoom=True)
        viewport.tools.append(ViewportPanTool(viewport))
        return viewport",Trait initialiser,
"def _component_changed(self, old, new):
        """""" Handles the component being changed.
        """"""
        canvas = self.canvas
        if old is not None:
            canvas.remove(old)
        if new is not None:
            canvas.add(new)",Handles the component being changed.,
"def _diagram_canvas_default(self):
        """""" Trait initialiser """"""

        canvas = Canvas()

        for tool in self.tools:
            canvas.tools.append(tool(canvas))

        return canvas",Trait initialiser,
"def _viewport_default(self):
        """""" Trait initialiser """"""

        vp = Viewport(component=self.diagram_canvas, enable_zoom=True)
        vp.view_position = [0,0]
        vp.tools.append(ViewportPanTool(vp))
        return vp",Trait initialiser,
"def _diagram_canvas_changed(self, new):
        """""" Handles the diagram canvas being set """"""

        logger.debug(""Diagram canvas changed!"")
        canvas = self.diagram_canvas

        for tool in self.tools:
            if canvas is not None:
                print ""Adding tool: %s"" % tool
                canvas.tools.append(tool(canvas))",Handles the diagram canvas being set,
"def _domain_model_changed_for_diagram(self, obj, name, old, new):
        """""" Handles the domain model changing """"""

        if old is not None:
            self.unmap_model(old)
        if new is not None:
            self.map_model(new)",Handles the domain model changing,
"def parse_xdot_data(self, data):
        """""" Parses xdot data and returns the associated components. """"""

        parser = self.parser
#        if pyparsing_version >= ""1.2"":
#            parser.parseWithTabs()
        if data:
            return parser.parseString(data)
        else:
            return []",Parses xdot data and returns the associated components.,
"def proc_font(self, tokens):
        """""" Sets the font. """"""

        size = int(tokens[""s""])
        self.pen.font = ""%s %d"" % (tokens[""b""], size)
        return []",Sets the font.,
"def _proc_polygon(self, tokens, filled):
        """""" Returns the components of a polygon. """"""

        pts = [(p[""x""], p[""y""]) for p in tokens[""points""]]
        component = Polygon(pen=self.pen, points=pts, filled=filled)

        return component",Returns the components of a polygon.,
"def proc_polyline(self, tokens):
        """""" Returns the components of a polyline. """"""

        pts = [(p[""x""], p[""y""]) for p in tokens[""points""]]
        component = Polyline(pen=self.pen, points=pts)

        return component",Returns the components of a polyline.,
"def _proc_bspline(self, tokens, filled):
        """""" Returns the components of a B-spline (Bezier curve). """"""

        pts = [(p[""x""], p[""y""]) for p in tokens[""points""]]
        component = BSpline(pen=self.pen, points=pts, filled=filled)

        return component",Returns the components of a B-spline (Bezier curve).,
"def proc_text(self, tokens):
        """""" Returns text components. """"""

        component = Text(pen=self.pen,
                         text_x=tokens[""x""],
                         text_y=tokens[""y""],
                         justify=tokens[""j""],
                         text_w=tokens[""w""],
                         text=tokens[""b""])

        return component",Returns text components.,
"def proc_image(self, tokens):
        """""" Returns the components of an image. """"""

        print ""IMAGE:"", tokens, tokens.asList(), tokens.keys()

        raise NotImplementedError",Returns the components of an image.,
"def save(self, obj):
        """""" Save to file.
        """"""
        fd = None
        try:
            fd = open(self.dot_file.absolute_path, ""wb"")
            obj.save_dot(fd)
        finally:
            if fd is not None:
                fd.close()
#        self.m_time = getmtime(self.adaptee.absolute_path)
        return",Save to file.,
"def load(self):
        """""" Load the file.
        """"""
        fd = None
        try:
            obj = parse_dot_file( self.dot_file.absolute_path )
        finally:
            if fd is not None:
                fd.close()
        return obj",Load the file.,
"def is_in(self, point_x, point_y):
        """""" Test if the point is within this ellipse """"""

        x = self.x_origin
        y = self.y_origin
        a = self.e_width#/2 # FIXME: Why divide by two
        b = self.e_height#/2

        return ((point_x-x)**2/(a**2)) + ((point_y-y)**2/(b**2)) < 1.0",Test if the point is within this ellipse,
"def _draw_bounds(self, gc):
        """""" Draws the component bounds for testing purposes """"""

        dx, dy = self.bounds
        x, y = self.position
        gc.rect(x, y, dx, dy)
        gc.stroke_path()",Draws the component bounds for testing purposes,
"def perform(self, event):
        """""" Perform the action.
        """"""
        wizard = NewDotGraphWizard(parent=self.window.control,
            window=self.window, title=""New Graph"")

        # Open the wizard
        if wizard.open() == OK:
            wizard.finished = True",Perform the action.,
"def polar(x, y, deg=0):        # radian if deg=0; degree if deg=1
    """""" Convert from rectangular (x,y) to polar (r,w)
        r = sqrt(x^2 + y^2)
        w = arctan(y/x) = [-\pi,\pi] = [-180,180]

    """"""

    if deg:
        return hypot(x, y), 180.0 * atan2(y, x) / pi
    else:
        return hypot(x, y), atan2(y, x)","Convert from rectangular (x,y) to polar (r,w)
        r = sqrt(x^2 + y^2)
        w = arctan(y/x) = [-\pi,\pi] = [-180,180]",
"def _parse_dot_code_fired(self):
        """""" Parses the dot_code string and replaces the existing model.
        """"""
        parser = GodotDataParser()
        graph  = parser.parse_dot_data(self.dot_code)
        if graph is not None:
            self.model = graph",Parses the dot_code string and replaces the existing model.,
"def new_model(self, info):
        """""" Handles the new Graph action. """"""

        if info.initialized:
            retval = confirm(parent  = info.ui.control,
                             message = ""Replace existing graph?"",
                             title   = ""New Graph"",
                             default = YES)
            if retval == YES:
                self.model = Graph()",Handles the new Graph action.,
"def configure_graph(self, info):
        """""" Handles display of the graph dot traits.
        """"""
        if info.initialized:
            self.model.edit_traits(parent=info.ui.control,
                kind=""live"", view=attr_view)",Handles display of the graph dot traits.,
"def configure_nodes(self, info):
        """""" Handles display of the nodes editor.
        """"""
        if info.initialized:
            self.model.edit_traits(parent=info.ui.control,
                kind=""live"", view=nodes_view)",Handles display of the nodes editor.,
"def configure_edges(self, info):
        """""" Handles display of the edges editor.
        """"""
        if info.initialized:
            self.model.edit_traits(parent=info.ui.control,
                kind=""live"", view=edges_view)",Handles display of the edges editor.,
"def about_godot(self, info):
        """""" Handles displaying a view about Godot.
        """"""
        if info.initialized:
            self.edit_traits(parent=info.ui.control,
                kind=""livemodal"", view=about_view)",Handles displaying a view about Godot.,
"def godot_options(self, info):
        """""" Handles display of the options menu. """"""

        if info.initialized:
            self.edit_traits( parent = info.ui.control,
                              kind   = ""livemodal"",
                              view   = ""options_view"" )",Handles display of the options menu.,
"def configure_dot_code(self, info):
        """""" Handles display of the dot code in a text editor.
        """"""
        if not info.initialized:
            return

        self.dot_code = str(self.model)
        retval = self.edit_traits( parent = info.ui.control,
                                   kind   = ""livemodal"",
                                   view   = ""dot_code_view"" )",Handles display of the dot code in a text editor.,
"def save_to_file_like(self, flo, format=None, **kwargs):
        """""" Save the object to a given file like object in the given format.
        """"""
        format = self.format if format is None else format
        save = getattr(self, ""save_%s"" % format, None)
        if save is None:
            raise ValueError(""Unknown format '%s'."" % format)
        save(flo, **kwargs)",Save the object to a given file like object in the given format.,
"def load_from_file_like(cls, flo, format=None):
        """""" Load the object to a given file like object with the given
            protocol.
        """"""
        format = self.format if format is None else format
        load = getattr(cls, ""load_%s"" % format, None)
        if load is None:
            raise ValueError(""Unknown format '%s'."" % format)
        return load(flo)","Load the object to a given file like object with the given
            protocol.",
"def save_to_file(self, filename, format=None, **kwargs):
        """""" Save the object to file given by filename.
        """"""
        if format is None:
            # try to derive protocol from file extension
            format = format_from_extension(filename)
        with file(filename, 'wb') as fp:
            self.save_to_file_like(fp, format, **kwargs)",Save the object to file given by filename.,
"def parse(filename, encoding=None):
    """"""
    !DEMO!
    Simple file parsing generator

    Args:
        filename: absolute or relative path to file on disk
        encoding: encoding string that is passed to open function
    """"""

    with open(filename, encoding=encoding) as source:
        for line in source:
            for word in line.split():
                yield word","!DEMO!
    Simple file parsing generator

    Args:
        filename: absolute or relative path to file on disk
        encoding: encoding string that is passed to open function",
"def add_chain(self, name, order):
        """"""
        Add chain to current shelve file

        Args:
            name: chain name
            order: markov chain order
        """"""

        if name not in self.chains:
            setattr(self.chains, name, MarkovChain(order=order))
        else:
            raise ValueError(""Chain with this name already exists"")","Add chain to current shelve file

        Args:
            name: chain name
            order: markov chain order",
"def remove_chain(self, name):
        """"""
        Remove chain from current shelve file

        Args:
            name: chain name
        """"""

        if name in self.chains:
            delattr(self.chains, name)
        else:
            raise ValueError(""Chain with this name not found"")","Remove chain from current shelve file

        Args:
            name: chain name",
"def get_node(self, ID):
        """""" Returns the node with the given ID or None.
        """"""
        for node in self.nodes:
            if node.ID == str(ID):
                return node
        return None",Returns the node with the given ID or None.,
"def _set_node_lists(self, new):
        """""" Maintains each edge's list of available nodes.
        """"""
        for edge in self.edges:
            edge._nodes = self.nodes",Maintains each edge's list of available nodes.,
"def parse_dot_file(filename):
    """""" Parses a DOT file and returns a Godot graph.
    """"""
    parser = GodotDataParser()
    graph  = parser.parse_dot_file(filename)
    del parser

    return graph",Parses a DOT file and returns a Godot graph.,
"def get_time_units_and_multiplier(seconds):
    """"""
    Given a duration in seconds, determines the best units and multiplier to
    use to display the time. Return value is a 2-tuple of units and multiplier.
    """"""
    for cutoff, units, multiplier in units_table:
        if seconds < cutoff:
            break
    return units, multiplier","Given a duration in seconds, determines the best units and multiplier to
    use to display the time. Return value is a 2-tuple of units and multiplier.",
"def format_duration(seconds):
    """"""Formats a number of seconds using the best units.""""""
    units, divider = get_time_units_and_multiplier(seconds)
    seconds *= divider
    return ""%.3f %s"" % (seconds, units)",Formats a number of seconds using the best units.,
"def _name_default(self):
        """""" Trait initialiser.
        """"""
        # 'obj' is a io.File
        self.obj.on_trait_change(self.on_path, ""path"")

        return basename(self.obj.path)",Trait initialiser.,
"def on_path(self, new):
        """""" Handle the file path changing.
        """"""
        self.name = basename(new)
        self.graph = self.editor_input.load()",Handle the file path changing.,
"def main():
    """""" Runs Godot.
    """"""
    application = GodotApplication( id=""godot"",
        plugins=[CorePlugin(),
                 PuddlePlugin(),
                 WorkbenchPlugin(),
                 ResourcePlugin(),
                 GodotPlugin()] )

    application.run()",Runs Godot.,
"def get_children ( self, object ):
        """""" Gets the object's children.
        """"""
        children = []
        children.extend( object.subgraphs )
        children.extend( object.clusters )
        children.extend( object.nodes )
        children.extend( object.edges )
        return children",Gets the object's children.,
"def get_label ( self, object ):
        """""" Gets the label to display for a specified object.
        """"""
        label = self.label
        if label[:1] == '=':
            return label[1:]

        label = xgetattr( object, label, '' )

        if self.formatter is None:
            return label

        return self.formatter( object, label )",Gets the label to display for a specified object.,
"def set_label ( self, object, label ):
        """""" Sets the label for a specified object.
        """"""
        label_name = self.label
        if label_name[:1] != '=':
            xsetattr( object, label_name, label )",Sets the label for a specified object.,
"def when_label_changed ( self, object, listener, remove ):
        """""" Sets up or removes a listener for the label being changed on a
            specified object.
        """"""
        label = self.label
        if label[:1] != '=':
            object.on_trait_change( listener, label, remove = remove,
                                    dispatch = 'ui' )","Sets up or removes a listener for the label being changed on a
            specified object.",
"def init ( self, parent ):
        """""" Finishes initialising the editor by creating the underlying toolkit
            widget.
        """"""
        self._graph = graph = Graph()
        ui = graph.edit_traits(parent=parent, kind=""panel"")
        self.control = ui.control","Finishes initialising the editor by creating the underlying toolkit
            widget.",
"def _nodes_replaced(self, object, name, old, new):
        """""" Handles a list of nodes being set.
        """"""
        self._delete_nodes(old)
        self._add_nodes(new)",Handles a list of nodes being set.,
"def _nodes_changed(self, object, name, undefined, event):
        """""" Handles addition and removal of nodes.
        """"""
        self._delete_nodes(event.removed)
        self._add_nodes(event.added)",Handles addition and removal of nodes.,
"def _delete_nodes(self, features):
        """""" Removes the node corresponding to each item in 'features'.
        """"""
        graph = self._graph

        if graph is not None:
            for feature in features:
                graph.delete_node( id(feature) )

        graph.arrange_all()",Removes the node corresponding to each item in 'features'.,
"def _edges_replaced(self, object, name, old, new):
        """""" Handles a list of edges being set.
        """"""
        self._delete_edges(old)
        self._add_edges(new)",Handles a list of edges being set.,
"def _edges_changed(self, object, name, undefined, event):
        """""" Handles addition and removal of edges.
        """"""
        self._delete_edges(event.removed)
        self._add_edges(event.added)",Handles addition and removal of edges.,
"def _get_name(self):
        """""" Property getter.
        """"""
        if (self.tail_node is not None) and (self.head_node is not None):
            return ""%s %s %s"" % (self.tail_node.ID, self.conn,
                                 self.head_node.ID)
        else:
            return ""Edge""",Property getter.,
"def node_factory(**row_factory_kw):
    """""" Give new nodes a unique ID. """"""

    if ""__table_editor__"" in row_factory_kw:
        graph = row_factory_kw[""__table_editor__""].object
        ID = make_unique_name(""n"", [node.ID for node in graph.nodes])
        del row_factory_kw[""__table_editor__""]
        return godot.node.Node(ID)
    else:
        return godot.node.Node(uuid.uuid4().hex[:6])",Give new nodes a unique ID.,
"def start(self, context):
		""""""Initialize the database connection.""""""
		
		self.config['alias'] = self.alias
		safe_config = dict(self.config)
		del safe_config['host']
		
		log.info(""Connecting MongoEngine database layer."", extra=dict(
				uri = redact_uri(self.config['host']),
				config = self.config,
			))
		
		self.connection = connect(**self.config)",Initialize the database connection.,
"def prepare(self, context):
		""""""Attach this connection's default database to the context using our alias.""""""
		
		context.db[self.alias] = MongoEngineProxy(self.connection)",Attach this connection's default database to the context using our alias.,
"def _component_default(self):
        """""" Trait initialiser.
        """"""
        component = Container(fit_window=False, auto_size=True,
            bgcolor=""green"")#, position=list(self.pos) )
        component.tools.append( MoveTool(component) )
#        component.tools.append( TraitsTool(component) )
        return component",Trait initialiser.,
"def _vp_default(self):
        """""" Trait initialiser.
        """"""
        vp = Viewport(component=self.component)
        vp.enable_zoom=True
#        vp.view_position = [-10, -10]
        vp.tools.append(ViewportPanTool(vp))
        return vp",Trait initialiser.,
"def _on_position_change(self, new):
        """""" Handles the poition of the component changing.
        """"""
        w, h = self.component.bounds
        self.pos = tuple([ new[0] + (w/2), new[1] + (h/2) ])",Handles the poition of the component changing.,
"def _pos_changed(self, new):
        """""" Handles the Graphviz position attribute changing.
        """"""
        w, h = self.component.bounds
        self.component.position = [ new[0] - (w/2), new[1] - (h/2) ]
#        self.component.position = list( new )
        self.component.request_redraw()",Handles the Graphviz position attribute changing.,
"def is_in(self, point_x, point_y):
        """""" Test if a point is within this polygonal region """"""

        point_array = array(((point_x, point_y),))
        vertices = array(self.points)
        winding = self.inside_rule == ""winding""
        result = points_in_polygon(point_array, vertices, winding)
        return result[0]",Test if a point is within this polygonal region,
"def _connect(self, context):
		""""""Initialize the database connection.""""""
		
		if __debug__:
			log.info(""Connecting "" + self.engine.partition(':')[0] + "" database layer."", extra=dict(
					uri = redact_uri(self.uri, self.protect),
					config = self.config,
					alias = self.alias,
				))
		
		self.connection = context.db[self.alias] = self._connector(self.uri, **self.config)",Initialize the database connection.,
"def _handle_event(self, event, *args, **kw):
		""""""Broadcast an event to the database connections registered.""""""
		
		for engine in self.engines.values():
			if hasattr(engine, event):
				getattr(engine, event)(*args, **kw)",Broadcast an event to the database connections registered.,
"def render_seo_links(self, scheme=None):
        """"""Render the rel=canonical, rel=prev and rel=next links to a Markup object for injection into a template""""""
        out = self.render_prev_next_links(scheme=scheme)

        if self.total_pages == 1:
            out += self.render_canonical_link(scheme=scheme)

        return out","Render the rel=canonical, rel=prev and rel=next links to a Markup object for injection into a template",
"def last_item_number(self):
        """"""
        :return: The last ""item number"", used when displaying messages to the user
        like ""Displaying items 1 to 10 of 123"" - in this example 10 would be returned
        """"""
        n = self.first_item_number + self.page_size - 1
        if n > self.total_items:
            return self.total_items
        return n",":return: The last ""item number"", used when displaying messages to the user
        like ""Displaying items 1 to 10 of 123"" - in this example 10 would be returned",
"def transform(self, X):
        '''
        :X: numpy ndarray 
        '''
        noise = self._noise_func(*self._args, size=X.shape)
        results = X + noise
        self.relative_noise_size_ = self.relative_noise_size(X, results)
        return results",:X: numpy ndarray,
"def relative_noise_size(self, data, noise):
        '''
        :data: original data as numpy matrix
        :noise: noise matrix as numpy matrix
        '''
        return np.mean([
            sci_dist.cosine(u / la.norm(u), v / la.norm(v))
            for u, v in zip(noise, data)
        ])",":data: original data as numpy matrix
        :noise: noise matrix as numpy matrix",
"def fit(self, X, y):
        '''
        :X: list of dict
        :y: labels
        '''
        self._avgs = average_by_label(X, y, self.reference_label)
        return self",":X: list of dict
        :y: labels",
"def transform(self, X, y=None):
        '''
        :X: list of dict
        '''
        return map_dict_list(
            X,
            key_func=lambda k, v: self.names[k.lower()],
            if_func=lambda k, v: k.lower() in self.names)",:X: list of dict,
"def format_price_commas(price):
    """"""
    Formats prices, rounding (i.e. to the nearest whole number of pounds) with commas
    """"""
    if price is None:
        return None
    if price >= 0:
        return jinja2.Markup('&pound;{:,.2f}'.format(price))
    else:
        return jinja2.Markup('-&pound;{:,.2f}'.format(-price))","Formats prices, rounding (i.e. to the nearest whole number of pounds) with commas",
"def ensure_dir(path):
    """"""Ensure that a needed directory exists, creating it if it doesn't""""""
    try:
        log.info('Ensuring directory exists: %s' % path)
        os.makedirs(path)
    except OSError:
        if not os.path.isdir(path):
            raise","Ensure that a needed directory exists, creating it if it doesn't",
"def to_base62(n):
    """"""
    Converts a number to base 62
    :param n: The number to convert
    :return: Base 62 representation of number (string)
    """"""
    remainder = n % 62
    result = BASE62_MAP[remainder]
    num = n // 62

    while num > 0:
        remainder = num % 62
        result = '%s%s' % (BASE62_MAP[remainder], result)
        num = num // 62

    return result","Converts a number to base 62
    :param n: The number to convert
    :return: Base 62 representation of number (string)",
"def from_base62(s):
    """"""
    Convert a base62 String back into a number
    :param s: The base62 encoded String
    :return: The number encoded in the String (integer)
    """"""
    result = 0

    for c in s:
        if c not in BASE62_MAP:
            raise Exception('Invalid base64 string: %s' % s)

        result = result * 62 + BASE62_MAP.index(c)

    return result","Convert a base62 String back into a number
    :param s: The base62 encoded String
    :return: The number encoded in the String (integer)",
"def put_text(self, key, contents):
        """"""Store the given text contents so that they are later retrievable by
        the given key.""""""

        self._blobservice.create_blob_from_text(
            self.uuid,
            key,
            contents
        )","Store the given text contents so that they are later retrievable by
        the given key.",
"def file_md5sum(filename):
    """"""
    :param filename: The filename of the file to process
    :returns: The MD5 hash of the file
    """"""
    hash_md5 = hashlib.md5()
    with open(filename, 'rb') as f:
        for chunk in iter(lambda: f.read(1024 * 4), b''):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()",":param filename: The filename of the file to process
    :returns: The MD5 hash of the file",
"def add_path(self, path):
        """"""
        Adds a path to search through when attempting to look up a module.

        :param path: the path the add to the list of searchable paths
        """"""
        if path not in self.paths:
            self.paths.append(path)","Adds a path to search through when attempting to look up a module.

        :param path: the path the add to the list of searchable paths",
"def tag_to_text(tag):
    """"""
    :param tag: Beautiful soup tag
    :return: Flattened text
    """"""
    out = []
    for item in tag.contents:
        # If it has a name, it is a tag
        if item.name:
            out.append(tag_to_text(item))
        else:
            # Just text!
            out.append(item)

    return ' '.join(out)",":param tag: Beautiful soup tag
    :return: Flattened text",
"def transform(self, X, y=None):
        '''
        :X: list of dict
        :y: labels
        '''
        return [{
            new_feature: self._fisher_pval(x, old_features)
            for new_feature, old_features in self.feature_groups.items()
            if len(set(x.keys()) & set(old_features))
        } for x in X]",":X: list of dict
        :y: labels",
"def _filtered_values(self, x: dict, feature_set: list=None):
        '''
        :x: dict which contains feature names and values
        :return: pairs of values which shows number of feature makes filter function true or false
        '''
        feature_set = feature_set or x
        n = sum(self.filter_func(x[i]) for i in feature_set if i in x)
        return [len(feature_set) - n, n]",":x: dict which contains feature names and values
        :return: pairs of values which shows number of feature makes filter function true or false",
"def print_location(**kwargs):
    """"""
    :param kwargs: Pass in the arguments to the function and they will be printed too!
    """"""
    stack = inspect.stack()[1]
    debug_print('{}:{} {}()'.format(stack[1], stack[2], stack[3]))

    for k, v in kwargs.items():
        lesser_debug_print('{} = {}'.format(k, v))",:param kwargs: Pass in the arguments to the function and they will be printed too!,
"def remove_namespaces(root):
    """"""Call this on an lxml.etree document to remove all namespaces""""""
    for elem in root.getiterator():
        if not hasattr(elem.tag, 'find'):
            continue

        i = elem.tag.find('}')
        if i >= 0:
            elem.tag = elem.tag[i + 1:]

    objectify.deannotate(root, cleanup_namespaces=True)",Call this on an lxml.etree document to remove all namespaces,
"def merge(self, new_dict):
        """"""Merges a dictionary into the Rule object.""""""
        actions = new_dict.pop(""actions"")
        for action in actions:
            self.add_action(action)

        self.__dict__.update(new_dict)",Merges a dictionary into the Rule object.,
"def execute_actions(self, cwd):
        """"""Iterates over the actions and executes them in order.""""""
        self._execute_globals(cwd)
        for action in self.actions:
            logger.info(""executing {}"".format(action))
            p = subprocess.Popen(action, shell=True, cwd=cwd)
            p.wait()",Iterates over the actions and executes them in order.,
"def get_context(self, value):
        """"""Ensure `image_rendition` is added to the global context.""""""
        context = super(RenditionAwareStructBlock, self).get_context(value)
        context['image_rendition'] = self.rendition.\
            image_rendition or 'original'
        return context",Ensure `image_rendition` is added to the global context.,
"def use_music_service(self, service_name, api_key=None):
        """"""
        Sets the current music service to service_name.
        
        :param str service_name: Name of the music service
        :param str api_key: Optional API key if necessary
        """"""

        self.connection_handler.use_music_service(service_name, api_key=api_key)","Sets the current music service to service_name.
        
        :param str service_name: Name of the music service
        :param str api_key: Optional API key if necessary",
"def set(self, k, v):
        """"""Add or update a key, value pair to the database""""""
        k = k.lstrip('/')
        url = '{}/{}'.format(self.endpoint, k)
        r = requests.put(url, data=str(v))
        if r.status_code != 200 or r.json() is not True:
            raise KVStoreError('PUT returned {}'.format(r.status_code))","Add or update a key, value pair to the database",
"def unix_time(dt=None, as_int=False):
    """"""Generate a unix style timestamp (in seconds)""""""
    if dt is None:
        dt = datetime.datetime.utcnow()

    if type(dt) is datetime.date:
        dt = date_to_datetime(dt)

    epoch = datetime.datetime.utcfromtimestamp(0)
    delta = dt - epoch
    
    if as_int:
        return int(delta.total_seconds())

    return delta.total_seconds()",Generate a unix style timestamp (in seconds),
"def is_christmas_period():
    """"""Is this the christmas period?""""""
    now = datetime.date.today()
    if now.month != 12:
        return False
    if now.day < 15:
        return False
    if now.day > 27:
        return False
    return True",Is this the christmas period?,
"def get_end_of_day(timestamp):
    """"""
    Given a date or a datetime, return a datetime at 23:59:59 on that day
    """"""
    return datetime.datetime(timestamp.year, timestamp.month, timestamp.day, 23, 59, 59)","Given a date or a datetime, return a datetime at 23:59:59 on that day",
"def transform(self, X):
        '''
        :param X: features.
        '''
        inverser_tranformer = self.dict_vectorizer_
        if self.feature_selection:
            inverser_tranformer = self.clone_dict_vectorizer_

        return inverser_tranformer.inverse_transform(
            self.transformer.transform(
                self.dict_vectorizer_.transform(X)))",:param X: features.,
"def from_csv(self, label_column='labels'):
        '''
        Read dataset from csv.
        '''
        df = pd.read_csv(self.path, header=0)
        X = df.loc[:, df.columns != label_column].to_dict('records')
        X = map_dict_list(X, if_func=lambda k, v: v and math.isfinite(v))
        y = list(df[label_column].values)
        return X, y",Read dataset from csv.,
"def from_json(self):
        '''
        Reads dataset from json.
        '''
        with gzip.open('%s.gz' % self.path,
                       'rt') if self.gz else open(self.path) as file:
            return list(map(list, zip(*json.load(file))))[::-1]",Reads dataset from json.,
"def to_json(self, X, y):
        '''
        Reads dataset to csv.

        :param X: dataset as list of dict.
        :param y: labels.
        '''
        with gzip.open('%s.gz' % self.path, 'wt') if self.gz else open(
                self.path, 'w') as file:
            json.dump(list(zip(y, X)), file)","Reads dataset to csv.

        :param X: dataset as list of dict.
        :param y: labels.",
"def map_dict_list(ds, key_func=None, value_func=None, if_func=None):
    '''
    :param List[Dict] ds: list of dict
    :param func key_func: func which will run on key.
    :param func value_func: func which will run on values.
    '''
    return [map_dict(d, key_func, value_func, if_func) for d in ds]",":param List[Dict] ds: list of dict
    :param func key_func: func which will run on key.
    :param func value_func: func which will run on values.",
"def check_reference_label(y, ref_label):
    '''
    :param list y: label
    :param ref_label: reference label
    '''
    set_y = set(y)
    if ref_label not in set_y:
        raise ValueError('There is not reference label in dataset. '
                         ""Reference label: '%s' ""
                         'Labels in dataset: %s' % (ref_label, set_y))",":param list y: label
    :param ref_label: reference label",
"def restore_data(self, data_dict):
        """"""
        Restore the data dict - update the flask session and this object
        """"""
        session[self._base_key] = data_dict
        self._data_dict = session[self._base_key]",Restore the data dict - update the flask session and this object,
"def _mergedict(a, b):
    """"""Recusively merge the 2 dicts.

    Destructive on argument 'a'.
    """"""
    for p, d1 in b.items():
        if p in a:
            if not isinstance(d1, dict):
                continue
            _mergedict(a[p], d1)
        else:
            a[p] = d1
    return a","Recusively merge the 2 dicts.

    Destructive on argument 'a'.",
"def register_block(self, block_type, block):
        """"""
        Registers `block` to `block_type` in the registry.
        """"""

        self._verify_block(block_type, block)
        self._registry[block_type] = block",Registers `block` to `block_type` in the registry.,
"def cli(*args, **kwargs):
    """"""
    

     `GitHub <https://github.com/littlemo/mohand>`_
    """"""
    log.debug('cli: {} {}'.format(args, kwargs))

    #  option  env 
    env.update(kwargs)","

     `GitHub <https://github.com/littlemo/mohand>`_",
"def _is_package(path):
    """"""
     Python 

    :param str path: 
    :return:  path  Python 
    :rtype: bool
    """"""
    def _exists(s):
        return os.path.exists(os.path.join(path, s))

    return (
        os.path.isdir(path) and
        (_exists('__init__.py') or _exists('__init__.pyc'))
    )"," Python 

    :param str path: 
    :return:  path  Python 
    :rtype: bool",
"def extract_commands(imported_vars):
    """"""
    ( ``click.core.Command`` )

    :param dict_items imported_vars: 
    :return: 
    :rtype: dict(str, object)
    """"""
    commands = dict()
    for tup in imported_vars:
        name, obj = tup
        if is_command_object(obj):
            commands.setdefault(name, obj)
    return commands","( ``click.core.Command`` )

    :param dict_items imported_vars: 
    :return: 
    :rtype: dict(str, object)",
"def scale_aphi(self, scale_parameter):
        """"""Scale the spectra by multiplying by linear scaling factor

        :param scale_parameter: Linear scaling factor
        """"""
        lg.info('Scaling a_phi by :: ' + str(scale_parameter))
        try:
            self.a_phi = self.a_phi * scale_parameter
        except:
            lg.exception(""Can't scale a_phi, check that it has been defined "")","Scale the spectra by multiplying by linear scaling factor

        :param scale_parameter: Linear scaling factor",
"def _write_iop_to_file(self, iop, file_name):
        """"""Generic iop file writer

        :param iop numpy array to write to file
        :param file_name the file and path to write the IOP to
        """"""
        lg.info('Writing :: ' + file_name)
        f = open(file_name, 'w')
        for i in scipy.nditer(iop):
            f.write(str(i) + '\n')","Generic iop file writer

        :param iop numpy array to write to file
        :param file_name the file and path to write the IOP to",
"def build_a(self):
        """"""Calculates the total absorption from water, phytoplankton and CDOM

        a = awater + acdom + aphi
        """"""
        lg.info('Building total absorption')
        self.a = self.a_water + self.a_cdom + self.a_phi","Calculates the total absorption from water, phytoplankton and CDOM

        a = awater + acdom + aphi",
"def build_c(self):
        """"""Calculates the total attenuation from the total absorption and total scattering

        c = a + b
        """"""
        lg.info('Building total attenuation C')
        self.c = self.a + self.b","Calculates the total attenuation from the total absorption and total scattering

        c = a + b",
"def build_all_iop(self):
        """"""Meta method that calls all of the build methods in the correct order

        self.build_a()
        self.build_bb()
        self.build_b()
        self.build_c()
        """"""
        lg.info('Building all b and c from IOPs')

        self.build_a()
        self.build_bb()
        self.build_b()
        self.build_c()","Meta method that calls all of the build methods in the correct order

        self.build_a()
        self.build_bb()
        self.build_b()
        self.build_c()",
"def string_to_float_list(string_var):
        """"""Pull comma separated string values out of a text file and converts them to float list""""""
        try:
            return [float(s) for s in string_var.strip('[').strip(']').split(', ')]
        except:
            return [float(s) for s in string_var.strip('[').strip(']').split(',')]",Pull comma separated string values out of a text file and converts them to float list,
"def set_handler(self, signals, handler=signal.SIG_DFL):
        """""" Takes a list of signals and sets a handler for them """"""
        for sig in signals:
            self.log.debug(""Creating handler for signal: {0}"".format(sig))
            signal.signal(sig, handler)",Takes a list of signals and sets a handler for them,
"def pseudo_handler(self, signum, frame):
        """""" Pseudo handler placeholder while signal is beind processed """"""
        self.log.warn(""Received sigal {0} but system is already busy processing a previous signal, current frame: {1}"".format(signum, str(frame)))",Pseudo handler placeholder while signal is beind processed,
"def abort(self, signum):
        """""" Run all abort tasks, then all exit tasks, then exit with error
        return status""""""
        self.log.info('Signal handler received abort request')
        self._abort(signum)
        self._exit(signum)
        os._exit(1)","Run all abort tasks, then all exit tasks, then exit with error
        return status",
"def reg_on_abort(self, callable_object, *args, **kwargs):
        """""" Register a function/method to be called when execution is aborted""""""
        persistent = kwargs.pop('persistent', False)
        event = self._create_event(callable_object, 'abort', persistent, *args, **kwargs)
        self.abort_callbacks.append(event)
        return event",Register a function/method to be called when execution is aborted,
"def fetch_sorted_metric(self, *args, **kwargs):
        """"""Fetch and sort time series data from OpenTSDB

        Takes the same parameters as `fetch_metric`, but returns a list of
        (timestamp, value) tuples sorted by timestamp.
        """"""
        return sorted(self.fetch_metric(*args, **kwargs).items(),
            key=lambda x: float(x[0]))","Fetch and sort time series data from OpenTSDB

        Takes the same parameters as `fetch_metric`, but returns a list of
        (timestamp, value) tuples sorted by timestamp.",
"def __sig_from_partial(self, inst):
        """"""Extract function signature from an existing partial instance.""""""

        self.pargl     = list(inst.pargl)
        self.kargl     = list(inst.kargl)
        self.def_argv  = inst.def_argv.copy()
        self.var_pargs = inst.var_pargs
        self.var_kargs = inst.var_kargs",Extract function signature from an existing partial instance.,
"def vlq2int(data):
    """"""Read one VLQ-encoded integer value from an input data stream.""""""
    # The VLQ is little-endian.
    byte = ord(data.read(1)) 
    value = byte & 0x7F
    shift = 1
    while byte & 0x80 != 0:
        byte = ord(data.read(1))
        value = ((byte & 0x7F) << shift * 7) | value
        shift += 1
    return value",Read one VLQ-encoded integer value from an input data stream.,
"def get_duration(self, seconds):
        """"""Transform duration into a human-readable form.""""""
        duration = """"
        minutes, seconds = divmod(seconds, 60)
        if minutes >= 60:
            hours, minutes = divmod(minutes, 60)
            duration = ""%sh "" % hours
        duration += ""%sm %ss"" % (minutes, seconds)
        return duration",Transform duration into a human-readable form.,
"def display_the_graphic_connection(self):
        """"""
        The following permits to attribute the function ""display_the_graphic"" to the slider.
        Because, to make a connection, we can not have parameters for the function, but ""display_the_graphic"" has some.
        """"""
        self.display_the_graphic(self.num_line, self.wavelength, self.data_wanted, self.information)","The following permits to attribute the function ""display_the_graphic"" to the slider.
        Because, to make a connection, we can not have parameters for the function, but ""display_the_graphic"" has some.",
"def display_error_message(self):
        """"""
        This function displays an error message when a wrong value is typed.
        """"""
        self.ui.error_label.setScaledContents(True)  # Warning image shown.
        self.ui.error_text_label.show()  # Warning message shown.
        self.ui.error_text_label.setStyleSheet('color: red')",This function displays an error message when a wrong value is typed.,
"def hide_error_message(self):
        """"""
        This function hides the error message when all values are correct.
        """"""
        self.ui.error_label.setScaledContents(False)  # Warning image hiden.
        self.ui.error_text_label.hide()",This function hides the error message when all values are correct.,
"def click(self, event):
        """"""
        This function intercepts the mouse's right click and its position.
        """"""
        if event.button == 3:
            if self.ui.tabWidget.currentIndex() == TabWidget.NORMAL_MODE:
                self.pos = QtGui.QCursor().pos()
                self.graphic_context_menu(self.pos)",This function intercepts the mouse's right click and its position.,
"def mouse_move(self, event):
        """"""
        The following gets back coordinates of the mouse on the canvas.
        """"""
        if (self.ui.tabWidget.currentIndex() == TabWidget.NORMAL_MODE):
            self.posX = event.xdata
            self.posY = event.ydata

            self.graphic_target(self.posX, self.posY)",The following gets back coordinates of the mouse on the canvas.,
"def genesis_signing_lockset(genesis, privkey):
    """"""
    in order to avoid a complicated bootstrapping, we define
    the genesis_signing_lockset as a lockset with one vote by any validator.
    """"""
    v = VoteBlock(0, 0, genesis.hash)
    v.sign(privkey)
    ls = LockSet(num_eligible_votes=1)
    ls.add(v)
    assert ls.has_quorum
    return ls","in order to avoid a complicated bootstrapping, we define
    the genesis_signing_lockset as a lockset with one vote by any validator.",
"def hr(self):
        """"""compute (height,round)
        We might have multiple rounds before we see consensus for a certain height.
        If everything is good, round should always be 0.
        """"""
        assert len(self), 'no votes, can not determine height'
        h = set([(v.height, v.round) for v in self.votes])
        assert len(h) == 1, len(h)
        return h.pop()","compute (height,round)
        We might have multiple rounds before we see consensus for a certain height.
        If everything is good, round should always be 0.",
"def has_quorum(self):
        """"""
        we've seen +2/3 of all eligible votes voting for one block.
        there is a quorum.
        """"""
        assert self.is_valid
        bhs = self.blockhashes()
        if bhs and bhs[0][1] > 2 / 3. * self.num_eligible_votes:
            return bhs[0][0]","we've seen +2/3 of all eligible votes voting for one block.
        there is a quorum.",
"def has_noquorum(self):
        """"""
        less than 1/3 of the known votes are on the same block
        """"""
        assert self.is_valid
        bhs = self.blockhashes()
        if not bhs or bhs[0][1] <= 1 / 3. * self.num_eligible_votes:
            assert not self.has_quorum_possible
            return True",less than 1/3 of the known votes are on the same block,
"def check(self):
        ""either invalid or one of quorum, noquorum, quorumpossible""
        if not self.is_valid:
            return True
        test = (self.has_quorum, self.has_quorum_possible, self.has_noquorum)
        assert 1 == len([x for x in test if x is not None])
        return True","either invalid or one of quorum, noquorum, quorumpossible",
"def to_block(self, env, parent=None):
        """"""Convert the transient block to a :class:`ethereum.blocks.Block`""""""
        return Block(self.header, self.transaction_list, self.uncles, env=env, parent=parent)",Convert the transient block to a :class:`ethereum.blocks.Block`,
"def approve(ctx, _spender='address', _value='uint256', returns=STATUS):
        """""" Standardized Contract API:
        function approve(address _spender, uint256 _value) returns (bool success)
        """"""
        ctx.allowances[ctx.msg_sender][_spender] += _value
        ctx.Approval(ctx.msg_sender, _spender, _value)
        return OK","Standardized Contract API:
        function approve(address _spender, uint256 _value) returns (bool success)",
"def last_lock(self):
        ""highest lock on height""
        rs = list(self.rounds)
        assert len(rs) < 2 or rs[0] > rs[1]  # FIXME REMOVE
        for r in self.rounds:  # is sorted highest to lowest
            if self.rounds[r].lock is not None:
                return self.rounds[r].lock",highest lock on height,
"def last_voted_blockproposal(self):
        ""the last block proposal node voted on""
        for r in self.rounds:
            if isinstance(self.rounds[r].proposal, BlockProposal):
                assert isinstance(self.rounds[r].lock, Vote)
                if self.rounds[r].proposal.blockhash == self.rounds[r].lock.blockhash:
                    return self.rounds[r].proposal",the last block proposal node voted on,
"def last_valid_lockset(self):
        ""highest valid lockset on height""
        for r in self.rounds:
            ls = self.rounds[r].lockset
            if ls.is_valid:
                return ls
        return None",highest valid lockset on height,
"def on_proposal(self, proposal, proto):
        ""called to inform about synced peers""
        assert isinstance(proto, HDCProtocol)
        assert isinstance(proposal, Proposal)
        if proposal.height >= self.cm.height:
            assert proposal.lockset.is_valid
            self.last_active_protocol = proto",called to inform about synced peers,
"def delay(self, sender, receiver, packet, add_delay=0):
        """"""
        bandwidths are inaccurate, as we don't account for parallel transfers here
        """"""
        bw = min(sender.ul_bandwidth, receiver.dl_bandwidth)
        delay = sender.base_latency + receiver.base_latency
        delay += len(packet) / bw
        delay += add_delay
        return delay","bandwidths are inaccurate, as we don't account for parallel transfers here",
"def deliver(self, sender, receiver, packet):
        ""deliver on edge of timeout_window""
        to = ConsensusManager.round_timeout
        assert to > 0
        print ""in slow transport deliver""
        super(SlowTransport, self).deliver(sender, receiver, packet, add_delay=to)",deliver on edge of timeout_window,
"def abi_encode_args(method, args):
    ""encode args for method: method_id|data""
    assert issubclass(method.im_class, NativeABIContract), method.im_class
    m_abi = method.im_class._get_method_abi(method)
    return zpad(encode_int(m_abi['id']), 4) + abi.encode_abi(m_abi['arg_types'], args)",encode args for method: method_id|data,
"def address_to_native_contract_class(self, address):
        ""returns class._on_msg_unsafe, use x.im_self to get class""
        assert isinstance(address, bytes) and len(address) == 20
        assert self.is_instance_address(address)
        nca = self.native_contract_address_prefix + address[-4:]
        return self.native_contracts[nca]","returns class._on_msg_unsafe, use x.im_self to get class",
"def validators_from_config(validators):
    """"""Consolidate (potentially hex-encoded) list of validators
    into list of binary address representations.
    """"""
    result = []
    for validator in validators:
        if len(validator) == 40:
            validator = validator.decode('hex')
        result.append(validator)
    return result","Consolidate (potentially hex-encoded) list of validators
    into list of binary address representations.",
"def update(self, data):
        ""returns True if unknown""
        if data not in self.filter:
            self.filter.append(data)
            if len(self.filter) > self.max_items:
                self.filter.pop(0)
            return True
        else:
            self.filter.append(self.filter.pop(0))
            return False",returns True if unknown,
"def on_receive_transactions(self, proto, transactions):
        ""receives rlp.decoded serialized""
        log.debug('----------------------------------')
        log.debug('remote_transactions_received', count=len(transactions), remote_id=proto)

        def _add_txs():
            for tx in transactions:
                self.add_transaction(tx, origin=proto)
        gevent.spawn(_add_txs)",receives rlp.decoded serialized,
"def img_from_vgg(x):
    '''Decondition an image from the VGG16 model.'''
    x = x.transpose((1, 2, 0))
    x[:, :, 0] += 103.939
    x[:, :, 1] += 116.779
    x[:, :, 2] += 123.68
    x = x[:,:,::-1]  # to RGB
    return x",Decondition an image from the VGG16 model.,
"def img_to_vgg(x):
    '''Condition an image for use with the VGG16 model.'''
    x = x[:,:,::-1]  # to BGR
    x[:, :, 0] -= 103.939
    x[:, :, 1] -= 116.779
    x[:, :, 2] -= 123.68
    x = x.transpose((2, 0, 1))
    return x",Condition an image for use with the VGG16 model.,
"def get_f_layer(self, layer_name):
        '''Create a function for the response of a layer.'''
        inputs = [self.net_input]
        if self.learning_phase is not None:
            inputs.append(K.learning_phase())
        return K.function(inputs, [self.get_layer_output(layer_name)])",Create a function for the response of a layer.,
"def get_layer_output(self, name):
        '''Get symbolic output of a layer.'''
        if not name in self._f_layer_outputs:
            layer = self.net.get_layer(name)
            self._f_layer_outputs[name] = layer.output
        return self._f_layer_outputs[name]",Get symbolic output of a layer.,
"def to_list(self):
        """"""
        Set the current encoder output to :class:`giraffez.Row` objects
        and returns the cursor.  This is the default value so it is not
        necessary to select this unless the encoder settings have been
        changed already.
        """"""
        self.conn.set_encoding(ROW_ENCODING_LIST)
        self.processor = lambda x, y: Row(x, y)
        return self","Set the current encoder output to :class:`giraffez.Row` objects
        and returns the cursor.  This is the default value so it is not
        necessary to select this unless the encoder settings have been
        changed already.",
"def items(self):
        """"""
        Represents the contents of the row as a :code:`dict` with the column
        names as keys, and the row's fields as values.

        :rtype: dict
        """"""
        return {k.name: v for k, v in zip(self.columns, self)}","Represents the contents of the row as a :code:`dict` with the column
        names as keys, and the row's fields as values.

        :rtype: dict",
"def specific_gains(string):
    """"""Convert string with gains of individual amplification elements to dict""""""
    if not string:
        return {}

    gains = {}
    for gain in string.split(','):
        amp_name, value = gain.split('=')
        gains[amp_name.strip()] = float(value.strip())
    return gains",Convert string with gains of individual amplification elements to dict,
"def device_settings(string):
    """"""Convert string with SoapySDR device settings to dict""""""
    if not string:
        return {}

    settings = {}
    for setting in string.split(','):
        setting_name, value = setting.split('=')
        settings[setting_name.strip()] = value.strip()
    return settings",Convert string with SoapySDR device settings to dict,
"def wrap(text, indent='    '):
    """"""Wrap text to terminal width with default indentation""""""
    wrapper = textwrap.TextWrapper(
        width=int(os.environ.get('COLUMNS', 80)),
        initial_indent=indent,
        subsequent_indent=indent
    )
    return '\n'.join(wrapper.wrap(text))",Wrap text to terminal width with default indentation,
"def detect_devices(soapy_args=''):
    """"""Returns detected SoapySDR devices""""""
    devices = simplesoapy.detect_devices(soapy_args, as_string=True)
    text = []
    text.append('Detected SoapySDR devices:')
    if devices:
        for i, d in enumerate(devices):
            text.append('  {}'.format(d))
    else:
        text.append('  No devices found!')
    return (devices, '\n'.join(text))",Returns detected SoapySDR devices,
"def set_center_freq(self, center_freq):
        """"""Set center frequency and clear averaged PSD data""""""
        psd_state = {
            'repeats': 0,
            'freq_array': self._base_freq_array + self._lnb_lo + center_freq,
            'pwr_array': None,
            'update_lock': threading.Lock(),
            'futures': [],
        }
        return psd_state",Set center frequency and clear averaged PSD data,
"def wait_for_result(self, psd_state):
        """"""Wait for all PSD threads to finish and return result""""""
        if len(psd_state['futures']) > 1:
            concurrent.futures.wait(psd_state['futures'])
        elif psd_state['futures']:
            psd_state['futures'][0].result()
        return self.result(psd_state)",Wait for all PSD threads to finish and return result,
"def update_async(self, psd_state, samples_array):
        """"""Compute PSD from samples and update average for given center frequency (asynchronously in another thread)""""""
        future = self._executor.submit(self.update, psd_state, samples_array)
        future.add_done_callback(self._release_future_memory)
        psd_state['futures'].append(future)
        return future",Compute PSD from samples and update average for given center frequency (asynchronously in another thread),
"def write_async(self, psd_data_or_future, time_start, time_stop, samples):
        """"""Write PSD of one frequncy hop (asynchronously in another thread)""""""
        return self._executor.submit(self.write, psd_data_or_future, time_start, time_stop, samples)",Write PSD of one frequncy hop (asynchronously in another thread),
"def write(self, f, time_start, time_stop, start, stop, step, samples, pwr_array):
        """"""Write data to file-like object""""""
        f.write(self.magic)
        f.write(self.header_struct.pack(
            self.version, time_start, time_stop, start, stop, step, samples, pwr_array.nbytes
        ))
        #pwr_array.tofile(f)
        f.write(pwr_array.tobytes())
        f.flush()",Write data to file-like object,
"def time_to_repeats(self, bins, integration_time):
        """"""Convert integration time to number of repeats""""""
        return math.ceil((self.device.sample_rate * integration_time) / bins)",Convert integration time to number of repeats,
"def close(self):
        """"""close()

        Disconnects the object from the bus.
        """"""
        os.close(self._fd)
        self._fd = -1
        self._addr = -1
        self._pec = 0","close()

        Disconnects the object from the bus.",
"def open(self, bus):
        """"""open(bus)

        Connects the object to the specified SMBus.
        """"""
        bus = int(bus)
        path = ""/dev/i2c-%d"" % (bus,)
        if len(path) >= MAXPATH:
                raise OverflowError(""Bus number is invalid."")
        try:
            self._fd = os.open(path, os.O_RDWR, 0)
        except OSError as e:
            raise IOError(e.errno)","open(bus)

        Connects the object to the specified SMBus.",
"def _set_addr(self, addr):
        """"""private helper method""""""
        if self._addr != addr:
            ioctl(self._fd, SMBUS.I2C_SLAVE, addr)
            self._addr = addr",private helper method,
"def write_quick(self, addr):
        """"""write_quick(addr)

        Perform SMBus Quick transaction.
        """"""
        self._set_addr(addr)
        if SMBUS.i2c_smbus_write_quick(self._fd, SMBUS.I2C_SMBUS_WRITE) != 0:
            raise IOError(ffi.errno)","write_quick(addr)

        Perform SMBus Quick transaction.",
"def read_byte(self, addr):
        """"""read_byte(addr) -> result

        Perform SMBus Read Byte transaction.
        """"""
        self._set_addr(addr)
        result = SMBUS.i2c_smbus_read_byte(self._fd)
        if result == -1:
            raise IOError(ffi.errno)
        return result","read_byte(addr) -> result

        Perform SMBus Read Byte transaction.",
"def write_byte(self, addr, val):
        """"""write_byte(addr, val)

        Perform SMBus Write Byte transaction.
        """"""
        self._set_addr(addr)
        if SMBUS.i2c_smbus_write_byte(self._fd, ffi.cast(""__u8"", val)) == -1:
            raise IOError(ffi.errno)","write_byte(addr, val)

        Perform SMBus Write Byte transaction.",
"def read_byte_data(self, addr, cmd):
        """"""read_byte_data(addr, cmd) -> result

        Perform SMBus Read Byte Data transaction.
        """"""
        self._set_addr(addr)
        res = SMBUS.i2c_smbus_read_byte_data(self._fd, ffi.cast(""__u8"", cmd))
        if res == -1:
            raise IOError(ffi.errno)
        return res","read_byte_data(addr, cmd) -> result

        Perform SMBus Read Byte Data transaction.",
"def read_word_data(self, addr, cmd):
        """"""read_word_data(addr, cmd) -> result

        Perform SMBus Read Word Data transaction.
        """"""
        self._set_addr(addr)
        result = SMBUS.i2c_smbus_read_word_data(self._fd, ffi.cast(""__u8"", cmd))
        if result == -1:
            raise IOError(ffi.errno)
        return result","read_word_data(addr, cmd) -> result

        Perform SMBus Read Word Data transaction.",
"def pec(self, value):
        """"""True if Packet Error Codes (PEC) are enabled""""""
        pec = bool(value)
        if pec != self._pec:
            if ioctl(self._fd, SMBUS.I2C_PEC, pec):
                raise IOError(ffi.errno)
            self._pec = pec",True if Packet Error Codes (PEC) are enabled,
"def start(cls, now, number, **options):
        """"""
        Return the starting datetime: ``number`` of units before ``now``.
        """"""
        return (cls.mask(now, **options) -
                timedelta(**{cls.__name__.lower(): number - 1}))",Return the starting datetime: ``number`` of units before ``now``.,
"def mask(cls, dt, **options):
        """"""
        Return a datetime with the same value as ``dt``, to a
        resolution of days.
        """"""
        return dt.replace(hour=0, minute=0, second=0, microsecond=0)","Return a datetime with the same value as ``dt``, to a
        resolution of days.",
"def start(cls, now, number, **options):
        """"""
        Return the starting datetime: ``number`` of years before ``now``.
        """"""
        return cls.mask(now).replace(year=(now.year - number + 1))",Return the starting datetime: ``number`` of years before ``now``.,
"def deactivate(self):
        """"""When deactivated the :class:`PortEventListener` will not run
        anything.
        """"""
        self.event_queue.put(self.TERMINATE_SIGNAL)
        self.dispatcher.join()
        self.detector.terminate()
        self.detector.join()","When deactivated the :class:`PortEventListener` will not run
        anything.",
"def gpio_interrupts_enable(self):
        """"""Enables GPIO interrupts.""""""
        try:
            bring_gpio_interrupt_into_userspace()
            set_gpio_interrupt_edge()
        except Timeout as e:
            raise InterruptEnableException(
                ""There was an error bringing gpio%d into userspace. %s"" %
                (GPIO_INTERRUPT_PIN, e.message)
            )",Enables GPIO interrupts.,
"def has_errors(self, form):
        """"""
        Find tab fields listed as invalid
        """"""
        return any([fieldname_error for fieldname_error in form.errors.keys()
                    if fieldname_error in self])",Find tab fields listed as invalid,
"def _extract_version(package_name):
    """"""
    Get package version from installed distribution or configuration file if not
    installed
    """"""
    try:
        return pkg_resources.get_distribution(package_name).version
    except pkg_resources.DistributionNotFound:
        _conf = read_configuration(os.path.join(PROJECT_DIR, ""setup.cfg""))
    return _conf[""metadata""][""version""]","Get package version from installed distribution or configuration file if not
    installed",
"def get_form_kwargs(self):
        """"""
        Pass template pack argument
        """"""
        kwargs = super(FormContainersMixin, self).get_form_kwargs()
        kwargs.update({
            'pack': ""foundation-{}"".format(self.kwargs.get('foundation_version'))
        })
        return kwargs",Pass template pack argument,
"def calc_wind_chill(t, windspeed, windspeed10min=None):
    '''
    calculates the wind chill value based upon the temperature (F) and
    wind.

    returns the wind chill in degrees F.
    '''

    w = max(windspeed10min, windspeed)
    return 35.74 + 0.6215 * t - 35.75 * (w ** 0.16) + 0.4275 * t * (w ** 0.16);","calculates the wind chill value based upon the temperature (F) and
    wind.

    returns the wind chill in degrees F.",
"def calc_humidity(temp, dewpoint):
    '''
    calculates the humidity via the formula from weatherwise.org
    return the relative humidity
    '''

    t = fahrenheit_to_celsius(temp)
    td = fahrenheit_to_celsius(dewpoint)

    num = 112 - (0.1 * t) + td
    denom = 112 + (0.9 * t)

    rh = math.pow((num / denom), 8)
    
    return rh","calculates the humidity via the formula from weatherwise.org
    return the relative humidity",
"def publish(self):
      '''
      Perform HTTP session to transmit defined weather values.
      '''
      return self._publish( self.args, self.server, self.URI)",Perform HTTP session to transmit defined weather values.,
"def get(data):
        '''
        return CRC calc value from raw serial data
        '''
        crc = 0
        for byte in array('B', data):
            crc = (VProCRC.CRC_TABLE[(crc >> 8) ^ byte] ^ ((crc & 0xFF) << 8))
        return crc",return CRC calc value from raw serial data,
"def verify(data):
        '''
        perform CRC check on raw serial data, return true if valid.
        a valid CRC == 0.
        '''
        if len(data) == 0:
            return False
        crc = VProCRC.get(data)
        if crc:
            log.info(""CRC Bad"")
        else:
            log.debug(""CRC OK"")
        return not crc","perform CRC check on raw serial data, return true if valid.
        a valid CRC == 0.",
"def _unpack_storm_date(date):
        '''
        given a packed storm date field, unpack and return 'YYYY-MM-DD' string.
        '''
        year = (date & 0x7f) + 2000  # 7 bits
        day = (date >> 7) & 0x01f  # 5 bits
        month = (date >> 12) & 0x0f  # 4 bits
        return ""%s-%s-%s"" % (year, month, day)","given a packed storm date field, unpack and return 'YYYY-MM-DD' string.",
"def _loop_cmd(self):
        '''
        reads a raw string containing data read from the device
        provided (in /dev/XXX) format. all reads are non-blocking.
        '''
        self._cmd('LOOP', 1)
        raw = self.port.read(LoopStruct.size)  # read data
        log_raw('read', raw)
        return raw","reads a raw string containing data read from the device
        provided (in /dev/XXX) format. all reads are non-blocking.",
"def unpack_from(self, buf, offset=0 ):
        '''
        unpacks data from 'buf' and returns a dication of named fields. the
        fields can be post-processed by extending the _post_unpack() method.
        '''
        data = super(Struct,self).unpack_from( buf, offset)
        items = dict(zip(self.fields,data))
        return self._post_unpack(items)","unpacks data from 'buf' and returns a dication of named fields. the
        fields can be post-processed by extending the _post_unpack() method.",
"def set( self, **kw):
      '''
      Store keyword args to be written to output file.
      '''
      self.args = kw
      log.debug( self.args )",Store keyword args to be written to output file.,
"def publish(self):
      '''
      Write output file.
      '''
      with open( self.file_name, 'w') as fh:
         for k,v in self.args.iteritems():
            buf = StringIO.StringIO()
            buf.write(k)
            self._append_vals(buf,v)
            fh.write(buf.getvalue() + '\n')
            buf.close()",Write output file.,
"def And(cls, *requirements):
        """"""
        Short cut helper to construct a combinator that uses
        :meth:`operator.and_` to reduce requirement results and stops
        evaluating on the first False.

        This is also exported at the module level as ``And``
        """"""
        return cls(*requirements, op=operator.and_, until=False)","Short cut helper to construct a combinator that uses
        :meth:`operator.and_` to reduce requirement results and stops
        evaluating on the first False.

        This is also exported at the module level as ``And``",
"def Or(cls, *requirements):
        """"""
        Short cut helper to construct a combinator that uses
        :meth:`operator.or_` to reduce requirement results and stops evaluating
        on the first True.

        This is also exported at the module level as ``Or``
        """"""
        return cls(*requirements, op=operator.or_, until=True)","Short cut helper to construct a combinator that uses
        :meth:`operator.or_` to reduce requirement results and stops evaluating
        on the first True.

        This is also exported at the module level as ``Or``",
"def override(self, override, use_parent=False):
        """"""
        Allows temporarily pushing an override context, yields the new context
        into the following block.
        """"""
        self.push(override, use_parent)
        yield self.current
        self.pop()","Allows temporarily pushing an override context, yields the new context
        into the following block.",
"def additional(self, additional, use_parent=False):
        """"""
        Allows temporarily pushing an additional context, yields the new context
        into the following block.
        """"""
        self.push(additional, use_parent)
        yield self.current
        self.pop()","Allows temporarily pushing an additional context, yields the new context
        into the following block.",
"def unduplicate_field_names(field_names):
    """"""Append a number to duplicate field names to make them unique. """"""
    res = []
    for k in field_names:
        if k in res:
            i = 1
            while k + '_' + str(i) in res:
                i += 1
            k += '_' + str(i)
        res.append(k)
    return res",Append a number to duplicate field names to make them unique.,
"def get_dataframe(self):
        """"""Returns a Pandas DataFrame instance built from the result set.""""""
        if pd is None:
            raise ImportError(""Try installing Pandas first."")
        frame = pd.DataFrame(self[:], columns=(self and self.keys) or [])
        return frame",Returns a Pandas DataFrame instance built from the result set.,
"def get_widgets_sorted(self):
        """"""Returns the widgets sorted by position.""""""
        result = []
        for widget_name, widget in self.get_widgets().items():
            result.append((widget_name, widget, widget.position))
        result.sort(key=lambda x: x[2])
        return result",Returns the widgets sorted by position.,
"def get_widgets_that_need_update(self):
        """"""
        Returns all widgets that need an update.

        This should be scheduled every minute via crontab.

        """"""
        result = []
        for widget_name, widget in self.get_widgets().items():
            if widget.should_update():
                result.append(widget)
        return result","Returns all widgets that need an update.

        This should be scheduled every minute via crontab.",
"def unregister_widget(self, widget_cls):
        """"""Unregisters the given widget.""""""
        if widget_cls.__name__ in self.widgets:
            del self.widgets[widget_cls().get_name()]",Unregisters the given widget.,
"def get_last_update(self):
        """"""Gets or creates the last update object for this widget.""""""
        instance, created = \
            models.DashboardWidgetLastUpdate.objects.get_or_create(
                widget_name=self.get_name())
        return instance",Gets or creates the last update object for this widget.,
"def getByGeocode(self, lat, lon):
        """"""
        :param lat: latitude
        :param lon: longitude
        Get Foodie and Nightlife Index, list of popular cuisines and nearby restaurants around the given coordinates
        """"""
        params = {""lat"": lat, ""lon"": lon}
        response = self.api.get(""/geocode"", params)
        return response",":param lat: latitude
        :param lon: longitude
        Get Foodie and Nightlife Index, list of popular cuisines and nearby restaurants around the given coordinates",
"def getDailyMenu(self, restaurant_id):
        """"""
        :param restaurant_id: id of restaurant whose details are requested
        :return: json response
        Get daily menu using Zomato restaurant ID.
        """"""
        params = {""res_id"": restaurant_id}
        daily_menu = self.api.get(""/dailymenu"", params)
        return daily_menu",":param restaurant_id: id of restaurant whose details are requested
        :return: json response
        Get daily menu using Zomato restaurant ID.",
"def unstack(self):
        """"""
        Unstack array and return a new BoltArraySpark via flatMap().
        """"""
        from bolt.spark.array import BoltArraySpark

        if self._rekeyed:
            rdd = self._rdd
        else:
            rdd = self._rdd.flatMap(lambda kv: zip(kv[0], list(kv[1])))

        return BoltArraySpark(rdd, shape=self.shape, split=self.split)",Unstack array and return a new BoltArraySpark via flatMap().,
"def getmask(inds, n):
        """"""
        Obtain a binary mask by setting a subset of entries to true.

        Parameters
        ----------
        inds : array-like
            Which indices to set as true.

        n : int
            The length of the target mask.
        """"""
        inds = asarray(inds, 'int')
        mask = zeros(n, dtype=bool)
        mask[inds] = True
        return mask","Obtain a binary mask by setting a subset of entries to true.

        Parameters
        ----------
        inds : array-like
            Which indices to set as true.

        n : int
            The length of the target mask.",
"def repartition(self, npartitions):
        """"""
        Repartitions the underlying RDD

        Parameters
        ----------
        npartitions : int
            Number of partitions to repartion the underlying RDD to
        """"""

        rdd = self._rdd.repartition(npartitions)
        return self._constructor(rdd, ordered=False).__finalize__(self)","Repartitions the underlying RDD

        Parameters
        ----------
        npartitions : int
            Number of partitions to repartion the underlying RDD to",
"def first(self):
        """"""
        Return the first element of an array
        """"""
        from bolt.local.array import BoltArrayLocal
        rdd = self._rdd if self._ordered else self._rdd.sortByKey()
        return BoltArrayLocal(rdd.values().first())",Return the first element of an array,
"def swapaxes(self, axis1, axis2):
        """"""
        Return the array with two axes interchanged.

        Parameters
        ----------
        axis1 : int
            The first axis to swap

        axis2 : int
            The second axis to swap
        """"""
        p = list(range(self.ndim))
        p[axis1] = axis2
        p[axis2] = axis1

        return self.transpose(p)","Return the array with two axes interchanged.

        Parameters
        ----------
        axis1 : int
            The first axis to swap

        axis2 : int
            The second axis to swap",
"def astype(self, dtype, casting='unsafe'):
        """"""
        Cast the array to a specified type.

        Parameters
        ----------
        dtype : str or dtype
            Typecode or data-type to cast the array to (see numpy)
        """"""
        rdd = self._rdd.mapValues(lambda v: v.astype(dtype, 'K', casting))
        return self._constructor(rdd, dtype=dtype).__finalize__(self)","Cast the array to a specified type.

        Parameters
        ----------
        dtype : str or dtype
            Typecode or data-type to cast the array to (see numpy)",
"def toarray(self):
        """"""
        Returns the contents as a local array.

        Will likely cause memory problems for large objects.
        """"""
        rdd = self._rdd if self._ordered else self._rdd.sortByKey()
        x = rdd.values().collect()
        return asarray(x).reshape(self.shape)","Returns the contents as a local array.

        Will likely cause memory problems for large objects.",
"def allclose(a, b):
    """"""
    Test that a and b are close and match in shape.

    Parameters
    ----------
    a : ndarray
        First array to check

    b : ndarray
        First array to check
    """"""
    from numpy import allclose
    return (a.shape == b.shape) and allclose(a, b)","Test that a and b are close and match in shape.

    Parameters
    ----------
    a : ndarray
        First array to check

    b : ndarray
        First array to check",
"def iterexpand(arry, extra):
    """"""
    Expand dimensions by iteratively append empty axes.

    Parameters
    ----------
    arry : ndarray
        The original array

    extra : int
        The number of empty axes to append
    """"""
    for d in range(arry.ndim, arry.ndim+extra):
        arry = expand_dims(arry, axis=d)
    return arry","Expand dimensions by iteratively append empty axes.

    Parameters
    ----------
    arry : ndarray
        The original array

    extra : int
        The number of empty axes to append",
"def plfit_lsq(x,y):
    """"""
    Returns A and B in y=Ax^B
    http://mathworld.wolfram.com/LeastSquaresFittingPowerLaw.html
    """"""
    n = len(x)
    btop = n * (log(x)*log(y)).sum() - (log(x)).sum()*(log(y)).sum()
    bbottom = n*(log(x)**2).sum() - (log(x).sum())**2
    b = btop / bbottom
    a = ( log(y).sum() - b * log(x).sum() ) / n

    A = exp(a)
    return A,b","Returns A and B in y=Ax^B
    http://mathworld.wolfram.com/LeastSquaresFittingPowerLaw.html",
"def plotcdf(x,xmin,alpha):
    """"""
    Plots CDF and powerlaw
    """"""

    x=sort(x)
    n=len(x)
    xcdf = arange(n,0,-1,dtype='float')/float(n)

    q = x[x>=xmin]
    fcdf = (q/xmin)**(1-alpha)
    nc = xcdf[argmax(x>=xmin)]
    fcdf_norm = nc*fcdf

    loglog(x,xcdf)
    loglog(q,fcdf_norm)",Plots CDF and powerlaw,
"def discrete_max_likelihood_arg(data, xmin, alpharange=(1.5,3.5), n_alpha=201):
    """"""
    Returns the *argument* of the max of the likelihood of the data given an input xmin
    """"""
    likelihoods = discrete_likelihood_vector(data, xmin, alpharange=alpharange, n_alpha=n_alpha)
    Largmax = np.argmax(likelihoods)
    return Largmax",Returns the *argument* of the max of the likelihood of the data given an input xmin,
"def discrete_max_likelihood(data, xmin, alpharange=(1.5,3.5), n_alpha=201):
    """"""
    Returns the *argument* of the max of the likelihood of the data given an input xmin
    """"""
    likelihoods = discrete_likelihood_vector(data, xmin, alpharange=alpharange, n_alpha=n_alpha)
    Lmax = np.max(likelihoods)
    return Lmax",Returns the *argument* of the max of the likelihood of the data given an input xmin,
"def plot_lognormal_pdf(self,**kwargs):
        """"""
        Plot the fitted lognormal distribution
        """"""
        if not hasattr(self,'lognormal_dist'):
            return

        normalized_pdf = self.lognormal_dist.pdf(self.data)/self.lognormal_dist.pdf(self.data).max()
        minY,maxY = pylab.gca().get_ylim()
        pylab.plot(self.data,normalized_pdf*maxY,'.',**kwargs)",Plot the fitted lognormal distribution,
"def hash_md5(self):
        """"""Calculate md5 fingerprint.

        Shamelessly copied from http://stackoverflow.com/questions/6682815/deriving-an-ssh-fingerprint-from-a-public-key-in-python

        For specification, see RFC4716, section 4.""""""
        fp_plain = hashlib.md5(self._decoded_key).hexdigest()
        return ""MD5:"" + ':'.join(a + b for a, b in zip(fp_plain[::2], fp_plain[1::2]))","Calculate md5 fingerprint.

        Shamelessly copied from http://stackoverflow.com/questions/6682815/deriving-an-ssh-fingerprint-from-a-public-key-in-python

        For specification, see RFC4716, section 4.",
"def hash_sha256(self):
        """"""Calculate sha256 fingerprint.""""""
        fp_plain = hashlib.sha256(self._decoded_key).digest()
        return (b""SHA256:"" + base64.b64encode(fp_plain).replace(b""="", b"""")).decode(""utf-8"")",Calculate sha256 fingerprint.,
"def hash_sha512(self):
        """"""Calculates sha512 fingerprint.""""""
        fp_plain = hashlib.sha512(self._decoded_key).digest()
        return (b""SHA512:"" + base64.b64encode(fp_plain).replace(b""="", b"""")).decode(""utf-8"")",Calculates sha512 fingerprint.,
"def decode_key(cls, pubkey_content):
        """"""Decode base64 coded part of the key.""""""
        try:
            decoded_key = base64.b64decode(pubkey_content.encode(""ascii""))
        except (TypeError, binascii.Error):
            raise MalformedDataError(""Unable to decode the key"")
        return decoded_key",Decode base64 coded part of the key.,
"def mechs(self):
        """"""
        The set of mechanisms supported by the credential.

        :type: :class:`~gssapi.oids.OIDSet`
        """"""
        if not self._mechs:
            self._mechs = self._inquire(False, False, False, True)[3]
        return self._mechs","The set of mechanisms supported by the credential.

        :type: :class:`~gssapi.oids.OIDSet`",
"def main(properties=properties, options=options, **custom_options):
    """"""Imports and runs setup function with given properties.""""""
    return init(**dict(options, **custom_options))(**properties)",Imports and runs setup function with given properties.,
"def _create_file():
    """"""
    Returns a file handle which is used to record audio
    """"""
    f = wave.open('audio.wav', mode='wb')
    f.setnchannels(2)
    p = pyaudio.PyAudio()
    f.setsampwidth(p.get_sample_size(pyaudio.paInt16))
    f.setframerate(p.get_default_input_device_info()['defaultSampleRate'])
    try:
        yield f
    finally:
        f.close()",Returns a file handle which is used to record audio,
"def djfrontend_h5bp_css(version=None):
    """"""
    Returns HTML5 Boilerplate CSS file.
    Included in HTML5 Boilerplate.
    """"""
    if version is None:
        version = getattr(settings, 'DJFRONTEND_H5BP_CSS', DJFRONTEND_H5BP_CSS_DEFAULT)

    return format_html(
        '<link rel=""stylesheet"" href=""{0}djfrontend/css/h5bp/{1}/h5bp.css"">',
        _static_url, version)","Returns HTML5 Boilerplate CSS file.
    Included in HTML5 Boilerplate.",
"def djfrontend_normalize(version=None):
    """"""
    Returns Normalize CSS file.
    Included in HTML5 Boilerplate.
    """"""
    if version is None:
        version = getattr(settings, 'DJFRONTEND_NORMALIZE', DJFRONTEND_NORMALIZE_DEFAULT)

    return format_html(
        '<link rel=""stylesheet"" href=""{0}djfrontend/css/normalize/{1}/normalize.css"">',
        _static_url, version)","Returns Normalize CSS file.
    Included in HTML5 Boilerplate.",
"def calc_expiry_time(minutes_valid):
    """"""Return specific time an auth_hash will expire.""""""
    return (
        timezone.now() + datetime.timedelta(minutes=minutes_valid + 1)
    ).replace(second=0, microsecond=0)",Return specific time an auth_hash will expire.,
"def get_user_token(user, purpose, minutes_valid):
    """"""Return login token info for given user.""""""
    token = ''.join(
        dumps([
            user.get_username(),
            get_auth_hash(user, purpose),
        ]).encode('base64').split('\n')
    )
    return {
        'id': get_meteor_id(user),
        'token': token,
        'tokenExpires': calc_expiry_time(minutes_valid),
    }",Return login token info for given user.,
"def user_factory(self):
        """"""Retrieve the current user (or None) from the database.""""""
        if this.user_id is None:
            return None
        return self.user_model.objects.get(pk=this.user_id)",Retrieve the current user (or None) from the database.,
"def auth_failed(**credentials):
        """"""Consistent fail so we don't provide attackers with valuable info.""""""
        if credentials:
            user_login_failed.send_robust(
                sender=__name__,
                credentials=auth._clean_credentials(credentials),
            )
        raise MeteorError(403, 'Authentication failed.')",Consistent fail so we don't provide attackers with valuable info.,
"def check_secure():
        """"""Check request, return False if using SSL or local connection.""""""
        if this.request.is_secure():
            return True  # using SSL
        elif this.request.META['REMOTE_ADDR'] in [
                'localhost',
                '127.0.0.1',
        ]:
            return True  # localhost
        raise MeteorError(403, 'Authentication refused without SSL.')","Check request, return False if using SSL or local connection.",
"def login(self, params):
        """"""Login either with resume token or password.""""""
        if 'password' in params:
            return self.login_with_password(params)
        elif 'resume' in params:
            return self.login_with_resume_token(params)
        else:
            self.auth_failed(**params)",Login either with resume token or password.,
"def read(path, default=None, encoding='utf8'):
    """"""Read encoded contents from specified path or return default.""""""
    if not path:
        return default
    try:
        with io.open(path, mode='r', encoding=encoding) as contents:
            return contents.read()
    except IOError:
        if default is not None:
            return default
        raise",Read encoded contents from specified path or return default.,
"def get_pk_value_on_save(self, instance):
        """"""Generate ID if required.""""""
        value = super(AleaIdField, self).get_pk_value_on_save(instance)
        if not value:
            value = self.get_seeded_value(instance)
        return value",Generate ID if required.,
"def pre_save(self, model_instance, add):
        """"""Generate ID if required.""""""
        value = super(AleaIdField, self).pre_save(model_instance, add)
        if (not value) and self.default in (meteor_random_id, NOT_PROVIDED):
            value = self.get_seeded_value(model_instance)
            setattr(model_instance, self.attname, value)
        return value",Generate ID if required.,
"def set_default_forwards(app_name, operation, apps, schema_editor):
    """"""Set default value for AleaIdField.""""""
    model = apps.get_model(app_name, operation.model_name)
    for obj_pk in model.objects.values_list('pk', flat=True):
        model.objects.filter(pk=obj_pk).update(**{
            operation.name: get_meteor_id(model, obj_pk),
        })",Set default value for AleaIdField.,
"def set_default_reverse(app_name, operation, apps, schema_editor):
    """"""Unset default value for AleaIdField.""""""
    model = apps.get_model(app_name, operation.model_name)
    for obj_pk in model.objects.values_list('pk', flat=True):
        get_meteor_id(model, obj_pk)",Unset default value for AleaIdField.,
"def truncate(self, app_label, schema_editor, models):
        """"""Truncate tables.""""""
        for model_name in models:
            model = '%s_%s' % (app_label, model_name)
            schema_editor.execute(
                'TRUNCATE TABLE %s RESTART IDENTITY CASCADE' % (
                    model.lower(),
                ),
            )",Truncate tables.,
"def database_forwards(self, app_label, schema_editor, from_state, to_state):
        """"""Use schema_editor to apply any forward changes.""""""
        self.truncate(app_label, schema_editor, self.truncate_forwards)",Use schema_editor to apply any forward changes.,
"def database_backwards(self, app_label, schema_editor, from_state, to_state):
        """"""Use schema_editor to apply any reverse changes.""""""
        self.truncate(app_label, schema_editor, self.truncate_backwards)",Use schema_editor to apply any reverse changes.,
"def initialize_options(self):
        """"""Set command option defaults.""""""
        setuptools.command.build_py.build_py.initialize_options(self)
        self.meteor = 'meteor'
        self.meteor_debug = False
        self.build_lib = None
        self.package_dir = None
        self.meteor_builds = []
        self.no_prune_npm = None
        self.inplace = True",Set command option defaults.,
"def path_to_dir(*path_args):
        """"""Convert a UNIX-style path into platform specific directory spec.""""""
        return os.path.join(
            *list(path_args[:-1]) + path_args[-1].split(posixpath.sep)
        )",Convert a UNIX-style path into platform specific directory spec.,
"def state(self):
        """"""Return internal state, useful for testing.""""""
        return {'c': self.c, 's0': self.s0, 's1': self.s1, 's2': self.s2}","Return internal state, useful for testing.",
"def random_string(self, length, alphabet):
        """"""Return string of `length` elements chosen from `alphabet`.""""""
        return ''.join(
            self.choice(alphabet) for n in range(length)
        )",Return string of `length` elements chosen from `alphabet`.,
"def api_path_map(self):
        """"""Cached dict of api_path: func.""""""
        if self._api_path_cache is None:
            self._api_path_cache = {
                api_path: func
                for api_path, func
                in api_endpoints(self)
            }
        return self._api_path_cache",Cached dict of api_path: func.,
"def clear_api_path_map_cache(self):
        """"""Clear out cache for api_path_map.""""""
        self._api_path_cache = None
        for api_provider in self.api_providers:
            if six.get_method_self(
                api_provider.clear_api_path_map_cache,
            ) is not None:
                api_provider.clear_api_path_map_cache()",Clear out cache for api_path_map.,
"def dprint(name, val):
    """"""Debug print name and val.""""""
    from pprint import pformat
    print(
        '% 5s: %s' % (
            name,
            '\n       '.join(
                pformat(
                    val, indent=4, width=75,
                ).split('\n')
            ),
        ),
    )",Debug print name and val.,
"def on_close(self, *args, **kwargs):
        """"""Handle closing of websocket connection.""""""
        if self.connection is not None:
            del self.pgworker.connections[self.connection.pk]
            self.connection.delete()
            self.connection = None
        signals.request_finished.send(sender=self.__class__)
        safe_call(self.logger.info, '- %s %s', self, args or 'CLOSE')",Handle closing of websocket connection.,
"def recv_ping(self, id_=None):
        """"""DDP ping handler.""""""
        if id_ is None:
            self.reply('pong')
        else:
            self.reply('pong', id=id_)",DDP ping handler.,
"def recv_sub(self, id_, name, params):
        """"""DDP sub handler.""""""
        self.api.sub(id_, name, *params)",DDP sub handler.,
"def recv_unsub(self, id_=None):
        """"""DDP unsub handler.""""""
        if id_:
            self.api.unsub(id_)
        else:
            self.reply('nosub')",DDP unsub handler.,
"def recv_method(self, method, params, id_, randomSeed=None):
        """"""DDP method handler.""""""
        if randomSeed is not None:
            this.random_streams.random_seed = randomSeed
            this.alea_random = alea.Alea(randomSeed)
        self.api.method(method, params, id_)
        self.reply('updated', methods=[id_])",DDP method handler.,
"def print(self, msg, *args, **kwargs):
        """"""Print formatted msg if verbosity set at 1 or above.""""""
        if self.verbosity >= 1:
            print(msg, *args, **kwargs)",Print formatted msg if verbosity set at 1 or above.,
"def add_web_servers(self, listen_addrs, debug=False, **ssl_args):
        """"""Add WebSocketServer for each (host, port) in listen_addrs.""""""
        self.servers.extend(
            self.get_web_server(listen_addr, debug=debug, **ssl_args)
            for listen_addr in listen_addrs
        )","Add WebSocketServer for each (host, port) in listen_addrs.",
"def get_web_server(self, listen_addr, debug=False, **ssl_args):
        """"""Setup WebSocketServer on listen_addr (host, port).""""""
        return geventwebsocket.WebSocketServer(
            listen_addr,
            self.resource,
            debug=debug,
            **{key: val for key, val in ssl_args.items() if val is not None}
        )","Setup WebSocketServer on listen_addr (host, port).",
"def run(self):
        """"""Run DDP greenlets.""""""
        self.logger.debug('PostgresGreenlet run')
        self.start()
        self._stop_event.wait()
        # wait for all threads to stop.
        gevent.joinall(self.threads + [DDPLauncher.pgworker])
        self.threads = []",Run DDP greenlets.,
"def stop(self):
        """"""Stop subtasks and let run() finish.""""""
        self._stop_event.set()
        if self.select_greenlet is not None:
            self.select_greenlet.kill()
            self.select_greenlet.get()
            gevent.sleep()",Stop subtasks and let run() finish.,
"def meteor_random_id(name=None, length=17):
    """"""Generate a new ID, optionally using namespace of given `name`.""""""
    if name is None:
        stream = THREAD_LOCAL.alea_random
    else:
        stream = THREAD_LOCAL.random_streams[name]
    return stream.random_string(length, METEOR_ID_CHARS)","Generate a new ID, optionally using namespace of given `name`.",
"def autodiscover():
    """"""Import all `ddp` submodules from `settings.INSTALLED_APPS`.""""""
    from django.utils.module_loading import autodiscover_modules
    from dddp.api import API
    autodiscover_modules('ddp', register_to=API)
    return API",Import all `ddp` submodules from `settings.INSTALLED_APPS`.,
"def send_message(self, message, **kwargs):
        """"""
        Sends a push notification to this device via GCM
        """"""

        from ..libs.gcm import gcm_send_message
        data = kwargs.pop(""extra"", {})
        if message is not None:
            data[""message""] = message

        return gcm_send_message(registration_id=self.registration_id,
                data=data, **kwargs)",Sends a push notification to this device via GCM,
"def apns_fetch_inactive_ids():
    """"""
    Queries the APNS server for id's that are no longer active since
    the last fetch
    """"""
    with closing(_apns_create_socket_to_feedback()) as socket:
        inactive_ids = []

        for _, registration_id in _apns_receive_feedback(socket):
            inactive_ids.append(codecs.encode(registration_id, 'hex_codec'))

        return inactive_ids","Queries the APNS server for id's that are no longer active since
    the last fetch",
"def gcm_send_message(registration_id, data, encoding='utf-8', **kwargs):
    """"""
    Standalone method to send a single gcm notification
    """"""

    messenger = GCMMessenger(registration_id, data, encoding=encoding, **kwargs)
    return messenger.send_plain()",Standalone method to send a single gcm notification,
"def gcm_send_bulk_message(registration_ids, data, encoding='utf-8', **kwargs):
    """"""
    Standalone method to send bulk gcm notifications
    """"""

    messenger = GCMMessenger(registration_ids, data, encoding=encoding, **kwargs)
    return messenger.send_bulk()",Standalone method to send bulk gcm notifications,
"def translate(term=None, phrase=None, api_key=GIPHY_PUBLIC_KEY, strict=False,
              rating=None):
    """"""
    Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the translate method.
    """"""
    return Giphy(api_key=api_key, strict=strict).translate(
        term=term, phrase=phrase, rating=rating)","Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the translate method.",
"def trending(limit=DEFAULT_SEARCH_LIMIT, api_key=GIPHY_PUBLIC_KEY,
             strict=False, rating=None):
    """"""
    Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the trending method. Note that this will return
    a generator
    """"""
    return Giphy(api_key=api_key, strict=strict).trending(
        limit=limit, rating=rating)","Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the trending method. Note that this will return
    a generator",
"def gif(gif_id, api_key=GIPHY_PUBLIC_KEY, strict=False):
    """"""
    Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the gif method.
    """"""
    return Giphy(api_key=api_key, strict=strict).gif(gif_id)","Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the gif method.",
"def screensaver(tag=None, api_key=GIPHY_PUBLIC_KEY, strict=False):
    """"""
    Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the screensaver method.
    """"""
    return Giphy(api_key=api_key, strict=strict).screensaver(tag=tag)","Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the screensaver method.",
"def upload(tags, file_path, username=None, api_key=GIPHY_PUBLIC_KEY,
           strict=False):
    """"""
    Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the upload method.
    """"""
    return Giphy(api_key=api_key, strict=strict).upload(
        tags, file_path, username)","Shorthand for creating a Giphy api wrapper with the given api key
    and then calling the upload method.",
"def _fetch(self, endpoint_name, **params):
        """"""
        Wrapper for making an api request from giphy
        """"""
        params['api_key'] = self.api_key

        resp = requests.get(self._endpoint(endpoint_name), params=params)
        resp.raise_for_status()

        data = resp.json()
        self._check_or_raise(data.get('meta', {}))

        return data",Wrapper for making an api request from giphy,
"def trending_list(self, rating=None, limit=DEFAULT_SEARCH_LIMIT):
        """"""
        Suppose you expect the `trending` method to just give you a list rather
        than a generator. This method will have that effect. Equivalent to::

            >>> g = Giphy()
            >>> results = list(g.trending())
        """"""
        return list(self.trending(limit=limit, rating=rating))","Suppose you expect the `trending` method to just give you a list rather
        than a generator. This method will have that effect. Equivalent to::

            >>> g = Giphy()
            >>> results = list(g.trending())",
"def fetch_feed_by_username(self, username):
        """"""
        Retrieve the video feed by username
        Returns:
        gdata.youtube.YouTubeVideoFeed object
        """"""
        # Don't use trailing slash
        youtube_url = 'http://gdata.youtube.com/feeds/api'
        uri = os.sep.join([youtube_url, ""users"", username, ""uploads""])
        return Api.yt_service.GetYouTubeVideoFeed(uri)","Retrieve the video feed by username
        Returns:
        gdata.youtube.YouTubeVideoFeed object",
"def entry(self):
        """"""
        Connects to Youtube Api and retrieves the video entry object

        Return:
            gdata.youtube.YouTubeVideoEntry
        """"""
        api = Api()
        api.authenticate()
        return api.fetch_video(self.video_id)","Connects to Youtube Api and retrieves the video entry object

        Return:
            gdata.youtube.YouTubeVideoEntry",
"def regenerate(self):
        """""" Method for `Regenerate Key <https://m2x.att.com/developer/documentation/v2/keys#Regenerate-Key>`_ endpoint.

        :raises: :class:`~requests.exceptions.HTTPError` if an error occurs when sending the HTTP request
        """"""
        self.data.update(
            self.api.post(self.item_path(self.key) + '/regenerate')
        )","Method for `Regenerate Key <https://m2x.att.com/developer/documentation/v2/keys#Regenerate-Key>`_ endpoint.

        :raises: :class:`~requests.exceptions.HTTPError` if an error occurs when sending the HTTP request",
"def dumps(trees):
    """"""
    Serialize a list of trees in Newick format.

    :param trees: List of Node objects or a single Node object.
    :return: Newick formatted string.
    """"""
    if isinstance(trees, Node):
        trees = [trees]
    return ';\n'.join([tree.newick for tree in trees]) + ';'","Serialize a list of trees in Newick format.

    :param trees: List of Node objects or a single Node object.
    :return: Newick formatted string.",
"def newick(self):
        """"""The representation of the Node in Newick format.""""""
        label = self.name or ''
        if self._length:
            label += ':' + self._length
        descendants = ','.join([n.newick for n in self.descendants])
        if descendants:
            descendants = '(' + descendants + ')'
        return descendants + label",The representation of the Node in Newick format.,
"def get_node(self, label):
        """"""
        Gets the specified node by name.

        :return: Node or None if name does not exist in tree
        """"""
        for n in self.walk():
            if n.name == label:
                return n","Gets the specified node by name.

        :return: Node or None if name does not exist in tree",
"def prune_by_names(self, leaf_names, inverse=False):
        """"""
        Perform an (inverse) prune, with leaves specified by name.
        :param node_names: A list of leaaf Node names (strings)
        :param inverse: Specifies whether to remove nodes in the list or not\
                in the list.
        """"""
        self.prune([l for l in self.walk() if l.name in leaf_names], inverse)","Perform an (inverse) prune, with leaves specified by name.
        :param node_names: A list of leaaf Node names (strings)
        :param inverse: Specifies whether to remove nodes in the list or not\
                in the list.",
"def remove_internal_names(self):
        """"""
        Set the name of all non-leaf nodes in the subtree to None.
        """"""
        self.visit(lambda n: setattr(n, 'name', None), lambda n: not n.is_leaf)",Set the name of all non-leaf nodes in the subtree to None.,
"def remove_leaf_names(self):
        """"""
        Set the name of all leaf nodes in the subtree to None.
        """"""
        self.visit(lambda n: setattr(n, 'name', None), lambda n: n.is_leaf)",Set the name of all leaf nodes in the subtree to None.,
"def auth_required(realm, auth_func):
    '''Decorator that protect methods with HTTP authentication.'''
    def auth_decorator(func):
        def inner(self, *args, **kw):
            if self.get_authenticated_user(auth_func, realm):
                return func(self, *args, **kw)
        return inner
    return auth_decorator",Decorator that protect methods with HTTP authentication.,
"def require_setting(self, name, feature=""this feature""):
        """"""Raises an exception if the given app setting is not defined.""""""
        if name not in self.settings:
            raise Exception(""You must define the '%s' setting in your ""
                            ""application to use %s"" % (name, feature))",Raises an exception if the given app setting is not defined.,
"def get_cookie(self, name, default=None):
        """"""Gets the value of the cookie with the given name, else default.""""""
        assert self.cookie_monster, 'Cookie Monster not set'
        return self.cookie_monster.get_cookie(name, default)","Gets the value of the cookie with the given name, else default.",
"def clear_cookie(self, name, path=""/"", domain=None):
        """"""Deletes the cookie with the given name.""""""
        assert self.cookie_monster, 'Cookie Monster not set'
        #, path=path, domain=domain)
        self.cookie_monster.delete_cookie(name)",Deletes the cookie with the given name.,
"def url_concat(url, args):
    """"""Concatenate url and argument dictionary regardless of whether
    url has existing query parameters.

    >>> url_concat(""http://example.com/foo?a=b"", dict(c=""d""))
    'http://example.com/foo?a=b&c=d'
    """"""
    if not args: return url
    if url[-1] not in ('?', '&'):
        url += '&' if ('?' in url) else '?'
    return url + urllib.urlencode(args)","Concatenate url and argument dictionary regardless of whether
    url has existing query parameters.

    >>> url_concat(""http://example.com/foo?a=b"", dict(c=""d""))
    'http://example.com/foo?a=b&c=d'",
"def get_list(self, name):
        """"""Returns all values for the given header as a list.""""""
        norm_name = HTTPHeaders._normalize_name(name)
        return self._as_list.get(norm_name, [])",Returns all values for the given header as a list.,
"def get_all(self):
        """"""Returns an iterable of all (name, value) pairs.

        If a header has multiple values, multiple pairs will be
        returned with the same name.
        """"""
        for name, list in self._as_list.iteritems():
            for value in list:
                yield (name, value)","Returns an iterable of all (name, value) pairs.

        If a header has multiple values, multiple pairs will be
        returned with the same name.",
"def utf8(value):
    """"""Converts a string argument to a byte string.

    If the argument is already a byte string or None, it is returned unchanged.
    Otherwise it must be a unicode string and is encoded as utf8.
    """"""
    if isinstance(value, _UTF8_TYPES):
        return value
    assert isinstance(value, unicode)
    return value.encode(""utf-8"")","Converts a string argument to a byte string.

    If the argument is already a byte string or None, it is returned unchanged.
    Otherwise it must be a unicode string and is encoded as utf8.",
"def to_unicode(value):
    """"""Converts a string argument to a unicode string.

    If the argument is already a unicode string or None, it is returned
    unchanged.  Otherwise it must be a byte string and is decoded as utf8.
    """"""
    if isinstance(value, _TO_UNICODE_TYPES):
        return value
    assert isinstance(value, bytes)
    return value.decode(""utf-8"")","Converts a string argument to a unicode string.

    If the argument is already a unicode string or None, it is returned
    unchanged.  Otherwise it must be a byte string and is decoded as utf8.",
"def dumps(obj):
    """"""
    Serializes a dictionary into Appinfo data.
    :param obj: A dictionary to serialize.
    :return:
    """"""
    if not isinstance(obj, dict):
        raise TypeError('can only dump a dictionary as an Appinfo but got ' + type(obj).__name__)

    return b''.join(AppinfoEncoder(obj).iter_encode())","Serializes a dictionary into Appinfo data.
    :param obj: A dictionary to serialize.
    :return:",
"def dumps(obj):
    """"""
    Serializes a dictionary into ACF data.
    :param obj: A dictionary to serialize.
    :return: ACF data.
    """"""
    if not isinstance(obj, dict):
        raise TypeError('can only dump a dictionary as an ACF but got ' + type(obj).__name__)

    return '\n'.join(_dumps(obj, level=0)) + '\n'","Serializes a dictionary into ACF data.
    :param obj: A dictionary to serialize.
    :return: ACF data.",
"def occupancy(grid, points, spacing=0.01):
    """"""Return a vector with the occupancy of each grid point for 
    given array of points""""""
    distances = ((grid[:,None,:] - points[None,:,:])**2).sum(axis=2)
    occupied = (distances < spacing).sum(axis=1)
    return occupied","Return a vector with the occupancy of each grid point for 
    given array of points",
"def iter_resource(filename):
    """"""
    Return a stream for a given resource file in the module.

    The resource file has to be part of the module and its filenane given
    relative to the module.
    """"""
    with pkg_resources.resource_stream(__name__, filename) as resource:
        for line in resource:
            yield line.decode('utf-8')","Return a stream for a given resource file in the module.

    The resource file has to be part of the module and its filenane given
    relative to the module.",
"def message_users(users, message, level=constants.INFO):
    """"""
    Send a message to a group of users.

    :param users: Users queryset
    :param message: Message to show
    :param level: Message level
    """"""
    for user in users:
        message_user(user, message, level)","Send a message to a group of users.

    :param users: Users queryset
    :param message: Message to show
    :param level: Message level",
"def get_messages(user):
    """"""
    Fetch messages for given user.  Returns None if no such message exists.

    :param user: User instance
    """"""
    key = _user_key(user)
    result = cache.get(key)
    if result:
        cache.delete(key)
        return result
    return None","Fetch messages for given user.  Returns None if no such message exists.

    :param user: User instance",
"def verify_profile_name(msg, cfg):
    """"""
    Verifies the profile name exists in the config.json file.

    Args:
        :msg: (Message class) an instance of a message class.
        :cfg: (jsonconfig.Config) config instance.
    """"""
    if msg.profile not in cfg.data:
        raise UnknownProfileError(msg.profile)","Verifies the profile name exists in the config.json file.

    Args:
        :msg: (Message class) an instance of a message class.
        :cfg: (jsonconfig.Config) config instance.",
"def get_data_from_user(msg_type):
    """"""Get the required 'settings' from the user and return as a dict.""""""
    data = {}
    for k, v in CONFIG[msg_type][""settings""].items():
        data[k] = input(v + "": "")
    return data",Get the required 'settings' from the user and return as a dict.,
"def get_auth_from_user(msg_type):
    """"""Get the required 'auth' from the user and return as a dict.""""""
    auth = []
    for k, v in CONFIG[msg_type][""auth""].items():
        auth.append((k, getpass(v + "": "")))
    return OrderedDict(auth)",Get the required 'auth' from the user and return as a dict.,
"def _construct_message(self):
        """"""Build the message params.""""""
        self.message[""text""] = """"
        if self.from_:
            self.message[""text""] += ""From: "" + self.from_ + ""\n""
        if self.subject:
            self.message[""text""] += ""Subject: "" + self.subject + ""\n""

        self.message[""text""] += self.body
        self._add_attachments()",Build the message params.,
"def _construct_message(self):
        """"""Set the message token/channel, then call the bas class constructor.""""""
        self.message = {""token"": self._auth, ""channel"": self.channel}
        super()._construct_message()","Set the message token/channel, then call the bas class constructor.",
"def validate_twilio(attr, value):
    """"""Twilio input validator function.""""""
    if attr in (""from_"", ""to""):
        check_valid(""Twilio"", attr, value, validus.isphone, ""phone number"")
    elif attr in (""attachments""):
        check_valid(""Twilio"", attr, value, validus.isurl, ""url"")",Twilio input validator function.,
"def validate_slackpost(attr, value):
    """"""SlackPost input validator function.""""""
    if attr in (""channel"", ""credentials""):
        if not isinstance(value, str):
            raise InvalidMessageInputError(""SlackPost"", attr, value, ""string"")
    elif attr in (""attachments""):
        check_valid(""SlackPost"", attr, value, validus.isurl, ""url"")",SlackPost input validator function.,
"def _send_coroutine():
    """"""
    Creates a running coroutine to receive message instances and send
    them in a futures executor.
    """"""
    with PoolExecutor() as executor:
        while True:
            msg = yield
            future = executor.submit(msg.send)
            future.add_done_callback(_exception_handler)","Creates a running coroutine to receive message instances and send
    them in a futures executor.",
"def add_message(self, msg):
        """"""Add a message to the futures executor.""""""
        try:
            self._coro.send(msg)
        except AttributeError:
            raise UnsupportedMessageTypeError(msg.__class__.__name__)",Add a message to the futures executor.,
"def get_body_from_file(kwds):
    """"""Reads message body if specified via filepath.""""""
    if kwds[""file""] and os.path.isfile(kwds[""file""]):
        kwds[""body""] = open(kwds[""file""], ""r"").read()
        kwds[""file""] = None",Reads message body if specified via filepath.,
"def send_message(msg_type, kwds):
    """"""Do some final preprocessing and send the message.""""""
    if kwds[""file""]:
        get_body_from_file(kwds)
    kwargs = trim_args(kwds)
    send(msg_type, send_async=False, **kwargs)",Do some final preprocessing and send the message.,
"def get_server(address=None):
        """"""Return an SMTP servername guess from outgoing email address.""""""
        if address:
            domain = address.split(""@"")[1]
            try:
                return SMTP_SERVERS[domain]
            except KeyError:
                return (""smtp."" + domain, 465)
        return (None, None)",Return an SMTP servername guess from outgoing email address.,
"def _generate_email(self):
        """"""Put the parts of the email together.""""""
        self.message = MIMEMultipart()
        self._add_header()
        self._add_body()
        self._add_attachments()",Put the parts of the email together.,
"def _add_header(self):
        """"""Add email header info.""""""
        self.message[""From""] = self.from_
        self.message[""Subject""] = self.subject
        if self.to:
            self.message[""To""] = self.list_to_string(self.to)
        if self.cc:
            self.message[""Cc""] = self.list_to_string(self.cc)
        if self.bcc:
            self.message[""Bcc""] = self.list_to_string(self.bcc)",Add email header info.,
"def _add_body(self):
        """"""Add body content of email.""""""
        if self.body:
            b = MIMEText(""text"", ""plain"")
            b.set_payload(self.body)
            self.message.attach(b)",Add body content of email.,
"def _get_ssl(self):
        """"""Get an SMTP session with SSL.""""""
        return smtplib.SMTP_SSL(
            self.server, self.port, context=ssl.create_default_context()
        )",Get an SMTP session with SSL.,
"def _get_tls(self):
        """"""Get an SMTP session with TLS.""""""
        session = smtplib.SMTP(self.server, self.port)
        session.ehlo()
        session.starttls(context=ssl.create_default_context())
        session.ehlo()
        return session",Get an SMTP session with TLS.,
"def delete(self, filename=None):
        """"""Remove tags from a file.""""""

        if self.tags is not None:
            if filename is None:
                filename = self.filename
            else:
                warnings.warn(
                    ""delete(filename=...) is deprecated, reload the file"",
                    DeprecationWarning)
            return self.tags.delete(filename)",Remove tags from a file.,
"def unload(self):
        '''Releases renderer resources associated with this image.'''
        if self._handle != -1:
            lib.UnloadImage(self._handle)
        self._handle = -1",Releases renderer resources associated with this image.,
"def clear(self):
        """"""Clear all keys from the comment.""""""

        for i in list(self._internal):
            self._internal.remove(i)",Clear all keys from the comment.,
"def read(self):
        """"""Read the chunks data""""""
        self.__fileobj.seek(self.data_offset)
        self.data = self.__fileobj.read(self.data_size)",Read the chunks data,
"def delete(self):
        """"""Removes the chunk from the file""""""
        delete_bytes(self.__fileobj, self.size, self.offset)
        if self.parent_chunk is not None:
            self.parent_chunk.resize(self.parent_chunk.data_size - self.size)",Removes the chunk from the file,
"def delete(self, filename=None):
        """"""Completely removes the ID3 chunk from the AIFF file""""""

        if filename is None:
            filename = self.filename
        delete(filename)
        self.clear()",Completely removes the ID3 chunk from the AIFF file,
"def load(self, filename, **kwargs):
        """"""Load stream and tag information from a file.""""""
        self.filename = filename

        try:
            self.tags = _IFFID3(filename, **kwargs)
        except ID3Error:
            self.tags = None

        try:
            fileobj = open(filename, ""rb"")
            self.info = AIFFInfo(fileobj)
        finally:
            fileobj.close()",Load stream and tag information from a file.,
"def  process_normal_line( self, line ):
        """"""process a normal line and check whether it is the start of a new block""""""
        for f in re_source_block_formats:
            if f.start.match( line ):
                self.add_block_lines()
                self.format = f
                self.lineno = fileinput.filelineno()

        self.lines.append( line )",process a normal line and check whether it is the start of a new block,
"def  add_block_lines( self ):
        """"""add the current accumulated lines and create a new block""""""
        if self.lines != []:
            block = SourceBlock( self, self.filename, self.lineno, self.lines )

            self.blocks.append( block )
            self.format = None
            self.lines  = []",add the current accumulated lines and create a new block,
"def  make_html_words( self, words ):
        """""" convert a series of simple words into some HTML text """"""
        line = """"
        if words:
            line = html_quote( words[0] )
            for w in words[1:]:
                line = line + "" "" + html_quote( w )

        return line",convert a series of simple words into some HTML text,
"def  make_html_code( self, lines ):
        """""" convert a code sequence to HTML """"""
        line = code_header + '\n'
        for l in lines:
            line = line + html_quote( l ) + '\n'

        return line + code_footer",convert a code sequence to HTML,
"def  make_html_items( self, items ):
        """""" convert a field's content into some valid HTML """"""
        lines = []
        for item in items:
            if item.lines:
                lines.append( self.make_html_code( item.lines ) )
            else:
                lines.append( self.make_html_para( item.words ) )

        return string.join( lines, '\n' )",convert a field's content into some valid HTML,
"def get(cls, controller):
        '''Find a mapping that can apply to the given controller.  Returns None if unsuccessful.

        :param controller: :class:`Controller` to look up
        :return: :class:`ControllerMapping`
        '''
        try:
            return cls._registry[(controller.vendor_id, controller.product_id)]
        except KeyError:
            return None","Find a mapping that can apply to the given controller.  Returns None if unsuccessful.

        :param controller: :class:`Controller` to look up
        :return: :class:`ControllerMapping`",
"def  set_section( self, section_name ):
        """"""set current section during parsing""""""
        if not self.sections.has_key( section_name ):
            section = DocSection( section_name )
            self.sections[section_name] = section
            self.section                = section
        else:
            self.section = self.sections[section_name]",set current section during parsing,
"def  get_markup( self, tag_name ):
        """"""return the DocMarkup corresponding to a given tag in a block""""""
        for m in self.markups:
            if m.tag == string.lower( tag_name ):
                return m
        return None",return the DocMarkup corresponding to a given tag in a block,
"def utf8(data):
    """"""Convert a basestring to a valid UTF-8 str.""""""

    if isinstance(data, bytes):
        return data.decode(""utf-8"", ""replace"").encode(""utf-8"")
    elif isinstance(data, text_type):
        return data.encode(""utf-8"")
    else:
        raise TypeError(""only unicode/bytes types can be converted to UTF-8"")",Convert a basestring to a valid UTF-8 str.,
"def get_glyph(self, char):
        '''Retrieves a :class:`Glyph` that renders the given character.

        :param char: the character (a string)
        '''
        try:
            return self._glyphs[char]
        except KeyError:
            glyph = self._font_file.get_glyph(self._size, self._content_scale, char, self._flags)
            self._glyphs[char] = glyph
            return glyph","Retrieves a :class:`Glyph` that renders the given character.

        :param char: the character (a string)",
"def measure_string(self, str):
        '''Calculates the width of the given string in this font.

        :param str: the string to measure
        :return float: width of the string, in pixels
        '''
        style = bacon.text.Style(self)
        run = bacon.text.GlyphRun(style, str)
        glyph_layout = bacon.text.GlyphLayout([run], 0, 0)
        return glyph_layout.content_width","Calculates the width of the given string in this font.

        :param str: the string to measure
        :return float: width of the string, in pixels",
"def delete(self):
        """"""
        Deletes this record set.
        """"""

        cset = ChangeSet(connection=self.connection, hosted_zone_id=self.zone_id)
        cset.add_change('DELETE', self)

        return self.connection._change_resource_record_sets(cset)",Deletes this record set.,
"def delall(self, key):
        """"""Delete all tags of a given kind; see getall.""""""
        if key in self:
            del(self[key])
        else:
            key = key + "":""
            for k in self.keys():
                if k.startswith(key):
                    del(self[k])",Delete all tags of a given kind; see getall.,
"def loaded_frame(self, tag):
        """"""Deprecated; use the add method.""""""
        # turn 2.2 into 2.3/2.4 tags
        if len(type(tag).__name__) == 3:
            tag = type(tag).__base__(tag)
        self[tag.HashKey] = tag",Deprecated; use the add method.,
"def unload(self):
        '''Release all resources associated with the sound.'''
        if self._handle != -1:
            lib.UnloadSound(self._handle)
            self._handle = -1",Release all resources associated with the sound.,
"def filter_glyph_names( alist, filter ):
  """"""filter `alist' by taking _out_ all glyph names that are in `filter'""""""

  count  = 0
  extras = []

  for name in alist:
    try:
      filtered_index = filter.index( name )
    except:
      extras.append( name )

  return extras",filter `alist' by taking _out_ all glyph names that are in `filter,
"def  file_exists( pathname ):
    """"""checks that a given file exists""""""
    result = 1
    try:
        file = open( pathname, ""r"" )
        file.close()
    except:
        result = None
        sys.stderr.write( pathname + "" couldn't be accessed\n"" )

    return result",checks that a given file exists,
"def alias_item(self, alias):
        """"""Gets an item by its alias.""""""
        ident = self.alias[alias]
        return self.items[ident]",Gets an item by its alias.,
"def freeze_dict(dict_):
    """"""Freezes ``dict`` into ``tuple``.

    A typical usage is packing ``dict`` into hashable.

    e.g.::

        >>> freeze_dict({'a': 1, 'b': 2})
        (('a', 1), ('b', 2))
    """"""
    pairs = dict_.items()
    key_getter = operator.itemgetter(0)
    return tuple(sorted(pairs, key=key_getter))","Freezes ``dict`` into ``tuple``.

    A typical usage is packing ``dict`` into hashable.

    e.g.::

        >>> freeze_dict({'a': 1, 'b': 2})
        (('a', 1), ('b', 2))",
"def initialize_bars(self, sender=None, **kwargs):
        """"""Calls the initializers of all bound navigation bars.""""""
        for bar in self.bars.values():
            for initializer in bar.initializers:
                initializer(self)",Calls the initializers of all bound navigation bars.,
"def bind_bar(self, sender=None, **kwargs):
        """"""Binds a navigation bar into this extension instance.""""""
        bar = kwargs.pop('bar')
        self.bars[bar.name] = bar",Binds a navigation bar into this extension instance.,
"def args(self):
        """"""The arguments which will be passed to ``url_for``.

        :type: :class:`dict`
        """"""
        if self._args is None:
            return {}
        if callable(self._args):
            return dict(self._args())
        return dict(self._args)","The arguments which will be passed to ``url_for``.

        :type: :class:`dict`",
"def lang(self, language):
        """"""Set lang""""""
        if isinstance(language, str):
            self._lang = [language]
        elif isinstance(language, collections.Iterable):
            self._lang = list(language)

        if any(lang not in self._supported_langs for lang in self._lang):
            raise BadArgumentError(""Unsupported language"")",Set lang,
"def config_path(self, value):
        """"""Set config_path""""""
        self._config_path = value or ''
        if not isinstance(self._config_path, str):
            raise BadArgumentError(""config_path must be string: {}"".format(
                self._config_path))",Set config_path,
"def dictionary(self, value):
        """"""Set dictionary""""""
        self._dictionary = value or {}
        if not isinstance(self._dictionary, dict):
            raise BadArgumentError(""dictionary must be dict: {}"".format(
                self._dictionary))",Set dictionary,
"def validate(metric_class):
    """"""
    Does basic Metric option validation. 
    """"""
    if not hasattr(metric_class, 'label'):
        raise ImproperlyConfigured(""No 'label' attribute found for metric %s."" % metric_class.__name__)
    
    if not hasattr(metric_class, 'widget'):
        raise ImproperlyConfigured(""No 'widget' attribute found for metric %s."" % metric_class.__name__)",Does basic Metric option validation.,
"def calculate_statistics(stat, frequencies):
    """"""
    Calculates all of the metrics associated with the registered gadgets.
    """"""
    stats = ensure_list(stat)
    frequencies = ensure_list(frequencies)

    for stat in stats:
        for f in frequencies:
            print ""Calculating %s (%s)..."" % (stat.__name__, settings.STATISTIC_FREQUENCY_DICT[f])
            stat.calculate(f)",Calculates all of the metrics associated with the registered gadgets.,
"def get_GET_array(request, var_name, fail_silently=True):
    """"""
    Returns the GET array's contents for the specified variable.
    """"""

    vals = request.GET.getlist(var_name)
    if not vals:
        if fail_silently:
            return []
        else:
            raise Exception, _(""No array called '%(varname)s' in GET variables"") % {'varname': var_name}

    return vals",Returns the GET array's contents for the specified variable.,
"def get_GET_bool(request, var_name, default=True):
    """"""
    Tries to extract a boolean variable from the specified request.
    """"""

    val = request.GET.get(var_name, default)
    if isinstance(val, str) or isinstance(val, unicode):
        val = True if val[0] == 't' else False

    return val",Tries to extract a boolean variable from the specified request.,
"def get_next_colour():
    """"""
    Gets the next colour in the Geckoboard colour list.
    """"""

    colour = settings.GECKOBOARD_COLOURS[get_next_colour.cur_colour]

    get_next_colour.cur_colour += 1
    if get_next_colour.cur_colour >= len(settings.GECKOBOARD_COLOURS):
        get_next_colour.cur_colour = 0

    return colour",Gets the next colour in the Geckoboard colour list.,
"def geckoboard_geckometer(request):
    """"""
    Returns a Geck-o-Meter control for the specified metric.
    """"""

    params = get_gecko_params(request, cumulative=True)
    metric = Metric.objects.get(uid=params['uid'])

    return (metric.latest_count(frequency=params['frequency'], count=not params['cumulative'],
        cumulative=params['cumulative']), params['min'], params['max'])",Returns a Geck-o-Meter control for the specified metric.,
"def get_active_stats(self):
        """"""
        Returns all of the active statistics for the gadgets currently registered.
        """"""
        stats = []
        for gadget in self._registry.values():
            for s in gadget.stats:
                if s not in stats:
                    stats.append(s)
        return stats",Returns all of the active statistics for the gadgets currently registered.,
"def register(self, gadget):
        """"""
        Registers a gadget object.
        If a gadget is already registered, this will raise AlreadyRegistered.
        """"""
        if gadget in self._registry:
            raise AlreadyRegistered
        else:
            self._registry.append(gadget)","Registers a gadget object.
        If a gadget is already registered, this will raise AlreadyRegistered.",
"def unregister(self, gadgets):
        """"""
        Unregisters the specified gadget(s) if it/they has/have already been registered.
        ""gadgets"" can be a single class or a tuple/list of classes to unregister.
        """"""
        gadgets = maintenance.ensure_list(gadgets)
        for gadget in gadgets:
            while gadget in self._registry:
                self._registry.remove(gadget)","Unregisters the specified gadget(s) if it/they has/have already been registered.
        ""gadgets"" can be a single class or a tuple/list of classes to unregister.",
"def error(self, message, code=1):
        """"""
        Print error and stop command
        """"""
        print >>sys.stderr, message
        sys.exit(code)",Print error and stop command,
"def string_input(prompt=''):
    """"""Python 3 input()/Python 2 raw_input()""""""
    v = sys.version[0]
    if v == '3':
        return input(prompt)
    else:
        return raw_input(prompt)",Python 3 input()/Python 2 raw_input(),
"def schedule(self, year):
        """"""Gets schedule information for a team-season.

        :year: The year for which we want the schedule.
        :returns: DataFrame of schedule information.
        """"""
        doc = self.get_year_doc('{}_games'.format(year))
        table = doc('table#games')
        df = sportsref.utils.parse_table(table)
        return df","Gets schedule information for a team-season.

        :year: The year for which we want the schedule.
        :returns: DataFrame of schedule information.",
"def date(self):
        """"""Returns the date of the game. See Python datetime.date documentation
        for more.
        :returns: A datetime.date object with year, month, and day attributes.
        """"""
        match = re.match(r'(\d{4})(\d{2})(\d{2})', self.boxscore_id)
        year, month, day = map(int, match.groups())
        return datetime.date(year=year, month=month, day=day)","Returns the date of the game. See Python datetime.date documentation
        for more.
        :returns: A datetime.date object with year, month, and day attributes.",
"def weekday(self):
        """"""Returns the day of the week on which the game occurred.
        :returns: String representation of the day of the week for the game.

        """"""
        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',
                'Saturday', 'Sunday']
        date = self.date()
        wd = date.weekday()
        return days[wd]","Returns the day of the week on which the game occurred.
        :returns: String representation of the day of the week for the game.",
"def home(self):
        """"""Returns home team ID.
        :returns: 3-character string representing home team's ID.
        """"""
        doc = self.get_doc()
        table = doc('table.linescore')
        relURL = table('tr').eq(2)('a').eq(2).attr['href']
        home = sportsref.utils.rel_url_to_id(relURL)
        return home","Returns home team ID.
        :returns: 3-character string representing home team's ID.",
"def home_score(self):
        """"""Returns score of the home team.
        :returns: int of the home score.
        """"""
        doc = self.get_doc()
        table = doc('table.linescore')
        home_score = table('tr').eq(2)('td')[-1].text_content()
        return int(home_score)","Returns score of the home team.
        :returns: int of the home score.",
"def away_score(self):
        """"""Returns score of the away team.
        :returns: int of the away score.
        """"""
        doc = self.get_doc()
        table = doc('table.linescore')
        away_score = table('tr').eq(1)('td')[-1].text_content()
        return int(away_score)","Returns score of the away team.
        :returns: int of the away score.",
"def winner(self):
        """"""Returns the team ID of the winning team. Returns NaN if a tie.""""""
        hmScore = self.home_score()
        awScore = self.away_score()
        if hmScore > awScore:
            return self.home()
        elif hmScore < awScore:
            return self.away()
        else:
            return None",Returns the team ID of the winning team. Returns NaN if a tie.,
"def season(self):
        """"""
        Returns the year ID of the season in which this game took place.
        Useful for week 17 January games.

        :returns: An int representing the year of the season.
        """"""
        date = self.date()
        return date.year - 1 if date.month <= 3 else date.year","Returns the year ID of the season in which this game took place.
        Useful for week 17 January games.

        :returns: An int representing the year of the season.",
"def surface(self):
        """"""The playing surface on which the game was played.

        :returns: string representing the type of surface. Returns np.nan if
        not avaiable.
        """"""
        doc = self.get_doc()
        table = doc('table#game_info')
        giTable = sportsref.utils.parse_info_table(table)
        return giTable.get('surface', np.nan)","The playing surface on which the game was played.

        :returns: string representing the type of surface. Returns np.nan if
        not avaiable.",
"def ref_info(self):
        """"""Gets a dictionary of ref positions and the ref IDs of the refs for
        that game.

        :returns: A dictionary of ref positions and IDs.
        """"""
        doc = self.get_doc()
        table = doc('table#officials')
        return sportsref.utils.parse_info_table(table)","Gets a dictionary of ref positions and the ref IDs of the refs for
        that game.

        :returns: A dictionary of ref positions and IDs.",
"def get_main_doc(self):
        """"""Returns PyQuery object for the main season URL.
        :returns: PyQuery object.
        """"""
        url = (sportsref.nba.BASE_URL +
               '/leagues/NBA_{}.html'.format(self.yr))
        return pq(sportsref.utils.get_html(url))","Returns PyQuery object for the main season URL.
        :returns: PyQuery object.",
"def get_sub_doc(self, subpage):
        """"""Returns PyQuery object for a given subpage URL.
        :subpage: The subpage of the season, e.g. 'per_game'.
        :returns: PyQuery object.
        """"""
        html = sportsref.utils.get_html(self._subpage_url(subpage))
        return pq(html)","Returns PyQuery object for a given subpage URL.
        :subpage: The subpage of the season, e.g. 'per_game'.
        :returns: PyQuery object.",
"def get_team_ids(self):
        """"""Returns a list of the team IDs for the given year.
        :returns: List of team IDs.
        """"""
        df = self.team_stats_per_game()
        if not df.empty:
            return df.index.tolist()
        else:
            print('ERROR: no teams found')
            return []","Returns a list of the team IDs for the given year.
        :returns: List of team IDs.",
"def team_names_to_ids(self):
        """"""Mapping from full team names to 3-letter team IDs.
        :returns: Dictionary with tean names as keys and team IDs as values.
        """"""
        d = self.team_ids_to_names()
        return {v: k for k, v in d.items()}","Mapping from full team names to 3-letter team IDs.
        :returns: Dictionary with tean names as keys and team IDs as values.",
"def _get_team_stats_table(self, selector):
        """"""Helper function for stats tables on season pages. Returns a
        DataFrame.""""""
        doc = self.get_main_doc()
        table = doc(selector)
        df = sportsref.utils.parse_table(table)
        df.set_index('team_id', inplace=True)
        return df","Helper function for stats tables on season pages. Returns a
        DataFrame.",
"def _get_player_stats_table(self, identifier):
        """"""Helper function for player season stats.

        :identifier: string identifying the type of stat, e.g. 'per_game'.
        :returns: A DataFrame of stats.
        """"""
        doc = self.get_sub_doc(identifier)
        table = doc('table#{}_stats'.format(identifier))
        df = sportsref.utils.parse_table(table)
        return df","Helper function for player season stats.

        :identifier: string identifying the type of stat, e.g. 'per_game'.
        :returns: A DataFrame of stats.",
"def roy_voting(self):
        """"""Returns a DataFrame containing information about ROY voting.""""""
        url = '{}/awards/awards_{}.html'.format(sportsref.nba.BASE_URL, self.yr)
        doc = pq(sportsref.utils.get_html(url))
        table = doc('table#roy')
        df = sportsref.utils.parse_table(table)
        return df",Returns a DataFrame containing information about ROY voting.,
"def season(self):
        """"""
        Returns the year ID of the season in which this game took place.

        :returns: An int representing the year of the season.
        """"""
        d = self.date()
        if d.month >= 9:
            return d.year + 1
        else:
            return d.year","Returns the year ID of the season in which this game took place.

        :returns: An int representing the year of the season.",
"def get_class_instance_key(cls, args, kwargs):
    """"""
    Returns a unique identifier for a class instantiation.
    """"""
    l = [id(cls)]
    for arg in args:
        l.append(id(arg))
    l.extend((k, id(v)) for k, v in kwargs.items())
    return tuple(sorted(l))",Returns a unique identifier for a class instantiation.,
"def height(self):
        """"""Returns the player's height (in inches).
        :returns: An int representing a player's height in inches.
        """"""
        doc = self.get_main_doc()
        raw = doc('span[itemprop=""height""]').text()
        try:
            feet, inches = map(int, raw.split('-'))
            return feet * 12 + inches
        except ValueError:
            return None","Returns the player's height (in inches).
        :returns: An int representing a player's height in inches.",
"def weight(self):
        """"""Returns the player's weight (in pounds).
        :returns: An int representing a player's weight in pounds.
        """"""
        doc = self.get_main_doc()
        raw = doc('span[itemprop=""weight""]').text()
        try:
            weight = re.match(r'(\d+)lb', raw).group(1)
            return int(weight)
        except ValueError:
            return None","Returns the player's weight (in pounds).
        :returns: An int representing a player's weight in pounds.",
"def hand(self):
        """"""Returns the player's handedness.
        :returns: 'L' for left-handed, 'R' for right-handed.
        """"""
        doc = self.get_main_doc()
        hand = re.search(r'Shoots:\s*(L|R)', doc.text()).group(1)
        return hand","Returns the player's handedness.
        :returns: 'L' for left-handed, 'R' for right-handed.",
"def stats_per_game(self, kind='R', summary=False):
        """"""Returns a DataFrame of per-game box score stats.""""""
        return self._get_stats_table('per_game', kind=kind, summary=summary)",Returns a DataFrame of per-game box score stats.,
"def stats_totals(self, kind='R', summary=False):
        """"""Returns a DataFrame of total box score statistics by season.""""""
        return self._get_stats_table('totals', kind=kind, summary=summary)",Returns a DataFrame of total box score statistics by season.,
"def stats_per36(self, kind='R', summary=False):
        """"""Returns a DataFrame of per-36-minutes stats.""""""
        return self._get_stats_table('per_minute', kind=kind, summary=summary)",Returns a DataFrame of per-36-minutes stats.,
"def stats_per100(self, kind='R', summary=False):
        """"""Returns a DataFrame of per-100-possession stats.""""""
        return self._get_stats_table('per_poss', kind=kind, summary=summary)",Returns a DataFrame of per-100-possession stats.,
"def stats_advanced(self, kind='R', summary=False):
        """"""Returns a DataFrame of advanced stats.""""""
        return self._get_stats_table('advanced', kind=kind, summary=summary)",Returns a DataFrame of advanced stats.,
"def stats_shooting(self, kind='R', summary=False):
        """"""Returns a DataFrame of shooting stats.""""""
        return self._get_stats_table('shooting', kind=kind, summary=summary)",Returns a DataFrame of shooting stats.,
"def stats_pbp(self, kind='R', summary=False):
        """"""Returns a DataFrame of play-by-play stats.""""""
        return self._get_stats_table('advanced_pbp', kind=kind,
                                     summary=summary)",Returns a DataFrame of play-by-play stats.,
"def _get_player_stats_table(self, subpage, table_id):
        """"""Helper function for player season stats.

        :identifier: string identifying the type of stat, e.g. 'passing'.
        :returns: A DataFrame of stats.
        """"""
        doc = self.get_sub_doc(subpage)
        table = doc('table#{}'.format(table_id))
        df = sportsref.utils.parse_table(table)
        return df","Helper function for player season stats.

        :identifier: string identifying the type of stat, e.g. 'passing'.
        :returns: A DataFrame of stats.",
"def team_ids(year):
    """"""Returns a mapping from team name to team ID for a given season. Inverse
    mapping of team_names. Example of a full team name: ""New England Patriots""

    :year: The year of the season in question (as an int).
    :returns: A dictionary with full team name keys and teamID values.
    """"""
    names = team_names(year)
    return {v: k for k, v in names.items()}","Returns a mapping from team name to team ID for a given season. Inverse
    mapping of team_names. Example of a full team name: ""New England Patriots""

    :year: The year of the season in question (as an int).
    :returns: A dictionary with full team name keys and teamID values.",
"def wins(self, year):
        """"""Returns the # of regular season wins a team in a year.

        :year: The year for the season in question.
        :returns: The number of regular season wins.
        """"""
        schedule = self.schedule(year)
        if schedule.empty:
            return np.nan
        return schedule.query('week_num <= 17').is_win.sum()","Returns the # of regular season wins a team in a year.

        :year: The year for the season in question.
        :returns: The number of regular season wins.",
"def stadium(self, year):
        """"""Returns the ID for the stadium in which the team played in a given
        year.

        :year: The year in question.
        :returns: A string representing the stadium ID.
        """"""
        anchor = self._year_info_pq(year, 'Stadium')('a')
        return sportsref.utils.rel_url_to_id(anchor.attr['href'])","Returns the ID for the stadium in which the team played in a given
        year.

        :year: The year in question.
        :returns: A string representing the stadium ID.",
"def wait(self):
        """"""Wait until all processes have reached the barrier.""""""
        with self.cvar:
            self.count.value += 1
            self.cvar.notify_all()
            while self.count.value < self.n_procs:
                self.cvar.wait()",Wait until all processes have reached the barrier.,
"def put_direct(self):
        """"""
        Allows direct access to the buffer element.
        Blocks until there is room to write into the buffer.

        :return: A guard object that returns the buffer element.
        """"""

        # Once the guard is released, write_idx will be placed into read_queue.
        return self.Guard(self.read_queue, self.arys, self.__put_idx)","Allows direct access to the buffer element.
        Blocks until there is room to write into the buffer.

        :return: A guard object that returns the buffer element.",
"def close(self):
        """"""Close the queue, signalling that no more data can be put into the queue.""""""
        self.read_queue.put(QueueClosed)
        self.write_queue.put(QueueClosed)","Close the queue, signalling that no more data can be put into the queue.",
"def close(self):
        """"""Close the stream.""""""
        self.flush()
        if self._myfd is not None:
            self._myfd.close()
            self._myfd = None",Close the stream.,
"def with_ignored_exceptions(self, *ignored_exceptions):
        """"""
        Set a list of exceptions that should be ignored inside the wait loop.
        """"""
        for exception in ignored_exceptions:
            self._ignored_exceptions = self._ignored_exceptions + (exception,)
        return self",Set a list of exceptions that should be ignored inside the wait loop.,
"def s2h(ss):
    """"""convert seconds to a pretty ""d hh:mm:ss.s"" format""""""
    mm, ss = divmod(ss, 60)
    hh, mm = divmod(mm, 60)
    dd, hh = divmod(hh, 24)
    tstr = ""%02i:%04.1f"" % (mm, ss)
    if hh > 0:
        tstr = (""%02i:"" % hh) + tstr
    if dd > 0:
        tstr = (""%id "" % dd) + tstr
    return tstr","convert seconds to a pretty ""d hh:mm:ss.s"" format",
"def main_volume(self, operator, value=None):
        """"""
        Execute Main.Volume.

        Returns int
        """"""
        try:
            res = int(self.exec_command('main', 'volume', operator, value))
            return res

        except (ValueError, TypeError):
            pass

        return None","Execute Main.Volume.

        Returns int",
"def main_source(self, operator, value=None):
        """"""
        Execute Main.Source.

        Returns int
        """"""
        try:
            source = int(self.exec_command('main', 'source', operator, value))
            return source
        except (ValueError, TypeError):
            pass

        return None","Execute Main.Source.

        Returns int",
"def power_off(self):
        """"""Power the device off.""""""
        status = self.status()
        if status['power']:  # Setting power off when it is already off can cause hangs
            self._send(self.CMD_POWERSAVE + self.CMD_OFF)",Power the device off.,
"def power_on(self):
        """"""Power the device on.""""""
        status = self.status()
        if not status['power']:
            self._send(self.CMD_ON, read_reply=True)
            sleep(0.5)",Power the device on.,
"def set_volume(self, volume):
        """"""Set volume level of the device. Accepts integer values 0-200.""""""
        if 0 <= volume <= 200:
            volume = format(volume, ""02x"")  # Convert to hex
            self._send(self.CMD_VOLUME + volume)",Set volume level of the device. Accepts integer values 0-200.,
"def _lazysecret(secret, blocksize=32, padding='}'):
    """"""Pads secret if not legal AES block size (16, 24, 32)""""""
    if not len(secret) in (16, 24, 32):
        return secret + (blocksize - len(secret)) * padding
    return secret","Pads secret if not legal AES block size (16, 24, 32)",
"def _crc(plaintext):
    """"""Generates crc32. Modulo keep the value within int range.""""""
    if not isinstance(plaintext, six.binary_type):
        plaintext = six.b(plaintext)
    return (zlib.crc32(plaintext) % 2147483647) & 0xffffffff",Generates crc32. Modulo keep the value within int range.,
"def google_url(self,song_name,website):
		''' It will return the google url to be searched'''
		name='+'.join(song_name)
		prefix='https://www.google.co.in/search?q='	
		website=website.split("" "")
		suffix='+'.join(website)
		url=prefix+name+suffix
		#print url
		return url",It will return the google url to be searched,
"def parse_google(self,html):
		'''It will parse google html response
			and return the first url
		 '''
		soup = BeautifulSoup(html)
		href=soup.find('div','g').find('a').get('href')
		href_list=href.split('&')
		download_url=href_list[0]
		download_url=download_url.strip()
		download_url=download_url.replace('/url?q=','')
		return download_url","It will parse google html response
			and return the first url",
"def Parse(self,song_name,website):
		'''
		song_name is a list of strings
		website is a string
		It will return the url from where music file needs to be downloaded
		'''
		url_to_be_parsed=self.google_url(song_name,website)
		file_download=FileDownload()
		html=file_download.get_html_response(url_to_be_parsed)
		website_url=self.parse_google(html)
		return website_url","song_name is a list of strings
		website is a string
		It will return the url from where music file needs to be downloaded",
"def file_download_using_wget(self,url):
		'''It will download file specified by url using wget utility of linux '''
		file_name=url.split('/')[-1]
		print 'Downloading file %s '%file_name
		command='wget -c --read-timeout=50 --tries=3 -q --show-progress --no-check-certificate '
		url='""'+url+'""'
		command=command+url
		os.system(command)",It will download file specified by url using wget utility of linux,
"def main():
    """"""Main CLI entrypoint.""""""
    #print VERSION
    from commands.download import Download
    options = docopt(__doc__, version=VERSION)
    #print ""You reached here""
    #print options
    print ""working.""
    p=Download(options)
    p.run()",Main CLI entrypoint.,
"def get_location_observation(lat, lng, token):
    """"""Lookup observations by geo coordinates.""""""
    req = requests.get(
        API_ENDPOINT_GEO % (lat, lng),
        params={
            'token': token
        })

    if req.status_code == 200 and req.json()[""status""] == ""ok"":
        return parse_observation_response(req.json()[""data""])
    return {}",Lookup observations by geo coordinates.,
"def path_without_suffix(self):
        """"""The relative path to asset without suffix.
        Example::

            >>> attrs = AssetAttributes(environment, 'js/app.js')
            >>> attrs.path_without_suffix
            'js/app'
        """"""
        if self.suffix:
            return self.path[:-len(''.join(self.suffix))]
        return self.path","The relative path to asset without suffix.
        Example::

            >>> attrs = AssetAttributes(environment, 'js/app.js')
            >>> attrs.path_without_suffix
            'js/app'",
"def compilers(self):
        """"""The list of compilers used to build asset.""""""
        return [self.environment.compilers.get(e) for e in self.compiler_extensions]",The list of compilers used to build asset.,
"def processors(self):
        """"""The list of all processors (preprocessors, compilers,
        postprocessors) used to build asset.
        """"""
        return self.preprocessors + list(reversed(self.compilers)) + self.postprocessors","The list of all processors (preprocessors, compilers,
        postprocessors) used to build asset.",
"def mimetype(self):
        """"""MIME type of the asset.""""""
        return (self.environment.mimetypes.get(self.format_extension) or
                self.compiler_mimetype or 'application/octet-stream')",MIME type of the asset.,
"def compiler_mimetype(self):
        """"""Implicit MIME type of the asset by its compilers.""""""
        for compiler in reversed(self.compilers):
            if compiler.result_mimetype:
                return compiler.result_mimetype
        return None",Implicit MIME type of the asset by its compilers.,
"def compiler_format_extension(self):
        """"""Implicit format extension on the asset by its compilers.""""""
        for extension, mimetype in self.environment.mimetypes.items():
            if mimetype == self.compiler_mimetype:
                return extension
        return None",Implicit format extension on the asset by its compilers.,
"def register(self, mimetype, processor):
        """"""Register passed `processor` for passed `mimetype`.""""""
        if mimetype not in self or processor not in self[mimetype]:
            self.setdefault(mimetype, []).append(processor)",Register passed `processor` for passed `mimetype`.,
"def unregister(self, mimetype, processor):
        """"""Remove passed `processor` for passed `mimetype`. If processor for
        this MIME type does not found in the registry, nothing happens.
        """"""
        if mimetype in self and processor in self[mimetype]:
            self[mimetype].remove(processor)","Remove passed `processor` for passed `mimetype`. If processor for
        this MIME type does not found in the registry, nothing happens.",
"def register_defaults(self):
        """"""Register :class:`~gears.processors.DirectivesProcessor` as
        a preprocessor for `text/css` and `application/javascript` MIME types.
        """"""
        self.register('text/css', DirectivesProcessor.as_handler())
        self.register('application/javascript', DirectivesProcessor.as_handler())","Register :class:`~gears.processors.DirectivesProcessor` as
        a preprocessor for `text/css` and `application/javascript` MIME types.",
"def register_defaults(self):
        """"""Register default compilers, preprocessors and MIME types.""""""
        self.mimetypes.register_defaults()
        self.preprocessors.register_defaults()
        self.postprocessors.register_defaults()","Register default compilers, preprocessors and MIME types.",
"def get_process(self):
        """"""Returns :class:`subprocess.Popen` instance with args from
        :meth:`get_args` result and piped stdin, stdout and stderr.
        """"""
        return Popen(self.get_args(), stdin=PIPE, stdout=PIPE, stderr=PIPE)","Returns :class:`subprocess.Popen` instance with args from
        :meth:`get_args` result and piped stdin, stdout and stderr.",
"def get_meta_netnode():
    """"""
    Get the netnode used to store settings metadata in the current IDB.
    Note that this implicitly uses the open IDB via the idc iterface.
    """"""
    node_name = ""$ {org:s}.{application:s}"".format(
        org=IDA_SETTINGS_ORGANIZATION,
        application=IDA_SETTINGS_APPLICATION)
    return netnode.Netnode(node_name)","Get the netnode used to store settings metadata in the current IDB.
    Note that this implicitly uses the open IDB via the idc iterface.",
"def import_settings(settings, config_path):
    """"""
    Import settings from the given file system path to given settings instance.

    type settings: IDASettingsInterface
    type config_path: str
    """"""
    other = QtCore.QSettings(config_path, QtCore.QSettings.IniFormat)
    for k in other.allKeys():
        settings[k] = other.value(k)","Import settings from the given file system path to given settings instance.

    type settings: IDASettingsInterface
    type config_path: str",
"def export_settings(settings, config_path):
    """"""
    Export the given settings instance to the given file system path.

    type settings: IDASettingsInterface
    type config_path: str
    """"""
    other = QtCore.QSettings(config_path, QtCore.QSettings.IniFormat)
    for k, v in settings.iteritems():
        other.setValue(k, v)","Export the given settings instance to the given file system path.

    type settings: IDASettingsInterface
    type config_path: str",
"def directory(self):
        """"""
        Fetch the IDASettings instance for the curren plugin with directory scope.

        rtype: IDASettingsInterface
        """"""
        if self._config_directory is None:
            ensure_ida_loaded()
        return DirectoryIDASettings(self._plugin_name, directory=self._config_directory)","Fetch the IDASettings instance for the curren plugin with directory scope.

        rtype: IDASettingsInterface",
"def table(name, auth=None, eager=True):
    """"""Returns a given table for the given user.""""""
    auth = auth or []
    dynamodb = boto.connect_dynamodb(*auth)

    table = dynamodb.get_table(name)
    return Table(table=table, eager=eager)",Returns a given table for the given user.,
"def tables(auth=None, eager=True):
    """"""Returns a list of tables for the given user.""""""
    auth = auth or []
    dynamodb = boto.connect_dynamodb(*auth)

    return [table(t, auth, eager=eager) for t in dynamodb.list_tables()]",Returns a list of tables for the given user.,
"def metadata_id(item):
        """"""Extracts the identifier from an item depending on its type.""""""

        if Crates.metadata_category(item) == CATEGORY_CRATES:
            return str(item['id'])
        else:
            ts = item['fetched_on']
            ts = str_to_datetime(ts)
            return str(ts.timestamp())",Extracts the identifier from an item depending on its type.,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return CratesClient(self.sleep_time, self.archive, from_archive)",Init client,
"def __fetch_summary(self):
        """"""Fetch summary""""""

        raw_summary = self.client.summary()
        summary = json.loads(raw_summary)
        summary['fetched_on'] = str(datetime_utcnow())

        yield summary",Fetch summary,
"def __fetch_crate_owner_team(self, crate_id):
        """"""Get crate team owner""""""

        raw_owner_team = self.client.crate_attribute(crate_id, 'owner_team')

        owner_team = json.loads(raw_owner_team)

        return owner_team",Get crate team owner,
"def __fetch_crate_owner_user(self, crate_id):
        """"""Get crate user owners""""""

        raw_owner_user = self.client.crate_attribute(crate_id, 'owner_user')

        owner_user = json.loads(raw_owner_user)

        return owner_user",Get crate user owners,
"def __fetch_crate_versions(self, crate_id):
        """"""Get crate versions data""""""

        raw_versions = self.client.crate_attribute(crate_id, ""versions"")

        version_downloads = json.loads(raw_versions)

        return version_downloads",Get crate versions data,
"def __fetch_crate_version_downloads(self, crate_id):
        """"""Get crate version downloads""""""

        raw_version_downloads = self.client.crate_attribute(crate_id, ""downloads"")

        version_downloads = json.loads(raw_version_downloads)

        return version_downloads",Get crate version downloads,
"def __fetch_crate_data(self, crate_id):
        """"""Get crate data""""""

        raw_crate = self.client.crate(crate_id)

        crate = json.loads(raw_crate)
        return crate['crate']",Get crate data,
"def summary(self):
        """"""Get Crates.io summary""""""

        path = urijoin(CRATES_API_URL, CATEGORY_SUMMARY)
        raw_content = self.fetch(path)

        return raw_content",Get Crates.io summary,
"def crates(self, from_page=1):
        """"""Get crates in alphabetical order""""""

        path = urijoin(CRATES_API_URL, CATEGORY_CRATES)
        raw_crates = self.__fetch_items(path, from_page)

        return raw_crates",Get crates in alphabetical order,
"def crate(self, crate_id):
        """"""Get a crate by its ID""""""

        path = urijoin(CRATES_API_URL, CATEGORY_CRATES, crate_id)
        raw_crate = self.fetch(path)

        return raw_crate",Get a crate by its ID,
"def crate_attribute(self, crate_id, attribute):
        """"""Get crate attribute""""""

        path = urijoin(CRATES_API_URL, CATEGORY_CRATES, crate_id, attribute)
        raw_attribute_data = self.fetch(path)

        return raw_attribute_data",Get crate attribute,
"def fetch(self, url, payload=None):
        """"""Return the textual content associated to the Response object""""""

        response = super().fetch(url, payload=payload)

        return response.text",Return the textual content associated to the Response object,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return KitsuneClient(self.url, self.archive, from_archive)",Init client,
"def fetch(self, url, params):
        """"""Return the textual content associated to the Response object""""""

        logger.debug(""Kitsune client calls API: %s params: %s"",
                     url, str(params))

        response = super().fetch(url, payload=params)

        return response.text",Return the textual content associated to the Response object,
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return ReMoClient(self.url, self.archive, from_archive)",Init client,
"def io_priority(self):
        """"""
        IO priority for this instance.
        """"""
        return (
            self._iocb.aio_reqprio
            if self._iocb.u.c.flags & libaio.IOCB_FLAG_IOPRIO else
            None
        )",IO priority for this instance.,
"def close(self):
        """"""
        Cancels all pending IO blocks.
        Waits until all non-cancellable IO blocks finish.
        De-initialises AIO context.
        """"""
        if self._ctx is not None:
            # Note: same as io_destroy
            self._io_queue_release(self._ctx)
            del self._ctx","Cancels all pending IO blocks.
        Waits until all non-cancellable IO blocks finish.
        De-initialises AIO context.",
"def _init_client(self, from_archive=False):
        """"""Init client""""""

        return MozillaClubClient(self.url, self.archive, from_archive)",Init client,
"def get_cells(self):
        """"""Retrieve all cells from the spreadsheet.""""""

        logger.info(""Retrieving all cells spreadsheet data ..."")
        logger.debug(""MozillaClub client calls API: %s"", self.base_url)
        raw_cells = self.fetch(self.base_url)

        return raw_cells.text",Retrieve all cells from the spreadsheet.,
"def get_data_files(dirname):
    """"""Return data files in directory *dirname*""""""
    flist = []
    for dirpath, _dirnames, filenames in os.walk(dirname):
        for fname in filenames:
            flist.append(osp.join(dirpath, fname))
    return flist",Return data files in directory *dirname*,
"def permission_factory(self):
        """"""Load default permission factory.""""""
        if self._permission_factory is None:
            imp = self.app.config['RECORDS_UI_DEFAULT_PERMISSION_FACTORY']
            self._permission_factory = obj_or_import_string(imp)
        return self._permission_factory",Load default permission factory.,
"def init_app(self, app):
        """"""Flask application initialization.

        :param app: The Flask application.
        """"""
        self.init_config(app)
        app.extensions['invenio-records-ui'] = _RecordUIState(app)","Flask application initialization.

        :param app: The Flask application.",
"def close(self):
        # type: () -> None
        """"""Close the socket to free system resources.

        After the socket is closed, further operations with socket
        will fail. Multiple calls to close will have no effect.
        """"""

        if self._closed:
            return
        self._socket.close()
        self._closed = True","Close the socket to free system resources.

        After the socket is closed, further operations with socket
        will fail. Multiple calls to close will have no effect.",
"def remove_client(self, client):
        # type: (object) -> None
        """"""Remove the client from the users of the socket.

        If there are no more clients for the socket, it
        will close automatically.
        """"""

        try:
            self._clients.remove(id(client))
        except ValueError:
            pass

        if len(self._clients) < 1:
            self.close()","Remove the client from the users of the socket.

        If there are no more clients for the socket, it
        will close automatically.",
"def increment(self, name, count=1, rate=1):
        # type: (str, int, float) -> None
        """"""Increment a Counter metric""""""

        if self._should_send_metric(name, rate):
            self._request(
                Counter(
                    self._create_metric_name_for_request(name),
                    int(count),
                    rate
                ).to_request()
            )",Increment a Counter metric,
"def _request(self, data):
        # type: (str) -> None
        """"""Override parent by buffering the metric instead of sending now""""""

        data = bytearray(""{}\n"".format(data).encode())
        self._prepare_batches_for_storage(len(data))
        self._batches[-1].extend(data)",Override parent by buffering the metric instead of sending now,
"def batch_client(self, size=512):
        # type: (int) -> BatchClient
        """"""Return a batch client with same settings of the client""""""

        batch_client = BatchClient(self.host, self.port, self.prefix, size)
        self._configure_client(batch_client)
        return batch_client",Return a batch client with same settings of the client,
"def unit_client(self):
        # type: () -> Client
        """"""Return a client with same settings of the batch client""""""

        client = Client(self.host, self.port, self.prefix)
        self._configure_client(client)
        return client",Return a client with same settings of the batch client,
"def flush(self):
        # type: () -> BatchClient
        """"""Send buffered metrics in batch requests""""""

        address = self.remote_address
        while len(self._batches) > 0:
            self._socket.sendto(self._batches[0], address)
            self._batches.popleft()
        return self",Send buffered metrics in batch requests,
"def my_permission_factory(record, *args, **kwargs):
    """"""My permission factory.""""""
    def can(self):
        rec = Record.get_record(record.id)
        return rec.get('access', '') == 'open'
    return type('MyPermissionChecker', (), {'can': can})()",My permission factory.,
"def batch_client(self, size=512):
        # type: (int) -> TCPBatchClient
        """"""Return a TCP batch client with same settings of the TCP client""""""

        batch_client = TCPBatchClient(self.host, self.port, self.prefix, size)
        self._configure_client(batch_client)
        return batch_client",Return a TCP batch client with same settings of the TCP client,
"def flush(self):
        """"""Send buffered metrics in batch requests over TCP""""""
        # type: () -> TCPBatchClient
        while len(self._batches) > 0:
            self._socket.sendall(self._batches[0])
            self._batches.popleft()
        return self",Send buffered metrics in batch requests over TCP,
"def unit_client(self):
        # type: () -> TCPClient
        """"""Return a TCPClient with same settings of the batch TCP client""""""

        client = TCPClient(self.host, self.port, self.prefix)
        self._configure_client(client)
        return client",Return a TCPClient with same settings of the batch TCP client,
"def any_float(min_value=0, max_value=100, precision=2):
    """"""
    Returns random float
    
    >>> result = any_float(min_value=0, max_value=100, precision=2)
    >>> type(result)
    <type 'float'>
    >>> result >=0 and result <= 100
    True

    """"""
    return round(random.uniform(min_value, max_value), precision)","Returns random float
    
    >>> result = any_float(min_value=0, max_value=100, precision=2)
    >>> type(result)
    <type 'float'>
    >>> result >=0 and result <= 100
    True",
"def _deprecated_register(self, py_class, to_om, om_cd, om_name, to_py=None):
        """"""
        This is a shorthand for:

           ``self.register_to_python(om_cd, om_name, to_py)``
           ``self.register_to_openmath(py_class, to_om)``
        """"""
        self.register_to_python(om_cd, om_name, to_py)
        self.register_to_openmath(py_class, to_om)","This is a shorthand for:

           ``self.register_to_python(om_cd, om_name, to_py)``
           ``self.register_to_openmath(py_class, to_om)``",
"def init_app(self, app):
        """"""
        Used to initialize redis with app object
        """"""

        app.config.setdefault('REDIS_URLS', {
            'main': 'redis://localhost:6379/0',
            'admin': 'redis://localhost:6379/1',
        })

        app.before_request(self.before_request)

        self.app = app",Used to initialize redis with app object,
"def valid_choices(choices):
    """"""
    Return list of choices's keys
    """"""
    for key, value in choices:
        if isinstance(value, (list, tuple)):
            for key, _ in value:
                yield key
        else:
            yield key",Return list of choices's keys,
"def register(self, field_type, impl=None):
        """"""
        Register form field data function.
        
        Could be used as decorator
        """"""
        def _wrapper(func):
            self.registry[field_type] = func
            return func

        if impl:
            return _wrapper(impl)
        return _wrapper","Register form field data function.
        
        Could be used as decorator",
"def field_required_attribute(function):
    """"""
    Sometimes return None if field is not required

    >>> result = any_form_field(forms.BooleanField(required=False))
    >>> result in ['', 'True', 'False']
    True
    """"""
    def _wrapper(field, **kwargs):
        if not field.required and random.random < 0.1:
            return None
        return function(field, **kwargs)
    return _wrapper","Sometimes return None if field is not required

    >>> result = any_form_field(forms.BooleanField(required=False))
    >>> result in ['', 'True', 'False']
    True",
"def field_choices_attibute(function):
    """"""
    Selection from field.choices
    """"""
    def _wrapper(field, **kwargs):
        if hasattr(field.widget, 'choices'):
            return random.choice(list(valid_choices(field.widget.choices)))
        return function(field, **kwargs)

    return _wrapper",Selection from field.choices,
"def model_choice_field_data(field, **kwargs):
    """"""
    Return one of first ten items for field queryset
    """"""
    data = list(field.queryset[:10])
    if data:
        return random.choice(data)
    else:
        raise TypeError('No %s available in queryset' % field.queryset.model)",Return one of first ten items for field queryset,
"def encode_bytes(obj, nsprefix=None):
    """""" Encodes an OpenMath element into a string.

    :param obj: Object to encode as string.
    :type obj: OMAny

    :rtype: bytes
    """"""

    node = encode_xml(obj, nsprefix)
    return etree.tostring(node)","Encodes an OpenMath element into a string.

    :param obj: Object to encode as string.
    :type obj: OMAny

    :rtype: bytes",
"def decode_bytes(xml, validator=None, snippet=False):
    """""" Decodes a stream into an OpenMath object.

    :param xml: XML to decode.
    :type xml: bytes

    :param validator: Validator to use.

    :param snippet: Is this an OpenMath snippet, or a full object?
    :type snippet: Bool

    :rtype: OMAny
    """"""
    return decode_stream(io.BytesIO(xml), validator, snippet)","Decodes a stream into an OpenMath object.

    :param xml: XML to decode.
    :type xml: bytes

    :param validator: Validator to use.

    :param snippet: Is this an OpenMath snippet, or a full object?
    :type snippet: Bool

    :rtype: OMAny",
"def tag(version=__version__):
    """"""Deploy a version tag.""""""
    build = local(""git tag {0}"".format(version))
    if build.succeeded:
        local(""git push --tags"")",Deploy a version tag.,
"def any_field_blank(function):
    """"""
    Sometimes return None if field could be blank
    """"""
    def wrapper(field, **kwargs):
        if kwargs.get('isnull', False):
            return None
    
        if field.blank and random.random < 0.1:
            return None
        return function(field, **kwargs)
    return wrapper",Sometimes return None if field could be blank,
"def any_biginteger_field(field, **kwargs):
    """"""
    Return random value for BigIntegerField

    >>> result = any_field(models.BigIntegerField())
    >>> type(result)
    <type 'long'>
    """"""
    min_value = kwargs.get('min_value', 1)
    max_value = kwargs.get('max_value', 10**10)
    return long(xunit.any_int(min_value=min_value, max_value=max_value))","Return random value for BigIntegerField

    >>> result = any_field(models.BigIntegerField())
    >>> type(result)
    <type 'long'>",
"def any_positiveinteger_field(field, **kwargs):
    """"""
    An positive integer

    >>> result = any_field(models.PositiveIntegerField())
    >>> type(result)
    <type 'int'>
    >>> result > 0
    True
    """"""
    min_value = kwargs.get('min_value', 1)
    max_value = kwargs.get('max_value', 9999)
    return xunit.any_int(min_value=min_value, max_value=max_value)","An positive integer

    >>> result = any_field(models.PositiveIntegerField())
    >>> type(result)
    <type 'int'>
    >>> result > 0
    True",
"def any_char_field(field, **kwargs):
    """"""
    Return random value for CharField

    >>> result = any_field(models.CharField(max_length=10))
    >>> type(result)
    <type 'str'>
    """"""
    min_length = kwargs.get('min_length', 1)
    max_length = kwargs.get('max_length', field.max_length)
    return xunit.any_string(min_length=min_length, max_length=max_length)","Return random value for CharField

    >>> result = any_field(models.CharField(max_length=10))
    >>> type(result)
    <type 'str'>",
"def any_integer_field(field, **kwargs):
    """"""
    Return random value for IntegerField
    >>> result = any_field(models.IntegerField())
    >>> type(result)
    <type 'int'>
    """"""
    min_value = kwargs.get('min_value', -10000)
    max_value = kwargs.get('max_value', 10000)
    return xunit.any_int(min_value=min_value, max_value=max_value)","Return random value for IntegerField
    >>> result = any_field(models.IntegerField())
    >>> type(result)
    <type 'int'>",
"def any_time_field(field, **kwargs):
    """"""
    Return random value for TimeField
    >>> result = any_field(models.TimeField())
    >>> type(result)
    <type 'datetime.time'>
    """"""
    return time(
        xunit.any_int(min_value=0, max_value=23),
        xunit.any_int(min_value=0, max_value=59),
        xunit.any_int(min_value=0, max_value=59))","Return random value for TimeField
    >>> result = any_field(models.TimeField())
    >>> type(result)
    <type 'datetime.time'>",
"def to_array(data):
    """"""
    Import a blosc array into a numpy array.

    Arguments:
        data: A blosc packed numpy array

    Returns:
        A numpy array with data from a blosc compressed array
    """"""
    try:
        numpy_data = blosc.unpack_array(data)
    except Exception as e:
        raise ValueError(""Could not load numpy data. {}"".format(e))

    return numpy_data","Import a blosc array into a numpy array.

    Arguments:
        data: A blosc packed numpy array

    Returns:
        A numpy array with data from a blosc compressed array",
"def from_array(array):
    """"""
    Export a numpy array to a blosc array.

    Arguments:
        array: The numpy array to compress to blosc array

    Returns:
        Bytes/String. A blosc compressed array
    """"""
    try:
        raw_data = blosc.pack_array(array)
    except Exception as e:
        raise ValueError(""Could not compress data from array. {}"".format(e))

    return raw_data","Export a numpy array to a blosc array.

    Arguments:
        array: The numpy array to compress to blosc array

    Returns:
        Bytes/String. A blosc compressed array",
"def remove(self, name):
        """"""Remove workspace from config file.""""""
        if not (self.exists(name)):
            raise ValueError(""Workspace `%s` doesn't exists."" % name)

        self.config[""workspaces""].pop(name, 0)
        self.config.write()",Remove workspace from config file.,
"def list(self):
        """"""List all available workspaces.""""""
        ws_list = {}

        for key, value in self.config[""workspaces""].items():
            ws_list[key] = dict({""name"": key}, **value)

        return ws_list",List all available workspaces.,
"def get(self, name):
        """"""
        Get workspace infos from name.
        Return None if workspace doesn't exists.
        """"""
        ws_list = self.list()
        return ws_list[name] if name in ws_list else None","Get workspace infos from name.
        Return None if workspace doesn't exists.",
"def repository_exists(self, workspace, repo):
        """"""Return True if workspace contains repository name.""""""
        if not self.exists(workspace):
            return False

        workspaces = self.list()
        return repo in workspaces[workspace][""repositories""]",Return True if workspace contains repository name.,
"def check_version():
    """"""
    Tells you if you have an old version of ndio.
    """"""
    import requests
    r = requests.get('https://pypi.python.org/pypi/ndio/json').json()
    r = r['info']['version']
    if r != version:
        print(""A newer version of ndio is available. "" +
              ""'pip install -U ndio' to update."")
    return r",Tells you if you have an old version of ndio.,
"def to_voxels(array):
    """"""
    Converts an array to its voxel list.

    Arguments:
        array (numpy.ndarray): A numpy nd array. This must be boolean!

    Returns:
        A list of n-tuples
    """"""
    if type(array) is not numpy.ndarray:
        raise ValueError(""array argument must be of type numpy.ndarray"")
    return numpy.argwhere(array)","Converts an array to its voxel list.

    Arguments:
        array (numpy.ndarray): A numpy nd array. This must be boolean!

    Returns:
        A list of n-tuples",
"def execute(self, args):
        """"""Execute update subcommand.""""""
        if args.name is not None:
            self.print_workspace(args.name)
        elif args.all is not None:
            self.print_all()",Execute update subcommand.,
"def print_update(self, repo_name, repo_path):
        """"""Print repository update.""""""
        color = Color()
        self.logger.info(color.colored(
            ""=> [%s] %s"" % (repo_name, repo_path), ""green""))
        try:
            repo = Repository(repo_path)
            repo.update()
        except RepositoryError as e:
            self.logger.error(e)
            pass
        print(""\n"")",Print repository update.,
"def set_file_handler(self, logfile):
        """"""Set FileHandler""""""
        handler = logging.FileHandler(logfile)
        handler.setLevel(logging.NOTSET)
        handler.setFormatter(Formatter(FORMAT))

        self.addHandler(handler)",Set FileHandler,
"def set_console_handler(self, debug=False):
        """"""Set Console handler.""""""
        console = logging.StreamHandler()
        console.setFormatter(Formatter(LFORMAT))
        if not debug:
            console.setLevel(logging.INFO)

        self.addHandler(console)",Set Console handler.,
"def print_workspace(self, name):
        """"""Print workspace status.""""""
        path_list = find_path(name, self.config)

        if len(path_list) == 0:
            self.logger.error(""No matches for `%s`"" % name)
            return False

        for name, path in path_list.items():
            self.print_status(name, path)",Print workspace status.,
"def print_status(self, repo_name, repo_path):
        """"""Print repository status.""""""
        color = Color()
        self.logger.info(color.colored(
            ""=> [%s] %s"" % (repo_name, repo_path), ""green""))
        try:
            repo = Repository(repo_path)
            repo.status()
        except RepositoryError as e:
            self.logger.error(e)
            pass
        print(""\n"")",Print repository status.,
"def write(self):
        """"""
        Write config in configuration file.
        Data must me a dict.
        """"""
        file = open(self.config_file, ""w+"")
        file.write(yaml.dump(dict(self), default_flow_style=False))
        file.close()","Write config in configuration file.
        Data must me a dict.",
"def clone(self, url):
        """"""Clone repository from url.""""""
        return self.execute(""%s branch %s %s"" % (self.executable,
                                                 url, self.path))",Clone repository from url.,
"def get_version():
    """"""Get version from package resources.""""""
    requirement = pkg_resources.Requirement.parse(""yoda"")
    provider = pkg_resources.get_provider(requirement)
    return provider.version",Get version from package resources.,
"def mix_and_match(name, greeting='Hello', yell=False):
    '''Mixing and matching positional args and keyword options.'''
    say = '%s, %s' % (greeting, name)
    if yell:
        print '%s!' % say.upper()
    else:
        print '%s.' % say",Mixing and matching positional args and keyword options.,
"def option_decorator(name, greeting, yell):
    '''Same as mix_and_match, but using the @option decorator.'''
    # Use the @option decorator when you need more control over the
    # command line options.
    say = '%s, %s' % (greeting, name)
    if yell:
        print '%s!' % say.upper()
    else:
        print '%s.' % say","Same as mix_and_match, but using the @option decorator.",
"def ping(self, suffix='public_tokens/'):
        """"""
        Return the status-code of the API (estimated using the public-tokens
        lookup page).

        Arguments:
            suffix (str : 'public_tokens/'): The url endpoint to check

        Returns:
            int: status code
        """"""
        return self.remote_utils.ping(super(neuroRemote, self).url(), suffix)","Return the status-code of the API (estimated using the public-tokens
        lookup page).

        Arguments:
            suffix (str : 'public_tokens/'): The url endpoint to check

        Returns:
            int: status code",
"def url(self, suffix=""""):
        """"""
        Return a constructed URL, appending an optional suffix (uri path).

        Arguments:
            suffix (str : """"): The suffix to append to the end of the URL

        Returns:
            str: The complete URL
        """"""
        return super(neuroRemote,
                     self).url('{}/'.format(self._ext) + suffix)","Return a constructed URL, appending an optional suffix (uri path).

        Arguments:
            suffix (str : """"): The suffix to append to the end of the URL

        Returns:
            str: The complete URL",
"def execute(self, args):
        """"""Execute show subcommand.""""""
        if args.name is not None:
            self.show_workspace(slashes2dash(args.name))
        elif args.all is not None:
            self.show_all()",Execute show subcommand.,
"def show_all(self):
        """"""Show details for all workspaces.""""""
        for ws in self.workspace.list().keys():
            self.show_workspace(ws)
            print(""\n\n"")",Show details for all workspaces.,
"def url(self, endpoint=''):
        """"""
        Get the base URL of the Remote.

        Arguments:
            None
        Returns:
            `str` base URL
        """"""
        if not endpoint.startswith('/'):
            endpoint = ""/"" + endpoint
        return self.protocol + ""://"" + self.hostname + endpoint","Get the base URL of the Remote.

        Arguments:
            None
        Returns:
            `str` base URL",
"def ping(self, endpoint=''):
        """"""
        Ping the server to make sure that you can access the base URL.

        Arguments:
            None
        Returns:
            `boolean` Successful access of server (or status code)
        """"""
        r = requests.get(self.url() + ""/"" + endpoint)
        return r.status_code","Ping the server to make sure that you can access the base URL.

        Arguments:
            None
        Returns:
            `boolean` Successful access of server (or status code)",
"def RAMON(typ):
        """"""
        Takes str or int, returns class type
        """"""
        if six.PY2:
            lookup = [str, unicode]
        elif six.PY3:
            lookup = [str]

        if type(typ) is int:
            return _ramon_types[typ]
        elif type(typ) in lookup:
            return _ramon_types[_types[typ]]","Takes str or int, returns class type",
"def get_public_tokens(self):
        """"""
        Get a list of public tokens available on this server.

        Arguments:
            None

        Returns:
            str[]: list of public tokens
        """"""
        r = self.remote_utils.get_url(self.url() + ""public_tokens/"")
        return r.json()","Get a list of public tokens available on this server.

        Arguments:
            None

        Returns:
            str[]: list of public tokens",
"def get_proj_info(self, token):
        """"""
        Return the project info for a given token.

        Arguments:
            token (str): Token to return information for

        Returns:
            JSON: representation of proj_info
        """"""
        r = self.remote_utils.get_url(self.url() + ""{}/info/"".format(token))
        return r.json()","Return the project info for a given token.

        Arguments:
            token (str): Token to return information for

        Returns:
            JSON: representation of proj_info",
"def ping(self, url, endpoint=''):
        """"""
        Ping the server to make sure that you can access the base URL.

        Arguments:
            None
        Returns:
            `boolean` Successful access of server (or status code)
        """"""
        r = self.get_url(url + ""/"" + endpoint)
        return r.status_code","Ping the server to make sure that you can access the base URL.

        Arguments:
            None
        Returns:
            `boolean` Successful access of server (or status code)",
"def nvim_io_recover(self, io: NvimIORecover[A]) -> NvimIO[B]:
        '''calls `map` to shift the recover execution to flat_map_nvim_io
        '''
        return eval_step(self.vim)(io.map(lambda a: a))",calls `map` to shift the recover execution to flat_map_nvim_io,
"def ugettext(message, context=None):
    """"""Always return a stripped string, localized if possible""""""
    stripped = strip_whitespace(message)

    message = add_context(context, stripped) if context else stripped

    ret = django_ugettext(message)

    # If the context isn't found, we need to return the string without it
    return stripped if ret == message else ret","Always return a stripped string, localized if possible",
"def _percent(data, part, total):
    """"""
    Calculate a percentage.
    """"""
    try:
        return round(100 * float(data[part]) / float(data[total]), 1)
    except ZeroDivisionError:
        return 0",Calculate a percentage.,
"def _get_cache_slabs(server_name=None):
    """"""
    Get slabs info.
    """"""
    server_info = {}
    for svr in mc_client.get_slabs():
        svr_info = svr[0].split(' ')
        svr_name = svr_info[0]
        if server_name and server_name == svr_name:
            return svr[1]
        server_info[svr_name] = svr[1]
    return server_info",Get slabs info.,
"def _context_data(data, request=None):
    """"""
    Add admin global context, for compatibility with Django 1.7
    """"""
    try:
        return dict(site.each_context(request).items() + data.items())
    except AttributeError:
        return data","Add admin global context, for compatibility with Django 1.7",
"def server_status(request):
    """"""
    Return the status of all servers.
    """"""
    data = {
        'cache_stats': _get_cache_stats(),
        'can_get_slabs': hasattr(mc_client, 'get_slabs'),
    }
    return render_to_response('memcache_admin/server_status.html', data, RequestContext(request))",Return the status of all servers.,
"def stats(request, server_name):
    """"""
    Show server statistics.
    """"""
    server_name = server_name.strip('/')
    data = _context_data({
        'title': _('Memcache Statistics for %s') % server_name,
        'cache_stats': _get_cache_stats(server_name),
    },
        request)
    return render_to_response('memcache_admin/stats.html', data, RequestContext(request))",Show server statistics.,
"def slabs(request, server_name):
    """"""
    Show server slabs.
    """"""
    data = _context_data({
        'title': _('Memcache Slabs for %s') % server_name,
        'cache_slabs': _get_cache_slabs(server_name),
    },
        request)
    return render_to_response('memcache_admin/slabs.html', data, RequestContext(request))",Show server slabs.,
"def apply_config(self, applicator):
        """"""
        Replace any config tokens in the file's path with values from the config.
        """"""
        if type(self._fpath) == str:
            self._fpath = applicator.apply(self._fpath)",Replace any config tokens in the file's path with values from the config.,
"def path(self):
        """"""
        Get the path to the file relative to its parent.
        """"""
        if self._parent:
            return os.path.join(self._parent.path, self._fpath)
        else:
            return self._fpath",Get the path to the file relative to its parent.,
"def read(self):
        """"""
        Read and return the contents of the file.
        """"""
        with open(self.path) as f:
            d = f.read()
        return d",Read and return the contents of the file.,
"def write(self, data, mode='w'):
        """"""
        Write data to the file.

        `data` is the data to write
        `mode` is the mode argument to pass to `open()`
        """"""
        with open(self.path, mode) as f:
            f.write(data)","Write data to the file.

        `data` is the data to write
        `mode` is the mode argument to pass to `open()`",
"def create(self):
        """"""
        Create the file.

        If the file already exists an exception will be raised
        """"""
        if not os.path.exists(self.path):
            open(self.path, 'a').close()
        else:
            raise Exception(""File exists: {}"".format(self.path))","Create the file.

        If the file already exists an exception will be raised",
"def apply_config(self, applicator):
        """"""
        Replace any config tokens with values from the config.
        """"""
        if type(self._path) == str:
            self._path = applicator.apply(self._path)

        for key in self._children:
            self._children[key].apply_config(applicator)",Replace any config tokens with values from the config.,
"def path(self):
        """"""
        Return the path to this directory.
        """"""
        p = ''

        if self._parent and self._parent.path:
            p = os.path.join(p, self._parent.path)
        if self._base:
            p = os.path.join(p, self._base)
        if self._path:
            p = os.path.join(p, self._path)

        return p",Return the path to this directory.,
"def remove(self, recursive=True, ignore_error=True):
        """"""
        Remove the directory.
        """"""
        try:
            if recursive or self._cleanup == 'recursive':
                shutil.rmtree(self.path)
            else:
                os.rmdir(self.path)
        except Exception as e:
            if not ignore_error:
                raise e",Remove the directory.,
"def prepare(self):
        """"""
        Prepare the Directory for use in an Environment.

        This will create the directory if the create flag is set.
        """"""
        if self._create:
            self.create()
        for k in self._children:
            self._children[k]._env = self._env
            self._children[k].prepare()","Prepare the Directory for use in an Environment.

        This will create the directory if the create flag is set.",
"def cleanup(self):
        """"""
        Clean up children and remove the directory.

        Directory will only be removed if the cleanup flag is set.
        """"""
        for k in self._children:
            self._children[k].cleanup()

        if self._cleanup:
            self.remove(True)","Clean up children and remove the directory.

        Directory will only be removed if the cleanup flag is set.",
"def path_to(self, path):
        """"""
        Find the path to something inside this directory.
        """"""
        return os.path.join(self.path, str(path))",Find the path to something inside this directory.,
"def list(self):
        """"""
        List the contents of the directory.
        """"""
        return [File(f, parent=self) for f in os.listdir(self.path)]",List the contents of the directory.,
"def write(self, filename, data, mode='w'):
        """"""
        Write to a file in the directory.
        """"""
        with open(self.path_to(str(filename)), mode) as f:
            f.write(data)",Write to a file in the directory.,
"def read(self, filename):
        """"""
        Read a file from the directory.
        """"""
        with open(self.path_to(str(filename))) as f:
            d = f.read()
        return d",Read a file from the directory.,
"def save(self):
        """"""
        Save the state to a file.
        """"""
        with open(self.path, 'w') as f:
            f.write(yaml.dump(dict(self.d)))",Save the state to a file.,
"def load(self):
        """"""
        Load a saved state file.
        """"""
        if os.path.exists(self.path):
            with open(self.path, 'r') as f:
                self.d = yaml.safe_load(f.read().replace('\t', ' '*4))",Load a saved state file.,
"def cleanup(self):
        """"""
        Clean up the saved state.
        """"""
        if os.path.exists(self.path):
            os.remove(self.path)",Clean up the saved state.,
"def _child(self, path):
        """"""
        Return a ConfigNode object representing a child node with the specified
        relative path.
        """"""
        if self._path:
            path = '{}.{}'.format(self._path, path)
        return ConfigNode(root=self._root, path=path)","Return a ConfigNode object representing a child node with the specified
        relative path.",
"def _get_value(self):
        """"""
        Get the value represented by this node.
        """"""
        if self._path:
            try:
                container, last = self._resolve_path()
                return container[last]
            except KeyError:
                return None
            except IndexError:
                return None
        else:
            return self._data",Get the value represented by this node.,
"def process_input(self):
        """"""Called when socket is read-ready""""""
        try:
            pyngus.read_socket_input(self.connection, self.socket)
        except Exception as e:
            LOG.error(""Exception on socket read: %s"", str(e))
            self.connection.close_input()
            self.connection.close()
        self.connection.process(time.time())",Called when socket is read-ready,
"def create_caller(self, method_map, source_addr, target_addr,
                      receiver_properties, sender_properties):
        """""" Caller factory
        """"""
        if self.caller:
            self.caller.destroy()
        self.caller = MyCaller(method_map, self, source_addr, target_addr,
                               receiver_properties, sender_properties)
        return self.caller",Caller factory,
"def _not_reentrant(func):
    """"""Decorator that prevents callbacks from calling into link methods that
    are not reentrant """"""
    def wrap(*args, **kws):
        link = args[0]
        if link._callback_lock.in_callback:
            m = ""Link %s cannot be invoked from a callback!"" % func
            raise RuntimeError(m)
        return func(*args, **kws)
    return wrap","Decorator that prevents callbacks from calling into link methods that
    are not reentrant",
"def source_address(self):
        """"""Return the authorative source of the link.""""""
        # If link is a sender, source is determined by the local
        # value, else use the remote.
        if self._pn_link.is_sender:
            return self._pn_link.source.address
        else:
            return self._pn_link.remote_source.address",Return the authorative source of the link.,
"def target_address(self):
        """"""Return the authorative target of the link.""""""
        # If link is a receiver, target is determined by the local
        # value, else use the remote.
        if self._pn_link.is_receiver:
            return self._pn_link.target.address
        else:
            return self._pn_link.remote_target.address",Return the authorative target of the link.,
"def reject(self, pn_condition=None):
        """"""See Link Reject, AMQP1.0 spec.""""""
        self._pn_link.source.type = proton.Terminus.UNSPECIFIED
        super(SenderLink, self).reject(pn_condition)","See Link Reject, AMQP1.0 spec.",
"def reject(self, pn_condition=None):
        """"""See Link Reject, AMQP1.0 spec.""""""
        self._pn_link.target.type = proton.Terminus.UNSPECIFIED
        super(ReceiverLink, self).reject(pn_condition)","See Link Reject, AMQP1.0 spec.",
"def new_sender(self, name):
        """"""Create a new sender link.""""""
        pn_link = self._pn_session.sender(name)
        return self.request_sender(pn_link)",Create a new sender link.,
"def request_sender(self, pn_link):
        """"""Create link from request for a sender.""""""
        sl = SenderLink(self._connection, pn_link)
        self._links.add(sl)
        return sl",Create link from request for a sender.,
"def new_receiver(self, name):
        """"""Create a new receiver link.""""""
        pn_link = self._pn_session.receiver(name)
        return self.request_receiver(pn_link)",Create a new receiver link.,
"def request_receiver(self, pn_link):
        """"""Create link from request for a receiver.""""""
        rl = ReceiverLink(self._connection, pn_link)
        self._links.add(rl)
        return rl",Create link from request for a receiver.,
"def link_destroyed(self, link):
        """"""Link has been destroyed.""""""
        self._links.discard(link)
        if not self._links:
            # no more links
            LOG.debug(""destroying unneeded session"")
            self._pn_session.close()
            self._pn_session.free()
            self._pn_session = None
            self._connection = None",Link has been destroyed.,
"def _ep_need_close(self):
        """"""Peer has closed its end of the session.""""""
        LOG.debug(""Session %s close requested - closing..."",
                  self._name)
        links = self._links.copy()  # may modify _links
        for link in links:
            link._session_closed()",Peer has closed its end of the session.,
"def extendMarkdown(self, md, md_globals):
        """"""Modifies inline patterns.""""""
        mark_tag = SimpleTagPattern(MARK_RE, 'mark')
        md.inlinePatterns.add('mark', mark_tag, '_begin')",Modifies inline patterns.,
"def receiver_remote_closed(self, receiver_link, pn_condition):
        """"""Peer has closed its end of the link.""""""
        LOG.debug(""receiver_remote_closed condition=%s"", pn_condition)
        receiver_link.close()
        self.done = True",Peer has closed its end of the link.,
"def receiver_failed(self, receiver_link, error):
        """"""Protocol error occurred.""""""
        LOG.warn(""receiver_failed error=%s"", error)
        receiver_link.close()
        self.done = True",Protocol error occurred.,
"def get_host_port(server_address):
    """"""Parse the hostname and port out of the server_address.""""""
    regex = re.compile(r""^amqp://([a-zA-Z0-9.]+)(:([\d]+))?$"")
    x = regex.match(server_address)
    if not x:
        raise Exception(""Bad address syntax: %s"" % server_address)
    matches = x.groups()
    host = matches[0]
    port = int(matches[2]) if matches[2] else None
    return host, port",Parse the hostname and port out of the server_address.,
"def output_data(self):
        """"""Get a buffer of data that needs to be written to the network.
        """"""
        c = self.has_output
        if c <= 0:
            return None
        try:
            buf = self._pn_transport.peek(c)
        except Exception as e:
            self._connection_failed(str(e))
            return None
        return buf",Get a buffer of data that needs to be written to the network.,
"def _connection_failed(self, error=""Error not specified!""):
        """"""Clean up after connection failure detected.""""""
        if not self._error:
            LOG.error(""Connection failed: %s"", str(error))
            self._error = error",Clean up after connection failure detected.,
"def _ep_active(self):
        """"""Both ends of the Endpoint have become active.""""""
        LOG.debug(""Connection is up"")
        if self._handler:
            with self._callback_lock:
                self._handler.connection_active(self)",Both ends of the Endpoint have become active.,
"def _ep_need_close(self):
        """"""The remote has closed its end of the endpoint.""""""
        LOG.debug(""Connection remotely closed"")
        if self._handler:
            cond = self._pn_connection.remote_condition
            with self._callback_lock:
                self._handler.connection_remote_closed(self, cond)",The remote has closed its end of the endpoint.,
"def _ep_error(self, error):
        """"""The endpoint state machine failed due to protocol error.""""""
        super(Connection, self)._ep_error(error)
        self._connection_failed(""Protocol error occurred."")",The endpoint state machine failed due to protocol error.,
"def _string_width(self, s):
        """"""Get width of a string in the current font""""""
        s = str(s)
        w = 0
        for char in s:
            char = ord(char)
            w += self.character_widths[char]
        return w * self.font_size / 1000.0",Get width of a string in the current font,
"def _set_compression(self, value):
        """""" May be used to compress PDF files. Code is more readable
            for testing and inspection if not compressed. Requires a boolean. """"""
        if isinstance(value, bool):
            self.compression = value
        else:
            raise Exception(
                TypeError, ""%s is not a valid option for compression"" % value)","May be used to compress PDF files. Code is more readable
            for testing and inspection if not compressed. Requires a boolean.",
"def _out(self, stream, page=None):
        """""" Stores the pdf code in a buffer. If it is page related,
            provide the page object.

        """"""
        if page is not None:
            page.buffer += str(stream) + ""\n""
        else:
            self.buffer += str(stream) + ""\n""","Stores the pdf code in a buffer. If it is page related,
            provide the page object.",
"def _put_stream(self, stream):
        """""" Creates a PDF text stream sandwich.

        """"""
        self._out('stream')
        self._out(stream)
        self._out('endstream')",Creates a PDF text stream sandwich.,
"def _set_default_font(self):
        """""" Internal method to set the initial default font. Change
            the font using set_font method.""""""
        self.font = PDFFont(self.session)
        self.font._set_index()
        self.fonts.append(self.font)
        self.fontkeys.append(self.font.font_key)","Internal method to set the initial default font. Change
            the font using set_font method.",
"def set_font_size(self, size):
        """"""Convenience method for just changing font size.""""""
        if self.font.font_size == size:
            pass
        else:
            self.font._set_size(size)",Convenience method for just changing font size.,
"def _get_orientation_changes(self):
        """""" Returns a list of the pages that have
            orientation changes.""""""
        self.orientation_changes = []
        for page in self.pages:
            if page.orientation_change is True:
                self.orientation_changes.append(page.index)
            else:
                pass
        return self.orientation_changes","Returns a list of the pages that have
            orientation changes.",
"def _output_fonts(self):
        """""" Called by the PDFLite object to prompt creating
            the font objects.""""""
        self.session._save_object_number()
        self._output_encoding_diffs()
        self._output_font_files()

        for font in self.fonts:
            obj = self.session._add_object()
            font._set_number(obj.id)
            font._output()","Called by the PDFLite object to prompt creating
            the font objects.",
"def _output_images(self):
        """""" Creates reference images, that can be
            drawn throughout the document.""""""
        for image in self.images:
            obj = self.session._add_object()
            image._set_number(obj.id)
            image._output()","Creates reference images, that can be
            drawn throughout the document.",
"def absolute_position(self, x, y):
        """"""return the absolute position of x,y in user space w.r.t. default user space""""""
        (a, b, c, d, e, f) = self._currentMatrix
        xp = a * x + c * y + e
        yp = b * x + d * y + f
        return xp, yp","return the absolute position of x,y in user space w.r.t. default user space",
"def rotate(self, theta):
        """"""Rotate current graphic state by the angle theta (in degrees).""""""
        c = cos(theta * pi / 180)
        s = sin(theta * pi / 180)
        self.transform(c, s, -s, c, 0, 0)",Rotate current graphic state by the angle theta (in degrees).,
"def _set_font(self, family=None, style=None, size=None):
        """"""Select a font; size given in points""""""
        self._set_family(family)
        self._set_style(style)
        self._set_size(size)
        self._set_font_key()
        self._set_name()
        self._set_character_widths()",Select a font; size given in points,
"def _string_width(self, s):
        """"""Get width of a string in the current font""""""
        s = str(s)
        w = 0
        for i in s:
            w += self.character_widths[i]
        return w * self.font_size / 1000.0",Get width of a string in the current font,
"def _put_header(self):
        """""" Standard first line in a PDF. """"""
        self.session._out('%%PDF-%s' % self.pdf_version)
        if self.session.compression:
            self.session.buffer += '%' + chr(235) + chr(236) + chr(237) + chr(238) + ""\n""",Standard first line in a PDF.,
"def _output_to_file(self):
        """""" Save to filepath specified on
            init. (Will throw an error if
            the document is already open).

        """"""
        f = open(self.filepath, 'wb')
        if not f:
            raise Exception('Unable to create output file: ', self.filepath)
        f.write(self.session.buffer)
        f.close()","Save to filepath specified on
            init. (Will throw an error if
            the document is already open).",
"def x_fit(self, test_length):
        """""" Test to see if the line can has enough space for the given length. """"""
        if (self.x + test_length) >= self.xmax:
            return False
        else:
            return True",Test to see if the line can has enough space for the given length.,
"def y_fit(self, test_length):
        """""" Test to see if the page has enough space for the given text height. """"""
        if (self.y + test_length) >= self.ymax:
            return False
        else:
            return True",Test to see if the page has enough space for the given text height.,
"def x_is_greater_than(self, test_ordinate):
        """""" Comparison for x coordinate""""""
        self._is_coordinate(test_ordinate)
        if self.x > test_ordinate.x:
            return True
        else:
            return False",Comparison for x coordinate,
"def y_is_greater_than(self, test_ordinate):
        """"""Comparison for y coordinate""""""
        self._is_coordinate(test_ordinate)
        if self.y > test_ordinate.y:
            return True
        else:
            return False",Comparison for y coordinate,
"def copy(self):
        """""" Create a copy, and return it.""""""
        new_cursor = self.__class__(self.x, self.y)
        new_cursor.set_bounds(self.xmin, self.ymin, self.xmax, self.ymax, self.ymaxmax)
        new_cursor.set_deltas(self.dx, self.dy)
        return new_cursor","Create a copy, and return it.",
"def x_plus(self, dx=None):
        """""" Mutable x addition. Defaults to set delta value. """"""
        if dx is None:
            self.x += self.dx
        else:
            self.x = self.x + dx",Mutable x addition. Defaults to set delta value.,
"def y_plus(self, dy=None):
        """""" Mutable y addition. Defaults to set delta value. """"""
        if dy is None:
            self.y += self.dy
        else:
            self.y = self.y + dy",Mutable y addition. Defaults to set delta value.,
"def _draw(self):
        """""" Don't use this, use document.draw_table """"""
        self._compile()
        self.rows[0]._advance_first_row()
        self._set_borders()
        self._draw_fill()
        self._draw_borders()
        self._draw_text()
        self._set_final_cursor()","Don't use this, use document.draw_table",
"def themes_path():
    """"""
    Retrieve the location of the themes directory from the location of this package

    This is taken from Sphinx's theme documentation
    """"""
    package_dir = os.path.abspath(os.path.dirname(__file__))
    return os.path.join(package_dir, 'themes')","Retrieve the location of the themes directory from the location of this package

    This is taken from Sphinx's theme documentation",
"def Compute(self):
    '''
    Computes the light curve model
    
    '''
    
    err = _Compute(self.transit, self.limbdark, self.settings, self.arrays)
    if err != _ERR_NONE: RaiseError(err)",Computes the light curve model,
"def Bin(self):
    '''
    Bins the light curve model to the provided time array
    
    '''
    
    err = _Bin(self.transit, self.limbdark, self.settings, self.arrays)
    if err != _ERR_NONE: RaiseError(err)",Bins the light curve model to the provided time array,
"def __recv(self, size=4096):
        """"""Reads data from the socket.

        Raises:
            NNTPError: When connection times out or read from socket fails.
        """"""
        data = self.socket.recv(size)
        if not data:
            raise NNTPError(""Failed to read from socket"")
        self.__buffer.write(data)","Reads data from the socket.

        Raises:
            NNTPError: When connection times out or read from socket fails.",
"def info(self, code, message, compressed=False):
        """"""The complete content of an info response.

        This should only used for commands that return small or known amounts of
        data.

        Returns:
            A the complete content of a textual response.
        """"""
        return """".join([x for x in self.info_gen(code, message, compressed)])","The complete content of an info response.

        This should only used for commands that return small or known amounts of
        data.

        Returns:
            A the complete content of a textual response.",
"def list_extensions_gen(self):
        """"""Generator for the LIST EXTENSIONS command.
        """"""
        code, message = self.command(""LIST EXTENSIONS"")
        if code != 202:
            raise NNTPReplyError(code, message)

        for line in self.info_gen(code, message):
            yield line.strip()",Generator for the LIST EXTENSIONS command.,
"def head(self, msgid_article=None):
        """"""HEAD command.
        """"""
        args = None
        if msgid_article is not None:
            args = utils.unparse_msgid_article(msgid_article)

        code, message = self.command(""HEAD"", args)
        if code != 221:
            raise NNTPReplyError(code, message)

        return utils.parse_headers(self.info_gen(code, message))",HEAD command.,
"def xgtitle(self, pattern=None):
        """"""XGTITLE command.
        """"""
        args = pattern

        code, message = self.command(""XGTITLE"", args)
        if code != 282:
            raise NNTPReplyError(code, message)

        return self.info(code, message)",XGTITLE command.,
"def xhdr(self, header, msgid_range=None):
        """"""XHDR command.
        """"""
        args = header
        if range is not None:
            args += "" "" + utils.unparse_msgid_range(msgid_range)

        code, message = self.command(""XHDR"", args)
        if code != 221:
            raise NNTPReplyError(code, message)

        return self.info(code, message)",XHDR command.,
"def xpat(self, header, id_range, *pattern):
        """"""XPAT command.
        """"""
        return [x for x in self.xpat_gen(header, id_range, *pattern)]",XPAT command.,
"def xfeature_compress_gzip(self, terminator=False):
        """"""XFEATURE COMPRESS GZIP command.
        """"""
        args = ""TERMINATOR"" if terminator else None

        code, message = self.command(""XFEATURE COMPRESS GZIP"", args)
        if code != 290:
            raise NNTPReplyError(code, message)

        return True",XFEATURE COMPRESS GZIP command.,
"def _offset(value):
    """"""Parse timezone to offset in seconds.

    Args:
        value: A timezone in the '+0000' format. An integer would also work.

    Returns:
        The timezone offset from GMT in seconds as an integer.
    """"""
    o = int(value)
    if o == 0:
        return 0
    a = abs(o)
    s = a*36+(a%100)*24
    return (o//a)*s","Parse timezone to offset in seconds.

    Args:
        value: A timezone in the '+0000' format. An integer would also work.

    Returns:
        The timezone offset from GMT in seconds as an integer.",
"def _fix_alert_config_dict(alert_config):
        """"""
        Fix the alert config .args() dict for the correct key name
        """"""
        data = alert_config.args()
        data['params_set'] = data.get('args')
        del data['args']
        return data",Fix the alert config .args() dict for the correct key name,
"def _get_login_payload(self, username, password):
        """"""
        returns the payload the login page expects
        :rtype: dict
        """"""
        payload = {
            'csrfmiddlewaretoken': self._get_csrf_token(),
            'ajax': '1',
            'next': '/app/',
            'username': username,
            'password': password
        }
        return payload","returns the payload the login page expects
        :rtype: dict",
"def unparse_headers(hdrs):
    """"""Parse a dictionary of headers to a string.

    Args:
        hdrs: A dictionary of headers.

    Returns:
        The headers as a string that can be used in an NNTP POST.
    """"""
    return """".join([unparse_header(n, v) for n, v in hdrs.items()]) + ""\r\n""","Parse a dictionary of headers to a string.

    Args:
        hdrs: A dictionary of headers.

    Returns:
        The headers as a string that can be used in an NNTP POST.",
"def defaults_docstring(cls, header=None, indent=None, footer=None):
        """"""Add the default values to the class docstring""""""
        return defaults_docstring(cls.defaults, header=header,
                                  indent=indent, footer=footer)",Add the default values to the class docstring,
"def set_value(self, value):
        """"""Set the value

        This invokes hooks for type-checking and bounds-checking that
        may be implemented by sub-classes.
        """"""
        self.check_bounds(value)
        self.check_type(value)
        self.__value__ = value","Set the value

        This invokes hooks for type-checking and bounds-checking that
        may be implemented by sub-classes.",
"def check_type(self, value):
        """"""Hook for type-checking, invoked during assignment. Allows size 1
        numpy arrays and lists, but raises TypeError if value can not
        be cast to a scalar.

        """"""
        try:
            scalar = asscalar(value)
        except ValueError as e:
            raise TypeError(e)

        super(Parameter, self).check_type(scalar)","Hook for type-checking, invoked during assignment. Allows size 1
        numpy arrays and lists, but raises TypeError if value can not
        be cast to a scalar.",
"def set_free(self, free):
        """"""Set free/fixed status """"""
        if free is None:
            self.__free__ = False
            return
        self.__free__ = bool(free)",Set free/fixed status,
"def set_errors(self, errors):
        """"""Set parameter error estimate """"""
        if errors is None:
            self.__errors__ = None
            return
        self.__errors__ = [asscalar(e) for e in errors]",Set parameter error estimate,
"def load_and_parse(self):
        """"""
        Load the metrics file from the given path
        """"""
        f = open(self.file_path, ""r"")
        metrics_json = f.read()
        self.metrics = json.loads(metrics_json)",Load the metrics file from the given path,
"def extract_dictionary(self, metrics):
        """"""
        Extract required fields from an array
        """"""
        new_metrics = {}
        for m in metrics:
            metric = self.extract_fields(m)
            new_metrics[m['name']] = metric
        return new_metrics",Extract required fields from an array,
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        ApiCli.get_arguments(self)
        if self.args.hostGroupId is not None:
            self.hostGroupId = self.args.hostGroupId

        self.path = ""v1/hostgroup/{0}"".format(str(self.hostGroupId))",Extracts the specific arguments of this CLI,
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        HostgroupModify.get_arguments(self)

        if self.args.host_group_id is not None:
            self.host_group_id = self.args.host_group_id

        self.path = ""v1/hostgroup/"" + str(self.host_group_id)",Extracts the specific arguments of this CLI,
"def option_group(self, text):
    """"""option_group = ""["" , expression , ""]"" ;""""""
    self._attempting(text)
    return concatenation([
      ""["",
      self.expression,
      ""]""
    ], ignore_whitespace=True)(text).retyped(TokenType.option_group)","option_group = ""["" , expression , ""]"" ;",
"def operator(self, text):
    """"""operator = ""|"" | ""."" | "","" | ""-"";""""""
    self._attempting(text)
    return alternation([
      ""|"",
      ""."",
      "","",
      ""-""
    ])(text).retyped(TokenType.operator)","operator = ""|"" | ""."" | "","" | ""-"";",
"def op_mult(self, text):
    """"""op_mult = ""*"" ;""""""
    self._attempting(text)
    return terminal(""*"")(text).retyped(TokenType.op_mult)","op_mult = ""*"" ;",
"def op_add(self, text):
    """"""op_add = ""+"" ;""""""
    self._attempting(text)
    return terminal(""+"")(text).retyped(TokenType.op_add)","op_add = ""+"" ;",
"def clear_derived(self):
        """""" Reset the value of all Derived properties to None

        This is called by setp (and by extension __setattr__)
        """"""
        for p in self.params.values():
            if isinstance(p, Derived):
                p.clear_value()","Reset the value of all Derived properties to None

        This is called by setp (and by extension __setattr__)",
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        ApiCli.get_arguments(self)
        if self.args.pluginName is not None:
            self.pluginName = self.args.pluginName

        self.path = ""v1/plugins/{0}/components"".format(self.pluginName)",Extracts the specific arguments of this CLI,
"def method(self, value):
        """"""
        Before assigning the value validate that is in one of the
        HTTP methods we implement
        """"""
        keys = self._methods.keys()
        if value not in keys:
            raise AttributeError(""Method value not in "" + str(keys))
        else:
            self._method = value","Before assigning the value validate that is in one of the
        HTTP methods we implement",
"def _get_url_parameters(self):
        """"""
        Encode URL parameters
        """"""
        url_parameters = ''
        if self._url_parameters is not None:
            url_parameters = '?' + urllib.urlencode(self._url_parameters)
        return url_parameters",Encode URL parameters,
"def _do_get(self):
        """"""
        HTTP Get Request
        """"""
        return requests.get(self._url, data=self._data, headers=self._headers, auth=(self._email, self._api_token))",HTTP Get Request,
"def _do_delete(self):
        """"""
        HTTP Delete Request
        """"""
        return requests.delete(self._url, data=self._data, headers=self._headers, auth=(self._email, self._api_token))",HTTP Delete Request,
"def _do_post(self):
        """"""
        HTTP Post Request
        """"""
        return requests.post(self._url, data=self._data, headers=self._headers, auth=(self._email, self._api_token))",HTTP Post Request,
"def _do_put(self):
        """"""
        HTTP Put Request
        """"""
        return requests.put(self._url, data=self._data, headers=self._headers, auth=(self._email, self._api_token))",HTTP Put Request,
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        # ApiCli.get_arguments(self)
        if self.args.file_name is not None:
            self.file_name = self.args.file_name",Extracts the specific arguments of this CLI,
"def execute(self):
        """"""
        Run the steps to execute the CLI
        """"""
        # self._get_environment()
        self.add_arguments()
        self._parse_args()
        self.get_arguments()
        if self._validate_arguments():
            self._plot_data()
        else:
            print(self._message)",Run the steps to execute the CLI,
"def validate_sceneInfo(self):
        """"""Check scene name and whether remote file exists. Raises
        WrongSceneNameError if the scene name is wrong.
        """"""
        if self.sceneInfo.prefix not in self.__satellitesMap:
            raise WrongSceneNameError('USGS Downloader: Prefix of %s (%s) is invalid'
                                      % (self.sceneInfo.name, self.sceneInfo.prefix))","Check scene name and whether remote file exists. Raises
        WrongSceneNameError if the scene name is wrong.",
"def validate_bands(bands):
        """"""Validate bands parameter.""""""
        if not isinstance(bands, list):
            raise TypeError('Parameter bands must be a ""list""')
        valid_bands = list(range(1, 12)) + ['BQA']
        for band in bands:
            if band not in valid_bands:
                raise InvalidBandError('%s is not a valid band' % band)",Validate bands parameter.,
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        ApiCli.get_arguments(self)
        if self.args.metric_name is not None:
            self._metric_name = self.args.metric_name

        self.path = ""v1/metrics/{0}"".format(self._metric_name)",Extracts the specific arguments of this CLI,
"def normalize(self, dt, is_dst=False):
        '''Correct the timezone information on the given datetime'''
        if dt.tzinfo is None:
            raise ValueError('Naive time - no tzinfo set')
        return dt.replace(tzinfo=self)",Correct the timezone information on the given datetime,
"def esc_join(iterable, delimiter="" "", escape=""\\""):
  """"""Join an iterable by a delimiter, replacing instances of delimiter in items
  with escape + delimiter.
  """"""
  rep = escape + delimiter
  return delimiter.join(i.replace(delimiter, rep) for i in iterable)","Join an iterable by a delimiter, replacing instances of delimiter in items
  with escape + delimiter.",
"def get_newline_positions(text):
  """"""Returns a list of the positions in the text where all new lines occur. This is used by
  get_line_and_char to efficiently find coordinates represented by offset positions.
  """"""
  pos = []
  for i, c in enumerate(text):
    if c == ""\n"":
      pos.append(i)
  return pos","Returns a list of the positions in the text where all new lines occur. This is used by
  get_line_and_char to efficiently find coordinates represented by offset positions.",
"def _dump_text(self):
        """"""
        Send output in textual format
        """"""
        results = self._relay_output['result'];

        for l in results:
            dt = time.strftime(""%Y-%m-%dT%H:%M:%SZ"", time.gmtime(int(l[1]['ts'])))
            print(""{0} {1} {2} {3}"".format(l[0], dt, l[1]['type'], l[1]['msg']))",Send output in textual format,
"def _handle_results(self):
        """"""
        Call back function to be implemented by the CLI.
        """"""
        # Only process if we get HTTP result of 200
        if self._api_result.status_code == requests.codes.ok:
            self._relay_output = json.loads(self._api_result.text)
            if self._raw:
                self._dump_json()
            else:
                self._dump_text()",Call back function to be implemented by the CLI.,
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""

        AlarmModify.get_arguments(self)
        self._alarm_id = self.args.alarm_id if self.args.alarm_id is not None else None
        self.get_api_parameters()",Extracts the specific arguments of this CLI,
"def _handle_results(self):
        """"""
        Call back function to be implemented by the CLI.
        """"""

        # Only process if we get HTTP result of 200
        if self._api_result.status_code == requests.codes.ok:
            self._relays = json.loads(self._api_result.text)
            self._filter()
            self._dump_json()",Call back function to be implemented by the CLI.,
"def main(context, **kwargs):
    """"""
    virtue discovers and runs tests found in the given objects.

    Provide it with one or more tests (packages, modules or objects) to run.

    """"""

    result = run(**kwargs)
    context.exit(not result.wasSuccessful())","virtue discovers and runs tests found in the given objects.

    Provide it with one or more tests (packages, modules or objects) to run.",
"def rule(self, text):
    """"""rule = identifier , ""="" , expression , "";"" ;""""""
    self._attempting(text)
    return concatenation([
      self.identifier,
      ""="",
      self.expression,
      "";"",
    ], ignore_whitespace=True)(text).retyped(TokenType.rule)","rule = identifier , ""="" , expression , "";"" ;",
"def special_handling(self, text):
    """"""special_handling = ""?"" , identifier , ""?"" ;""""""
    self._attempting(text)
    return concatenation([
      ""?"",
      self.identifier,
      ""?"",
    ], ignore_whitespace=True)(text).retyped(TokenType.special_handling)","special_handling = ""?"" , identifier , ""?"" ;",
"def number(self, text):
    """"""number = digit - ""0"" . {digit} ;""""""
    self._attempting(text)
    return concatenation([
      exclusion(
        self.digit,
        ""0""
      ),
      zero_or_more(
        self.digit,
        ignore_whitespace=False
      ),
    ], ignore_whitespace=False)(text).compressed(TokenType.number)","number = digit - ""0"" . {digit} ;",
"def grammar(self):
    """"""The parse tree generated by the source.""""""
    if self._grammar is None:
      self.parser = Parser()
      grammar = self.parser.parse(self.input_source)
      self._grammar = grammar.trimmed().flattened().flattened(self._flatten)
    return self._grammar",The parse tree generated by the source.,
"def rules(self):
    """"""The AST rules.""""""
    if self._rules is None:
      self._rules = []
      for child in self.grammar.children:
        if child.is_type(TokenType.rule):
          name, expression = child.children
          self._rules.append(Rule(name.value, self._expression_to_asn(expression), name.position, child.consumed))
    return self._rules",The AST rules.,
"def comments(self):
    """"""The AST comments.""""""
    if self._comments is None:
      self._comments = [c for c in self.grammar.children if c.is_type(TokenType.comment)]
    return self._comments",The AST comments.,
"def directives(self):
    """"""The diretives parsed from the comments.""""""
    if self._directives is None:
      self._directives = []
      for comment in self.comments:
        self._directives.extend(self.directives_from_comment(comment))
    return self._directives",The diretives parsed from the comments.,
"def output_source(self):
    """"""The python source of the parser generated from the input source.""""""
    if self._output_source is None:
      self._output_source = self._compile()
    return self._output_source",The python source of the parser generated from the input source.,
"def _get_imports(self):
    """"""Reads the directives and generates source code for custom imports.""""""
    import_directives = [d for d in self.directives if d.name == ""import""]
    if import_directives:
      return ""\n"" + ""\n"".join(d.args[""value""] for d in import_directives)
    else:
      return """"",Reads the directives and generates source code for custom imports.,
"def _get_entry_point(self):
    """"""Gets the entry_point value for the parser.""""""
    ep = self._find_directive(""entry_point"")
    if ep:
      return ep.args[""value""]
    else:
      return self.rules[0].name",Gets the entry_point value for the parser.,
"def _get_rule_source(self, rule):
    """"""Gets the variable part of the source code for a rule.""""""
    p = len(self.input_source) + rule.position
    source = self.input_source[p:p + rule.consumed].rstrip()
    return self._indent(source, depth=self.indent + ""   "", skip_first_line=True)",Gets the variable part of the source code for a rule.,
"def _expression_to_asn(self, expression):
    """"""Convert an expression to an Abstract Syntax Tree Node.""""""
    new_children = [self._node_to_asn(c) for c in expression.children]
    return self._remove_grouping_groups(infix_to_optree(new_children))",Convert an expression to an Abstract Syntax Tree Node.,
"def _ast_terminal_to_code(self, terminal, **kwargs):
    """"""Convert an AST terminal to python source code.""""""
    value = _replace(terminal.value)
    if self.use_terminal_shorthand:
      return [value]
    else:
      return [""terminal({})"".format(value)]",Convert an AST terminal to python source code.,
"def _ast_option_group_to_code(self, option_group, **kwargs):
    """"""Convert an AST option group to python source code.""""""
    lines = [""option(""]
    lines.extend(self._indent(self._ast_to_code(option_group.expression)))
    lines.append("")"")
    return lines",Convert an AST option group to python source code.,
"def _ast_special_handling_to_code(self, special_handling, **kwargs):
    """"""Convert an AST sepcial handling to python source code.""""""
    ident = special_handling.value.svalue
    if ident in PB_SPECIAL_HANDLING:
      return [""PB.{0}"".format(ident)]
    else:
      return [""self.{0}"".format(ident)]",Convert an AST sepcial handling to python source code.,
"def _ast_op_exclude_to_code(self, opr, **kwargs):
    """"""Convert an AST exclude op to python source code.""""""
    opl, opr = opr.operands

    lines = [""exclusion(""]
    lines.extend(self._indent(self._ast_to_code(opl)))
    lines[-1] += "",""
    lines.extend(self._indent(self._ast_to_code(opr)))
    lines.append("")"")
    return lines",Convert an AST exclude op to python source code.,
"def _ast_op_repeat_to_code(self, opr, ignore_whitespace=False, **kwargs):
    """"""Convert an AST repeat op to python source code.""""""
    lines = [""one_or_more(""]
    lines.extend(self._indent(self._ast_to_code(opr.operands[0])))
    lines[-1] += "",""
    lines.append(self._indent(""ignore_whitespace={}"".format(bool(ignore_whitespace))))
    lines.append("")"")
    return lines",Convert an AST repeat op to python source code.,
"def _find_directives(self, pred):
    """"""Finds all directives with a certain name, or that passes a predicate.""""""
    if isinstance(pred, str):
      return [d for d in self.directives if d.name == pred]
    else:
      return [d for d in self.directives if pred(d)]","Finds all directives with a certain name, or that passes a predicate.",
"def _flatten(child, parent):
    """"""Custom flattening method for the parse tree.""""""
    return parent.is_type(TokenType.expression) and child.node_type == parent.node_type",Custom flattening method for the parse tree.,
"def directives_from_comment(cls, comment):
    """"""A directive is a line in a comment that begins with '!'.""""""
    comment_contents = comment.value[2:-2].strip()
    comment_lines = (l.strip() for l in comment_contents.split(""\n""))
    directives = (l[1:].strip() for l in comment_lines if l.startswith(""!""))

    for directive_def in directives:
      yield cls.parse_directive_def(directive_def)",A directive is a line in a comment that begins with '!'.,
"def parse_directive_def(cls, directive_def):
    """"""Turns a directive definition string into a directive object.""""""
    name, *kwargs = esc_split(directive_def, ignore_empty=True)
    return Directive(name, {key: value for key, value in (esc_split(arg, ""="") for arg in kwargs)})",Turns a directive definition string into a directive object.,
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        ApiCli.get_arguments(self)
        if self.args.hostGroupName is not None:
            self.url_parameters = {""name"": self.args.hostGroupName}",Extracts the specific arguments of this CLI,
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        ApiCli.get_arguments(self)
        if self.args.plugin_name is not None:
            self.plugin_name = self.args.plugin_name

        self.path = ""v1/plugins/{0}"".format(self.plugin_name)",Extracts the specific arguments of this CLI,
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        ApiCli.get_arguments(self)
        self._alarm_id = self.args.alarm_id if self.args.alarm_id is not None else None",Extracts the specific arguments of this CLI,
"def _handle_results(self):
        """"""
        Handle the results of the API call
        """"""

        # Only process if we get HTTP return code other 200.
        if self._api_result.status_code != requests.codes.ok:
            print(self.colorize_json(self._api_result.text))",Handle the results of the API call,
"def get_id(id):
 """"""Get a new id if the provided one is None.""""""
 if id == None:
  id = wx.NewId()
  logger.debug('Generated new ID %s.', id)
 else:
  logger.debug('Using provided id %s.', id)
 return id",Get a new id if the provided one is None.,
"def remove_accelerator(control, key):
 """"""
 Removes an accelerator from control.
 
 control: The control to affect.
 key: The key to remove.
 """"""
 key = str_to_key(key)
 t = _tables.get(control, [])
 for a in t:
  if a[:2] == key:
   t.remove(a)
   if t:
    _tables[control] = t
   else:
    del _tables[control]
   update_accelerators(control)
   return True
 return False","Removes an accelerator from control.
 
 control: The control to affect.
 key: The key to remove.",
"def remove_hotkey(control, key):
 """"""
 Remove a global hotkey.
 
 control - The control to affect
 key - The key to remove.
 """"""
 l = _hotkeys.get(control, [])
 for a in l:
  key_str, id = a
  if key_str == key:
   control.Unbind(wx.EVT_HOTKEY, id = id)
   control.UnregisterHotKey(id)
   l.remove(a)
   if l:
    _hotkeys[control] = l
   else:
    del _hotkeys[control]","Remove a global hotkey.
 
 control - The control to affect
 key - The key to remove.",
"def _configure_logging(self):
        """"""
        Configure logging based on command line options
        """"""
        if self.args.logLevel is not None:
            logging.basicConfig(level=self.levels[self.args.logLevel])
        logging.info(""Set logging level to {0}"".format(self.args.logLevel))",Configure logging based on command line options,
"def pprint(root, depth=0, space_unit=""    ""):
  """"""Pretty print an optree, starting at root.""""""
  spacing = space_unit * depth

  if isinstance(root, OptreeNode):
    print(""{0}Operator ({1})"".format(spacing, root.opnode.operator.symbol if root.opnode else ""None -> IDENTITY""))
    for operand in root.operands:
      pprint(operand, depth + 1)
  else:
    print(""{0} {1}"".format(spacing, root))","Pretty print an optree, starting at root.",
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        ApiCli.get_arguments(self)
        if self.args.pluginName is not None:
            self.pluginName = self.args.pluginName",Extracts the specific arguments of this CLI,
"def _process_properties(self, properties):
        """"""
        Transforms the command line properties into python dictionary
        :return:
        """"""
        if properties is not None:
            self._properties = {}
            for p in properties:
                d = p.split('=')
                self._properties[d[0]] = d[1]","Transforms the command line properties into python dictionary
        :return:",
"def get_arguments(self):
        """"""
        Extracts the specific arguments of this CLI
        """"""
        ApiCli.get_arguments(self)
        self._alarm_name = self.args.alarm_name if self.args.alarm_name is not None else None",Extracts the specific arguments of this CLI,
"def read(self):
        """"""
        Load the metrics file from the given path
        """"""
        f = open(self.path, ""r"")
        self.manifest_json = f.read()",Load the metrics file from the given path,
"def load(self):
        """"""
        Read the file and parse JSON into dictionary
        """"""
        manifest = PluginManifest(self.file_path)
        manifest.get()
        self.manifest = manifest.get_manifest()",Read the file and parse JSON into dictionary,
"def getMetricDefinition(self, name):
        """"""
        Looks up the metric definition from the definitions from the API call
        """"""
        metric = None
        for m in self.metric_definitions:
            if m['name'] == name:
                metric = m
                break
        return metric",Looks up the metric definition from the definitions from the API call,
"def printMetricsHeader(self, m, d):
        """"""
        Prints out table header based on the size of the data in columns
        """"""
        mstr = ""Metric Name""
        dstr = ""Description""

        print('|{0}{1}|{2}{3}|'.format(mstr, ' ' * (m - len(mstr)), dstr, ' ' * (d - len(dstr))))
        print('|:{0}|:{1}|'.format('-' * (m - 1), '-' * (d - 1)))",Prints out table header based on the size of the data in columns,
"def getFieldsColumnLengths(self):
        """"""
        Gets the maximum length of each column in the field table
        """"""
        nameLen = 0
        descLen = 0
        for f in self.fields:
            nameLen = max(nameLen, len(f['title']))
            descLen = max(descLen, len(f['description']))
        return (nameLen, descLen)",Gets the maximum length of each column in the field table,
"def getMetricsColumnLengths(self):
        """"""
        Gets the maximum length of each column
        """"""
        displayLen = 0
        descLen = 0
        for m in self.metrics:
            displayLen = max(displayLen, len(m['displayName']))
            descLen = max(descLen, len(m['description']))
        return (displayLen, descLen)",Gets the maximum length of each column,
"def escapeUnderscores(self):
        """"""
        Escape underscores so that the markdown is correct
        """"""
        new_metrics = []
        for m in self.metrics:
            m['name'] = m['name'].replace(""_"", ""\_"")
            new_metrics.append(m)
        self.metrics = new_metrics",Escape underscores so that the markdown is correct,
"def printMetrics(self, m, d):
        """"""
        Prints out table rows based on the size of the data in columns
        """"""
        for metric in self.metrics:
            mstr = metric['displayName']
            dstr = metric['description']
            mlen = m - len(mstr)
            dlen = d - len(dstr)
            print(""|{0}{1}|{2}{3}|"".format(mstr, ' ' * mlen, dstr, ' ' * dlen))",Prints out table rows based on the size of the data in columns,
"def printFields(self, f, d):
        """"""
        Prints out table rows based on the size of the data in columns
        """"""
        for field in self.fields:
            fstr = field[""title""]
            dstr = field[""description""]
            flen = f - len(fstr)
            dlen = d - len(dstr)
            print(""|{0}{1}|{2}{3}|"".format(fstr, ' ' * flen, dstr, ' ' * dlen))",Prints out table rows based on the size of the data in columns,
"def outputFieldMarkdown(self):
        """"""
        Sends the field definitions ot standard out
        """"""
        f, d = self.getFieldsColumnLengths()

        fc, dc = self.printFieldsHeader(f, d)
        f = max(fc, f)
        d = max(dc, d)
        self.printFields(f, d)",Sends the field definitions ot standard out,
"def outputMetricMarkdown(self):
        """"""
        Sends the markdown of the metric definitions to standard out
        """"""
        self.escapeUnderscores()
        m, d = self.getMetricsColumnLengths()

        self.printMetricsHeader(m, d)
        self.printMetrics(m, d)",Sends the markdown of the metric definitions to standard out,
"def generateMarkdown(self):
        """"""
        Look up each of the metrics and then output in Markdown
        """"""
        self.generateMetricDefinitions()
        self.generateFieldDefinitions()
        self.generateDashboardDefinitions()
        self.outputMarkdown()",Look up each of the metrics and then output in Markdown,
"def parse(self, text):
    """"""Attempt to parse source code.""""""
    self.original_text = text

    try:
      return getattr(self, self.entry_point)(text)
    except (DeadEnd) as exc:
      raise ParserError(self.most_consumed, ""Failed to parse input"") from exc
    return tree",Attempt to parse source code.,
"def _attempting(self, text):
    """"""Keeps track of the furthest point in the source code the parser has reached to this point.""""""
    consumed = len(self.original_text) - len(text)
    self.most_consumed = max(consumed, self.most_consumed)",Keeps track of the furthest point in the source code the parser has reached to this point.,
"def output_raw(self, text):
        """"""
        Output results in raw JSON format
        """"""
        payload = json.loads(text)
        out = json.dumps(payload, sort_keys=True, indent=self._indent, separators=(',', ': '))
        print(self.colorize_json(out))",Output results in raw JSON format,
"def trimmed_pred_default(node, parent):
  """"""The default predicate used in Node.trimmed.""""""
  return isinstance(node, ParseNode) and (node.is_empty or node.is_type(ParseNodeType.terminal))",The default predicate used in Node.trimmed.,
"def zero_or_more(extractor, *, ignore_whitespace=False):
  """"""Returns a partial of _get_repetition with bounds set to (0, None) that accepts only a text
  argument.
  """"""
  return partial(_get_repetition, extractor, bounds=(0, None), ignore_whitespace=ignore_whitespace)","Returns a partial of _get_repetition with bounds set to (0, None) that accepts only a text
  argument.",
"def one_or_more(extractor, *, ignore_whitespace=False):
  """"""Returns a partial of _get_repetition with bounds set to (1, None) that accepts only a text
  argument.
  """"""
  return partial(_get_repetition, extractor, bounds=(1, None), ignore_whitespace=ignore_whitespace)","Returns a partial of _get_repetition with bounds set to (1, None) that accepts only a text
  argument.",
"def repeated(extractor, times, *, ignore_whitespace=False):
  """"""Returns a partial of _get_repetition with bounds set to (times, times) that accepts only a text
  argument.
  """"""
  return partial(_get_repetition,
                 extractor,
                 bounds=(times, times),
                 ignore_whitespace=ignore_whitespace)","Returns a partial of _get_repetition with bounds set to (times, times) that accepts only a text
  argument.",
"def repetition(extractor, bounds, *, ignore_whitespace=False):
  """"""Returns a partial of _get_repetition that accepts only a text argument.""""""
  return partial(_get_repetition, extractor, bounds=bounds, ignore_whitespace=ignore_whitespace)",Returns a partial of _get_repetition that accepts only a text argument.,
"def _split_ignored(text, ignore_whitespace=True):
  """"""Return (leading whitespace, trailing text) if ignore_whitespace is true, or ("""", text) if
  False.
  """"""
  if ignore_whitespace:
    leading_ws_count = _count_leading_whitespace(text)
    ignored_ws = text[:leading_ws_count]
    use_text = text[leading_ws_count:]
    return (ignored_ws, use_text)
  else:
    return ("""", text)","Return (leading whitespace, trailing text) if ignore_whitespace is true, or ("""", text) if
  False.",
"def _count_leading_whitespace(text):
  """"""Returns the number of characters at the beginning of text that are whitespace.""""""
  idx = 0
  for idx, char in enumerate(text):
    if not char.isspace():
      return idx
  return idx + 1",Returns the number of characters at the beginning of text that are whitespace.,
"def is_empty(self):
    """"""Returns True if this node has no children, or if all of its children are ParseNode instances
    and are empty.
    """"""
    return all(isinstance(c, ParseNode) and c.is_empty for c in self.children)","Returns True if this node has no children, or if all of its children are ParseNode instances
    and are empty.",
"def add_ignored(self, ignored):
    """"""Add ignored text to the node. This will add the length of the ignored text to the node's
    consumed property.
    """"""
    if ignored:
      if self.ignored:
        self.ignored = ignored + self.ignored
      else:
        self.ignored = ignored

    self.consumed += len(ignored)","Add ignored text to the node. This will add the length of the ignored text to the node's
    consumed property.",
"def is_type(self, value):
    """"""Returns True if node_type == value.

    If value is a tuple, node_type is checked against each member and True is returned if any of
    them match.
    """"""
    if isinstance(value, tuple):
      for opt in value:
        if self.node_type == opt:
          return True
      return False
    else:
      return self.node_type == value","Returns True if node_type == value.

    If value is a tuple, node_type is checked against each member and True is returned if any of
    them match.",
"def retyped(self, new_type):
    """"""Returns a new node with the same contents as self, but with a new node_type.""""""
    return ParseNode(new_type,
                      children=list(self.children),
                      consumed=self.consumed,
                      position=self.position,
                      ignored=self.ignored)","Returns a new node with the same contents as self, but with a new node_type.",
"def get_scope_list(self) -> list:
        """"""
        Return the list of all contained scope from global to local
        """"""
        # by default only return scoped name
        lstparent = [self]
        p = self.get_parent()
        while p is not None:
            lstparent.append(p)
            p = p.get_parent()
        return lstparent",Return the list of all contained scope from global to local,
"def position(self) -> Position:
        """"""The current position of the cursor.""""""
        return Position(self._index, self._lineno, self._col_offset)",The current position of the cursor.,
"def max_readed_position(self) -> Position:
        """"""The index of the deepest character readed.""""""
        return Position(self._maxindex, self._maxline, self._maxcol)",The index of the deepest character readed.,
"def step_next_char(self):
        """"""Puts the cursor on the next character.""""""
        self._index += 1
        self._col_offset += 1
        if self._index > self._maxindex:
            self._maxindex = self._index
            self._maxcol = self._col_offset
            self._maxline = self._lineno",Puts the cursor on the next character.,
"def step_next_line(self):
        """"""Sets cursor as beginning of next line.""""""
        self._eol.append(self.position)
        self._lineno += 1
        self._col_offset = 0",Sets cursor as beginning of next line.,
"def step_prev_line(self):
        """"""Sets cursor as end of previous line.""""""
        #TODO(bps): raise explicit error for unregistered eol
        #assert self._eol[-1].index == self._index
        if len(self._eol) > 0:
            self.position = self._eol.pop()",Sets cursor as end of previous line.,
"def save_context(self) -> bool:
        """"""Save current position.""""""
        self._contexts.append(self._cursor.position)
        return True",Save current position.,
"def restore_context(self) -> bool:
        """"""Rollback to previous saved position.""""""
        self._cursor.position = self._contexts.pop()
        return False",Rollback to previous saved position.,
"def to_fmt(self):
    """"""
    Return an Fmt representation for pretty-printing
    """"""
    params = """"
    txt = fmt.sep("" "", ['val'])
    name = self.show_name()
    if name != """":
        txt.lsdata.append(name)
    txt.lsdata.append('(%s)' % self.value)
    txt.lsdata.append(': ' + self.tret)
    return txt",Return an Fmt representation for pretty-printing,
"def set_name(self, name: str):
        """""" You could set the name after construction """"""
        self.name = name
        # update internal names
        lsig = self._hsig.values()
        self._hsig = {}
        for s in lsig:
            self._hsig[s.internal_name()] = s",You could set the name after construction,
"def count_types(self) -> int:
        """""" Count subtypes """"""
        n = 0
        for s in self._hsig.values():
            if type(s).__name__ == 'Type':
                n += 1
        return n",Count subtypes,
"def count_vars(self) -> int:
        """""" Count var define by this scope """"""
        n = 0
        for s in self._hsig.values():
            if hasattr(s, 'is_var') and s.is_var:
                n += 1
        return n",Count var define by this scope,
"def count_funs(self) -> int:
        """""" Count function define by this scope """"""
        n = 0
        for s in self._hsig.values():
            if hasattr(s, 'is_fun') and s.is_fun:
                n += 1
        return n",Count function define by this scope,
"def __update_count(self):
        """""" Update internal counters """"""
        self._ntypes = self.count_types()
        self._nvars = self.count_vars()
        self._nfuns = self.count_funs()",Update internal counters,
"def union(self, sig: Scope) -> Scope:
        """""" Create a new Set produce by the union of 2 Set """"""
        new = Scope(sig=self._hsig.values(), state=self.state)
        new |= sig
        return new",Create a new Set produce by the union of 2 Set,
"def intersection_update(self, oset: Scope) -> Scope:
        """""" Update Set with common values of another Set """"""
        keys = list(self._hsig.keys())
        for k in keys:
            if k not in oset:
                del self._hsig[k]
            else:
                self._hsig[k] = oset.get(k)
        return self",Update Set with common values of another Set,
"def intersection(self, sig: Scope) -> Scope:
        """""" Create a new Set produce by the intersection of 2 Set """"""
        new = Scope(sig=self._hsig.values(), state=self.state)
        new &= sig
        return new",Create a new Set produce by the intersection of 2 Set,
"def difference_update(self, oset: Scope) -> Scope:
        """""" Remove values common with another Set """"""
        keys = list(self._hsig.keys())
        for k in keys:
            if k in oset:
                del self._hsig[k]
        return self",Remove values common with another Set,
"def difference(self, sig: Scope) -> Scope:
        """""" Create a new Set produce by a Set subtracted by another Set """"""
        new = Scope(sig=self._hsig.values(), state=self.state)
        new -= sig
        return new",Create a new Set produce by a Set subtracted by another Set,
"def symmetric_difference(self, sig: Scope) -> Scope:
        """""" Create a new Set with values present in only one Set """"""
        new = Scope(sig=self._hsig.values(), state=self.state)
        new ^= sig
        return new",Create a new Set with values present in only one Set,
"def remove(self, it: Signature) -> bool:
        """""" Remove it but raise KeyError if not found """"""
        txt = it.internal_name()
        if txt not in self._hsig:
            raise KeyError(it.show_name() + ' not in Set')
        sig = self._hsig[txt]
        if isinstance(sig, Scope):
            sig.state = StateScope.LINKED
        del self._hsig[txt]
        return True",Remove it but raise KeyError if not found,
"def discard(self, it: Signature) -> bool:
        """""" Remove it only if present """"""
        txt = it.internal_name()
        if txt in self._hsig:
            sig = self._hsig[txt]
            if isinstance(sig, Scope):
                sig.state = StateScope.LINKED
            del self._hsig[txt]
            return True
        return False",Remove it only if present,
"def values(self) -> [Signature]:
        """""" Retrieve all values """"""
        if self.state == StateScope.EMBEDDED and self.parent is not None:
            return list(self._hsig.values()) + list(self.parent().values())
        else:
            return self._hsig.values()",Retrieve all values,
"def first(self) -> Signature:
        """""" Retrieve the first Signature ordered by mangling descendant """"""
        k = sorted(self._hsig.keys())
        return self._hsig[k[0]]",Retrieve the first Signature ordered by mangling descendant,
"def last(self) -> Signature:
        """""" Retrieve the last Signature ordered by mangling descendant """"""
        k = sorted(self._hsig.keys())
        return self._hsig[k[-1]]",Retrieve the last Signature ordered by mangling descendant,
"def get(self, key: str, default=None) -> Signature:
        """""" Get a signature instance by its internal_name """"""
        item = default
        if key in self._hsig:
            item = self._hsig[key]
        return item",Get a signature instance by its internal_name,
"def getsig_by_symbol_name(self, name: str) -> Signature:
        """""" Retrieve the unique Signature of a symbol.
        Fail if the Signature is not unique
        """"""
        subscope = self.get_by_symbol_name(name)
        if len(subscope) != 1:
            raise KeyError(""%s have multiple candidates in scope"" % name)
        v = list(subscope.values())
        return v[0]","Retrieve the unique Signature of a symbol.
        Fail if the Signature is not unique",
"def set(self, othernode):
        """"""allow to completly mutate the node into any subclasses of Node""""""
        self.__class__ = othernode.__class__
        self.clean()
        if len(othernode) > 0:
            for k, v in othernode.items():
                self[k] = v
        for k, v in vars(othernode).items():
            setattr(self, k, v)",allow to completly mutate the node into any subclasses of Node,
"def values(self):
        """"""
        in order
        """"""
        tmp = self
        while tmp is not None:
            yield tmp.data
            tmp = tmp.next",in order,
"def rvalues(self):
        """""" 
        in reversed order
        """"""
        tmp = self
        while tmp is not None:
            yield tmp.data
            tmp = tmp.prev",in reversed order,
"def _pixel_masked(hit, array):
    ''' Checks whether a hit (column/row) is masked or not. Array is 2D array with boolean elements corresponding to pixles indicating whether a pixel is disabled or not.
    '''
    if array.shape[0] > hit[""column""] and array.shape[1] > hit[""row""]:
        return array[hit[""column""], hit[""row""]]
    else:
        return False",Checks whether a hit (column/row) is masked or not. Array is 2D array with boolean elements corresponding to pixles indicating whether a pixel is disabled or not.,
"def _hit_ok(hit, min_hit_charge, max_hit_charge):
    ''' Check if given hit is withing the limits.
    '''
    # Omit hits with charge < min_hit_charge
    if hit['charge'] < min_hit_charge:
        return False

    # Omit hits with charge > max_hit_charge
    if max_hit_charge != 0 and hit['charge'] > max_hit_charge:
        return False

    return True",Check if given hit is withing the limits.,
"def _set_1d_array(array, value, size=-1):
    ''' Set array elemets to value for given number of elements (if size is negative number set all elements to value).
    '''
    if size >= 0:
        for i in range(size):
            array[i] = value
    else:
        for i in range(array.shape[0]):
            array[i] = value",Set array elemets to value for given number of elements (if size is negative number set all elements to value).,
"def _is_in_max_difference(value_1, value_2, max_difference):
    ''' Helper function to determine the difference of two values that can be np.uints. Works in python and numba mode.
    Circumvents numba bug #1653
    '''
    if value_1 <= value_2:
        return value_2 - value_1 <= max_difference
    return value_1 - value_2 <= max_difference","Helper function to determine the difference of two values that can be np.uints. Works in python and numba mode.
    Circumvents numba bug #1653",
"def set_parent(self, parent) -> object:
        """"""
        When we add a parent (from Symbol), don't forget to resolve.
        """"""
        ret = self
        if parent is not None:
            ret = self._sig.set_parent(parent)
            self.resolve()
        elif not hasattr(self, 'parent'):
            # only if parent didn't exist yet
            self.parent = None
        return ret","When we add a parent (from Symbol), don't forget to resolve.",
"def set_resolved_name(self, ref: dict, type_name2solve: TypeName,
                          type_name_ref: TypeName):
        """"""
        Warning!!! Need to rethink it when global poly type
        """"""
        if self.resolution[type_name2solve.value] is None:
            self.resolution[type_name2solve.value] = ref[type_name_ref.value]",Warning!!! Need to rethink it when global poly type,
"def to_fmt(self) -> fmt.indentable:
        """"""
        Return an Fmt representation for pretty-printing
        """"""
        lsb = []
        if len(self._lsig) > 0:
            for s in self._lsig:
                lsb.append(s.to_fmt())
        block = fmt.block(""("", "")"", fmt.sep(', ', lsb))
        qual = ""tuple""
        txt = fmt.sep("""", [qual, block])
        return txt",Return an Fmt representation for pretty-printing,
"def internal_name(self):
        """"""
        Return the unique internal name
        """"""
        unq = super().internal_name()
        if self.tret is not None:
            unq += ""_"" + self.tret
        return unq",Return the unique internal name,
"def _delete_local(self, filename):
        """"""Deletes the specified file from the local filesystem.""""""

        if os.path.exists(filename):
            os.remove(filename)",Deletes the specified file from the local filesystem.,
"def _find_by_path_s3(self, path, bucket_name):
        """"""Finds files by licking an S3 bucket's contents by prefix.""""""

        conn = S3Connection(self.access_key_id, self.access_key_secret)
        bucket = conn.get_bucket(bucket_name)

        s3_path = self._get_s3_path(path)

        return bucket.list(prefix=s3_path)",Finds files by licking an S3 bucket's contents by prefix.,
"def set_one(chainmap, thing_name, callobject):
    """""" Add a mapping with key thing_name for callobject in chainmap with
        namespace handling.
    """"""
    namespaces = reversed(thing_name.split("".""))
    lstname = []
    for name in namespaces:
        lstname.insert(0, name)
        strname = '.'.join(lstname)
        chainmap[strname] = callobject","Add a mapping with key thing_name for callobject in chainmap with
        namespace handling.",
"def add_method(cls):
    """"""Attach a method to a class.""""""
    def wrapper(f):
        #if hasattr(cls, f.__name__):
        #    raise AttributeError(""{} already has a '{}' attribute"".format(
        #        cls.__name__, f.__name__))
        setattr(cls, f.__name__, f)
        return f
    return wrapper",Attach a method to a class.,
"def read_eol(self) -> bool:
    """"""Return True if the parser can consume an EOL byte sequence.""""""
    if self.read_eof():
        return False
    self._stream.save_context()
    self.read_char('\r')
    if self.read_char('\n'):
        return self._stream.validate_context()
    return self._stream.restore_context()",Return True if the parser can consume an EOL byte sequence.,
"def pop_rule_nodes(self) -> bool:
        """"""Pop context variable that store rule nodes""""""
        self.rule_nodes = self.rule_nodes.parents
        self.tag_cache = self.tag_cache.parents
        self.id_cache = self.id_cache.parents
        return True",Pop context variable that store rule nodes,
"def parsed_stream(self, content: str, name: str=None):
        """"""Push a new Stream into the parser.
        All subsequent called functions will parse this new stream,
        until the 'popStream' function is called.
        """"""
        self._streams.append(Stream(content, name))","Push a new Stream into the parser.
        All subsequent called functions will parse this new stream,
        until the 'popStream' function is called.",
"def begin_tag(self, name: str) -> Node:
        """"""Save the current index under the given name.""""""
        # Check if we could attach tag cache to current rule_nodes scope
        self.tag_cache[name] = Tag(self._stream, self._stream.index)
        return True",Save the current index under the given name.,
"def end_tag(self, name: str) -> Node:
        """"""Extract the string between saved and current index.""""""
        self.tag_cache[name].set_end(self._stream.index)
        return True",Extract the string between saved and current index.,
"def peek_text(self, text: str) -> bool:
        """"""Same as readText but doesn't consume the stream.""""""
        start = self._stream.index
        stop = start + len(text)
        if stop > self._stream.eos_index:
            return False
        return self._stream[self._stream.index:stop] == text",Same as readText but doesn't consume the stream.,
"def one_char(self) -> bool:
        """"""Read one byte in stream""""""
        if self.read_eof():
            return False
        self._stream.incpos()
        return True",Read one byte in stream,
"def read_until_eof(self) -> bool:
        """"""Consume all the stream. Same as EOF in BNF.""""""
        if self.read_eof():
            return True
        # TODO: read ALL
        self._stream.save_context()
        while not self.read_eof():
            self._stream.incpos()
        return self._stream.validate_context()",Consume all the stream. Same as EOF in BNF.,
"def read_range(self, begin: str, end: str) -> int:
        """"""
        Consume head byte if it is >= begin and <= end else return false
        Same as 'a'..'z' in BNF
        """"""
        if self.read_eof():
            return False
        c = self._stream.peek_char
        if begin <= c <= end:
            self._stream.incpos()
            return True
        return False","Consume head byte if it is >= begin and <= end else return false
        Same as 'a'..'z' in BNF",
"def internal_name(self):
        """"""
        Return the unique internal name
        """"""
        unq = 'f_' + super().internal_name()
        if self.tparams is not None:
            unq += ""_"" + ""_"".join(self.tparams)
        if self.tret is not None:
            unq += ""_"" + self.tret
        return unq",Return the unique internal name,
"def set_end_of_cluster_function(self, function):
        ''' Adding function to module.
        This is maybe the only way to make the clusterizer to work with multiprocessing.
        '''
        self.cluster_functions._end_of_cluster_function = self._jitted(function)
        self._end_of_cluster_function = function","Adding function to module.
        This is maybe the only way to make the clusterizer to work with multiprocessing.",
"def set_end_of_event_function(self, function):
        ''' Adding function to module.
        This is maybe the only way to make the clusterizer to work with multiprocessing.
        '''
        self.cluster_functions._end_of_event_function = self._jitted(function)
        self._end_of_event_function = function","Adding function to module.
        This is maybe the only way to make the clusterizer to work with multiprocessing.",
"def add_ruleclause_name(self, ns_name, rid) -> bool:
    """"""Create a tree.Rule""""""
    ns_name.parser_tree = parsing.Rule(self.value(rid))
    return True",Create a tree.Rule,
"def add_rules(self, bnf, r) -> bool:
    """"""Attach a parser tree to the dict of rules""""""
    bnf[r.rulename] = r.parser_tree
    return True",Attach a parser tree to the dict of rules,
"def add_rule(self, rule, rn, alts) -> bool:
    """"""Add the rule name""""""
    rule.rulename = self.value(rn)
    rule.parser_tree = alts.parser_tree
    return True",Add the rule name,
"def add_read_sqstring(self, sequence, s):
    """"""Add a read_char/read_text primitive from simple quote string""""""
    v = self.value(s).strip(""'"")
    if len(v) > 1:
        sequence.parser_tree = parsing.Text(v)
        return True
    sequence.parser_tree = parsing.Char(v)
    return True",Add a read_char/read_text primitive from simple quote string,
"def add_range(self, sequence, begin, end):
    """"""Add a read_range primitive""""""
    sequence.parser_tree = parsing.Range(self.value(begin).strip(""'""),
                                         self.value(end).strip(""'""))
    return True",Add a read_range primitive,
"def add_capture(self, sequence, cpt):
    """"""Create a tree.Capture""""""
    cpt_value = self.value(cpt)
    sequence.parser_tree = parsing.Capture(cpt_value, sequence.parser_tree)
    return True",Create a tree.Capture,
"def add_bind(self, sequence, cpt):
    """"""Create a tree.Bind""""""
    cpt_value = self.value(cpt)
    sequence.parser_tree = parsing.Bind(cpt_value, sequence.parser_tree)
    return True",Create a tree.Bind,
"def add_hook(self, sequence, h):
    """"""Create a tree.Hook""""""
    sequence.parser_tree = parsing.Hook(h.name, h.listparam)
    return True",Create a tree.Hook,
"def param_num(self, param, n):
    """"""Parse a int in parameter list""""""
    param.pair = (int(self.value(n)), int)
    return True",Parse a int in parameter list,
"def param_str(self, param, s):
    """"""Parse a str in parameter list""""""
    param.pair = (self.value(s).strip('""'), str)
    return True",Parse a str in parameter list,
"def param_char(self, param, c):
    """"""Parse a char in parameter list""""""
    param.pair = (self.value(c).strip(""'""), str)
    return True",Parse a char in parameter list,
"def param_id(self, param, i):
    """"""Parse a node name in parameter list""""""
    param.pair = (self.value(i), parsing.Node)
    return True",Parse a node name in parameter list,
"def hook_name(self, hook, n):
    """"""Parse a hook name""""""
    hook.name = self.value(n)
    hook.listparam = []
    return True",Parse a hook name,
"def hook_param(self, hook, p):
    """"""Parse a hook parameter""""""
    hook.listparam.append(p.pair)
    return True",Parse a hook parameter,
"def add_directive2(self, sequence, d, s):
    """"""Add a directive in the sequence""""""
    sequence.parser_tree = parsing.Directive2(
        d.name,
        d.listparam,
        s.parser_tree
    )
    return True",Add a directive in the sequence,
"def to_yml(self):
    """"""
    Allow to get the YML string representation of a Node.::

        from pyrser.passes import to_yml

        t = Node()
        ...
        print(str(t.to_yml()))
    """"""
    pp = fmt.tab([])
    to_yml_item(self, pp.lsdata, """")
    return str(pp)","Allow to get the YML string representation of a Node.::

        from pyrser.passes import to_yml

        t = Node()
        ...
        print(str(t.to_yml()))",
"def add_state(self, s: State):
        """"""
        all state in the register have a uid
        """"""
        ids = id(s)
        uid = len(self.states)
        if ids not in self.states:
            self.states[ids] = (uid, s)",all state in the register have a uid,
"def to_dot_file(self, fname: str):
        """"""
        write a '.dot' file.
        """"""
        with open(fname, 'w') as f:
            f.write(self.to_dot())",write a '.dot' file.,
"def to_png_file(self, fname: str):
        """"""
        write a '.png' file.
        """"""
        cmd = pipes.Template()
        cmd.append('dot -Tpng > %s' % fname, '-.')
        with cmd.open('pipefile', 'w') as f:
            f.write(self.to_dot())",write a '.png' file.,
"def checkValue(self, v) -> State:
        """"""the str() of Values are stored internally for convenience""""""
        if self.wild_value:
            return self.nextstate(self.values['*'])
        elif str(v) in self.values:
            return self.nextstate(self.values[str(v)])
        return self",the str() of Values are stored internally for convenience,
"def infer_block(self, body, diagnostic=None):
        """"""
        Infer type on block is to type each of is sub-element
        """"""
        # RootBlockStmt has his own .infer_node (created via infer_type)
        for e in body:
            e.infer_node = InferNode(parent=self.infer_node)
            e.infer_type(diagnostic=diagnostic)",Infer type on block is to type each of is sub-element,
"def infer_subexpr(self, expr, diagnostic=None):
        """"""
        Infer type on the subexpr
        """"""
        expr.infer_node = InferNode(parent=self.infer_node)
        expr.infer_type(diagnostic=diagnostic)",Infer type on the subexpr,
"def infer_literal(self, args, diagnostic=None):
        """"""
        Infer type from an LITERAL!
        Type of literal depend of language.
        We adopt a basic convention
        """"""
        literal, t = args
        #self.type_node.add(EvalCtx.from_sig(Val(literal, t)))
        self.infer_node.scope_node.add(EvalCtx.from_sig(Val(literal, t)))","Infer type from an LITERAL!
        Type of literal depend of language.
        We adopt a basic convention",
"def iter_item_handles(self):
        """"""Return iterator over item handles.""""""

        bucket = self.s3resource.Bucket(self.bucket)

        for obj in bucket.objects.filter(Prefix=self.data_key_prefix).all():
            relpath = obj.get()['Metadata']['handle']

            yield relpath",Return iterator over item handles.,
"def visit_Rule(self, node: parsing.Rule) -> ast.expr:
        """"""Generates python code calling a rule.

        self.evalRule('rulename')
        """"""
        return ast.Call(
            ast.Attribute(ast.Name('self', ast.Load()),
                          'evalRule', ast.Load()),
            [ast.Str(node.name)], [], None, None)","Generates python code calling a rule.

        self.evalRule('rulename')",
"def visit_Scope(self, node: parsing.Capture) -> [ast.stmt] or ast.expr:
        """"""Generates python code for a scope.

        if not self.begin():
            return False
        res = self.pt()
        if not self.end():
            return False
        return res
        """"""
        return ast.Name('scope_not_implemented', ast.Load())
        raise NotImplementedError()","Generates python code for a scope.

        if not self.begin():
            return False
        res = self.pt()
        if not self.end():
            return False
        return res",
"def list_set_indent(lst: list, indent: int=1):
    """"""recurs into list for indentation""""""
    for i in lst:
        if isinstance(i, indentable):
            i.set_indent(indent)
        if isinstance(i, list):
            list_set_indent(i, indent)",recurs into list for indentation,
"def list_to_str(lst: list, content: str, indent: int=1):
    """"""recurs into list for string computing """"""
    for i in lst:
        if isinstance(i, indentable):
            content = i.to_str(content, indent)
        elif isinstance(i, list):
            content = list_to_str(i, content, indent)
        elif isinstance(i, str):
            content = catend(content, i, indent)
    return content",recurs into list for string computing,
"def echo_nodes(self, *rest):
    """"""
    Print nodes.

    example::

        R = [
            In : node #echo(""coucou"", 12, node)
        ]

    """"""
    txt = """"
    for thing in rest:
        if isinstance(thing, Node):
            txt += self.value(thing)
        else:
            txt += str(thing)
    print(txt)
    return True","Print nodes.

    example::

        R = [
            In : node #echo(""coucou"", 12, node)
        ]",
"def from_string(bnf: str, entry=None, *optional_inherit) -> Grammar:
    """"""
    Create a Grammar from a string
    """"""
    inherit = [Grammar] + list(optional_inherit)
    scope = {'grammar': bnf, 'entry': entry}
    return build_grammar(tuple(inherit), scope)",Create a Grammar from a string,
"def set_node_as_int(self, dst, src):
    """"""
        Set a node to a value captured from another node

        example::

            R = [
                In : node #setcapture(_, node)
            ]
    """"""
    dst.value = self.value(src)
    return True","Set a node to a value captured from another node

        example::

            R = [
                In : node #setcapture(_, node)
            ]",
"def get_subnode(self, dst, ast, expr):
    """"""
        get the value of subnode

        example::

            R = [
                __scope__:big  getsomethingbig:>big
                #get(_, big, '.val') // copy big.val into _
            ]
    """"""
    dst.value = eval('ast' + expr)
    return True","get the value of subnode

        example::

            R = [
                __scope__:big  getsomethingbig:>big
                #get(_, big, '.val') // copy big.val into _
            ]",
"def default_serializer(o):
    """"""Default serializer for json.""""""
    defs = (
        ((datetime.date, datetime.time),
         lambda x: x.isoformat(), ),
        ((datetime.datetime, ),
         lambda x: dt2utc_timestamp(x), ),
    )
    for types, fun in defs:
        if isinstance(o, types):
            return fun(o)",Default serializer for json.,
"def get(query, from_date, limit=0, **kwargs):
    """"""Get deposits.""""""
    dep_generator = _get_depositions()
    total_depids = 1  # Count of depositions is hard to determine

    # If limit provided, serve only first n=limit items
    if limit > 0:
        dep_generator = islice(dep_generator, limit)
        total_depids = limit
    return total_depids, dep_generator",Get deposits.,
"def _get_recids_invenio12(from_date):
    """"""Get BibDocs for Invenio 1.""""""
    from invenio.dbquery import run_sql
    return (id[0] for id in run_sql(
        'select id_bibrec from '
        'bibrec_bibdoc as r join bibdoc as d on r.id_bibdoc=d.id '
        'where d.modification_date >=%s',
        (from_date, ), run_on_slave=True))",Get BibDocs for Invenio 1.,
"def _get_recids_invenio2(from_date):
    """"""Get BibDocs for Invenio 2.""""""
    from invenio.legacy.dbquery import run_sql
    return (id[0] for id in run_sql(
        'select id_bibrec from '
        'bibrec_bibdoc as r join bibdoc as d on r.id_bibdoc=d.id '
        'where d.modification_date >=%s',
        (from_date, ), run_on_slave=True))",Get BibDocs for Invenio 2.,
"def _import_bibdoc():
    """"""Import BibDocFile.""""""
    try:
        from invenio.bibdocfile import BibRecDocs, BibDoc
    except ImportError:
        from invenio.legacy.bibdocfile.api import BibRecDocs, BibDoc
    return BibRecDocs, BibDoc",Import BibDocFile.,
"def get_check():
    """"""Get bibdocs to check.""""""
    try:
        from invenio.dbquery import run_sql
    except ImportError:
        from invenio.legacy.dbquery import run_sql

    return (
        run_sql('select count(id) from bibdoc', run_on_slave=True)[0][0],
        [id[0] for id in run_sql('select id from bibdoc', run_on_slave=True)],
    )",Get bibdocs to check.,
"def check(id_):
    """"""Check bibdocs.""""""
    BibRecDocs, BibDoc = _import_bibdoc()

    try:
        BibDoc(id_).list_all_files()
    except Exception:
        click.secho(""BibDoc {0} failed check."".format(id_), fg='red')",Check bibdocs.,
"def get(*args, **kwargs):
    """"""Get UserEXT objects.""""""
    try:
        from invenio.modules.accounts.models import UserEXT
    except ImportError:
        from invenio_accounts.models import UserEXT
    q = UserEXT.query
    return q.count(), q.all()",Get UserEXT objects.,
"def dump(u, from_date, with_json=True, latest_only=False, **kwargs):
    """"""Dump the UserEXt objects as a list of dictionaries.

    :param u: UserEXT to be dumped.
    :type u: `invenio_accounts.models.UserEXT [Invenio2.x]`
    :returns: User serialized to dictionary.
    :rtype: dict
    """"""
    return dict(id=u.id, method=u.method, id_user=u.id_user)","Dump the UserEXt objects as a list of dictionaries.

    :param u: UserEXT to be dumped.
    :type u: `invenio_accounts.models.UserEXT [Invenio2.x]`
    :returns: User serialized to dictionary.
    :rtype: dict",
"def get(*args, **kwargs):
    """"""Get communities.""""""
    from invenio.modules.communities.models import FeaturedCommunity
    q = FeaturedCommunity.query
    return q.count(), q.all()",Get communities.,
"def _get_modified_recids_invenio12(from_date):
    """"""Get record ids for Invenio 1.""""""
    from invenio.search_engine import search_pattern
    from invenio.dbquery import run_sql
    return set((id[0] for id in run_sql(
        'select id from bibrec where modification_date >= %s',
        (from_date, ), run_on_slave=True))), search_pattern",Get record ids for Invenio 1.,
"def dump_record_json(marcxml):
    """"""Dump JSON of record.""""""
    try:
        from invenio.modules.records.api import Record
        d = Record.create(marcxml, 'marc')
        return d.dumps(clean=True)
    except ImportError:
        from invenio.bibfield import create_record
        d = create_record(marcxml, master_format='marc')
        return d.dumps()",Dump JSON of record.,
"def get(query, from_date, **kwargs):
    """"""Get recids matching query and with changes.""""""
    recids, search_pattern = get_modified_recids(from_date)
    recids = recids.union(get_modified_bibdoc_recids(from_date))

    if query:
        recids = recids.intersection(
            set(search_pattern(p=query.encode('utf-8'))))

    return len(recids), recids",Get recids matching query and with changes.,
"def load_common(model_cls, data):
    """"""Helper function for loading JSON data verbatim into model.""""""
    obj = model_cls(**data)
    db.session.add(obj)
    db.session.commit()",Helper function for loading JSON data verbatim into model.,
"def collect_things_entry_points():
    """"""Collect entry points.""""""
    things = dict()
    for entry_point in iter_entry_points(group='invenio_migrator.things'):
        things[entry_point.name] = entry_point.load()
    return things",Collect entry points.,
"def init_app_context():
    """"""Initialize app context for Invenio 2.x.""""""
    try:
        from invenio.base.factory import create_app
        app = create_app()
        app.test_request_context('/').push()
        app.preprocess_request()
    except ImportError:
        pass",Initialize app context for Invenio 2.x.,
"def memoize(func):
    """"""Cache for heavy function calls.""""""
    cache = {}

    @wraps(func)
    def wrap(*args, **kwargs):
        key = '{0}{1}'.format(args, kwargs)
        if key not in cache:
            cache[key] = func(*args, **kwargs)
        return cache[key]
    return wrap",Cache for heavy function calls.,
"def _get_run_sql():
    """"""Import ``run_sql``.""""""
    try:
        from invenio.dbquery import run_sql
    except ImportError:
        from invenio.legacy.dbquery import run_sql
    return run_sql",Import ``run_sql``.,
"def get(*args, **kwargs):
    """"""Get users.""""""
    from invenio.modules.oauthclient.models import RemoteToken
    q = RemoteToken.query
    return q.count(), q.all()",Get users.,
"def load_token(data):
    """"""Load the oauth2server token from data dump.""""""
    from invenio_oauth2server.models import Token
    data['expires'] = iso2dt_or_none(data['expires'])
    load_common(Token, data)",Load the oauth2server token from data dump.,
"def config_imp_or_default(app, config_var_imp, default):
    """"""Import config var import path or use default value.""""""
    imp = app.config.get(config_var_imp)
    return import_string(imp) if imp else default",Import config var import path or use default value.,
"def init_app(self, app):
        """"""Flask application initialization.""""""
        self.init_config(app.config)
        state = _InvenioMigratorState(app)
        app.extensions['invenio-migrator'] = state
        app.cli.add_command(dumps)
        return state",Flask application initialization.,
"def get(*args, **kwargs):
    """"""Get users.""""""
    from invenio.modules.oauth2server.models import Client
    q = Client.query
    return q.count(), q.all()",Get users.,
"def _get_users_invenio2(*args, **kwargs):
    """"""Get user accounts from Invenio 2.""""""
    from invenio.modules.accounts.models import User
    q = User.query
    return q.count(), q.all()",Get user accounts from Invenio 2.,
"def get(*args, **kwargs):
    """"""Get users.""""""
    try:
        return _get_users_invenio12(*args, **kwargs)
    except ImportError:
        return _get_users_invenio2(*args, **kwargs)",Get users.,
"def loadcommunities(sources, logos_dir):
    """"""Load communities.""""""
    from invenio_migrator.tasks.communities import load_community
    loadcommon(sources, load_community, task_args=(logos_dir, ))",Load communities.,
"def loadusers(sources):
    """"""Load users.""""""
    from .tasks.users import load_user
    # Cannot be executed asynchronously due to duplicate emails and usernames
    # which can create a racing condition.
    loadcommon(sources, load_user, asynchronous=False)",Load users.,
"def main(port=8888):
    """"""Run as sample test server.""""""
    import tornado.ioloop

    routes = [] + TornadoProfiler().get_routes()
    app = tornado.web.Application(routes)
    app.listen(port)
    tornado.ioloop.IOLoop.current().start()",Run as sample test server.,
"def post(self):
        """"""Start a new profiler.""""""
        if is_profiler_running():
            self.set_status(201)
            self.finish()
            return

        start_profiling()
        self.set_status(201)
        self.finish()",Start a new profiler.,
"def post(self):
        """"""Dump current profiler statistics into a file.""""""
        filename = self.get_argument('filename', 'dump.prof')
        CProfileWrapper.profiler.dump_stats(filename)
        self.finish()",Dump current profiler statistics into a file.,
"def get(self):
        """"""Return current profiler statistics.""""""
        CProfileWrapper.profiler.print_stats()
        s = StringIO.StringIO()
        sortby = 'cumulative'
        ps = pstats.Stats(CProfileWrapper.profiler, stream=s).sort_stats(sortby)
        ps.print_stats()
        self.set_status(200)
        self.write(s.getvalue())
        self.finish()",Return current profiler statistics.,
"def delete(self):
        """"""Clear profiler statistics.""""""
        CProfileWrapper.profiler.create_stats()
        self.enable()
        self.set_status(204)
        self.finish()",Clear profiler statistics.,
"def post(self):
        """"""Start a new profiler.""""""
        CProfileWrapper.profiler = cProfile.Profile()
        CProfileWrapper.profiler.enable()
        self.running = True
        self.set_status(201)
        self.finish()",Start a new profiler.,
"def delete(self):
        """"""Stop the profiler.""""""
        CProfileWrapper.profiler.disable()
        self.running = False
        self.set_status(204)
        self.finish()",Stop the profiler.,
"def get(self):
        """"""Check if the profiler is running.""""""
        self.write({""running"": self.running})
        self.set_status(200)
        self.finish()",Check if the profiler is running.,
"def disable_timestamp(method):
    """"""Disable timestamp update per method.""""""
    @wraps(method)
    def wrapper(*args, **kwargs):
        result = None
        with correct_date():
            result = method(*args, **kwargs)
        return result
    return wrapper",Disable timestamp update per method.,
"def _add_ones_dim(arr):
    ""Adds a dimensions with ones to array.""
    arr = arr[..., np.newaxis]
    return np.concatenate((arr, np.ones_like(arr)), axis=-1)",Adds a dimensions with ones to array.,
"def delete_record(cls, record):
        """"""Delete a record and it's persistent identifiers.""""""
        record.delete()
        PersistentIdentifier.query.filter_by(
            object_type='rec', object_uuid=record.id,
        ).update({PersistentIdentifier.status: PIDStatus.DELETED})
        cls.delete_buckets(record)
        db.session.commit()",Delete a record and it's persistent identifiers.,
"def delete_buckets(cls, record):
        """"""Delete the bucket.""""""
        files = record.get('_files', [])
        buckets = set()
        for f in files:
            buckets.add(f.get('bucket'))
        for b_id in buckets:
            b = Bucket.get(b_id)
            b.deleted = True",Delete the bucket.,
"def missing_pids(self):
        """"""Filter persistent identifiers.""""""
        missing = []
        for p in self.pids:
            try:
                PersistentIdentifier.get(p.pid_type, p.pid_value)
            except PIDDoesNotExistError:
                missing.append(p)
        return missing",Filter persistent identifiers.,
"def prepare_revisions(self):
        """"""Prepare data.""""""
        # Prepare revisions
        self.revisions = []

        it = [self.data['record'][0]] if self.latest_only \
            else self.data['record']

        for i in it:
            self.revisions.append(self._prepare_revision(i))",Prepare data.,
"def prepare_pids(self):
        """"""Prepare persistent identifiers.""""""
        self.pids = []
        for fetcher in self.pid_fetchers:
            val = fetcher(None, self.revisions[-1][1])
            if val:
                self.pids.append(val)",Prepare persistent identifiers.,
"def is_deleted(self, record=None):
        """"""Check if record is deleted.""""""
        record = record or self.revisions[-1][1]
        return any(
            col == 'deleted'
            for col in record.get('collections', [])
        )",Check if record is deleted.,
"def v_magnitude(v):
    """"""
    Simple vector helper function returning the length of a vector.
    
    ``v`` may be any vector, with any number of dimensions
    """"""
    return math.sqrt(sum(v[i]*v[i] for i in range(len(v))))","Simple vector helper function returning the length of a vector.
    
    ``v`` may be any vector, with any number of dimensions",
"def v_normalize(v):
    """"""
    Normalizes the given vector.
    
    The vector given may have any number of dimensions.
    """"""
    vmag = v_magnitude(v)
    return [ v[i]/vmag  for i in range(len(v)) ]","Normalizes the given vector.
    
    The vector given may have any number of dimensions.",
"def setLength(self,data,blength):
        """"""
        Sets the length of this bone on the given entity.
        
        ``data`` is the entity to modify in dictionary form.
        
        ``blength`` is the new length of the bone.
        """"""
        self.ensureBones(data)
        data[""_bones""][self.name][""length""]=blength","Sets the length of this bone on the given entity.
        
        ``data`` is the entity to modify in dictionary form.
        
        ``blength`` is the new length of the bone.",
"def setParent(self,parent):
        """"""
        Sets the parent of this bone for all entities.
        
        Note that this method must be called before many other methods to ensure internal state has been initialized.
        
        This method also registers this bone as a child of its parent.
        """"""
        self.parent = parent
        self.parent.child_bones[self.name]=self","Sets the parent of this bone for all entities.
        
        Note that this method must be called before many other methods to ensure internal state has been initialized.
        
        This method also registers this bone as a child of its parent.",
"def getVertices(self,data):
        """"""
        Returns the vertices of this region already transformed and ready-to-use.
        
        Internally uses :py:meth:`Bone.transformVertices()`\ .
        """"""
        return self.bone.transformVertices(data,self.vertices,self.dims)","Returns the vertices of this region already transformed and ready-to-use.
        
        Internally uses :py:meth:`Bone.transformVertices()`\ .",
"def set_state(self):
        """"""
        Sets the state required for this actor.
        
        Currently translates the matrix to the position of the actor.
        """"""
        x,y,z = self.obj.pos
        glTranslatef(x,y,z)","Sets the state required for this actor.
        
        Currently translates the matrix to the position of the actor.",
"def unset_state(self):
        """"""
        Resets the state required for this actor to the default state.
        
        Currently resets the matrix to its previous translation.
        """"""
        x,y,z = self.obj.pos
        glTranslatef(-x,-y,-z)","Resets the state required for this actor to the default state.
        
        Currently resets the matrix to its previous translation.",
"def set_state(self):
        """"""
        Sets the state required for this vertex region.
        
        Currently binds and enables the texture of the material of the region.
        """"""
        glEnable(self.region.material.target)
        glBindTexture(self.region.material.target, self.region.material.id)
        self.region.bone.setRotate(self.data)","Sets the state required for this vertex region.
        
        Currently binds and enables the texture of the material of the region.",
"def unset_state(self):
        """"""
        Resets the state required for this actor to the default state.
        
        Currently only disables the target of the texture of the material, it may still be bound.
        """"""
        glDisable(self.region.material.target)
        self.region.bone.unsetRotate(self.data)","Resets the state required for this actor to the default state.
        
        Currently only disables the target of the texture of the material, it may still be bound.",
"def setModel(self,model):
        """"""
        Sets the model this actor should use when drawing.
        
        This method also automatically initializes the new model and removes the old, if any.
        """"""
        if self.model is not None:
            self.model.cleanup(self)
        self.model = model
        model.create(self)","Sets the model this actor should use when drawing.
        
        This method also automatically initializes the new model and removes the old, if any.",
"def write_reports(self, relative_path, suite_name, reports,
                      package_name=None):
        """"""write the collection of reports to the given path""""""

        dest_path = self.reserve_file(relative_path)
        with open(dest_path, 'wb') as outf:
            outf.write(toxml(reports, suite_name, package_name=package_name))
        return dest_path",write the collection of reports to the given path,
"def addMenu(self,menu):
        """"""
        Adds a menu to the list of menus.
        """"""
        # If there is no menu selected currently, this menu will automatically be made active.
        # Add the line above to the docstring if fixed
        self.menus[menu.name]=menu
        self.peng.sendEvent(""peng3d:window.menu.add"",{""peng"":self.peng,""window"":self,""menu"":menu})",Adds a menu to the list of menus.,
"def redraw_label(self):
        """"""
        Re-calculates the position of the Label.
        """"""
        # Convenience variables
        sx,sy = self.size
        x,y = self.pos
        
        # Label position
        self._label.anchor_x = ""left""
        self._label.x = x+sx/2.+sx
        self._label.y = y+sy/2.+sy*.15
        self._label._update()",Re-calculates the position of the Label.,
"def registerEventHandlers(self):
        """"""
        Registers the motion and drag handlers.
        
        Note that because of the way pyglet treats mouse dragging, there is also an handler registered to the on_mouse_drag event.
        """"""
        self.world.registerEventHandler(""on_mouse_motion"",self.on_mouse_motion)
        self.world.registerEventHandler(""on_mouse_drag"",self.on_mouse_drag)","Registers the motion and drag handlers.
        
        Note that because of the way pyglet treats mouse dragging, there is also an handler registered to the on_mouse_drag event.",
"def getView(self,name):
        """"""
        Returns the view with name ``name``\ .
        
        Raises a :py:exc:`ValueError` if the view does not exist.
        """"""
        if name not in self.views:
            raise ValueError(""Unknown world view"")
        return self.views[name]","Returns the view with name ``name``\ .
        
        Raises a :py:exc:`ValueError` if the view does not exist.",
"def render3d(self,view=None):
        """"""
        Renders the world in 3d-mode.
        
        If you want to render custom terrain, you may override this method. Be careful that you still call the original method or else actors may not be rendered.
        """"""
        for actor in self.actors.values():
            actor.render(view)","Renders the world in 3d-mode.
        
        If you want to render custom terrain, you may override this method. Be careful that you still call the original method or else actors may not be rendered.",
"def render3d(self,view=None):
        """"""
        Renders the world.
        """"""
        super(StaticWorld,self).render3d(view)
        self.batch3d.draw()",Renders the world.,
"def on_menu_enter(self,old):
        """"""
        Fake event handler, same as :py:meth:`WorldView.on_menu_enter()` but forces mouse exclusivity.
        """"""
        super(WorldViewMouseRotatable,self).on_menu_enter(old)
        self.world.peng.window.toggle_exclusivity(True)","Fake event handler, same as :py:meth:`WorldView.on_menu_enter()` but forces mouse exclusivity.",
"def on_menu_exit(self,new):
        """"""
        Fake event handler, same as :py:meth:`WorldView.on_menu_exit()` but force-disables mouse exclusivity.
        """"""
        super(WorldViewMouseRotatable,self).on_menu_exit(new)
        self.world.peng.window.toggle_exclusivity(False)","Fake event handler, same as :py:meth:`WorldView.on_menu_exit()` but force-disables mouse exclusivity.",
"def on_key_press(self,symbol,modifiers):
        """"""
        Keyboard event handler handling only the escape key.
        
        If an escape key press is detected, mouse exclusivity is toggled via :py:meth:`PengWindow.toggle_exclusivity()`\ .
        """"""
        if symbol == key.ESCAPE:
            self.world.peng.window.toggle_exclusivity()
            return pyglet.event.EVENT_HANDLED","Keyboard event handler handling only the escape key.
        
        If an escape key press is detected, mouse exclusivity is toggled via :py:meth:`PengWindow.toggle_exclusivity()`\ .",
"def resourceExists(self,name,ext=""""):
        """"""
        Returns whether or not the resource with the given name and extension exists.
        
        This must not mean that the resource is meaningful, it simply signals that the file exists.
        """"""
        return os.path.exists(self.resourceNameToPath(name,ext))","Returns whether or not the resource with the given name and extension exists.
        
        This must not mean that the resource is meaningful, it simply signals that the file exists.",
"def getModel(self,name):
        """"""
        Gets the model object by the given name.
        
        If it was loaded previously, a cached version will be returned.
        If it was not loaded, it will be loaded and inserted into the cache.
        """"""
        if name in self.modelobjcache:
            return self.modelobjcache[name]
        return self.loadModel(name)","Gets the model object by the given name.
        
        If it was loaded previously, a cached version will be returned.
        If it was not loaded, it will be loaded and inserted into the cache.",
"def loadModel(self,name):
        """"""
        Loads the model of the given name.
        
        The model will also be inserted into the cache.
        """"""
        m = model.Model(self.peng,self,name)
        self.modelobjcache[name]=m
        self.peng.sendEvent(""peng3d:rsrc.model.load"",{""peng"":self.peng,""name"":name})
        return m","Loads the model of the given name.
        
        The model will also be inserted into the cache.",
"def getModelData(self,name):
        """"""
        Gets the model data associated with the given name.
        
        If it was loaded, a cached copy will be returned.
        It it was not loaded, it will be loaded and cached.
        """"""
        if name in self.modelcache:
            return self.modelcache[name]
        return self.loadModelData(name)","Gets the model data associated with the given name.
        
        If it was loaded, a cached copy will be returned.
        It it was not loaded, it will be loaded and cached.",
"def addWidget(self,widget):
        """"""
        Adds a widget to this container.
        
        Note that trying to add the Container to itself will be ignored.
        """"""
        if self is widget: # Prevents being able to add the container to itself, causing a recursion loop on redraw
            return
        self.widgets[widget.name]=widget","Adds a widget to this container.
        
        Note that trying to add the Container to itself will be ignored.",
"def mouse_aabb(mpos,size,pos):
    """"""
    AABB Collision checker that can be used for most axis-aligned collisions.
    
    Intended for use in widgets to check if the mouse is within the bounds of a particular widget.
    """"""
    return pos[0]<=mpos[0]<=pos[0]+size[0] and pos[1]<=mpos[1]<=pos[1]+size[1]","AABB Collision checker that can be used for most axis-aligned collisions.
    
    Intended for use in widgets to check if the mouse is within the bounds of a particular widget.",
"def deleteCategory(self,name):
        """"""
        Deletes the category with the given name.
        
        If the category does not exist, a :py:exc:`KeyError` will be thrown.
        """"""
        if name not in self.categories:
            raise KeyError(""No Category with name '%s'""%name)
        del self.categories[name]
        self.redraw()","Deletes the category with the given name.
        
        If the category does not exist, a :py:exc:`KeyError` will be thrown.",
"def p(self):
        """"""
        Helper property containing the percentage this slider is ""filled"".
        
        This property is read-only.
        """"""
        return (self.n-self.nmin)/max((self.nmax-self.nmin),1)","Helper property containing the percentage this slider is ""filled"".
        
        This property is read-only.",
"def doAction(self,action):
        """"""
        Helper method that calls all callbacks registered for the given action.
        """"""
        if not hasattr(self,""actions""):
            return
        for f,args,kwargs in self.actions.get(action,[]):
            f(*args,**kwargs)",Helper method that calls all callbacks registered for the given action.,
"def setView(self,name):
        """"""
        Sets the view used to the specified ``name``\ .
        
        The name must be known to the world or else a :py:exc:`ValueError` is raised.
        """"""
        if name not in self.world.views:
            raise ValueError(""Invalid viewname for world!"")
        self.viewname = viewname
        self.view = self.world.getView(self.viewname)","Sets the view used to the specified ``name``\ .
        
        The name must be known to the world or else a :py:exc:`ValueError` is raised.",
"def predraw(self):
        """"""
        Sets up the attributes used by :py:class:`Layer3D()` and calls :py:meth:`Layer3D.predraw()`\ .
        """"""
        self.cam = self.view.cam
        super(LayerWorld,self).predraw()",Sets up the attributes used by :py:class:`Layer3D()` and calls :py:meth:`Layer3D.predraw()`\ .,
"def redraw_layer(self,name):
        """"""
        Redraws the given layer.
        
        :raises ValueError: If there is no Layer with the given name.
        """"""
        if name not in self._layers:
            raise ValueError(""Layer %s not part of widget, cannot redraw"")
        self._layers[name].on_redraw()","Redraws the given layer.
        
        :raises ValueError: If there is no Layer with the given name.",
"def draw(self):
        """"""
        Draws all layers of this LayeredWidget.
        
        This should normally be unneccessary, since it is recommended that layers use Vertex Lists instead of OpenGL Immediate Mode.
        """"""
        super(LayeredWidget,self).draw()
        for layer,_ in self.layers:
            layer._draw()","Draws all layers of this LayeredWidget.
        
        This should normally be unneccessary, since it is recommended that layers use Vertex Lists instead of OpenGL Immediate Mode.",
"def delete(self):
        """"""
        Deletes all layers within this LayeredWidget before deleting itself.
        
        Recommended to call if you are removing the widget, but not yet exiting the interpreter.
        """"""
        for layer,_ in self.layers:
            layer.delete()
        self.layers = []
        self._layers = {}
        super(LayeredWidget,self).delete()","Deletes all layers within this LayeredWidget before deleting itself.
        
        Recommended to call if you are removing the widget, but not yet exiting the interpreter.",
"def on_redraw(self):
        """"""
        Called when the Layer should be redrawn.
        
        If a subclass uses the :py:meth:`initialize()` Method, it is very important to also call the Super Class Method to prevent crashes.
        """"""
        super(WidgetLayer,self).on_redraw()
        if not self._initialized:
            self.initialize()
            self._initialized = True","Called when the Layer should be redrawn.
        
        If a subclass uses the :py:meth:`initialize()` Method, it is very important to also call the Super Class Method to prevent crashes.",
"def getSize(self):
        """"""
        Returns the size of the layer, with the border size already subtracted.
        """"""
        return self.widget.size[0]-self.border[0]*2,self.widget.size[1]-self.border[1]*2","Returns the size of the layer, with the border size already subtracted.",
"def addImage(self,name,rsrc):
        """"""
        Adds an image to the internal registry.
        
        ``rsrc`` should be a 2-tuple of ``(resource_name,category)``\ .
        """"""
        self.imgs[name]=self.widget.peng.resourceMgr.getTex(*rsrc)","Adds an image to the internal registry.
        
        ``rsrc`` should be a 2-tuple of ``(resource_name,category)``\ .",
"def switchImage(self,name):
        """"""
        Switches the active image to the given name.
        
        :raises ValueError: If there is no such image
        """"""
        if name not in self.imgs:
            raise ValueError(""No image of name '%s'""%name)
        elif self.cur_img==name:
            return
        
        self.cur_img = name
        self.on_redraw()","Switches the active image to the given name.
        
        :raises ValueError: If there is no such image",
"def set_fields(self, fields = None, **kwargs):
    """"""
    Sets the fields.
    """"""
    self.fields = []
    if fields != None:
      for field in fields: 
        self.fields.append(field)",Sets the fields.,
"def add_fields(self, fields = None, **kwargs):
    """"""
    Add the fields into the list of fields.
    """"""
    if fields != None:
      for field in fields: 
        self.fields.append(field)",Add the fields into the list of fields.,
"def space(self):
    """"""
    Returns the dimension of the embedded space of each element.
    """"""
    return self.elements.type.argiope.map(
           lambda t: ELEMENTS[t].space)",Returns the dimension of the embedded space of each element.,
"def nvert(self):
    """"""
    Returns the number of vertices of eache element according to its type/
    """"""
    return self.elements.type.argiope.map(
           lambda t: ELEMENTS[t].nvert)",Returns the number of vertices of eache element according to its type/,
"def stats(self):
    """"""
    Returns mesh quality and geometric stats.
    """"""
    cv = self.centroids_and_volumes()
    angles  = self.angles()
    edges = self.edges()
    return pd.concat([cv , angles[[""stats""]], edges[[""stats""]] ], 
                     axis = 1).sort_index(axis = 1)",Returns mesh quality and geometric stats.,
"def element_set_to_node_set(self, tag):
    """"""
    Makes a node set from an element set.
    """"""
    nodes, elements = self.nodes, self.elements
    loc = (elements.conn[elements[(""sets"", tag, """")]]
           .stack().stack().unique())
    loc = loc[loc != 0]
    nodes[(""sets"", tag)] = False
    nodes.loc[loc, (""sets"", tag) ] = True",Makes a node set from an element set.,
"def surface_to_element_sets(self, tag):
    """"""
    Creates elements sets corresponding to a surface.
    """"""
    surface = self.elements.surfaces[tag]
    for findex in surface.keys():
      if surface[findex].sum() != 0:
        self.elements[(""sets"", ""_SURF_{0}_FACE{1}""
                     .format(tag, findex[1:]), """")] = surface[findex]",Creates elements sets corresponding to a surface.,
"def fields_metadata(self):
    """"""
    Returns fields metadata as a dataframe.
    """"""  
    return (pd.concat([f.metadata() for f in self.fields], axis = 1)
            .transpose()
            .sort_values([""step_num"", ""frame"", ""label"", ""position""]))",Returns fields metadata as a dataframe.,
"def metadata(self):
    """"""
    Returns metadata as a dataframe.
    """"""
    return pd.Series({
           ""part"": self.part,
           ""step_num"": self.step_num,
           ""step_label"": self.step_label,
           ""frame"": self.frame,
           ""frame_value"": self.frame_value,
           ""label"": self.label,
           ""position"": self.position,                    
    })",Returns metadata as a dataframe.,
"def make_directories(self):
    """"""
    Checks if required directories exist and creates them if needed.
    """"""
    if os.path.isdir(self.workdir) == False: os.mkdir(self.workdir)",Checks if required directories exist and creates them if needed.,
"def list_to_string(l = range(200), width = 40, indent = ""  ""):
    """"""
    Converts a list-like to string with given line width.
    """"""
    l = [str(v) + "","" for v in l]
    counter = 0
    out = """" + indent
    for w in l:
        s = len(w)
        if counter + s > width: 
            out += ""\n"" + indent
            counter = 0
        out += w
        counter += s
    return out.strip("","")",Converts a list-like to string with given line width.,
"def _unsorted_set(df, label, **kwargs):
    """"""
    Returns a set as inp string with unsorted option.
    """"""
    out = ""*NSET, NSET={0}, UNSORTED\n"".format(label)
    labels = df.index.values
    return out + argiope.utils.list_to_string(labels, **kwargs)",Returns a set as inp string with unsorted option.,
"def write_inp(self):
     """"""
     Returns the material definition as a string in Abaqus INP format.
     """"""
     template = self.get_template()
     return template.substitute({""class"": self.__class__.__name__,
                                 ""label"": self.label}).strip()",Returns the material definition as a string in Abaqus INP format.,
"def _get_axis_mode(self, axis):
        ""will get the axis mode for the current series""
        if all([isinstance(getattr(s, axis), TimeVariable) for s in self._series]):
            return 'time'
        return None",will get the axis mode for the current series,
"def create_setter(func, attrs):
    """"""Create the __set__ method for the descriptor.""""""
    def _set(self, instance, value, name=None):
        args = [getattr(self, attr) for attr in attrs]
        if not func(value, *args):
            raise ValueError(self.err_msg(instance, value))
    return _set",Create the __set__ method for the descriptor.,
"def make_class(clsname, func, attrs):
    """"""Turn a funcs list element into a class object.""""""
    clsdict = {""__set__"": create_setter(func, attrs)}
    if len(attrs) > 0:
        clsdict[""__init__""] = create_init(attrs)
    clsobj = type(str(clsname), (Descriptor, ), clsdict)
    clsobj.__doc__ = docstrings.get(clsname)
    return clsobj",Turn a funcs list element into a class object.,
"def cycle(self):
        """"""
        Cycles through notifications with latest results from data feeds.
        """"""
        messages = self.poll_datafeeds()
        notifications = self.process_notifications(messages)

        self.draw_notifications(notifications)",Cycles through notifications with latest results from data feeds.,
"def try_convert(value):
        """"""Convert value to a numeric value or raise a ValueError
        if that isn't possible.

        """"""
        convertible = ForceNumeric.is_convertible(value)
        if not convertible or isinstance(value, bool):
            raise ValueError
        if isinstance(str(value), str):
            return ForceNumeric.str_to_num(value)
        return float(value)","Convert value to a numeric value or raise a ValueError
        if that isn't possible.",
"def str_to_num(str_value):
        """"""Convert str_value to an int or a float, depending on the
        numeric value represented by str_value.

        """"""
        str_value = str(str_value)
        try:
            return int(str_value)
        except ValueError:
            return float(str_value)","Convert str_value to an int or a float, depending on the
        numeric value represented by str_value.",
"def domain_name_left_cuts(domain):
    '''returns a list of strings created by splitting the domain on
    '.' and successively cutting off the left most portion
    '''
    cuts = []
    if domain:
        parts = domain.split('.')
        for i in range(len(parts)):
            cuts.append( '.'.join(parts[i:]))
    return cuts","returns a list of strings created by splitting the domain on
    '.' and successively cutting off the left most portion",
"def _read_varint(self):
        """"""Read exactly a varint out of the underlying file.""""""
        buf = self._read(8)
        (n, l) = _DecodeVarint(buf, 0)
        self._unread(buf[l:])
        return n",Read exactly a varint out of the underlying file.,
"def _read_a(self, cls):
        """"""Read some protobuf-encoded object stored in a single block
        out of the file.""""""
        o = cls()
        o.ParseFromString(self._read_block())
        return o","Read some protobuf-encoded object stored in a single block
        out of the file.",
"def make_doc_id_range(doc_id):
    '''Construct a tuple(begin, end) of one-tuple kvlayer keys from a
    hexdigest doc_id.

    '''
    assert len(doc_id) == 32, 'expecting 32 hex string, not: %r' % doc_id
    bin_docid = base64.b16decode(doc_id.upper())
    doc_id_range = ((bin_docid,), (bin_docid,))
    return doc_id_range","Construct a tuple(begin, end) of one-tuple kvlayer keys from a
    hexdigest doc_id.",
"def streamitem_to_key_data(si):
    '''
    extract the parts of a StreamItem that go into a kvlayer key,
    convert StreamItem to blob for storage.

    return (kvlayer key tuple), data blob
    '''
    key = key_for_stream_item(si)
    data = streamcorpus.serialize(si)
    errors, data = streamcorpus.compress_and_encrypt(data)
    assert not errors, errors
    return key, data","extract the parts of a StreamItem that go into a kvlayer key,
    convert StreamItem to blob for storage.

    return (kvlayer key tuple), data blob",
"def working_directory(path):
    """"""Change working directory and restore the previous on exit""""""
    prev_dir = os.getcwd()
    os.chdir(str(path))
    try:
        yield
    finally:
        os.chdir(prev_dir)",Change working directory and restore the previous on exit,
"def strip_prefix(s, prefix, strict=False):
    """"""Removes the prefix, if it's there, otherwise returns input string unchanged.
    If strict is True, also ensures the prefix was present""""""
    if s.startswith(prefix):
        return s[len(prefix) :]
    elif strict:
        raise WimpyError(""string doesn't start with prefix"")
    return s","Removes the prefix, if it's there, otherwise returns input string unchanged.
    If strict is True, also ensures the prefix was present",
"def strip_suffix(s, suffix, strict=False):
    """"""Removes the suffix, if it's there, otherwise returns input string unchanged.
    If strict is True, also ensures the suffix was present""""""
    if s.endswith(suffix):
        return s[: len(s) - len(suffix)]
    elif strict:
        raise WimpyError(""string doesn't end with suffix"")
    return s","Removes the suffix, if it's there, otherwise returns input string unchanged.
    If strict is True, also ensures the suffix was present",
"def is_subsequence(needle, haystack):
    """"""Are all the elements of needle contained in haystack, and in the same order?
    There may be other elements interspersed throughout""""""
    it = iter(haystack)
    for element in needle:
        if element not in it:
            return False
    return True","Are all the elements of needle contained in haystack, and in the same order?
    There may be other elements interspersed throughout",
"def exit(self):
        """"""Stop the simple WSGI server running the appliation.""""""
        if self._server is not None:
            self._server.shutdown()
            self._server.server_close()
            self._server = None",Stop the simple WSGI server running the appliation.,
"def add_header(self, name, value):
        """"""Add an HTTP header to response object.

        Arguments:
          name (str): HTTP header field name
          value (str): HTTP header field value
        """"""
        if value is not None:
            self._headers.append((name, value))","Add an HTTP header to response object.

        Arguments:
          name (str): HTTP header field name
          value (str): HTTP header field value",
"def status_line(self):
        """"""Return the HTTP response status line.

        The status line is determined from :attr:`status` code. For
        example, if the status code is 200, then '200 OK' is returned.

        Returns:
          str: Status line
        """"""
        return (str(self.status) + ' ' +
                Response._responses[self.status].phrase)","Return the HTTP response status line.

        The status line is determined from :attr:`status` code. For
        example, if the status code is 200, then '200 OK' is returned.

        Returns:
          str: Status line",
"def get_file_lines(file_name):
    """"""Return a list of non-empty lines from `file_path`.""""""
    file_path = path.join(path.dirname(path.abspath(__file__)), file_name)
    with open(file_path) as file_obj:
        return [line for line in file_obj.read().splitlines() if line]",Return a list of non-empty lines from `file_path`.,
"def get_describers():
    """"""
    Return a describer tuple in the form `(name, position)`,
    where position is either 'prefix' or 'suffix'.
    """"""
    adjectives = map(lambda x: (x, 'prefix'), get_file_lines('adjectives.txt'))
    animal_nouns = map(lambda x: (x, 'suffix'), get_file_lines('nouns.txt'))
    return list(chain(adjectives, animal_nouns))","Return a describer tuple in the form `(name, position)`,
    where position is either 'prefix' or 'suffix'.",
"def _random_adjspecies_pair():
    """"""Return an ordered 2-tuple containing a species and a describer.""""""
    describer, desc_position = random_describer()
    if desc_position == 'prefix':
        return (describer, random_species())
    elif desc_position == 'suffix':
        return (random_species(), describer)",Return an ordered 2-tuple containing a species and a describer.,
"def shutdown(self):
        '''
        send SIGTERM to the tagger child process
        '''
        if self._child:
            try:
                self._child.terminate()
            except OSError, exc:
                if exc.errno == 3:
                    ## child is already gone, possibly because it ran
                    ## out of memory and caused us to shutdown
                    pass",send SIGTERM to the tagger child process,
"def mult(p, n):
    """"""Returns a Pattern that matches exactly n repetitions of Pattern p.
    """"""
    np = P()
    while n >= 1:
        if n % 2:
            np = np + p
        p = p + p
        n = n // 2
    return np",Returns a Pattern that matches exactly n repetitions of Pattern p.,
"def fix_emails(text):
    '''Replace all angle bracket emails with a unique key.'''
    emails = bracket_emails.findall(text)

    keys = []
    for email in emails:
	_email = email.replace(""<"",""&lt;"").replace("">"",""&gt;"")
        text = text.replace(email, _email)

    return text",Replace all angle bracket emails with a unique key.,
"def make_label_index(self, stream_item):
        'make a sortedcollection on body.labels'
        labels = stream_item.body.labels.get(self.annotator_id)
        if not labels:
            labels = []

        self.label_index = SortedCollection(
            [l for l in labels if OffsetType.CHARS in l.offsets],
            key=lambda label: label.offsets[OffsetType.CHARS].first)",make a sortedcollection on body.labels,
"def load_external_stages(self, path):
        '''Add external stages from the Python module in `path`.

        `path` must be a path to a Python module source that contains
        a `Stages` dictionary, which is a map from stage name to callable.

        :param str path: path to the module file
        '''
        mod = imp.load_source('', path)
        self.update(mod.Stages)","Add external stages from the Python module in `path`.

        `path` must be a path to a Python module source that contains
        a `Stages` dictionary, which is a map from stage name to callable.

        :param str path: path to the module file",
"def paths(input_dir):
    'yield all file paths under input_dir'
    for root, dirs, fnames in os.walk(input_dir):
        for i_fname in fnames:
            i_path = os.path.join(root, i_fname)
            yield i_path",yield all file paths under input_dir,
"def tasks(self, key_prefix=''):
        '''
        generate the data objects for every task
        '''
        for row in self._tasks.get_range():
            logger.debug(row)
            if not row[0].startswith(key_prefix):
                continue
            data = json.loads(row[1]['task_data'])
            data['task_key'] = row[0]
            yield data",generate the data objects for every task,
"def files(text):
    '''
    Iterate over <FILENAME> XML-like tags and tokenize with nltk
    '''
    for f_match in filename_re.finditer(text):
        yield f_match.group('stream_id'), f_match.group('tagged_doc')",Iterate over <FILENAME> XML-like tags and tokenize with nltk,
"def get_sentences(self, ner_dom):
        '''parse the sentences and tokens out of the XML'''
        lp_parser = LingPipeParser(self.config)
        lp_parser.set(ner_dom)
        sentences = list( lp_parser.sentences() )
        return sentences, lp_parser.relations, lp_parser.attributes",parse the sentences and tokens out of the XML,
"def sentences_to_char_tokens(si_sentences):
    '''Convert stream item sentences to character ``Offset``s.'''
    for sentence in si_sentences:
        for token in sentence.tokens:
            if OffsetType.CHARS in token.offsets:
                yield token",Convert stream item sentences to character ``Offset``s.,
"def char_tokens_to_char_offsets(si_tokens):
    '''Convert character ``Offset``s to character ranges.'''
    for token in si_tokens:
        offset = token.offsets[OffsetType.CHARS]
        yield offset.first, offset.first + offset.length",Convert character ``Offset``s to character ranges.,
"def text_index(self):
        '''Returns the one-based index of the current text node.'''
        # This is the number of text nodes we've seen so far.
        # If we are currently in a text node, great; if not then add
        # one for the text node that's about to begin.
        i = self.tags.get(TextElement, 0)
        if self.last_tag is not TextElement:
            i += 1
        return i",Returns the one-based index of the current text node.,
"def descendants(elem):
    '''
    Yields all the elements descendant of elem in document order
    '''
    for child in elem.xml_children:
        if isinstance(child, element):
            yield child
            yield from descendants(child)",Yields all the elements descendant of elem in document order,
"def select_elements(source):
    '''
    Yields all the elements from the source
    source - if an element, yields all child elements in order; if any other iterator yields the elements from that iterator
    '''
    if isinstance(source, element):
        source = source.xml_children
    return filter(lambda x: isinstance(x, element), source)","Yields all the elements from the source
    source - if an element, yields all child elements in order; if any other iterator yields the elements from that iterator",
"def select_name(source, name):
    '''
    Yields all the elements with the given name
    source - if an element, starts with all child elements in order; can also be any other iterator
    name - will yield only elements with this name
    '''
    return filter(lambda x: x.xml_name == name, select_elements(source))","Yields all the elements with the given name
    source - if an element, starts with all child elements in order; can also be any other iterator
    name - will yield only elements with this name",
"def select_name_pattern(source, pat):
    '''
    Yields elements from the source whose name matches the given regular expression pattern
    source - if an element, starts with all child elements in order; can also be any other iterator
    pat - re.pattern object
    '''
    return filter(lambda x: pat.match(x.xml_name) is not None, select_elements(source))","Yields elements from the source whose name matches the given regular expression pattern
    source - if an element, starts with all child elements in order; can also be any other iterator
    pat - re.pattern object",
"def select_value(source, val):
    '''
    Yields elements from the source with the given value (accumulated child text)
    source - if an element, starts with all child elements in order; can also be any other iterator
    val - string value to match
    '''
    if isinstance(source, element):
        source = source.xml_children
    return filter(lambda x: x.xml_value == val, source)","Yields elements from the source with the given value (accumulated child text)
    source - if an element, starts with all child elements in order; can also be any other iterator
    val - string value to match",
"def following_siblings(elem):
    '''
    Yields elements and text which have the same parent as elem, but come afterward in document order
    '''
    it = itertools.dropwhile(lambda x: x != elem, elem.xml_parent.xml_children)
    next(it) #Skip the element itself
    return it","Yields elements and text which have the same parent as elem, but come afterward in document order",
"def svg2png(svg_file_path, png_file_path, dpi=150, inkscape_binpath=None):
    """""" Transform SVG file to PNG file
    """"""
    return inkscape_export(svg_file_path, png_file_path, export_flag=""-e"",
                           dpi=dpi, inkscape_binpath=inkscape_binpath)",Transform SVG file to PNG file,
"def search(self):
        '''Start the optimisation/search using the supplied optimisation
        method with the supplied inputs for the supplied function'''
        search = self._method(inputs=self._inputs, function=self._function,
                              state=self._state)
        search.run()","Start the optimisation/search using the supplied optimisation
        method with the supplied inputs for the supplied function",
"def insertText(self, data, insertBefore=None):
        """"""Insert data as text in the current node, positioned before the
        start of node insertBefore or to the end of the node's text.
        """"""
        if insertBefore:
            self.insertBefore(tree.text(data), insertBefore)
        else:
            self.xml_append(tree.text(data))","Insert data as text in the current node, positioned before the
        start of node insertBefore or to the end of the node's text.",
"def insertBefore(self, node, refNode):
        """"""Insert node as a child of the current node, before refNode in the
        list of child nodes. Raises ValueError if refNode is not a child of
        the current node""""""
        offset = self.xml_children.index(refNode)
        self.xml_insert(node, offset)","Insert node as a child of the current node, before refNode in the
        list of child nodes. Raises ValueError if refNode is not a child of
        the current node",
"def cloneNode(self):
        """"""Return a shallow copy of the current node i.e. a node with the same
        name and attributes but with no parent or child nodes
        """"""
        attrs = self.xml_attributes.copy()
        return element(self.xml_name, attrs=attrs)","Return a shallow copy of the current node i.e. a node with the same
        name and attributes but with no parent or child nodes",
"def main():
    """"""
    Processing notification call main function.
    """"""

    # getting info for creating event
    options = parse_options()
    config = parse_config(options)
    credentials = get_google_credentials(options, config)

    if not options.get_google_credentials:
        create_event(options, config, credentials)",Processing notification call main function.,
"def cleanup(workdir, extension):
    """""" Remove the files in workdir that have the given extension.

    Parameters
    ----------
    workdir:
        Folder path from where to clean the files.

    extension: str
        File extension without the dot, e.g., 'txt'
    """"""
    [os.remove(f) for f in glob(os.path.join(workdir, '*.' + extension))]","Remove the files in workdir that have the given extension.

    Parameters
    ----------
    workdir:
        Folder path from where to clean the files.

    extension: str
        File extension without the dot, e.g., 'txt'",
"def cleanup_docstamp_output(output_dir=''):
    """""" Remove the 'tmp*.aux', 'tmp*.out' and 'tmp*.log' files in `output_dir`.
    :param output_dir:
    """"""
    suffixes = ['aux', 'out', 'log']
    files = [f for suf in suffixes for f in glob(os.path.join(output_dir, 'tmp*.{}'.format(suf)))]
    [os.remove(file) for file in files]","Remove the 'tmp*.aux', 'tmp*.out' and 'tmp*.log' files in `output_dir`.
    :param output_dir:",
"def create_italic(self, tag):
        """"""
        See if span tag has italic style and wrap with em tag.
        """"""
        style = tag.get('style')
        if style and 'font-style:italic' in style:
            tag.wrap(self.soup.new_tag('em'))",See if span tag has italic style and wrap with em tag.,
"def create_strong(self, tag):
        """"""
        See if span tag has bold style and wrap with strong tag.
        """"""
        style = tag.get('style')
        if (style and
                ('font-weight:bold' in style or 'font-weight:700' in style)):
            tag.wrap(self.soup.new_tag('strong'))",See if span tag has bold style and wrap with strong tag.,
"def create_underline(self, tag):
        """"""
        See if span tag has underline style and wrap with u tag.
        """"""
        style = tag.get('style')
        if style and 'text-decoration:underline' in style:
            tag.wrap(self.soup.new_tag('u'))",See if span tag has underline style and wrap with u tag.,
"def remove_empty(self, tag):
        """"""
        Remove non-self-closing tags with no children *and* no content.
        """"""
        has_children = len(tag.contents)
        has_text = len(list(tag.stripped_strings))
        if not has_children and not has_text and not tag.is_empty_element:
            tag.extract()",Remove non-self-closing tags with no children *and* no content.,
"def clean_linebreaks(self, tag):
        """"""
        get unicode string without any other content transformation.
        and clean extra spaces
        """"""
        stripped = tag.decode(formatter=None)
        stripped = re.sub('\s+', ' ', stripped)
        stripped = re.sub('\n', '', stripped)
        return stripped","get unicode string without any other content transformation.
        and clean extra spaces",
"def _parse_href(self, href):
        """"""
        Extract ""real"" URL from Google redirected url by getting `q`
        querystring parameter.
        """"""
        params = parse_qs(urlsplit(href).query)
        return params.get('q')","Extract ""real"" URL from Google redirected url by getting `q`
        querystring parameter.",
"def _parse_attr(self, tagname, attr, value):
        """"""
        Parse attribute. Delegate to href parser for hrefs, otherwise return
        value.
        """"""
        if tagname == 'a' and attr == 'href':
            return self._parse_href(value)
        else:
            return value","Parse attribute. Delegate to href parser for hrefs, otherwise return
        value.",
"def to_json_str(self):
        """"""Convert data to json string representation.

        Returns:
          json representation as string.
        """"""
        adict = dict(vars(self), sort_keys=True)
        adict['type'] = self.__class__.__name__
        return json.dumps(adict)","Convert data to json string representation.

        Returns:
          json representation as string.",
"def p_function_call(p):
    """"""
    FunctionCall : NAME FormalArguments
    """"""
    #Hacking around the ambiguity between node type test & function call
    if p[1] in ('node', 'text'):
        p[0] = ast.NodeType(p[1])
    else:
        p[0] = ast.FunctionCall(p[1], p[2])",FunctionCall : NAME FormalArguments,
"def boolean_arg(ctx, obj):
    '''
    Handles LiteralObjects as well as computable arguments
    '''
    if hasattr(obj, 'compute'):
        obj = next(obj.compute(ctx), False)
    return to_boolean(obj)",Handles LiteralObjects as well as computable arguments,
"def number_arg(ctx, obj):
    '''
    Handles LiteralObjects as well as computable arguments
    '''
    if hasattr(obj, 'compute'):
        obj = next(obj.compute(ctx), False)
    return to_number(obj)",Handles LiteralObjects as well as computable arguments,
"def string_arg(ctx, obj):
    '''
    Handles LiteralObjects as well as computable arguments
    '''
    if hasattr(obj, 'compute'):
        obj = next(obj.compute(ctx), False)
    return to_string(obj)",Handles LiteralObjects as well as computable arguments,
"def concat(ctx, *strings):
    '''
    Yields one string, concatenation of argument strings
    '''
    strings = flatten([ (s.compute(ctx) if callable(s) else s) for s in strings ])
    strings = (next(string_arg(ctx, s), '') for s in strings)
    #assert(all(map(lambda x: isinstance(x, str), strings)))
    #FIXME: Check arg types
    yield ''.join(strings)","Yields one string, concatenation of argument strings",
"def starts_with(ctx, full, part):
    '''
    Yields one boolean, whether the first string starts with the second
    '''
    full = next(string_arg(ctx, full), '')
    part = next(string_arg(ctx, part), '')
    yield full.startswith(part)","Yields one boolean, whether the first string starts with the second",
"def contains(ctx, full, part):
    '''
    Yields one boolean, whether the first string contains the second
    '''
    full = next(string_arg(ctx, full), '')
    part = next(string_arg(ctx, part), '')
    yield part in full","Yields one boolean, whether the first string contains the second",
"def substring_before(ctx, full, part):
    '''
    Yields one string
    '''
    full = next(string_arg(ctx, full), '')
    part = next(string_arg(ctx, part), '')
    yield full.partition(part)[0]",Yields one string,
"def substring_after(ctx, full, part):
    '''
    Yields one string
    '''
    full = next(string_arg(ctx, full), '')
    part = next(string_arg(ctx, part), '')
    yield full.partition(part)[-1]",Yields one string,
"def substring(ctx, full, start, length):
    '''
    Yields one string
    '''
    full = next(string_arg(ctx, full), '')
    start = int(next(to_number(start)))
    length = int(next(to_number(length)))
    yield full[start-1:start-1+length]",Yields one string,
"def string_length(ctx, s=None):
    '''
    Yields one number
    '''
    if s is None:
        s = ctx.node
    elif callable(s):
        s = next(s.compute(ctx), '')
    yield len(s)",Yields one number,
"def _serialize(xp_ast):
    '''Generate token strings which, when joined together, form a valid
    XPath serialization of the AST.'''

    if hasattr(xp_ast, '_serialize'):
        for tok in xp_ast._serialize():
            yield(tok)
    elif isinstance(xp_ast, str):
        yield(repr(xp_ast))","Generate token strings which, when joined together, form a valid
    XPath serialization of the AST.",
"def centroid(self):
        """"""Returns the envelope centroid as a (x, y) tuple.""""""
        return self.min_x + self.width * 0.5, self.min_y + self.height * 0.5","Returns the envelope centroid as a (x, y) tuple.",
"def expand(self, other):
        """"""Expands this envelope by the given Envelope or tuple.

        Arguments:
        other -- Envelope, two-tuple, or four-tuple
        """"""
        if len(other) == 2:
            other += other
        mid = len(other) // 2
        self.ll = map(min, self.ll, other[:mid])
        self.ur = map(max, self.ur, other[mid:])","Expands this envelope by the given Envelope or tuple.

        Arguments:
        other -- Envelope, two-tuple, or four-tuple",
"def polygon(self):
        """"""Returns an OGR Geometry for this envelope.""""""
        ring = ogr.Geometry(ogr.wkbLinearRing)
        for coord in self.ll, self.lr, self.ur, self.ul, self.ll:
            ring.AddPoint_2D(*coord)
        polyg = ogr.Geometry(ogr.wkbPolygon)
        polyg.AddGeometryDirectly(ring)
        return polyg",Returns an OGR Geometry for this envelope.,
"def from_name(cls, name):
        ""Imports a mass table from a file""
        filename = os.path.join(package_dir, 'data', name + '.txt')
        return cls.from_file(filename, name)",Imports a mass table from a file,
"def from_file(cls, filename, name=''):
        ""Imports a mass table from a file""
        df = pd.read_csv(filename, header=0, delim_whitespace=True, index_col=[0, 1])['M']
        df.name = name
        return cls(df=df, name=name)",Imports a mass table from a file,
"def intersection(self, table):
        """"""
        Select nuclei which also belong to ``table``

        Parameters
        ----------
        table: Table, Table object

        Example:
        ----------
        Table('AME2003').intersection(Table('AME1995'))
        """"""
        idx = self.df.index & table.df.index
        return Table(df=self.df[idx], name=self.name)","Select nuclei which also belong to ``table``

        Parameters
        ----------
        table: Table, Table object

        Example:
        ----------
        Table('AME2003').intersection(Table('AME1995'))",
"def odd_odd(self):
        """"""Selects odd-odd nuclei from the table:

        >>> Table('FRDM95').odd_odd
        Out[13]:
        Z   N
        9   9       1.21
            11      0.10
            13      3.08
            15      9.32
        ...
        """"""
        return self.select(lambda Z, N: (Z % 2) and (N % 2), name=self.name)","Selects odd-odd nuclei from the table:

        >>> Table('FRDM95').odd_odd
        Out[13]:
        Z   N
        9   9       1.21
            11      0.10
            13      3.08
            15      9.32
        ...",
"def odd_even(self):
        """"""
        Selects odd-even nuclei from the table
        """"""
        return self.select(lambda Z, N: (Z % 2) and not(N % 2), name=self.name)",Selects odd-even nuclei from the table,
"def even_odd(self):
        """"""
        Selects even-odd nuclei from the table
        """"""
        return self.select(lambda Z, N: not(Z % 2) and (N % 2), name=self.name)",Selects even-odd nuclei from the table,
"def even_even(self):
        """"""
        Selects even-even nuclei from the table
        """"""
        return self.select(lambda Z, N: not(Z % 2) and not(N % 2), name=self.name)",Selects even-even nuclei from the table,
"def error(self, relative_to='AME2003'):
        """"""
        Calculate error difference

        Parameters
        ----------
        relative_to : string,
            a valid mass table name.

        Example:
        ----------
        >>> Table('DUZU').error(relative_to='AME2003')
        """"""
        df = self.df - Table(relative_to).df
        return Table(df=df)","Calculate error difference

        Parameters
        ----------
        relative_to : string,
            a valid mass table name.

        Example:
        ----------
        >>> Table('DUZU').error(relative_to='AME2003')",
"def q_alpha(self):
        """"""Return Q_alpha""""""
        M_ALPHA = 2.4249156         # He4 mass excess in MeV
        f = lambda parent, daugther: parent - daugther - M_ALPHA
        return self.derived('Q_alpha', (-2, -2), f)",Return Q_alpha,
"def q_beta(self):
        """"""Return Q_beta""""""
        f = lambda parent, daugther: parent - daugther
        return self.derived('Q_beta', (1, -1), f)",Return Q_beta,
"def s2n(self):
        """"""Return 2 neutron separation energy""""""
        M_N = 8.0713171         # neutron mass excess in MeV
        f = lambda parent, daugther: -parent + daugther + 2 * M_N
        return self.derived('s2n', (0, -2), f)",Return 2 neutron separation energy,
"def s1n(self):
        """"""Return 1 neutron separation energy""""""
        M_N = 8.0713171         # neutron mass excess in MeV
        f = lambda parent, daugther: -parent + daugther + M_N
        return self.derived('s1n', (0, -1), f)",Return 1 neutron separation energy,
"def s2p(self):
        """"""Return 2 proton separation energy""""""
        M_P = 7.28897050         # proton mass excess in MeV
        f = lambda parent, daugther: -parent + daugther + 2 * M_P
        return self.derived('s2p', (-2, 0), f)",Return 2 proton separation energy,
"def s1p(self):
        """"""Return 1 proton separation energy""""""
        M_P = 7.28897050         # proton mass excess in MeV
        f = lambda parent, daugther: -parent + daugther + M_P
        return self.derived('s1p', (-1, 0), f)",Return 1 proton separation energy,
"def derived(self, name, relative_coords, formula):
        """"""Helper function for derived quantities""""""
        relZ, relN = relative_coords
        daughter_idx = [(x[0] + relZ, x[1] + relN) for x in self.df.index]
        values = formula(self.df.values, self.df.loc[daughter_idx].values)
        return Table(df=pd.Series(values, index=self.df.index, name=name + '(' + self.name + ')'))",Helper function for derived quantities,
"def ds2n(self):
        """"""Calculates the derivative of the neutron separation energies:

        ds2n(Z,A) = s2n(Z,A) - s2n(Z,A+2)
        """"""
        idx = [(x[0] + 0, x[1] + 2) for x in self.df.index]
        values = self.s2n.values - self.s2n.loc[idx].values
        return Table(df=pd.Series(values, index=self.df.index, name='ds2n' + '(' + self.name + ')'))","Calculates the derivative of the neutron separation energies:

        ds2n(Z,A) = s2n(Z,A) - s2n(Z,A+2)",
"def ds2p(self):
        """"""Calculates the derivative of the neutron separation energies:

        ds2n(Z,A) = s2n(Z,A) - s2n(Z,A+2)
        """"""
        idx = [(x[0] + 2, x[1]) for x in self.df.index]
        values = self.s2p.values - self.s2p.loc[idx].values
        return Table(df=pd.Series(values, index=self.df.index, name='ds2p' + '(' + self.name + ')'))","Calculates the derivative of the neutron separation energies:

        ds2n(Z,A) = s2n(Z,A) - s2n(Z,A+2)",
"def bootstrap(self, path_or_uri):
        """""" Initialize a database.

        :param database_path: The absolute path to the database to initialize.
        """"""
        _logger.debug(""Bootstrapping new database: %s"", path_or_uri)
        self.database_uri = _urify_db(path_or_uri)
        db = sa.create_engine(self.database_uri)
        Base.metadata.create_all(db)","Initialize a database.

        :param database_path: The absolute path to the database to initialize.",
"def search(self, query):
        """""" Search the database for the given query. Will find partial matches. """"""
        results = self.session.query(Domain).filter(Domain.name.ilike('%%%s%%' % query)).all()
        return results",Search the database for the given query. Will find partial matches.,
"def srid(self):
        """"""Returns the EPSG ID as int if it exists.""""""
        epsg_id = (self.GetAuthorityCode('PROJCS') or
                   self.GetAuthorityCode('GEOGCS'))
        try:
            return int(epsg_id)
        except TypeError:
            return",Returns the EPSG ID as int if it exists.,
"def main():
    """""" Main entry point for the CLI. """"""
    args = get_args()
    ret_code = args.target(args)
    _logger.debug('Exiting with code %d', ret_code)
    sys.exit(ret_code)",Main entry point for the CLI.,
"def update_file(url, filename):
    """"""Update the content of a single file.""""""
    resp = urlopen(url)
    if resp.code != 200:
        raise Exception('GET {} failed.'.format(url))
    with open(_get_package_path(filename), 'w') as fp:
        for l in resp:
            if not l.startswith(b'#'):
                fp.write(l.decode('utf8'))
    print('Updated {}'.format(filename))",Update the content of a single file.,
"def available_drivers():
    """"""Returns a dictionary of enabled GDAL Driver metadata keyed by the
    'ShortName' attribute.
    """"""
    drivers = {}
    for i in range(gdal.GetDriverCount()):
        d = gdal.GetDriver(i)
        drivers[d.ShortName] = d.GetMetadata()
    return drivers","Returns a dictionary of enabled GDAL Driver metadata keyed by the
    'ShortName' attribute.",
"def frombytes(data, size, bandtype=gdal.GDT_Byte):
    """"""Returns an in-memory raster initialized from a pixel buffer.

    Arguments:
    data -- byte buffer of raw pixel data
    size -- two or three-tuple of (xsize, ysize, bandcount)
    bandtype -- band data type
    """"""
    r = ImageDriver('MEM').raster('', size, bandtype)
    r.frombytes(data)
    return r","Returns an in-memory raster initialized from a pixel buffer.

    Arguments:
    data -- byte buffer of raw pixel data
    size -- two or three-tuple of (xsize, ysize, bandcount)
    bandtype -- band data type",
"def array(self, envelope=()):
        """"""Returns an NDArray, optionally subset by spatial envelope.

        Keyword args:
        envelope -- coordinate extent tuple or Envelope
        """"""
        args = ()
        if envelope:
            args = self.get_offset(envelope)
        return self.ds.ReadAsArray(*args)","Returns an NDArray, optionally subset by spatial envelope.

        Keyword args:
        envelope -- coordinate extent tuple or Envelope",
"def driver(self):
        """"""Returns the underlying ImageDriver instance.""""""
        if self._driver is None:
            self._driver = ImageDriver(self.ds.GetDriver())
        return self._driver",Returns the underlying ImageDriver instance.,
"def nodata(self):
        """"""Returns read only property for band nodata value, assuming single
        band rasters for now.
        """"""
        if self._nodata is None:
            self._nodata = self[0].GetNoDataValue()
        return self._nodata","Returns read only property for band nodata value, assuming single
        band rasters for now.",
"def ReadRaster(self, *args, **kwargs):
        """"""Returns raster data bytes for partial or full extent.

        Overrides gdal.Dataset.ReadRaster() with the full raster size by
        default.
        """"""
        args = args or (0, 0, self.ds.RasterXSize, self.ds.RasterYSize)
        return self.ds.ReadRaster(*args, **kwargs)","Returns raster data bytes for partial or full extent.

        Overrides gdal.Dataset.ReadRaster() with the full raster size by
        default.",
"def shape(self):
        """"""Returns a tuple of row, column, (band count if multidimensional).""""""
        shp = (self.ds.RasterYSize, self.ds.RasterXSize, self.ds.RasterCount)
        return shp[:2] if shp[2] <= 1 else shp","Returns a tuple of row, column, (band count if multidimensional).",
"def lookup_alphabet(charset):
    '''
    retrieves a named charset or treats the input as a custom alphabet and use that
    '''
    if charset in PRESETS:
        return PRESETS[charset]
    if len(charset) < 16:
        _logger.warning('very small alphabet in use, possibly a failed lookup?')
    return charset",retrieves a named charset or treats the input as a custom alphabet and use that,
"def _encode_chunk(self, data, index):
        '''
        gets a chunk from the input data, converts it to a number and
        encodes that number
        '''
        chunk = self._get_chunk(data, index)
        return self._encode_long(self._chunk_to_long(chunk))","gets a chunk from the input data, converts it to a number and
        encodes that number",
"def _encode_long(self, val):
        '''
        encodes an integer of 8*self.chunklen[0] bits using the specified
        alphabet
        '''
        return ''.join([
                self.alphabet[(val//len(self.alphabet)**i) % len(self.alphabet)]
                for i in reversed(range(self.chunklen[1]))
            ])","encodes an integer of 8*self.chunklen[0] bits using the specified
        alphabet",
"def _chunk_to_long(self, chunk):
        '''
        parses a chunk of bytes to integer using big-endian representation
        '''
        return sum([
                256**(self.chunklen[0]-1-i) * ord_byte(chunk[i])
                for i in range(self.chunklen[0])
            ])",parses a chunk of bytes to integer using big-endian representation,
"def _get_chunk(self, data, index):
        '''
        partition the data into chunks and retrieve the chunk at the given index
        '''
        return data[index*self.chunklen[0]:(index+1)*self.chunklen[0]]",partition the data into chunks and retrieve the chunk at the given index,
"def memoize(func):
    """"""Cache result of function call.""""""
    cache = {}

    @wraps(func)
    def inner(filename):
        if filename not in cache:
            cache[filename] = func(filename)
        return cache[filename]
    return inner",Cache result of function call.,
"def _regexp(filename):
    """"""Get a list of patterns from a file and make a regular expression.""""""
    lines = _get_resource_content(filename).decode('utf-8').splitlines()
    return re.compile('|'.join(lines))",Get a list of patterns from a file and make a regular expression.,
"def _detect_timezone():
    '''
    Get timezone as set by the system
    '''
    default_timezone = 'America/New_York'
    locale_code = locale.getdefaultlocale()
    return default_timezone if not locale_code[0] else \
        str(pytz.country_timezones[locale_code[0][-2:]][0])",Get timezone as set by the system,
"def api_url(full_version, resource):
    '''
    >>> # Harmonize api endpoints
    >>> # __version__ should be like major.minor.fix
    >>> from my_app import __version__
    >>> api_url(__version__, '/some/endpoint')
    /v0/some/endpoint
    '''
    return '/v{}/{}'.format(dna.utils.Version(full_version).major, resource)",">>> # Harmonize api endpoints
    >>> # __version__ should be like major.minor.fix
    >>> from my_app import __version__
    >>> api_url(__version__, '/some/endpoint')
    /v0/some/endpoint",
"def activate_pdb_hook():
    ''' Catch exceptions with a prompt for post-mortem analyzis'''
    def debug_exception(type_exception, value, tb):
        import pdb
        pdb.post_mortem(tb)

    import sys
    sys.excepthook = debug_exception",Catch exceptions with a prompt for post-mortem analyzis,
"def emphasis(obj, align=True):
    ''' Clearer data printing '''
    if isinstance(obj, dict):
        if align:
            pretty_msg = os.linesep.join(
                [""%25s: %s"" % (k, obj[k]) for k in sorted(obj.keys())])
        else:
            pretty_msg = json.dumps(obj, indent=4, sort_keys=True)
    else:
        return obj
    return pretty_msg",Clearer data printing,
"def worker_main(job_handler, host, port):
    """"""
    Starts an asyncio event loop to connect to the master and run jobs.
    """"""

    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(None)
    loop.run_until_complete(handle_jobs(job_handler, host, port, loop=loop))
    loop.close()",Starts an asyncio event loop to connect to the master and run jobs.,
"def _send_message(self, msg):
        """"""Add message to queue and start processing the queue.""""""
        LWLink.the_queue.put_nowait(msg)
        if LWLink.thread is None or not LWLink.thread.isAlive():
            LWLink.thread = Thread(target=self._send_queue)
            LWLink.thread.start()",Add message to queue and start processing the queue.,
"def turn_on_light(self, device_id, name):
        """"""Create the message to turn light on.""""""
        msg = ""!%sFdP32|Turn On|%s"" % (device_id, name)
        self._send_message(msg)",Create the message to turn light on.,
"def turn_on_switch(self, device_id, name):
        """"""Create the message to turn switch on.""""""
        msg = ""!%sF1|Turn On|%s"" % (device_id, name)
        self._send_message(msg)",Create the message to turn switch on.,
"def turn_off(self, device_id, name):
        """"""Create the message to turn light or switch off.""""""
        msg = ""!%sF0|Turn Off|%s"" % (device_id, name)
        self._send_message(msg)",Create the message to turn light or switch off.,
"def _send_queue(self):
        """"""If the queue is not empty, process the queue.""""""
        while not LWLink.the_queue.empty():
            self._send_reliable_message(LWLink.the_queue.get_nowait())","If the queue is not empty, process the queue.",
"def computed_displaywidth():
    '''Figure out a reasonable default with. Use os.environ['COLUMNS'] if possible,
    and failing that use 80.
    '''
    try:
        width = int(os.environ['COLUMNS'])
    except (KeyError, ValueError):
        width = get_terminal_size().columns

    return width or 80","Figure out a reasonable default with. Use os.environ['COLUMNS'] if possible,
    and failing that use 80.",
"def reset_(self):
        """"""Restore default values of options in this section.""""""
        for opt, meta in self.defaults_():
            self[opt] = meta.default",Restore default values of options in this section.,
"def set_config_files_(self, *config_files):
        """"""Set the list of config files.

        Args:
            config_files (pathlike): path of config files, given in the order
                of reading.
        """"""
        self._config_files = tuple(pathlib.Path(path) for path in config_files)","Set the list of config files.

        Args:
            config_files (pathlike): path of config files, given in the order
                of reading.",
"def read_config_(self, cfile):
        """"""Read a config file and set config values accordingly.

        Returns:
            dict: content of config file.
        """"""
        if not cfile.exists():
            return {}
        try:
            conf_dict = toml.load(str(cfile))
        except toml.TomlDecodeError:
            return None
        self.update_(conf_dict)
        return conf_dict","Read a config file and set config values accordingly.

        Returns:
            dict: content of config file.",
"def zsh_version():
    """"""Try to guess zsh version, return (0, 0) on failure.""""""
    try:
        out = subprocess.check_output(shlex.split('zsh --version'))
    except (FileNotFoundError, subprocess.CalledProcessError):
        return (0, 0)
    match = re.search(br'[0-9]+\.[0-9]+', out)
    return tuple(map(int, match.group(0).split(b'.'))) if match else (0, 0)","Try to guess zsh version, return (0, 0) on failure.",
"def line_received(self, line):
        """"""
        Called when a complete line is found from the remote worker. Decodes
        a response object from the line, then passes it to the worker object.
        """"""

        response = json.loads(line.decode(""utf-8""))
        self._worker.response_received(response)","Called when a complete line is found from the remote worker. Decodes
        a response object from the line, then passes it to the worker object.",
"def connection_lost(self, exc):
        """"""
        Called when the connection to the remote worker is broken. Closes the
        worker.
        """"""

        logger.debug(""worker connection lost"")

        self._worker.close()
        self._workers.remove(self._worker)","Called when the connection to the remote worker is broken. Closes the
        worker.",
"def close(self):
        """"""
        Closes the worker. No more jobs will be handled by the worker, and any
        running job is immediately returned to the job manager.
        """"""

        if self._closed:
            return

        self._closed = True

        if self._job is not None:
            self._manager.return_job(self._job)
            self._job = None","Closes the worker. No more jobs will be handled by the worker, and any
        running job is immediately returned to the job manager.",
"def run(self, job_list):
        """"""
        Runs a job set which consists of the jobs in an iterable job list.
        """"""

        if self._closed:
            raise RuntimeError(""master is closed"")

        return self._manager.add_job_set(job_list)",Runs a job set which consists of the jobs in an iterable job list.,
"def close(self):
        """"""
        Starts closing the HighFive master. The server will be closed and
        all queued job sets will be cancelled.
        """"""

        if self._closed:
            return

        self._closed = True

        self._server.close()
        self._manager.close()
        for worker in self._workers:
            worker.close()","Starts closing the HighFive master. The server will be closed and
        all queued job sets will be cancelled.",
"def _change(self):
        """"""
        Called when a state change has occurred. Waiters are notified that a
        change has occurred.
        """"""

        for waiter in self._waiters:
            if not waiter.done():
                waiter.set_result(None)
        self._waiters = []","Called when a state change has occurred. Waiters are notified that a
        change has occurred.",
"def add(self, result):
        """"""
        Adds a new result.
        """"""

        assert not self._complete

        self._results.append(result)
        self._change()",Adds a new result.,
"def _done(self):
        """"""
        Marks the job set as completed, and notifies all waiting tasks.
        """"""

        self._results.complete()
        waiters = self._waiters
        for waiter in waiters:
            waiter.set_result(None)
        self._manager.job_set_done(self)","Marks the job set as completed, and notifies all waiting tasks.",
"def cancel(self):
        """"""
        Cancels the job set. The job set is immediately finished, and all
        queued jobs are discarded.
        """"""

        if self._active_jobs == 0:
            return

        self._jobs = iter(())
        self._on_deck = None
        self._return_queue.clear()
        self._active_jobs = 0

        self._done()","Cancels the job set. The job set is immediately finished, and all
        queued jobs are discarded.",
"async def wait_done(self):
        """"""
        Waits until the job set is finished. Returns immediately if the job set
        is already finished.
        """"""
        
        if self._active_jobs > 0:
            future = self._loop.create_future()
            self._waiters.append(future)
            await future","Waits until the job set is finished. Returns immediately if the job set
        is already finished.",
"def add_result(self, job, result):
        """"""
        Adds the result of a job to the results list of the job's source job
        set.
        """"""

        if self._closed:
            return

        js = self._job_sources[job]
        del self._job_sources[job]
        js.add_result(result)","Adds the result of a job to the results list of the job's source job
        set.",
"def _uniquify(_list):
    """"""Remove duplicates in a list.""""""
    seen = set()
    result = []
    for x in _list:
        if x not in seen:
            result.append(x)
            seen.add(x)
    return result",Remove duplicates in a list.,
"def _list_all_cached():
    """"""
    Reads the description cache, returning each instance's information.
    :return: A list of host entries.
    :rtype: [:py:class:`HostEntry`]
    """"""
    with open(get_cache_location()) as f:
        contents = f.read()
        objects = json.loads(contents)
        return [HostEntry.from_dict(obj) for obj in objects]","Reads the description cache, returning each instance's information.
    :return: A list of host entries.
    :rtype: [:py:class:`HostEntry`]",
"def sort_by(cls, entries, attribute):
        """"""
        Sorts a list of entries by the given attribute.
        """"""
        def key(entry):
            return entry._get_attrib(attribute, convert_to_str=True)
        return sorted(entries, key=key)",Sorts a list of entries by the given attribute.,
"def display(self):
        """"""
        Returns the best name to display for this host. Uses the instance
        name if available; else just the public IP.

        :rtype: ``str``
        """"""
        if isinstance(self.name, six.string_types) and len(self.name) > 0:
            return '{0} ({1})'.format(self.name, self.public_ip)
        else:
            return self.public_ip","Returns the best name to display for this host. Uses the instance
        name if available; else just the public IP.

        :rtype: ``str``",
"def add_timestamp(logger_class, log_method, event_dict):
    ''' Attach the event time, as unix epoch '''
    event_dict['timestamp'] = calendar.timegm(time.gmtime())
    return event_dict","Attach the event time, as unix epoch",
"def get_table_width(table):
    """"""
    Gets the width of the table that would be printed.
    :rtype: ``int``
    """"""
    columns = transpose_table(prepare_rows(table))
    widths = [max(len(cell) for cell in column) for column in columns]
    return len('+' + '|'.join('-' * (w + 2) for w in widths) + '+')","Gets the width of the table that would be printed.
    :rtype: ``int``",
"def get_color_hash(string, _min=MIN_COLOR_BRIGHT, _max=MAX_COLOR_BRIGHT):
    """"""
    Hashes a string and returns a number between ``min`` and ``max``.
    """"""
    hash_num = int(hashlib.sha1(string.encode('utf-8')).hexdigest()[:6], 16)
    _range = _max - _min
    num_in_range = hash_num % _range
    return color(_min + num_in_range)",Hashes a string and returns a number between ``min`` and ``max``.,
"def random_color(_min=MIN_COLOR, _max=MAX_COLOR):
    """"""Returns a random color between min and max.""""""
    return color(random.randint(_min, _max))",Returns a random color between min and max.,
"def check_credentials(username, password):
    ''' Verify basic http authentification '''
    user = models.User.objects(
        username=username,
        password=password
    ).first()
    return user or None",Verify basic http authentification,
"def check_token(token):
    ''' Verify http header token authentification '''
    user = models.User.objects(api_key=token).first()
    return user or None",Verify http header token authentification,
"def is_running(process):
    ''' `pgrep` returns an error code if no process was found '''
    try:
        pgrep = sh.Command('/usr/bin/pgrep')
        pgrep(process)
        flag = True
    except sh.ErrorReturnCode_1:
        flag = False
    return flag",`pgrep` returns an error code if no process was found,
"def render(self, name, value, attrs=None):
        """"""Include a hidden input to stored the serialized upload value.""""""
        context = attrs or {}
        context.update({'name': name, 'value': value, })
        return render_to_string(self.template_name, context)",Include a hidden input to stored the serialized upload value.,
"def networkdays(from_date, to_date, locale='en-US'):
    """""" Return the net work days according to RH's calendar. """"""
    holidays = locales[locale]
    return workdays.networkdays(from_date, to_date, holidays)",Return the net work days according to RH's calendar.,
"def _get_path(cmd):
    """"""Queries bash to find the path to a commmand on the system.""""""
    if cmd in _PATHS:
        return _PATHS[cmd]
    out = subprocess.check_output('which {}'.format(cmd), shell=True)
    _PATHS[cmd] = out.decode(""utf-8"").strip()
    return _PATHS[cmd]",Queries bash to find the path to a commmand on the system.,
"def relate(self, part, id=None):
		""""""Relate this package component to the supplied part.""""""
		assert part.name.startswith(self.base)
		name = part.name[len(self.base):].lstrip('/')
		rel = Relationship(self, name, part.rel_type, id=id)
		self.relationships.add(rel)
		return rel",Relate this package component to the supplied part.,
"def related(self, reltype):
		""""""Return a list of parts related to this one via reltype.""""""
		parts = []
		package = getattr(self, 'package', None) or self
		for rel in self.relationships.types.get(reltype, []):
			parts.append(package[posixpath.join(self.base, rel.target)])
		return parts",Return a list of parts related to this one via reltype.,
"def _load_rels(self, source):
		""""""Load relationships from source XML.""""""
		# don't get confused here - the original source is string data;
		#  the parameter source below is a Part object
		self.relationships.load(source=self, data=source)",Load relationships from source XML.,
"def _load_part(self, rel_type, name, data):
		""""""
		Load a part into this package based on its relationship type
		""""""
		if self.content_types.find_for(name) is None:
			log.warning('no content type found for part %(name)s' % vars())
			return
		cls = Part.classes_by_rel_type[rel_type]
		part = cls(self, name)
		part.load(data)
		self[name] = part
		return part",Load a part into this package based on its relationship type,
"def get_parts_by_class(self, cls):
		""""""
		Return all parts of this package that are instances of cls
		(where cls is passed directly to isinstance, so can be a class
		or sequence of classes).
		""""""
		return (part for part in self.parts.values() if isinstance(part, cls))","Return all parts of this package that are instances of cls
		(where cls is passed directly to isinstance, so can be a class
		or sequence of classes).",
"def find_for(self, name):
		""""""
		Get the correct content type for a given name
		""""""
		map = self.items
		# first search the overrides (by name)
		# then fall back to the defaults (by extension)
		# finally, return None if unmatched
		return map.get(name, None) or map.get(get_ext(name) or None, None)",Get the correct content type for a given name,
"def as_stream(self):
		""""""
		Return a zipped package as a readable stream
		""""""
		stream = io.BytesIO()
		self._store(stream)
		stream.seek(0)
		return stream",Return a zipped package as a readable stream,
"def _get_matching_segments(self, zf, name):
		""""""
		Return a generator yielding each of the segments who's names
		match name.
		""""""
		for n in zf.namelist():
			if n.startswith(name):
				yield zf.read(n)","Return a generator yielding each of the segments who's names
		match name.",
"def delete_file(self, filename):
        """"""Delete a file from the bucket.

        Parameters
        ----------
        filename : `str`
            Name of the file, relative to ``bucket_root/``.
        """"""
        key = os.path.join(self._bucket_root, filename)
        objects = list(self._bucket.objects.filter(Prefix=key))
        for obj in objects:
            obj.delete()","Delete a file from the bucket.

        Parameters
        ----------
        filename : `str`
            Name of the file, relative to ``bucket_root/``.",
"def loud(self, lang='englist'):
        """"""Speak loudly! FIVE! Use upper case!""""""
        lang_method = getattr(self, lang, None)
        if lang_method:
            return lang_method().upper()
        else:
            return self.english().upper()",Speak loudly! FIVE! Use upper case!,
"def pm(client, event, channel, nick, rest):
    'Arggh matey'
    if rest:
        rest = rest.strip()
        Karma.store.change(rest, 2)
        rcpt = rest
    else:
        rcpt = channel

    if random.random() > 0.95:
        return f""Arrggh ye be doin' great, grand work, {rcpt}!""
    return f""Arrggh ye be doin' good work, {rcpt}!""",Arggh matey,
"def lm(client, event, channel, nick, rest):
    'Rico Suave'
    if rest:
        rest = rest.strip()
        Karma.store.change(rest, 2)
        rcpt = rest
    else:
        rcpt = channel
    return f'Ests haciendo un buen trabajo, {rcpt}!'",Rico Suave,
"def fm(client, event, channel, nick, rest):
    'pmxbot parle franais'
    if rest:
        rest = rest.strip()
        Karma.store.change(rest, 2)
        rcpt = rest
    else:
        rcpt = channel
    return f'Vous bossez bien, {rcpt}!'",pmxbot parle franais,
"def zorsupas(client, event, channel, nick, rest):
    'Zor supas!  ! '
    if rest:
        rest = rest.strip()
        Karma.store.change(rest, 1)
        rcpt = rest
    else:
        rcpt = channel
    return (
        f'Zor supas {rcpt}, to zor zor barezi! '
        '      '
    )",Zor supas!  ! ,
"def danke(client, event, channel, nick, rest):
    'Danke schn!'
    if rest:
        rest = rest.strip()
        Karma.store.change(rest, 1)
        rcpt = rest
    else:
        rcpt = channel
    return f'Danke schn, {rcpt}! Danke schn!'",Danke schn!,
"def split_all(path):
	""""""
	recursively call os.path.split until we have all of the components
	of a pathname suitable for passing back to os.path.join.
	""""""
	drive, path = os.path.splitdrive(path)
	head, tail = os.path.split(path)
	terminators = [os.path.sep, os.path.altsep, '']
	parts = split_all(head) if head not in terminators else [head]
	return [drive] + parts + [tail]","recursively call os.path.split until we have all of the components
	of a pathname suitable for passing back to os.path.join.",
"def get_editor(filepath):
		""""""
		Give preference to an XML_EDITOR or EDITOR defined in the
		environment. Otherwise use notepad on Windows and edit on other
		platforms.
		""""""
		default_editor = ['edit', 'notepad'][sys.platform.startswith('win32')]
		return os.environ.get(
			'XML_EDITOR',
			os.environ.get('EDITOR', default_editor),
		)","Give preference to an XML_EDITOR or EDITOR defined in the
		environment. Otherwise use notepad on Windows and edit on other
		platforms.",
"def _dict_to_df(self, dictobj, xfield, yfield):
        """"""
        Converts a dictionnary to a pandas dataframe
        """"""
        x = []
        y = []
        for datapoint in dictobj:
            x.append(datapoint)
            y.append(dictobj[datapoint])
        df = pd.DataFrame({xfield[0]: x, yfield[0]: y})
        return df",Converts a dictionnary to a pandas dataframe,
"def text(length, choices=string.ascii_letters):
    """""" returns a random (fixed length) string

    :param length: string length
    :param choices: string containing all the chars can be used to build the string

    .. seealso::
       :py:func:`rtext`
    """"""
    return ''.join(choice(choices) for x in range(length))","returns a random (fixed length) string

    :param length: string length
    :param choices: string containing all the chars can be used to build the string

    .. seealso::
       :py:func:`rtext`",
"def binary(length):
    """"""
        returns a a random string that represent a binary representation

    :param length: number of bits
    """"""
    num = randint(1, 999999)
    mask = '0' * length
    return (mask + ''.join([str(num >> i & 1) for i in range(7, -1, -1)]))[-length:]","returns a a random string that represent a binary representation

    :param length: number of bits",
"def date(start, end):
    """"""Get a random date between two dates""""""

    stime = date_to_timestamp(start)
    etime = date_to_timestamp(end)

    ptime = stime + random.random() * (etime - stime)

    return datetime.date.fromtimestamp(ptime)",Get a random date between two dates,
"def _get_memoized_value(func, args, kwargs):
    """"""Used internally by memoize decorator to get/store function results""""""
    key = (repr(args), repr(kwargs))

    if not key in func._cache_dict:
        ret = func(*args, **kwargs)
        func._cache_dict[key] = ret

    return func._cache_dict[key]",Used internally by memoize decorator to get/store function results,
"def memoize(func):
    """"""Decorator that stores function results in a dictionary to be used on the
    next time that the same arguments were informed.""""""

    func._cache_dict = {}

    @wraps(func)
    def _inner(*args, **kwargs):
        return _get_memoized_value(func, args, kwargs)

    return _inner","Decorator that stores function results in a dictionary to be used on the
    next time that the same arguments were informed.",
"def get_root_argparser(self):
        """"""
        Gets the root argument parser object.
        """"""
        return self.arg_parse_class(description=self.get_help(), formatter_class=self.get_formatter_class())",Gets the root argument parser object.,
"def get_description(self):
        """"""
        Gets the description of the command. If its not supplied the first sentence of the doc string is used.
        """"""
        if self.description:
            return self.description
        elif self.__doc__ and self.__doc__.strip():
            return self.__doc__.strip().split('.')[0] + '.'
        else:
            return ''",Gets the description of the command. If its not supplied the first sentence of the doc string is used.,
"def get_help(self):
        """"""
        Gets the help text for the command. If its not supplied the doc string is used.
        """"""
        if self.help:
            return self.help
        elif self.__doc__ and self.__doc__.strip():
            return self.__doc__.strip()
        else:
            return ''",Gets the help text for the command. If its not supplied the doc string is used.,
"def get_athletes(self):
        """"""Get all available athletes
        This method is cached to prevent unnecessary calls to GC.
        """"""
        response = self._get_request(self.host)
        response_buffer = StringIO(response.text)
        
        return pd.read_csv(response_buffer)","Get all available athletes
        This method is cached to prevent unnecessary calls to GC.",
"def get_last_activities(self, n):
        """"""Get all activity data for the last activity

        Keyword arguments:
        """"""
        filenames = self.get_activity_list().iloc[-n:].filename.tolist()
        last_activities = [self.get_activity(f) for f in filenames]
        return last_activities","Get all activity data for the last activity

        Keyword arguments:",
"def _athlete_endpoint(self, athlete):
        """"""Construct athlete endpoint from host and athlete name

        Keyword arguments:
        athlete -- Full athlete name
        """"""
        return '{host}{athlete}'.format(
            host=self.host,
            athlete=quote_plus(athlete)
        )","Construct athlete endpoint from host and athlete name

        Keyword arguments:
        athlete -- Full athlete name",
"def get_version():
    """"""
    Return package version as listed in `__version__` in `init.py`.
    """"""
    with open(os.path.join(os.path.dirname(__file__), 'argparsetree', '__init__.py')) as init_py:
        return re.search('__version__ = [\'""]([^\'""]+)[\'""]', init_py.read()).group(1)",Return package version as listed in `__version__` in `init.py`.,
"def lookup_color(color):
    """"""
    Returns the hex color for any valid css color name
    
    >>> lookup_color('aliceblue')
    'F0F8FF'
    """"""
    if color is None: return
    color = color.lower()
    if color in COLOR_MAP:
        return COLOR_MAP[color]
    return color","Returns the hex color for any valid css color name
    
    >>> lookup_color('aliceblue')
    'F0F8FF'",
"def color_args(args, *indexes):
    """"""
    Color a list of arguments on particular indexes
    
    >>> c = color_args([None,'blue'], 1)
    >>> c.next()
    None
    >>> c.next()
    '0000FF'
    """"""
    for i,arg in enumerate(args):
        if i in indexes:
            yield lookup_color(arg)
        else:
            yield arg","Color a list of arguments on particular indexes
    
    >>> c = color_args([None,'blue'], 1)
    >>> c.next()
    None
    >>> c.next()
    '0000FF'",
"def tick(self, index, length):
        """"""
        Add tick marks in order of axes by width
        APIPARAM: chxtc     <axis index>,<length of tick mark>
        """"""
        assert int(length) <= 25, 'Width cannot be more than 25'
        self.data['ticks'].append('%s,%d'%(index,length))
        return self.parent","Add tick marks in order of axes by width
        APIPARAM: chxtc     <axis index>,<length of tick mark>",
"def type(self, atype):
        """"""
        Define the type of axes you wish to use
        atype must be one of x,t,y,r
        APIPARAM: chxt
        """"""
        for char in atype:
            assert char in 'xtyr', 'Invalid axes type: %s'%char
        if not ',' in atype:
            atype = ','.join(atype)
        self['chxt'] = atype
        return self.parent","Define the type of axes you wish to use
        atype must be one of x,t,y,r
        APIPARAM: chxt",
"def label(self, index, *args):
        """"""
        Label each axes one at a time
        args are of the form <label 1>,...,<label n>
        APIPARAM: chxl
        """"""
        self.data['labels'].append(
            str('%s:|%s'%(index, '|'.join(map(str,args)) )).replace('None','')
        )
        return self.parent","Label each axes one at a time
        args are of the form <label 1>,...,<label n>
        APIPARAM: chxl",
"def range(self, index, *args):
        """"""
        Set the range of each axis, one at a time
        args are of the form <start of range>,<end of range>,<interval>
        APIPARAM: chxr
        """"""
        self.data['ranges'].append('%s,%s'%(index,
                                    ','.join(map(smart_str, args))))
        return self.parent","Set the range of each axis, one at a time
        args are of the form <start of range>,<end of range>,<interval>
        APIPARAM: chxr",
"def render(self):
        """"""Render the axes data into the dict data""""""
        for opt,values in self.data.items():
            if opt == 'ticks':
                self['chxtc'] = '|'.join(values)
            else:
                self['chx%s'%opt[0]] = '|'.join(values)
        return self",Render the axes data into the dict data,
"def dataset(self, data, series=''):
        """"""
        Update the chart's dataset, can be two dimensional or contain string data
        """"""
        self._dataset = data
        self._series = series
        return self","Update the chart's dataset, can be two dimensional or contain string data",
"def line(self, *args):
        """"""
        Called one at a time for each dataset
        args are of the form::
            <data set n line thickness>,
            <length of line segment>,
            <length of blank segment>
        APIPARAM: chls
        """"""
        self.lines.append(','.join(['%.1f'%x for x in map(float,args)]))
        return self","Called one at a time for each dataset
        args are of the form::
            <data set n line thickness>,
            <length of line segment>,
            <length of blank segment>
        APIPARAM: chls",
"def color(self, *args):
        """"""
        Add a color for each dataset
        args are of the form <color 1>,...<color n>
        APIPARAM: chco
        """"""
        args = color_args(args, *range(len(args)))
        self['chco'] = ','.join(args)
        return self","Add a color for each dataset
        args are of the form <color 1>,...<color n>
        APIPARAM: chco",
"def label(self, *args):
        """"""
        Add a simple label to your chart
        call each time for each dataset
        APIPARAM: chl
        """"""
        if self['cht'] == 'qr':
            self['chl'] = ''.join(map(str,args))
        else:
            self['chl'] = '|'.join(map(str,args))
        return self","Add a simple label to your chart
        call each time for each dataset
        APIPARAM: chl",
"def legend_pos(self, pos):
        """"""
        Define a position for your legend to occupy
        APIPARAM: chdlp
        """"""
        assert pos in LEGEND_POSITIONS, 'Unknown legend position: %s'%pos
        self['chdlp'] = str(pos)
        return self","Define a position for your legend to occupy
        APIPARAM: chdlp",
"def title(self, title, *args):
        """"""
        Add a title to your chart
        args are optional style params of the form <color>,<font size>
        APIPARAMS: chtt,chts
        """"""
        self['chtt'] = title
        if args:
            args = color_args(args, 0)
            self['chts'] = ','.join(map(str,args))
        return self","Add a title to your chart
        args are optional style params of the form <color>,<font size>
        APIPARAMS: chtt,chts",
"def size(self,*args):
        """"""
        Set the size of the chart, args are width,height and can be tuple
        APIPARAM: chs
        """"""
        if len(args) == 2:
            x,y = map(int,args)
        else:
            x,y = map(int,args[0])
        self.check_size(x,y)
        self['chs'] = '%dx%d'%(x,y)
        return self","Set the size of the chart, args are width,height and can be tuple
        APIPARAM: chs",
"def url(self):
        """"""
        Returns the rendered URL of the chart
        """"""
        self.render()        
        return self._apiurl + '&'.join(self._parts()).replace(' ','+')",Returns the rendered URL of the chart,
"def show(self, *args, **kwargs):
        """"""
        Shows the chart URL in a webbrowser

        Other arguments passed to webbrowser.open
        """"""
        from webbrowser import open as webopen
        return webopen(str(self), *args, **kwargs)","Shows the chart URL in a webbrowser

        Other arguments passed to webbrowser.open",
"def urlopen(self):
        """"""
        Grabs readable PNG file pointer
        """"""
        req = Request(str(self))
        try:
            return urlopen(req)
        except HTTPError:
            _print('The server couldn\'t fulfill the request.')
        except URLError:
            _print('We failed to reach a server.')",Grabs readable PNG file pointer,
"def write(self, fp):
        """"""
        Writes out PNG image data in chunks to file pointer fp

        fp must support w or wb
        """"""
        urlfp = self.urlopen().fp
        while 1:
            try:
                fp.write(urlfp.next())
            except StopIteration:
                return","Writes out PNG image data in chunks to file pointer fp

        fp must support w or wb",
"def checksum(self):
        """"""
        Returns the unique SHA1 hexdigest of the chart URL param parts

        good for unittesting...
        """"""
        self.render()
        return new_sha(''.join(sorted(self._parts()))).hexdigest()","Returns the unique SHA1 hexdigest of the chart URL param parts

        good for unittesting...",
"def amount(min=1, max=sys.maxsize, decimal_places=2):
    """"""
        return a random floating number

    :param min: minimum value
    :param max: maximum value
    :param decimal_places: decimal places
    :return:
    """"""
    q = '.%s1' % '0' * (decimal_places - 1)
    return decimal.Decimal(uniform(min, max)).quantize(decimal.Decimal(q))","return a random floating number

    :param min: minimum value
    :param max: maximum value
    :param decimal_places: decimal places
    :return:",
"def signing_keys_as_jwks(self):
        """"""
        Build a JWKS from the signing keys belonging to the self signer

        :return: Dictionary
        """"""
        _l = [x.serialize() for x in self.self_signer.keyjar.get_signing_key()]
        if not _l:
            _l = [x.serialize() for x in
                  self.self_signer.keyjar.get_signing_key(owner=self.iss)]
        return {'keys': _l}","Build a JWKS from the signing keys belonging to the self signer

        :return: Dictionary",
"def verbose(self, msg, *args, **kwargs):
        """"""Log msg at 'verbose' level, debug < verbose < info""""""
        self.log(logging.VERBOSE, msg, *args, **kwargs)","Log msg at 'verbose' level, debug < verbose < info",
"def lessons(self):
        """"""
        lessons,``get_lesson()``

        :return: list of lessons
        :rtype: list
        """"""
        if hasattr(self, '_lessons'):
            return self._lessons
        else:
            self.get_lesson()
            return self._lessons","lessons,``get_lesson()``

        :return: list of lessons
        :rtype: list",
"def detail(self):
        """"""
        ,``get_detail()``

        :return: information of student
        :rtype: dict
        """"""
        if hasattr(self, '_detail'):
            return self._detail
        else:
            self.get_detail()
            return self._detail",",``get_detail()``

        :return: information of student
        :rtype: dict",
"def _letter_map(word):
    """"""Creates a map of letter use in a word.

    Args:
        word: a string to create a letter map from

    Returns:
        a dictionary of {letter: integer count of letter in word}
    """"""

    lmap = {}
    for letter in word:
        try:
            lmap[letter] += 1
        except KeyError:
            lmap[letter] = 1
    return lmap","Creates a map of letter use in a word.

    Args:
        word: a string to create a letter map from

    Returns:
        a dictionary of {letter: integer count of letter in word}",
"def asAMP(cls):
        """"""
        Returns the exception's name in an AMP Command friendly format.

        For example, given a class named ``ExampleExceptionClass``, returns
        ``""EXAMPLE_EXCEPTION_CLASS""``.
        """"""
        parts = groupByUpperCase(cls.__name__)
        return cls, ""_"".join(part.upper() for part in parts)","Returns the exception's name in an AMP Command friendly format.

        For example, given a class named ``ExampleExceptionClass``, returns
        ``""EXAMPLE_EXCEPTION_CLASS""``.",
"def get_last_value_from_timeseries(timeseries):
    """"""Gets the most recent non-zero value for a .last metric or zero
    for empty data.""""""
    if not timeseries:
        return 0
    for metric, points in timeseries.items():
        return next((p['y'] for p in reversed(points) if p['y'] > 0), 0)","Gets the most recent non-zero value for a .last metric or zero
    for empty data.",
"def validate_page_number(number):
    """"""Validate the given 1-based page number.""""""
    try:
        number = int(number)
    except (TypeError, ValueError):
        raise PageNotAnInteger('That page number is not an integer')
    if number < 1:
        raise EmptyPage('That page number is less than 1')
    return number",Validate the given 1-based page number.,
"def sh(cmd, escape=True):
    """""" Executes the given command.
    returns a 2-tuple with returncode (integer) and OUTPUT (string)
    """"""

    if escape:
        cmd = quote(cmd)

    process = Popen(cmd, stdout=PIPE, stderr=STDOUT, shell=True)
    output, unused_err = process.communicate()
    retcode = process.poll()

    return (retcode, output)","Executes the given command.
    returns a 2-tuple with returncode (integer) and OUTPUT (string)",
"def gzip(filename):
    """""" Gzip a file
    returns a 3-tuple with returncode (integer), terminal output (string)
    and the new filename.
    """"""

    ## run gzip
    retcode, output = sh('gzip %s' % filename)
    new_filename = filename+'.gz'

    return (retcode, output, new_filename)","Gzip a file
    returns a 3-tuple with returncode (integer), terminal output (string)
    and the new filename.",
"def chown(path, uid, guid, recursive=True):
    """""" alternative to os.chown.
        wraps around unix chown
        example:
            chown('/tmp/test/', bob, bob)

        returns 2-tuple: exitcode and terminal output
    """"""

    if recursive:
        cmd = 'chown -R %s:%s %s' % (uid, guid, path)
    else:
        cmd = 'chown %s:%s %s' % (uid, guid, path)

    return sh(cmd)","alternative to os.chown.
        wraps around unix chown
        example:
            chown('/tmp/test/', bob, bob)

        returns 2-tuple: exitcode and terminal output",
"def chmod(path, mode, recursive=True):
    """""" alternative to os.
    """"""

    if recursive:
        cmd = 'chmod -R %s %s' % (mode, path)
    else:
        cmd = 'chmod %s %s' % (mode, path)

    return sh(cmd)",alternative to os.,
"def update_signature(self, location):
        """"""
        Uses GET to get a newly signed metadata statement.

        :param location: A URL to which the request is sent
        :return: returns a dictionary with 'sms' and 'loc' as keys.
        """"""
        response = requests.get(location, **self.req_args())
        return self.parse_response(response)","Uses GET to get a newly signed metadata statement.

        :param location: A URL to which the request is sent
        :return: returns a dictionary with 'sms' and 'loc' as keys.",
"def urls_for(self, asset_type, *args, **kwargs):
        """"""Returns urls needed to include all assets of asset_type
        """"""
        return self.urls_for_depends(asset_type, *args, **kwargs) + \
               self.urls_for_self(asset_type, *args, **kwargs)",Returns urls needed to include all assets of asset_type,
"def html_tags(self, *args, **kwargs):
        """"""Return all html tags for all asset_type
        """"""
        html = []
        for asset_type in list_asset_types():
            html.append(self.html_tags_for(asset_type.name, *args, **kwargs))
        return ""\n"".join(html)",Return all html tags for all asset_type,
"def find_version(filename):
    """"""Uses re to pull out the assigned value to __version__ in filename.""""""

    with io.open(filename, encoding=""utf-8"") as version_file:
        version_match = re.search(r'^__version__ = [\'""]([^\'""]*)[\'""]',
                                  version_file.read(), re.M)
    if version_match:
        return version_match.group(1)
    return ""0.0-version-unknown""",Uses re to pull out the assigned value to __version__ in filename.,
"def _connected(client):
    """"""
    Connected to AMP server, start listening locally, and give the AMP
    client a reference to the local listening factory.
    """"""
    log.msg(""Connected to AMP server, starting to listen locally..."")
    localFactory = multiplexing.ProxyingFactory(client, ""hello"")
    return listeningEndpoint.listen(localFactory)","Connected to AMP server, start listening locally, and give the AMP
    client a reference to the local listening factory.",
"def import_modules(self):
        """"""Import customer's service module.""""""
        modules = self.get_modules()
        log.info(""import service modules: "" + str(modules))
        try:
            for module in modules:
                __import__(module)
        except ImportError as error:
            raise ImportModulesError(error.msg)",Import customer's service module.,
"def output(self, fieldNames=None, datemap=None, time_format=None):
        '''
        Output all fields using the fieldNames list. for fields in the list datemap indicates the field must
        be date
        '''

        count = self.printCursor(self._cursor, fieldNames, datemap, time_format)","Output all fields using the fieldNames list. for fields in the list datemap indicates the field must
        be date",
"def path(self):
        """"""Return path

        :returns: path
        :rtype: str
        :raises: None
        """"""
        p = os.path.normpath(self._path)
        if p.endswith(':'):
            p = p + os.path.sep
        return p","Return path

        :returns: path
        :rtype: str
        :raises: None",
"def path(self, value):
        """"""Set path

        :param value: The value for path
        :type value: str
        :raises: None
        """"""
        prepval = value.replace('\\', '/')
        self._path = posixpath.normpath(prepval)
        if self._path.endswith(':'):
            self._path = self._path + posixpath.sep","Set path

        :param value: The value for path
        :type value: str
        :raises: None",
"def clean(self, ):
        """"""Reimplemented from :class:`models.Model`. Check if startframe is before endframe

        :returns: None
        :rtype: None
        :raises: ValidationError
        """"""
        if self.startframe > self.endframe:
            raise ValidationError(""Shot starts before it ends: Framerange(%s - %s)"" % (self.startframe, self.endframe))","Reimplemented from :class:`models.Model`. Check if startframe is before endframe

        :returns: None
        :rtype: None
        :raises: ValidationError",
"def path(self, value):
        """"""Set path

        :param value: The value for path
        :type value: str
        :raises: None
        """"""
        prepval = value.replace('\\', '/')
        self._path = posixpath.normpath(prepval)","Set path

        :param value: The value for path
        :type value: str
        :raises: None",
"def addFactory(self, identifier, factory):
        """"""Adds a factory.

        After calling this method, remote clients will be able to
        connect to it.

        This will call ``factory.doStart``.

        """"""
        factory.doStart()
        self._factories[identifier] = factory","Adds a factory.

        After calling this method, remote clients will be able to
        connect to it.

        This will call ``factory.doStart``.",
"def removeFactory(self, identifier):
        """"""Removes a factory.

        After calling this method, remote clients will no longer be
        able to connect to it.

        This will call the factory's ``doStop`` method.

        """"""
        factory = self._factories.pop(identifier)
        factory.doStop()
        return factory","Removes a factory.

        After calling this method, remote clients will no longer be
        able to connect to it.

        This will call the factory's ``doStop`` method.",
"def receiveData(self, connection, data):
        """"""
        Receives some data for the given protocol.
        """"""
        try:
            protocol = self._protocols[connection]
        except KeyError:
            raise NoSuchConnection()

        protocol.dataReceived(data)
        return {}",Receives some data for the given protocol.,
"def disconnect(self, connection):
        """"""
        Disconnects the given protocol.
        """"""
        proto = self._protocols.pop(connection)
        proto.transport = None
        return {}",Disconnects the given protocol.,
"def _callRemote(self, command, **kwargs):
        """"""Shorthand for ``callRemote``.

        This uses the factory's connection to the AMP peer.

        """"""
        return self.factory.remote.callRemote(command, **kwargs)","Shorthand for ``callRemote``.

        This uses the factory's connection to the AMP peer.",
"def _sendData(self, data):
        """"""Actually sends data over the wire.

        """"""
        d = self._callRemote(Transmit, connection=self.connection, data=data)
        d.addErrback(log.err)",Actually sends data over the wire.,
"def connectionLost(self, reason):
        """"""If we already have an AMP connection registered on the factory,
        get rid of it.

        """"""
        if self.connection is not None:
            del self.factory.protocols[self.connection]","If we already have an AMP connection registered on the factory,
        get rid of it.",
"def getLocalProtocol(self, connectionIdentifier):
        """"""Attempts to get a local protocol by connection identifier.

        """"""
        for factory in self.localFactories:
            try:
                return factory.protocols[connectionIdentifier]
            except KeyError:
                continue

        raise NoSuchConnection()",Attempts to get a local protocol by connection identifier.,
"def remoteDataReceived(self, connection, data):
        """"""Some data was received from the remote end. Find the matching
        protocol and replay it.

        """"""
        proto = self.getLocalProtocol(connection)
        proto.transport.write(data)
        return {}","Some data was received from the remote end. Find the matching
        protocol and replay it.",
"def disconnect(self, connection):
        """"""The other side has asked us to disconnect.

        """"""
        proto = self.getLocalProtocol(connection)
        proto.transport.loseConnection()
        return {}",The other side has asked us to disconnect.,
"def enqueue(self, s):
        """"""
        Append `s` to the queue.
        
        Equivalent to::
        
            queue += s
            
        if `queue` where a regular string.
        """"""
        self._parts.append(s)
        self._len += len(s)","Append `s` to the queue.
        
        Equivalent to::
        
            queue += s
            
        if `queue` where a regular string.",
"def clock_on_right(mystring):
    '''Takes a string, and prints it with the time right aligned'''
    taken = length_no_ansi(mystring)
    padding = (get_terminal_size().columns - 1) - taken - 5
    clock = time.strftime(""%I:%M"", time.localtime())
    print(mystring + "" ""*padding + clock)","Takes a string, and prints it with the time right aligned",
"def wait(sec):
    '''
    Prints a timer with the format 0:00 to the console,
    and then clears the line when the timer is done
    '''
    while sec > 0:
        sys.stdout.write('\r' + str(sec//60).zfill(1) + "":"" +
                         str(sec % 60).zfill(2) + '     ')
        sec -= 1
        time.sleep(1)
        sys.stdout.write('\r' + '           ' + '\r')","Prints a timer with the format 0:00 to the console,
    and then clears the line when the timer is done",
"def main(arguments=None):
    """"""Main command line entry point.""""""

    if not arguments:
        arguments = sys.argv[1:]

    wordlist, sowpods, by_length, start, end = argument_parser(arguments)
    for word in wordlist:
        pretty_print(
            word,
            anagrams_in_word(word, sowpods, start, end),
            by_length,
        )",Main command line entry point.,
"def on_unregistered_type(self, typekey, packet):
        """"""
        Invoked if a packet with an unregistered type was received.
        
        Default behaviour is to log and close the connection.
        """"""
        log.msg(""Missing handler for typekey %s in %s. Closing connection."" % (typekey, type(self).__name__))
        self.transport.loseConnection()","Invoked if a packet with an unregistered type was received.
        
        Default behaviour is to log and close the connection.",
"def _ping(self, peerid, callid):
        """"""
        Called from remote to ask if a call made to here is still in progress.
        """"""
        if not (peerid, callid) in self._remote_to_local:
            logger.warn(""No remote call %s from %s. Might just be unfoutunate timing."" % (callid, peerid))",Called from remote to ask if a call made to here is still in progress.,
"def fromStringProto(self, inString, proto):
        """"""
        Defers to `amp.AmpList`, then gets the element from the list.
        """"""
        value, = amp.AmpList.fromStringProto(self, inString, proto)
        return value","Defers to `amp.AmpList`, then gets the element from the list.",
"def toStringProto(self, inObject, proto):
        """"""
        Wraps the object in a list, and then defers to ``amp.AmpList``.
        """"""
        return amp.AmpList.toStringProto(self, [inObject], proto)","Wraps the object in a list, and then defers to ``amp.AmpList``.",
"def unfurl(jwt):
    """"""
    Return the body of a signed JWT, without verifying the signature.
    
    :param jwt: A signed JWT 
    :return: The body of the JWT as a 'UTF-8' string
    """"""

    _rp_jwt = factory(jwt)
    return json.loads(_rp_jwt.jwt.part[1].decode('utf8'))","Return the body of a signed JWT, without verifying the signature.
    
    :param jwt: A signed JWT 
    :return: The body of the JWT as a 'UTF-8' string",
"def read_jwks_file(jwks_file):
    """"""
    Reads a file containing a JWKS and populates a
    :py:class:`oidcmsg.key_jar.KeyJar` from it.

    :param jwks_file: file name of the JWKS file 
    :return: A :py:class:`oidcmsg.key_jar.KeyJar` instance
    """"""
    _jwks = open(jwks_file, 'r').read()
    _kj = KeyJar()
    _kj.import_jwks(json.loads(_jwks), '')
    return _kj","Reads a file containing a JWKS and populates a
    :py:class:`oidcmsg.key_jar.KeyJar` from it.

    :param jwks_file: file name of the JWKS file 
    :return: A :py:class:`oidcmsg.key_jar.KeyJar` instance",
"def sync(self, folders):
        """"""Syncs a list of folders to their assicated buckets.
        
        folders: A list of 2-tuples in the form (folder, bucket)
        """"""
        if not folders:
            raise ValueError(""No folders to sync given"")
        for folder in folders:
            self.sync_folder(*folder)","Syncs a list of folders to their assicated buckets.
        
        folders: A list of 2-tuples in the form (folder, bucket)",
"def build(cli, path, package):
    """"""Build CLI dynamically based on the package structure.
    """"""
    for _, name, ispkg in iter_modules(path):
        module = import_module(f'.{name}', package)
        if ispkg:
            build(cli.group(name)(module.group),
                  module.__path__,
                  module.__package__)
        else:
            cli.command(name)(module.command)",Build CLI dynamically based on the package structure.,
"def readonly(cls, *args, **kwargs):
        """"""
        Return an already closed read-only instance of Fridge.
        Arguments are the same as for the constructor.
        """"""
        fridge = cls(*args, **kwargs)
        fridge.close()
        return fridge","Return an already closed read-only instance of Fridge.
        Arguments are the same as for the constructor.",
"def save(self):
        """"""
        Force saving the dictionary to the file.
        All data in the file is discarded.
        This method is called automatically by :meth:`close`.
        """"""
        self._check_open()
        self.file.truncate(0)
        self.file.seek(0)
        json.dump(self, self.file, **self.dump_args)","Force saving the dictionary to the file.
        All data in the file is discarded.
        This method is called automatically by :meth:`close`.",
"def card(func):
    """"""
    A decorator for providing a unittesting function/method with every card in
    a librarian card library database when it is called.
    """"""
    @wraps(func)
    def wrapped(*args, **kwargs):
        """"""Transparent wrapper.""""""
        return func(*args, **kwargs)
    TESTS.append(wrapped)
    return wrapped","A decorator for providing a unittesting function/method with every card in
    a librarian card library database when it is called.",
"def library(func):
    """"""
    A decorator for providing a unittest with a library and have it called only
    once.
    """"""
    @wraps(func)
    def wrapped(*args, **kwargs):
        """"""Transparent wrapper.""""""
        return func(*args, **kwargs)
    SINGLES.append(wrapped)
    return wrapped","A decorator for providing a unittest with a library and have it called only
    once.",
"def cli_run():
    """"""docstring for argparse""""""
    parser = argparse.ArgumentParser(description='Stupidly simple code answers from StackOverflow')
    parser.add_argument('query', help=""What's the problem ?"", type=str, nargs='+')
    parser.add_argument('-t','--tags', help='semicolon separated tags -> python;lambda')
    args = parser.parse_args()
    main(args)",docstring for argparse,
"def _writeResponse(self, response):
        """"""
        Serializes the response to JSON, and writes it to the transport.
        """"""
        encoded = dumps(response, default=_default)
        self.transport.write(encoded)","Serializes the response to JSON, and writes it to the transport.",
"def connectionLost(self, reason):
        """"""
        Tells the box receiver to stop receiving boxes.
        """"""
        self._remote.boxReceiver.stopReceivingBoxes(reason)
        return basic.NetstringReceiver.connectionLost(self, reason)",Tells the box receiver to stop receiving boxes.,
"def buildProtocol(self, addr):
        """"""
        Builds a bridge and associates it with an AMP protocol instance.
        """"""
        proto = self._factory.buildProtocol(addr)
        return JSONAMPDialectReceiver(proto)",Builds a bridge and associates it with an AMP protocol instance.,
"def make_shortcut(cmd):
    """"""return a function which runs the given cmd
    
    make_shortcut('ls') returns a function which executes
    envoy.run('ls ' + arguments)""""""
    def _(cmd_arguments, *args, **kwargs):
        return run(""%s %s"" % (cmd, cmd_arguments), *args, **kwargs)
    return _","return a function which runs the given cmd
    
    make_shortcut('ls') returns a function which executes
    envoy.run('ls ' + arguments)",
"def pout(msg, log=None):
    """"""Print 'msg' to stdout, and option 'log' at info level.""""""
    _print(msg, sys.stdout, log_func=log.info if log else None)","Print 'msg' to stdout, and option 'log' at info level.",
"def perr(msg, log=None):
    """"""Print 'msg' to stderr, and option 'log' at info level.""""""
    _print(msg, sys.stderr, log_func=log.error if log else None)","Print 'msg' to stderr, and option 'log' at info level.",
"def register(CommandSubClass):
    """"""A class decorator for Command classes to register in the default set.""""""
    name = CommandSubClass.name()
    if name in Command._all_commands:
        raise ValueError(""Command already exists: "" + name)
    Command._all_commands[name] = CommandSubClass
    return CommandSubClass",A class decorator for Command classes to register in the default set.,
"def toString(self, value):
        """"""
        If all of the constraints are satisfied with the given value, defers
        to the composed AMP argument's ``toString`` method.
        """"""
        self._checkConstraints(value)
        return self.baseArgument.toString(value)","If all of the constraints are satisfied with the given value, defers
        to the composed AMP argument's ``toString`` method.",
"def fromString(self, string):
        """"""
        Converts the string to a value using the composed AMP argument, then
        checks all the constraints against that value.
        """"""
        value = self.baseArgument.fromString(string)
        self._checkConstraints(value)
        return value","Converts the string to a value using the composed AMP argument, then
        checks all the constraints against that value.",
"def work(self):
        """"""
        Start ternya work.

        First, import customer's service modules.
        Second, init openstack mq.
        Third, keep a ternya connection that can auto-reconnect.
        """"""
        self.init_modules()
        connection = self.init_mq()
        TernyaConnection(self, connection).connect()","Start ternya work.

        First, import customer's service modules.
        Second, init openstack mq.
        Third, keep a ternya connection that can auto-reconnect.",
"def init_mq(self):
        """"""Init connection and consumer with openstack mq.""""""
        mq = self.init_connection()
        self.init_consumer(mq)
        return mq.connection",Init connection and consumer with openstack mq.,
"def init_modules(self):
        """"""Import customer's service modules.""""""
        if not self.config:
            raise ValueError(""please read your config file."")

        log.debug(""begin to import customer's service modules."")
        modules = ServiceModules(self.config)
        modules.import_modules()
        log.debug(""end to import customer's service modules."")",Import customer's service modules.,
"def load_name(self, name):
        """"""
        Implementation of the LOAD_NAME operation
        """"""
        if name in self.globals_:
            return self.globals_[name]
        
        b = self.globals_['__builtins__']
        if isinstance(b, dict):
            return b[name]
        else:
            return getattr(b, name)",Implementation of the LOAD_NAME operation,
"def pop(self, n):
        """"""
        Pop the **n** topmost items from the stack and return them as a ``list``.
        """"""
        poped = self.__stack[len(self.__stack) - n:]
        del self.__stack[len(self.__stack) - n:]
        return poped",Pop the **n** topmost items from the stack and return them as a ``list``.,
"def _connection(username=None, password=None, host=None, port=None):
    ""returns a connected cursor to the database-server.""

    c_opts = {}

    if username: c_opts['user'] = username
    if password: c_opts['passwd'] = password
    if host: c_opts['host'] = host
    if port: c_opts['port'] = port

    dbc = MySQLdb.connect(**c_opts)
    dbc.autocommit(True)
    return dbc",returns a connected cursor to the database-server.,
"def _atexit(self):
        """"""Invoked in the 'finally' block of Application.run.""""""
        self.log.debug(""Application._atexit"")
        if self._atexit_func:
            self._atexit_func(self)",Invoked in the 'finally' block of Application.run.,
"def cd(path):
    """"""Context manager that changes to directory `path` and return to CWD
    when exited.
    """"""
    old_path = os.getcwd()
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(old_path)","Context manager that changes to directory `path` and return to CWD
    when exited.",
"def debugger():
    """"""If called in the context of an exception, calls post_mortem; otherwise
    set_trace.
    ``ipdb`` is preferred over ``pdb`` if installed.
    """"""
    e, m, tb = sys.exc_info()
    if tb is not None:
        _debugger.post_mortem(tb)
    else:
        _debugger.set_trace()","If called in the context of an exception, calls post_mortem; otherwise
    set_trace.
    ``ipdb`` is preferred over ``pdb`` if installed.",
"def keys(self):
        """"""
        Implements the dict.keys() method
        """"""
        self.sync()
        for k in self.db.keys():
            try:
                yield self.key_conv['from'](k)
            except KeyError:
                yield k",Implements the dict.keys() method,
"def items(self):
        """"""
        Implements the dict.items() method
        """"""
        self.sync()
        for k, v in self.db.items():
            try:
                yield self.key_conv['from'](k), v
            except KeyError:
                yield k, v",Implements the dict.items() method,
"def clear(self):
        """"""
        Completely resets the database. This means that all information in
        the local cache and on disc will be erased.
        """"""
        if not os.path.isdir(self.fdir):
            os.makedirs(self.fdir, exist_ok=True)
            return

        for f in os.listdir(self.fdir):
            del self[f]","Completely resets the database. This means that all information in
        the local cache and on disc will be erased.",
"def update(self, ava):
        """"""
        Implements the dict.update() method
        """"""
        for key, val in ava.items():
            self[key] = val",Implements the dict.update() method,
"def hex(x):
    '''
    x-->bytes | bytearray
    Returns-->bytes: hex-encoded
    '''
    if isinstance(x, bytearray):
        x = bytes(x)
    return encode(x, 'hex')","x-->bytes | bytearray
    Returns-->bytes: hex-encoded",
"def fromBytes(x):
    '''
    x-->unicode string | bytearray | bytes
    Returns-->unicode string, with encoding=latin1
    '''
    if isinstance(x, unicode):
        return x
    if isinstance(x, bytearray):
        x = bytes(x)
    elif isinstance(x, bytes):
        pass
    else:
        return x  # unchanged (int etc)
    return decode(x, DEF_ENCODING)","x-->unicode string | bytearray | bytes
    Returns-->unicode string, with encoding=latin1",
"def get_rand_bytes(encoding='latin1', l=64, avoid=[]):
    '''
    encoding-->str: one of ENCODINGS
    l-->int: length of unicode str
    avoid-->list of int: to void (unprintable chars etc)
    Returns-->bytes representing unicode str of the requested encoding
    '''
    return encode(
        get_rand_str(encoding=encoding, l=l, avoid=avoid),
        encoding=encoding
    )","encoding-->str: one of ENCODINGS
    l-->int: length of unicode str
    avoid-->list of int: to void (unprintable chars etc)
    Returns-->bytes representing unicode str of the requested encoding",
"def is_global(pe_pe):
    '''
    Check if a PE_PE is globally defined, i.e. not inside a C_C
    '''
    if type(pe_pe).__name__ != 'PE_PE':
        pe_pe = one(pe_pe).PE_PE[8001]()
    
    if one(pe_pe).C_C[8003]():
        return False
    
    pe_pe = one(pe_pe).EP_PKG[8000].PE_PE[8001]()
    if not pe_pe:
        return True
    
    return is_global(pe_pe)","Check if a PE_PE is globally defined, i.e. not inside a C_C",
"def get_attribute_type(o_attr):
    '''
    Get the base data type (S_DT) associated with a BridgePoint attribute.
    '''
    ref_o_attr = one(o_attr).O_RATTR[106].O_BATTR[113].O_ATTR[106]()
    if ref_o_attr:
        return get_attribute_type(ref_o_attr)
    else:
        return one(o_attr).S_DT[114]()",Get the base data type (S_DT) associated with a BridgePoint attribute.,
"def _get_data_type_name(s_dt):
    '''
    Convert a BridgePoint data type to a pyxtuml meta model type.
    '''
    s_cdt = one(s_dt).S_CDT[17]()
    if s_cdt and s_cdt.Core_Typ in range(1, 6):
        return s_dt.Name.upper()
    
    if one(s_dt).S_EDT[17]():
        return 'INTEGER'
    
    s_dt = one(s_dt).S_UDT[17].S_DT[18]()
    if s_dt:
        return _get_data_type_name(s_dt)",Convert a BridgePoint data type to a pyxtuml meta model type.,
"def mk_bridge(metamodel, s_brg):
    '''
    Create a python function from a BridgePoint bridge.
    '''
    action = s_brg.Action_Semantics_internal
    label = s_brg.Name
    return lambda **kwargs: interpret.run_function(metamodel, label, 
                                                   action, kwargs)",Create a python function from a BridgePoint bridge.,
"def mk_function(metamodel, s_sync):
    '''
    Create a python function from a BridgePoint function.
    '''
    action = s_sync.Action_Semantics_internal
    label = s_sync.Name
    return lambda **kwargs: interpret.run_function(metamodel, label, 
                                                   action, kwargs)",Create a python function from a BridgePoint function.,
"def mk_association(m, r_rel):
    '''
    Create a pyxtuml association from a R_REL in ooaofooa.
    '''
    handler = {
        'R_SIMP': mk_simple_association,
        'R_ASSOC': mk_linked_association,
        'R_SUBSUP': mk_subsuper_association,
        'R_COMP': mk_derived_association,
    }
    inst = subtype(r_rel, 206)
    fn = handler.get(type(inst).__name__)
    return fn(m, inst)",Create a pyxtuml association from a R_REL in ooaofooa.,
"def load_metamodel(resource=None, load_globals=True):
    '''
    Load and return a metamodel expressed in ooaofooa from a *resource*.
    The resource may be either a filename, a path, or a list of filenames
    and/or paths.
    '''
    loader = _mk_loader(resource, load_globals)
    return loader.build_metamodel()","Load and return a metamodel expressed in ooaofooa from a *resource*.
    The resource may be either a filename, a path, or a list of filenames
    and/or paths.",
"def load_component(resource, name=None, load_globals=True):
    '''
    Load and return a model from a *resource*. The resource may be either a
    filename, a path, or a list of filenames and/or paths.
    '''
    loader = _mk_loader(resource, load_globals)
    return loader.build_component()","Load and return a model from a *resource*. The resource may be either a
    filename, a path, or a list of filenames and/or paths.",
"def accept(self, reply_socket, channel):
        """"""Sends ACCEPT reply.""""""
        info = self.info or b''
        self.send_raw(reply_socket, ACCEPT, info, *channel)",Sends ACCEPT reply.,
"def reject(self, reply_socket, call_id, topics=()):
        """"""Sends REJECT reply.""""""
        info = self.info or b''
        self.send_raw(reply_socket, REJECT, info, call_id, b'', topics)",Sends REJECT reply.,
"def file_input(self, file_object):
        '''
        Read and parse data from a *file object*, i.e. the type of object 
        returned by the builtin python function *open()*.
        '''
        return self.input(file_object.read(), name=file_object.name)","Read and parse data from a *file object*, i.e. the type of object 
        returned by the builtin python function *open()*.",
"def populate_classes(self, metamodel):
        '''
        Populate a *metamodel* with classes previously encountered from input.
        '''
        for stmt in self.statements:
            if isinstance(stmt, CreateClassStmt):
                metamodel.define_class(stmt.kind, stmt.attributes)",Populate a *metamodel* with classes previously encountered from input.,
"def populate(self, metamodel):
        '''
        Populate a *metamodel* with entities previously encountered from input.
        '''
        self.populate_classes(metamodel)
        self.populate_unique_identifiers(metamodel)
        self.populate_associations(metamodel)
        self.populate_instances(metamodel)
        self.populate_connections(metamodel)",Populate a *metamodel* with entities previously encountered from input.,
"def build_metamodel(self, id_generator=None):
        '''
        Build and return a *xtuml.MetaModel* containing previously loaded input.
        '''
        m = xtuml.MetaModel(id_generator)
        
        self.populate(m)
        
        return m",Build and return a *xtuml.MetaModel* containing previously loaded input.,
"def t_COMMA(self, t):
        r','
        t.endlexpos = t.lexpos + len(t.value)
        return t","r',",
"def t_FRACTION(self, t):
        r'(\d+)(\.\d+)'
        t.endlexpos = t.lexpos + len(t.value)
        return t",r'(\d+)(\.\d+),
"def t_RELID(self, t):
        r'R[0-9]+'
        t.endlexpos = t.lexpos + len(t.value)
        return t",r'R[0-9]+,
"def t_CARDINALITY(self, t):
        r'(1C)'
        t.endlexpos = t.lexpos + len(t.value)
        return t",r'(1C),
"def t_ID(self, t):
        r'[A-Za-z_][\w_]*'
        vup = t.value.upper()
        if vup in self.reserved:
            t.type = vup
        t.endlexpos = t.lexpos + len(t.value)
        return t",r'[A-Za-z_][\w_]*,
"def t_LPAREN(self, t):
        r'\('
        t.endlexpos = t.lexpos + len(t.value)
        return t",r'\(,
"def t_MINUS(self, t):
        r'-'
        t.endlexpos = t.lexpos + len(t.value)
        return t",r'-,
"def t_NUMBER(self, t):
        r'[0-9]+'
        t.endlexpos = t.lexpos + len(t.value)
        return t",r'[0-9]+,
"def t_RPAREN(self, t):
        r'\)'
        t.endlexpos = t.lexpos + len(t.value)
        return t",r'\),
"def t_SEMICOLON(self, t):
        r';'
        t.endlexpos = t.lexpos + len(t.value)
        return t",r';,
"def t_GUID(self, t):
        r'\""([^\\\n]|(\\.))*?\""'
        t.endlexpos = t.lexpos + len(t.value)
        return t","r'\""([^\\\n]|(\\.))*?\""",
"def t_newline(self, t):
        r'\n+'
        t.lexer.lineno += len(t.value)
        t.endlexpos = t.lexpos + len(t.value)",r'\n+,
"def p_statement(self, p):
        '''
        statement : create_table_statement SEMICOLON
                  | insert_into_statement SEMICOLON
                  | create_rop_statement SEMICOLON
                  | create_index_statement SEMICOLON
        '''
        p[0] = p[1]
        p[0].offset = p.lexpos(1)
        p[0].lineno = p.lineno(1)
        p[0].filename = p.lexer.filename","statement : create_table_statement SEMICOLON
                  | insert_into_statement SEMICOLON
                  | create_rop_statement SEMICOLON
                  | create_index_statement SEMICOLON",
"def p_create_rop_statement(self, p):
        '''create_rop_statement : CREATE ROP REF_ID RELID FROM association_end TO association_end'''
        args = [p[4]]
        args.extend(p[6])
        args.extend(p[8])
        p[0] = CreateAssociationStmt(*args)",create_rop_statement : CREATE ROP REF_ID RELID FROM association_end TO association_end,
"def p_cardinality_1(self, p):
        '''cardinality : NUMBER'''
        if p[1] != '1':
            raise ParsingException(""illegal cardinality (%s) at %s:%d"" % (p[1],
                                   p.lexer.filename, p.lineno(1)))
        p[0] = p[1]",cardinality : NUMBER,
"def p_cardinality_many(self, p):
        '''cardinality : ID'''
        if p[1] not in ['M', 'MC']:
            raise ParsingException(""illegal cardinality (%s) at %s:%d"" % (p[1],
                                   p.lexer.filename, p.lineno(1)))
        p[0] = p[1]",cardinality : ID,
"def eid(s):
    '''Encode id (bytes) as a Unicode string.

    The encoding is done such that lexicographic order is
    preserved. No concern is given to wasting space.

    The inverse of ``eid`` is ``did``.
    '''
    if isinstance(s, unicode):
        s = s.encode('utf-8')
    return u''.join('{:02x}'.format(ord(b)) for b in s)","Encode id (bytes) as a Unicode string.

    The encoding is done such that lexicographic order is
    preserved. No concern is given to wasting space.

    The inverse of ``eid`` is ``did``.",
"def did(s):
    '''Decode id (Unicode string) as a bytes.

    The inverse of ``did`` is ``eid``.
    '''
    return ''.join(chr(int(s[i:i+2], base=16)) for i in xrange(0, len(s), 2))","Decode id (Unicode string) as a bytes.

    The inverse of ``did`` is ``eid``.",
"def delete(self, content_id):
        '''Deletes the corresponding feature collection.

        If the FC does not exist, then this is a no-op.
        '''
        try:
            self.conn.delete(index=self.index, doc_type=self.type,
                             id=eid(content_id))
        except NotFoundError:
            pass","Deletes the corresponding feature collection.

        If the FC does not exist, then this is a no-op.",
"def delete_index(self):
        '''Deletes the underlying ES index.

        Only use this if you know what you're doing. This destroys
        the entire underlying ES index, which could be shared by
        multiple distinct ElasticStore instances.
        '''
        if self.conn.indices.exists(index=self.index):
            self.conn.indices.delete(index=self.index)","Deletes the underlying ES index.

        Only use this if you know what you're doing. This destroys
        the entire underlying ES index, which could be shared by
        multiple distinct ElasticStore instances.",
"def _source(self, feature_names):
        '''Maps feature names to ES's ""_source"" field.'''
        if feature_names is None:
            return True
        elif isinstance(feature_names, bool):
            return feature_names
        else:
            return map(lambda n: 'fc.' + n, feature_names)","Maps feature names to ES's ""_source"" field.",
"def _get_field_types(self):
        'Retrieve the field types. Useful for debugging.'
        mapping = self.conn.indices.get_mapping(
            index=self.index, doc_type=self.type)
        return mapping[self.index]['mappings'][self.type]['properties']",Retrieve the field types. Useful for debugging.,
"def _fc_index_disjunction_from_query(self, query_fc, fname):
        'Creates a disjunction for keyword scan queries.'
        if len(query_fc.get(fname, [])) == 0:
            return []
        terms = query_fc[fname].keys()

        disj = []
        for fname in self.indexes[fname]['feature_names']:
            disj.append({'terms': {fname_to_idx_name(fname): terms}})
        return disj",Creates a disjunction for keyword scan queries.,
"def fc_bytes(self, fc_dict):
        '''Take a feature collection in dict form and count its size in bytes.

        '''
        num_bytes = 0
        for _, feat in fc_dict.iteritems():
            num_bytes += len(feat)
        return num_bytes",Take a feature collection in dict form and count its size in bytes.,
"def get_lib_ffi_shared(libpath, c_hdr):
    '''
    libpath-->str: shared library filename with optional path
    c_hdr-->str: C-style header definitions for functions to wrap
    Returns-->(ffi, lib)
    '''
    lib = SharedLibWrapper(libpath, c_hdr)
    ffi = lib.ffi
    return (ffi, lib)","libpath-->str: shared library filename with optional path
    c_hdr-->str: C-style header definitions for functions to wrap
    Returns-->(ffi, lib)",
"def default_formatter(error):
    """"""Escape the error, and wrap it in a span with class ``error-message``""""""
    quoted = formencode.htmlfill.escape_formatter(error)
    return u'<span class=""error-message"">{0}</span>'.format(quoted)","Escape the error, and wrap it in a span with class ``error-message``",
"def basic_transform(val):
    '''A basic transform for strings and integers.'''
    if isinstance(val, int):
        return struct.pack('>i', val)
    else:
        return safe_lower_utf8(val)",A basic transform for strings and integers.,
"def safe_lower_utf8(x):
    '''x.lower().encode('utf-8') where x can be None, str, or unicode'''
    if x is None:
        return None
    x = x.lower()
    if isinstance(x, unicode):
        return x.encode('utf-8')
    return x","x.lower().encode('utf-8') where x can be None, str, or unicode",
"def delete_all(self):
        '''Deletes all storage.

        This includes every content object and all index data.
        '''
        self.kvl.clear_table(self.TABLE)
        self.kvl.clear_table(self.INDEX_TABLE)","Deletes all storage.

        This includes every content object and all index data.",
"def get_type_name(s_dt):
    '''
    get the xsd name of a S_DT
    '''
    s_cdt = nav_one(s_dt).S_CDT[17]()
    if s_cdt and s_cdt.Core_Typ in range(1, 6):
        return s_dt.Name
    
    s_edt = nav_one(s_dt).S_EDT[17]()
    if s_edt:
        return s_dt.Name
    
    s_udt = nav_one(s_dt).S_UDT[17]()
    if s_udt:
        return s_dt.Name",get the xsd name of a S_DT,
"def get_refered_attribute(o_attr):
    '''
    Get the the referred attribute.
    '''
    o_attr_ref = nav_one(o_attr).O_RATTR[106].O_BATTR[113].O_ATTR[106]()
    if o_attr_ref:
        return get_refered_attribute(o_attr_ref)
    else:
        return o_attr",Get the the referred attribute.,
"def build_user_type(s_udt):
    '''
    Build an xsd simpleType out of a S_UDT.
    '''
    s_dt_user = nav_one(s_udt).S_DT[17]()
    s_dt_base = nav_one(s_udt).S_DT[18]()
    
    base_name = get_type_name(s_dt_base)
    if base_name:
        user = ET.Element('xs:simpleType', name=s_dt_user.name)
        ET.SubElement(user, 'xs:restriction', base=base_name)
        
        return user",Build an xsd simpleType out of a S_UDT.,
"def prettify(xml_string):
    '''
    Indent an xml string with four spaces, and add an additional line break after each node.
    '''
    reparsed = xml.dom.minidom.parseString(xml_string)
    return reparsed.toprettyxml(indent=""    "")","Indent an xml string with four spaces, and add an additional line break after each node.",
"def track_production(f):
    '''
    decorator for adding positional information to returning nodes
    '''
    @wraps(f)
    def wrapper(self, p):
        r = f(self, p)
        node = p[0]
        if isinstance(node, Node) and len(p) > 1:
            set_positional_info(node, p)
        return r
    
    return wrapper",decorator for adding positional information to returning nodes,
"def t_SL_STRING(self, t):
        r'\/\/.*\n'
        t.lexer.lineno += t.value.count('\n')
        t.endlexpos = t.lexpos + len(t.value)",r'\/\/.*\n,
"def t_TICKED_PHRASE(self, t):
        r""\'[^\']*\'""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\'[^\']*\",
"def t_STRING(self, t):
        r'""[^""\n]*""'
        t.endlexpos = t.lexpos + len(t.value)
        return t","r'""[^""\n]*""",
"def t_END_FOR(self, t):
        r""(?i)end[\s]+for""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""(?i)end[\s]+for",
"def t_END_IF(self, t):
        r""(?i)end[\s]+if""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""(?i)end[\s]+if",
"def t_END_WHILE(self, t):
        r""(?i)end[\s]+while""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""(?i)end[\s]+while",
"def t_NAMESPACE(self, t):
        r""([0-9a-zA-Z_])+(?=::)""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""([0-9a-zA-Z_])+(?=::)",
"def t_ID(self, t):
        r""[a-zA-Z_][0-9a-zA-Z_]*|[a-zA-Z][0-9a-zA-Z_]*[0-9a-zA-Z_]+""
        t.endlexpos = t.lexpos + len(t.value)
        
        value = t.value.upper()
        if value in self.keywords:
            t.type = value
            
        return t","r""[a-zA-Z_][0-9a-zA-Z_]*|[a-zA-Z][0-9a-zA-Z_]*[0-9a-zA-Z_]+",
"def t_DOUBLECOLON(self, t):
        r""::""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""::",
"def t_DOUBLEEQUAL(self, t):
        r""\=\=""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\=\=",
"def t_NOTEQUAL(self, t):
        r""!\=""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""!\=",
"def t_ARROW(self, t):
        r""\-\>""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\-\>",
"def t_LE(self, t):
        r""\<\=""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\<\=",
"def t_GE(self, t):
        r""\>\=""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\>\=",
"def t_EQUAL(self, t):
        r""\=""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\=",
"def t_DOT(self, t):
        r""\.""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\.",
"def t_TIMES(self, t):
        r""\*""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\*",
"def t_COLON(self, t):
        r"":""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r"":",
"def t_LSQBR(self, t):
        r""\[""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\[",
"def t_RSQBR(self, t):
        r""\]""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\]",
"def t_QMARK(self, t):
        r""\?""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\?",
"def t_LESSTHAN(self, t):
        r""\<""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\<",
"def t_GT(self, t):
        r""\>""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\>",
"def t_PLUS(self, t):
        r""\+""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\+",
"def t_DIV(self, t):
        r""/""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""/",
"def t_MOD(self, t):
        r""%""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""%",
"def p_statement_list_1(self, p):
        '''statement_list : statement SEMICOLON statement_list'''
        p[0] = p[3]
        if p[1] is not None:
            p[0].children.insert(0, p[1])",statement_list : statement SEMICOLON statement_list,
"def p_statement_list_2(self, p):
        '''statement_list : statement SEMICOLON'''
        p[0] = StatementListNode()
        if p[1] is not None:
            p[0].children.insert(0, p[1])",statement_list : statement SEMICOLON,
"def p_bridge_assignment_statement(self, p):
        '''statement : BRIDGE variable_access EQUAL implicit_invocation'''
        p[4].__class__ = BridgeInvocationNode
        p[0] = AssignmentNode(variable_access=p[2],
                              expression=p[4])",statement : BRIDGE variable_access EQUAL implicit_invocation,
"def p_class_invocation_assignment_statement(self, p):
        '''statement : TRANSFORM variable_access EQUAL implicit_invocation'''
        p[4].__class__ = ClassInvocationNode
        p[0] = AssignmentNode(variable_access=p[2],
                              expression=p[4])",statement : TRANSFORM variable_access EQUAL implicit_invocation,
"def p_port_invocation_assignment_statement(self, p):
        '''statement : SEND variable_access EQUAL implicit_invocation'''
        p[4].__class__ = PortInvocationNode
        p[0] = AssignmentNode(variable_access=p[2],
                              expression=p[4])",statement : SEND variable_access EQUAL implicit_invocation,
"def p_port_event_generation(self, p):
        '''statement : SEND namespace DOUBLECOLON identifier LPAREN parameter_list RPAREN TO expression'''
        p[0] = GeneratePortEventNode(port_name=p[2],
                                     action_name=p[4],
                                     parameter_list=p[6],
                                     expression=p[9])",statement : SEND namespace DOUBLECOLON identifier LPAREN parameter_list RPAREN TO expression,
"def p_create_class_event_statement(self, p):
        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier CLASS'''
        p[0] = CreateClassEventNode(variable_name=p[4],
                                    event_specification=p[6],
                                    key_letter=p[8])",statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier CLASS,
"def p_create_assigner_event_statement(self, p):
        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier ASSIGNER'''
        p[0] = CreateClassEventNode(variable_name=p[4],
                                    event_specification=p[6],
                                    key_letter=p[8])",statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier ASSIGNER,
"def p_create_creator_event_statement(self, p):
        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier CREATOR'''
        p[0] = CreateCreatorEventNode(variable_name=p[4],
                                      event_specification=p[6],
                                      key_letter=p[8])",statement : CREATE EVENT INSTANCE variable_name OF event_specification TO identifier CREATOR,
"def p_create_instance_event_statement_1(self, p):
        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO variable_access'''
        p[0] = CreateInstanceEventNode(variable_name=p[4],
                                       event_specification=p[6],
                                       to_variable_access=p[8])",statement : CREATE EVENT INSTANCE variable_name OF event_specification TO variable_access,
"def p_create_instance_event_statement_2(self, p):
        '''statement : CREATE EVENT INSTANCE variable_name OF event_specification TO self_access'''
        p[0] = CreateInstanceEventNode(variable_name=p[4],
                                       event_specification=p[6],
                                       to_variable_access=p[8])",statement : CREATE EVENT INSTANCE variable_name OF event_specification TO self_access,
"def p_event_specification(self, p):
        '''event_specification : identifier event_meaning event_data'''
        p[0] = EventSpecNode(identifier=p[1],
                             meaning=p[2],
                             event_data=p[3])",event_specification : identifier event_meaning event_data,
"def p_ploymorphic_event_spec(self, p):
        '''event_specification : identifier TIMES event_meaning event_data'''
        p[0] = EventSpecNode(identifier=p[1],
                             meaning=p[3],
                             event_data=p[4])",event_specification : identifier TIMES event_meaning event_data,
"def p_for_statement(self, p):
        '''statement : FOR EACH variable_name IN variable_name block END_FOR'''
        p[0] = ForEachNode(instance_variable_name=p[3],
                           set_variable_name=p[5],
                           block=p[6])",statement : FOR EACH variable_name IN variable_name block END_FOR,
"def p_if_statement(self, p):
        '''statement : IF expression block elif_list else_clause END_IF'''
        p[0] = IfNode(expression=p[2],
                      block=p[3],
                      elif_list=p[4],
                      else_clause=p[5])",statement : IF expression block elif_list else_clause END_IF,
"def p_relate_statement_1(self, p):
        '''statement : RELATE instance_name TO instance_name ACROSS rel_id'''
        p[0] = RelateNode(from_variable_name=p[2],
                          to_variable_name=p[4],
                          rel_id=p[6],
                          phrase=None)",statement : RELATE instance_name TO instance_name ACROSS rel_id,
"def p_relate_statement_2(self, p):
        '''statement : RELATE instance_name TO instance_name ACROSS rel_id DOT phrase'''
        p[0] = RelateNode(from_variable_name=p[2],
                          to_variable_name=p[4],
                          rel_id=p[6],
                          phrase=p[8])",statement : RELATE instance_name TO instance_name ACROSS rel_id DOT phrase,
"def p_relate_using_statement_1(self, p):
        '''statement : RELATE instance_name TO instance_name ACROSS rel_id USING instance_name'''
        p[0] = RelateUsingNode(from_variable_name=p[2],
                               to_variable_name=p[4],
                               rel_id=p[6],
                               phrase=None,
                               using_variable_name=p[8])",statement : RELATE instance_name TO instance_name ACROSS rel_id USING instance_name,
"def p_unrelate_statement_1(self, p):
        '''statement : UNRELATE instance_name FROM instance_name ACROSS rel_id'''
        p[0] = UnrelateNode(from_variable_name=p[2],
                            to_variable_name=p[4],
                            rel_id=p[6],
                            phrase=None)",statement : UNRELATE instance_name FROM instance_name ACROSS rel_id,
"def p_unrelate_statement_2(self, p):
        '''statement : UNRELATE instance_name FROM instance_name ACROSS rel_id DOT phrase'''
        p[0] = UnrelateNode(from_variable_name=p[2],
                            to_variable_name=p[4],
                            rel_id=p[6],
                            phrase=p[8])",statement : UNRELATE instance_name FROM instance_name ACROSS rel_id DOT phrase,
"def p_select_from_statement_1(self, p):
        '''
        statement : SELECT ANY variable_name FROM INSTANCES OF identifier
                  | SELECT MANY variable_name FROM INSTANCES OF identifier
        '''
        p[0] = SelectFromNode(cardinality=p[2],
                              variable_name=p[3],
                              key_letter=p[7])","statement : SELECT ANY variable_name FROM INSTANCES OF identifier
                  | SELECT MANY variable_name FROM INSTANCES OF identifier",
"def p_select_from_statement_2(self, p):
        '''
        statement : SELECT ANY variable_name FROM identifier
                  | SELECT MANY variable_name FROM identifier
        '''
        p[0] = SelectFromNode(cardinality=p[2],
                              variable_name=p[3],
                              key_letter=p[5])","statement : SELECT ANY variable_name FROM identifier
                  | SELECT MANY variable_name FROM identifier",
"def p_navigation_step_1(self, p):
        '''navigation_step : ARROW identifier LSQBR identifier RSQBR'''
        p[0] = NavigationStepNode(key_letter=p[2],
                                  rel_id=p[4],
                                  phrase=None)",navigation_step : ARROW identifier LSQBR identifier RSQBR,
"def p_navigation_step_2(self, p):
        '''navigation_step : ARROW identifier LSQBR identifier DOT phrase RSQBR'''
        p[0] = NavigationStepNode(key_letter=p[2],
                                  rel_id=p[4],
                                  phrase=p[6])",navigation_step : ARROW identifier LSQBR identifier DOT phrase RSQBR,
"def p_implicit_invocation(self, p):
        '''implicit_invocation : namespace DOUBLECOLON identifier LPAREN parameter_list RPAREN'''
        p[0] = ImplicitInvocationNode(namespace=p[1],
                                      action_name=p[3],
                                      parameter_list=p[5])",implicit_invocation : namespace DOUBLECOLON identifier LPAREN parameter_list RPAREN,
"def p_operation_invocation_1(self, p):
        '''instance_invocation : structure DOT identifier LPAREN parameter_list RPAREN'''
        p[0] = InstanceInvocationNode(handle=p[1],
                                      action_name=p[3],
                                      parameter_list=p[5])",instance_invocation : structure DOT identifier LPAREN parameter_list RPAREN,
"def wrap(cls, message_parts):
        """"""Wraps exceptions in the context with :exc:`MalformedMessage`.""""""
        try:
            yield
        except BaseException as exception:
            __, __, tb = sys.exc_info()
            reraise(cls, cls(exception, message_parts), tb)",Wraps exceptions in the context with :exc:`MalformedMessage`.,
"def list_queues(self):
        """"""Create message content and properties to list all queues with QMFv2

        :returns: Tuple containing content and query properties
        """"""
        content = {""_what"": ""OBJECT"",
                   ""_schema_id"": {""_class_name"": ""queue""}}
        logger.debug(""Message content -> {0}"".format(content))

        return content, self.query_properties","Create message content and properties to list all queues with QMFv2

        :returns: Tuple containing content and query properties",
"def list_exchanges(self):
        """"""Create message content and properties to list all exchanges with QMFv2

        :returns: Tuple containing content and query properties
        """"""
        content = {""_what"": ""OBJECT"",
                   ""_schema_id"": {""_class_name"": ""exchange""}}
        logger.debug(""Message content -> {0}"".format(content))

        return content, self.query_properties","Create message content and properties to list all exchanges with QMFv2

        :returns: Tuple containing content and query properties",
"def get_most_recent_bike() -> Optional['Bike']:
        """"""
        Gets the most recently cached bike from the database.
        :return: The bike that was cached most recently.
        """"""
        try:
            return Bike.select().order_by(Bike.cached_date.desc()).get()
        except pw.DoesNotExist:
            return None","Gets the most recently cached bike from the database.
        :return: The bike that was cached most recently.",
"def serialize_instances(metamodel):
    '''
    Serialize all instances in a *metamodel*.
    '''
    s = ''
    for inst in metamodel.instances:
        s += serialize_instance(inst)
    
    return s",Serialize all instances in a *metamodel*.,
"def serialize_class(Cls):
    '''
    Serialize an xtUML metamodel class.
    '''
    metaclass = xtuml.get_metaclass(Cls)
    attributes = ['%s %s' % (name, ty.upper()) for name, ty in metaclass.attributes]
    
    s = 'CREATE TABLE %s (\n    ' % metaclass.kind
    s += ',\n    '.join(attributes)
    s += '\n);\n'

    return s",Serialize an xtUML metamodel class.,
"def serialize_schema(metamodel):
    '''
    Serialize all class and association definitions in a *metamodel*.
    '''
    s = ''
    for kind in sorted(metamodel.metaclasses.keys()):
        s += serialize_class(metamodel.metaclasses[kind].clazz)
    
    for ass in sorted(metamodel.associations, key=lambda x: x.rel_id):
        s += serialize_association(ass)
    
    return s",Serialize all class and association definitions in a *metamodel*.,
"def serialize_database(metamodel):
    '''
    Serialize all instances, class definitions, association definitions, and
    unique identifiers  in a *metamodel*.
    '''
    schema = serialize_schema(metamodel)
    instances = serialize_instances(metamodel)
    identifiers = serialize_unique_identifiers(metamodel)
    
    return ''.join([schema, instances, identifiers])","Serialize all instances, class definitions, association definitions, and
    unique identifiers  in a *metamodel*.",
"def persist_instances(metamodel, path, mode='w'):
    '''
    Persist all instances in a *metamodel* by serializing them and saving to a 
    *path* on disk.
    '''
    with open(path, mode) as f:
        for inst in metamodel.instances:
            s = serialize_instance(inst)
            f.write(s)","Persist all instances in a *metamodel* by serializing them and saving to a 
    *path* on disk.",
"def save(variable, filename):
    """"""Save variable on given path using Pickle
    
    Args:
        variable: what to save
        path (str): path of the output
    """"""
    fileObj = open(filename, 'wb')
    pickle.dump(variable, fileObj)
    fileObj.close()","Save variable on given path using Pickle
    
    Args:
        variable: what to save
        path (str): path of the output",
"def load(filename):
    """"""Load variable from Pickle file
    
    Args:
        path (str): path of the file to load

    Returns:
        variable read from path
    """"""
    fileObj = open(filename, 'rb')
    variable = pickle.load(fileObj)
    fileObj.close()
    return variable","Load variable from Pickle file
    
    Args:
        path (str): path of the file to load

    Returns:
        variable read from path",
"def partition(condition, collection) -> Tuple[List, List]:
    """"""Partitions a list into two based on a condition.""""""
    succeed, fail = [], []

    for x in collection:
        if condition(x):
            succeed.append(x)
        else:
            fail.append(x)

    return succeed, fail",Partitions a list into two based on a condition.,
"def get_metaclass(class_or_instance):
    '''
    Get the metaclass for a *class_or_instance*.
    '''
    if isinstance(class_or_instance, Class):
        return class_or_instance.__metaclass__
    
    elif issubclass(class_or_instance, Class):
        return class_or_instance.__metaclass__
    
    raise MetaException(""the provided argument is not an xtuml class or instance"")",Get the metaclass for a *class_or_instance*.,
"def delete(instance, disconnect=True):
    '''
    Delete an *instance* from its metaclass instance pool and optionally
    *disconnect* it from any links it might be connected to.
    '''
    if not isinstance(instance, Class):
        raise DeleteException(""the provided argument is not an xtuml instance"")
            
    return get_metaclass(instance).delete(instance, disconnect)","Delete an *instance* from its metaclass instance pool and optionally
    *disconnect* it from any links it might be connected to.",
"def disconnect(self, instance, another_instance):
        '''
        Disconnect an *instance* from *another_instance*.
        '''
        if instance not in self:
            return False
        
        if another_instance not in self[instance]: 
            return False

        self[instance].remove(another_instance)
        return True",Disconnect an *instance* from *another_instance*.,
"def attribute_type(self, attribute_name):
        '''
        Obtain the type of an attribute.
        '''
        attribute_name = attribute_name.upper()
        for name, ty in self.attributes:
            if name.upper() == attribute_name:
                return ty",Obtain the type of an attribute.,
"def add_link(self, metaclass, rel_id, phrase, conditional, many):
        '''
        Add a new link from *self* to *metaclass*.
        '''
        link = Link(self, rel_id, metaclass, phrase, conditional, many)
        key = (metaclass.kind.upper(), rel_id, phrase)
        self.links[key] = link

        return link",Add a new link from *self* to *metaclass*.,
"def append_attribute(self, name, type_name):
        '''
        Append an attribute with a given *name* and *type name* at the end of
        the list of attributes.
        '''
        attr = (name, type_name)
        self.attributes.append(attr)","Append an attribute with a given *name* and *type name* at the end of
        the list of attributes.",
"def insert_attribute(self, index, name, type_name):
        '''
        Insert an attribute with a given *name* and *type name* at some *index*
        in the list of attributes.
        '''
        attr = (name, type_name)
        self.attributes.insert(index, attr)","Insert an attribute with a given *name* and *type name* at some *index*
        in the list of attributes.",
"def delete_attribute(self, name):
        '''
        Delete an attribute with a given *name* from the list of attributes.
        '''
        for idx, attr in enumerate(self.attributes):
            attr_name, _ = attr
            if attr_name == name:
                del self.attributes[idx]
                return",Delete an attribute with a given *name* from the list of attributes.,
"def select_one(self, *args):
        '''
        Select a single instance from the instance pool. Query operators such as
        where_eq(), order_by() or filter functions may be passed as optional
        arguments.
        '''
        s = apply_query_operators(self.storage, args)
        return next(iter(s), None)","Select a single instance from the instance pool. Query operators such as
        where_eq(), order_by() or filter functions may be passed as optional
        arguments.",
"def select_many(self, *args):
        '''
        Select several instances from the instance pool. Query operators such as
        where_eq(), order_by() or filter functions may be passed as optional
        arguments.
        '''
        s = apply_query_operators(self.storage, args)
        if isinstance(s, QuerySet):
            return s
        else:
            return QuerySet(s)","Select several instances from the instance pool. Query operators such as
        where_eq(), order_by() or filter functions may be passed as optional
        arguments.",
"def instances(self):
        '''
        Obtain a sequence of all instances in the metamodel.
        '''
        for metaclass in self.metaclasses.values():
            for inst in metaclass.storage:
                yield inst",Obtain a sequence of all instances in the metamodel.,
"def find_metaclass(self, kind):
        '''
        Find a metaclass of some *kind* in the metamodel.
        '''
        ukind = kind.upper()
        if ukind in self.metaclasses:
            return self.metaclasses[ukind]
        else:
            raise UnknownClassException(kind)",Find a metaclass of some *kind* in the metamodel.,
"def clone(self, instance):
        '''
        Create a shallow clone of an *instance*.
        
        **Note:** the clone and the original instance **does not** have to be
        part of the same metaclass. 
        '''
        metaclass = get_metaclass(instance)
        metaclass = self.find_metaclass(metaclass.kind)
        return metaclass.clone(instance)","Create a shallow clone of an *instance*.
        
        **Note:** the clone and the original instance **does not** have to be
        part of the same metaclass.",
"def recv(socket, flags=0, capture=(lambda msgs: None)):
    """"""Receives header, payload, and topics through a ZeroMQ socket.

    :param socket: a zmq socket.
    :param flags: zmq flags to receive messages.
    :param capture: a function to capture received messages.

    """"""
    msgs = eintr_retry_zmq(socket.recv_multipart, flags)
    capture(msgs)
    return parse(msgs)","Receives header, payload, and topics through a ZeroMQ socket.

    :param socket: a zmq socket.
    :param flags: zmq flags to receive messages.
    :param capture: a function to capture received messages.",
"def parse_emails(values):
    '''
    Take a string or list of strings and try to extract all the emails
    '''
    emails = []
    if isinstance(values, str):
        values = [values]
    # now we know we have a list of strings
    for value in values:
        matches = re_emails.findall(value)
        emails.extend([match[2] for match in matches])
    return emails",Take a string or list of strings and try to extract all the emails,
"def rpc(f=None, **kwargs):
    """"""Marks a method as RPC.""""""
    if f is not None:
        if isinstance(f, six.string_types):
            if 'name' in kwargs:
                raise ValueError('name option duplicated')
            kwargs['name'] = f
        else:
            return rpc(**kwargs)(f)
    return functools.partial(_rpc, **kwargs)",Marks a method as RPC.,
"def rpc_spec_table(app):
    """"""Collects methods which are speced as RPC.""""""
    table = {}
    for attr, value in inspect.getmembers(app):
        rpc_spec = get_rpc_spec(value, default=None)
        if rpc_spec is None:
            continue
        table[rpc_spec.name] = (value, rpc_spec)
    return table",Collects methods which are speced as RPC.,
"def eintr_retry(exc_type, f, *args, **kwargs):
    """"""Calls a function.  If an error of the given exception type with
    interrupted system call (EINTR) occurs calls the function again.
    """"""
    while True:
        try:
            return f(*args, **kwargs)
        except exc_type as exc:
            if exc.errno != EINTR:
                raise
        else:
            break","Calls a function.  If an error of the given exception type with
    interrupted system call (EINTR) occurs calls the function again.",
"def eintr_retry_zmq(f, *args, **kwargs):
    """"""The specialization of :func:`eintr_retry` by :exc:`zmq.ZMQError`.""""""
    return eintr_retry(zmq.ZMQError, f, *args, **kwargs)",The specialization of :func:`eintr_retry` by :exc:`zmq.ZMQError`.,
"def next(self):
        '''
        Progress to the next identifier, and return the current one.
        '''
        val = self._current
        self._current = self.readfunc()
        return val","Progress to the next identifier, and return the current one.",
"def enter(self, node):
        '''
        Tries to invoke a method matching the pattern *enter_<type name>*, where
        <type name> is the name of the type of the *node*.
        '''
        name = 'enter_' + node.__class__.__name__
        fn = getattr(self, name, self.default_enter)
        fn(node)","Tries to invoke a method matching the pattern *enter_<type name>*, where
        <type name> is the name of the type of the *node*.",
"def leave(self, node):
        '''
        Tries to invoke a method matching the pattern *leave_<type name>*, where
        <type name> is the name of the type of the *node*.
        '''
        name = 'leave_' + node.__class__.__name__
        fn = getattr(self, name, self.default_leave)
        fn(node)","Tries to invoke a method matching the pattern *leave_<type name>*, where
        <type name> is the name of the type of the *node*.",
"def default_accept(self, node, **kwargs):
        '''
        The default accept behaviour is to decend into the iterable member
        *node.children* (if available).
        '''
        if not hasattr(node, 'children'):
            return
        
        for child in node.children:
            self.accept(child, **kwargs)","The default accept behaviour is to decend into the iterable member
        *node.children* (if available).",
"def render(self, node):
        '''
        Try to invoke a method matching the pattern *render_<type name>*, where
        <type name> is the name of the rendering *node*.
        '''
        name = 'render_' + type(node).__name__
        fn = getattr(self, name, self.default_render)
        return fn(node)","Try to invoke a method matching the pattern *render_<type name>*, where
        <type name> is the name of the rendering *node*.",
"def accept_S_SYS(self, inst):
        '''
        A System Model contains top-level packages
        '''
        for child in many(inst).EP_PKG[1401]():
            self.accept(child)",A System Model contains top-level packages,
"def accept_C_C(self, inst):
        '''
        A Component contains packageable elements
        '''
        for child in many(inst).PE_PE[8003]():
            self.accept(child)",A Component contains packageable elements,
"def accept_EP_PKG(self, inst):
        '''
        A Package contains packageable elements
        '''
        for child in many(inst).PE_PE[8000]():
            self.accept(child)",A Package contains packageable elements,
"def write_file (filename, contents):
    """"""Create a file with the specified name and write 'contents' (a
    sequence of strings without line terminators) to it.
    """"""
    contents = ""\n"".join(contents)
    if sys.version_info >= (3,):
        contents = contents.encode(""utf-8"")
    f = open(filename, ""wb"")        # always write POSIX-style manifest
    f.write(contents)
    f.close()","Create a file with the specified name and write 'contents' (a
    sequence of strings without line terminators) to it.",
"def _history_locked(self):
        """""" Returns whether history movement is locked.
        """"""
        return (self.history_lock and
                (self._get_edited_history(self._history_index) !=
                 self.input_buffer) and
                (self._get_prompt_cursor().blockNumber() !=
                 self._get_end_cursor().blockNumber()))",Returns whether history movement is locked.,
"def _get_edited_history(self, index):
        """""" Retrieves a history item, possibly with temporary edits.
        """"""
        if index in self._history_edits:
            return self._history_edits[index]
        elif index == len(self._history):
            return unicode()
        return self._history[index]","Retrieves a history item, possibly with temporary edits.",
"def _set_history(self, history):
        """""" Replace the current history with a sequence of history items.
        """"""
        self._history = list(history)
        self._history_edits = {}
        self._history_index = len(self._history)",Replace the current history with a sequence of history items.,
"def _store_edits(self):
        """""" If there are edits to the current input buffer, store them.
        """"""
        current = self.input_buffer
        if self._history_index == len(self._history) or \
                self._history[self._history_index] != current:
            self._history_edits[self._history_index] = current","If there are edits to the current input buffer, store them.",
"def t_NAME(t):
    r'[A-Za-z_][A-Za-z0-9_]*'
    # to simplify lexing, we match identifiers and keywords as a single thing
    # if it's a keyword, we change the type to the name of that keyword
    if t.value.upper() in reserved:
        t.type = t.value.upper()
        t.value = t.value.upper()
    return t",r'[A-Za-z_][A-Za-z0-9_]*,
"def t_STRING(t):
    r""'([^'\\]+|\\'|\\\\)*'""
    t.value = t.value.replace(r'\\', chr(92)).replace(r""\'"", r""'"")[1:-1]
    return t","r""'([^'\\]+|\\'|\\\\)*",
"def OnTimeToClose(self, evt):
        """"""Event handler for the button click.""""""
        print(""See ya later!"")
        sys.stdout.flush()
        self.cleanup_consoles(evt)
        self.Close()
        # Not sure why, but our IPython kernel seems to prevent normal WX
        # shutdown, so an explicit exit() call is needed.
        sys.exit()",Event handler for the button click.,
"def cleanup_files(self):
        """"""Clean up files, remove builds.""""""
        logger.debug('Cleaning up...')
        with indent_log():
            for req in self.reqs_to_cleanup:
                req.remove_temporary_source()

            if self._pip_has_created_build_dir():
                logger.debug('Removing temporary dir %s...', self.build_dir)
                rmtree(self.build_dir)","Clean up files, remove builds.",
"def StringIO(*args, **kw):
    """"""Thunk to load the real StringIO on demand""""""
    global StringIO
    try:
        from cStringIO import StringIO
    except ImportError:
        from StringIO import StringIO
    return StringIO(*args,**kw)",Thunk to load the real StringIO on demand,
"def add(self,dist):
        """"""Add `dist` if we ``can_add()`` it and it isn't already added""""""
        if self.can_add(dist) and dist.has_version():
            dists = self._distmap.setdefault(dist.key,[])
            if dist not in dists:
                dists.append(dist)
                if dist.key in self._cache:
                    _sort_dists(self._cache[dist.key])",Add `dist` if we ``can_add()`` it and it isn't already added,
"def activate(self,path=None):
        """"""Ensure distribution is importable on `path` (default=sys.path)""""""
        if path is None: path = sys.path
        self.insert_on(path)
        if path is sys.path:
            fixup_namespace_packages(self.location)
            map(declare_namespace, self._get_metadata('namespace_packages.txt'))",Ensure distribution is importable on `path` (default=sys.path),
"def _parsed_pkg_info(self):
        """"""Parse and cache metadata""""""
        try:
            return self._pkg_info
        except AttributeError:
            from email.parser import Parser
            self._pkg_info = Parser().parsestr(self.get_metadata(self.PKG_INFO))
            return self._pkg_info",Parse and cache metadata,
"def _collapse_leading_ws(header, txt):
    """"""
    ``Description`` header must preserve newlines; all others need not
    """"""
    if header.lower() == 'description':  # preserve newlines
        return '\n'.join([x[8:] if x.startswith(' ' * 8) else x
                          for x in txt.strip().splitlines()])
    else:
        return ' '.join([x.strip() for x in txt.splitlines()])",``Description`` header must preserve newlines; all others need not,
"def hideEvent(self, event):
        """""" Reimplemented to disconnect signal handlers and event filter.
        """"""
        super(CompletionWidget, self).hideEvent(event)
        self._text_edit.cursorPositionChanged.disconnect(self._update_current)
        self._text_edit.removeEventFilter(self)",Reimplemented to disconnect signal handlers and event filter.,
"def showEvent(self, event):
        """""" Reimplemented to connect signal handlers and event filter.
        """"""
        super(CompletionWidget, self).showEvent(event)
        self._text_edit.cursorPositionChanged.connect(self._update_current)
        self._text_edit.installEventFilter(self)",Reimplemented to connect signal handlers and event filter.,
"def _complete_current(self):
        """""" Perform the completion with the currently selected item.
        """"""
        self._current_text_cursor().insertText(self.currentItem().text())
        self.hide()",Perform the completion with the currently selected item.,
"def _current_text_cursor(self):
        """""" Returns a cursor with text between the start position and the
            current position selected.
        """"""
        cursor = self._text_edit.textCursor()
        if cursor.position() >= self._start_position:
            cursor.setPosition(self._start_position,
                               QtGui.QTextCursor.KeepAnchor)
        return cursor","Returns a cursor with text between the start position and the
            current position selected.",
"def registerAdminSite(appName, excludeModels=[]):
    """"""Registers the models of the app with the given ""appName"" for the admin site""""""
    for model in apps.get_app_config(appName).get_models():
        if model not in excludeModels:
            admin.site.register(model)","Registers the models of the app with the given ""appName"" for the admin site",
"def swap_memory():
    """"""Swap system memory as a (total, used, free, sin, sout) tuple.""""""
    mem = _psutil_mswindows.get_virtual_mem()
    total = mem[2]
    free = mem[3]
    used = total - free
    percent = usage_percent(used, total, _round=1)
    return nt_swapmeminfo(total, used, free, percent, 0, 0)","Swap system memory as a (total, used, free, sin, sout) tuple.",
"def disk_partitions(all):
    """"""Return disk partitions.""""""
    rawlist = _psutil_mswindows.get_disk_partitions(all)
    return [nt_partition(*x) for x in rawlist]",Return disk partitions.,
"def get_system_cpu_times():
    """"""Return system CPU times as a named tuple.""""""
    user, system, idle = 0, 0, 0
    # computes system global times summing each processor value
    for cpu_time in _psutil_mswindows.get_system_cpu_times():
        user += cpu_time[0]
        system += cpu_time[1]
        idle += cpu_time[2]
    return _cputimes_ntuple(user, system, idle)",Return system CPU times as a named tuple.,
"def get_system_per_cpu_times():
    """"""Return system per-CPU times as a list of named tuples.""""""
    ret = []
    for cpu_t in _psutil_mswindows.get_system_cpu_times():
        user, system, idle = cpu_t
        item = _cputimes_ntuple(user, system, idle)
        ret.append(item)
    return ret",Return system per-CPU times as a list of named tuples.,
"def get_system_users():
    """"""Return currently connected users as a list of namedtuples.""""""
    retlist = []
    rawlist = _psutil_mswindows.get_system_users()
    for item in rawlist:
        user, hostname, tstamp = item
        nt = nt_user(user, None, hostname, tstamp)
        retlist.append(nt)
    return retlist",Return currently connected users as a list of namedtuples.,
"def _stdout_raw(self, s):
        """"""Writes the string to stdout""""""
        print(s, end='', file=sys.stdout)
        sys.stdout.flush()",Writes the string to stdout,
"def _stderr_raw(self, s):
        """"""Writes the string to stdout""""""
        print(s, end='', file=sys.stderr)
        sys.stderr.flush()",Writes the string to stdout,
"def add_children(G, parent, level, n=2):
    """"""Add children recursively to a binary tree.""""""
    if level == 0:
        return
    for i in range(n):
        child = parent+str(i)
        G.add_node(child)
        G.add_edge(parent,child)
        add_children(G, child, level-1, n)",Add children recursively to a binary tree.,
"def make_bintree(levels):
    """"""Make a symmetrical binary tree with @levels""""""
    G = nx.DiGraph()
    root = '0'
    G.add_node(root)
    add_children(G, root, levels, 2)
    return G",Make a symmetrical binary tree with @levels,
"def submit_jobs(view, G, jobs):
    """"""Submit jobs via client where G describes the time dependencies.""""""
    results = {}
    for node in nx.topological_sort(G):
        with view.temp_flags(after=[ results[n] for n in G.predecessors(node) ]):
            results[node] = view.apply(jobs[node])
    return results",Submit jobs via client where G describes the time dependencies.,
"def validate_tree(G, results):
    """"""Validate that jobs executed after their dependencies.""""""
    for node in G:
        started = results[node].metadata.started
        for parent in G.predecessors(node):
            finished = results[parent].metadata.completed
            assert started > finished, ""%s should have happened after %s""%(node, parent)",Validate that jobs executed after their dependencies.,
"def make_color_table(in_class):
    """"""Build a set of color attributes in a class.

    Helper function for building the *TermColors classes.""""""

    for name,value in color_templates:
        setattr(in_class,name,in_class._base % value)","Build a set of color attributes in a class.

    Helper function for building the *TermColors classes.",
"def copy(self,name=None):
        """"""Return a full copy of the object, optionally renaming it.""""""
        if name is None:
            name = self.name
        return ColorScheme(name, self.colors.dict())","Return a full copy of the object, optionally renaming it.",
"def add_scheme(self,new_scheme):
        """"""Add a new color scheme to the table.""""""
        if not isinstance(new_scheme,ColorScheme):
            raise ValueError,'ColorSchemeTable only accepts ColorScheme instances'
        self[new_scheme.name] = new_scheme",Add a new color scheme to the table.,
"def home_lib(home):
    """"""Return the lib dir under the 'home' installation scheme""""""
    if hasattr(sys, 'pypy_version_info'):
        lib = 'site-packages'
    else:
        lib = os.path.join('lib', 'python')
    return os.path.join(home, lib)",Return the lib dir under the 'home' installation scheme,
"def set_style(self, style):
        """""" Sets the style to the specified Pygments style.
        """"""
        if isinstance(style, basestring):
            style = get_style_by_name(style)
        self._style = style
        self._clear_caches()",Sets the style to the specified Pygments style.,
"def _get_format_from_document(self, token, document):
        """""" Returns a QTextCharFormat for token by
        """"""
        code, html = self._formatter._format_lines([(token, u'dummy')]).next()
        self._document.setHtml(html)
        return QtGui.QTextCursor(self._document).charFormat()",Returns a QTextCharFormat for token by,
"def normalize_path(path):
    """"""
    Convert a path to its canonical, case-normalized, absolute version.

    """"""
    return os.path.normcase(os.path.realpath(os.path.expanduser(path)))","Convert a path to its canonical, case-normalized, absolute version.",
"def check_entry_points(dist, attr, value):
    """"""Verify that entry_points map is parseable""""""
    try:
        pkg_resources.EntryPoint.parse_map(value)
    except ValueError, e:
        raise DistutilsSetupError(e)",Verify that entry_points map is parseable,
"def last_blank(src):
    """"""Determine if the input source ends in a blank.

    A blank is either a newline or a line consisting of whitespace.

    Parameters
    ----------
    src : string
      A single or multiline string.
    """"""
    if not src: return False
    ll  = src.splitlines()[-1]
    return (ll == '') or ll.isspace()","Determine if the input source ends in a blank.

    A blank is either a newline or a line consisting of whitespace.

    Parameters
    ----------
    src : string
      A single or multiline string.",
"def transform_assign_system(line):
    """"""Handle the `files = !ls` syntax.""""""
    m = _assign_system_re.match(line)
    if m is not None:
        cmd = m.group('cmd')
        lhs = m.group('lhs')
        new_line = '%s = get_ipython().getoutput(%r)' % (lhs, cmd)
        return new_line
    return line",Handle the `files = !ls` syntax.,
"def transform_assign_magic(line):
    """"""Handle the `a = %who` syntax.""""""
    m = _assign_magic_re.match(line)
    if m is not None:
        cmd = m.group('cmd')
        lhs = m.group('lhs')
        new_line = '%s = get_ipython().magic(%r)' % (lhs, cmd)
        return new_line
    return line",Handle the `a = %who` syntax.,
"def transform_classic_prompt(line):
    """"""Handle inputs that start with '>>> ' syntax.""""""

    if not line or line.isspace():
        return line
    m = _classic_prompt_re.match(line)
    if m:
        return line[len(m.group(0)):]
    else:
        return line",Handle inputs that start with '>>> ' syntax.,
"def transform_ipy_prompt(line):
    """"""Handle inputs that start classic IPython prompt syntax.""""""

    if not line or line.isspace():
        return line
    #print 'LINE:  %r' % line # dbg
    m = _ipy_prompt_re.match(line)
    if m:
        #print 'MATCH! %r -> %r' % (line, line[len(m.group(0)):]) # dbg
        return line[len(m.group(0)):]
    else:
        return line",Handle inputs that start classic IPython prompt syntax.,
"def reset(self):
        """"""Reset the input buffer and associated state.""""""
        self.indent_spaces = 0
        self._buffer[:] = []
        self.source = ''
        self.code = None
        self._is_complete = False
        self._full_dedent = False",Reset the input buffer and associated state.,
"def _tr_system(line_info):
        ""Translate lines escaped with: !""
        cmd = line_info.line.lstrip().lstrip(ESC_SHELL)
        return '%sget_ipython().system(%r)' % (line_info.pre, cmd)",Translate lines escaped with: !,
"def _tr_help(line_info):
        ""Translate lines escaped with: ?/??""
        # A naked help line should just fire the intro help screen
        if not line_info.line[1:]:
            return 'get_ipython().show_usage()'
        
        return _make_help_call(line_info.ifun, line_info.esc, line_info.pre)",Translate lines escaped with: ?/??,
"def _tr_magic(line_info):
        ""Translate lines escaped with: %""
        tpl = '%sget_ipython().magic(%r)'
        cmd = ' '.join([line_info.ifun, line_info.the_rest]).strip()
        return tpl % (line_info.pre, cmd)",Translate lines escaped with: %,
"def _tr_quote(line_info):
        ""Translate lines escaped with: ,""
        return '%s%s(""%s"")' % (line_info.pre, line_info.ifun,
                             '"", ""'.join(line_info.the_rest.split()) )","Translate lines escaped with: ,",
"def _tr_paren(line_info):
        ""Translate lines escaped with: /""
        return '%s%s(%s)' % (line_info.pre, line_info.ifun,
                             "", "".join(line_info.the_rest.split()))",Translate lines escaped with: /,
"def reset(self):
        """"""Reset the input buffer and associated state.""""""
        super(IPythonInputSplitter, self).reset()
        self._buffer_raw[:] = []
        self.source_raw = ''
        self.cell_magic_parts = []
        self.processing_cell_magic = False",Reset the input buffer and associated state.,
"def source_raw_reset(self):
        """"""Return input and raw source and perform a full reset.
        """"""
        out = self.source
        out_r = self.source_raw
        self.reset()
        return out, out_r",Return input and raw source and perform a full reset.,
"def transform_cell(self, cell):
        """"""Process and translate a cell of input.
        """"""
        self.reset()
        self.push(cell)
        return self.source_reset()",Process and translate a cell of input.,
"def _init_observers(self):
        """"""Initialize observer storage""""""

        self.registered_types = set() #set of types that are observed
        self.registered_senders = set() #set of senders that are observed
        self.observers = {}",Initialize observer storage,
"def _group_report(self,group,name):
        """"""Report summary for a given job group.

        Return True if the group had any elements.""""""

        if group:
            print '%s jobs:' % name
            for job in group:
                print '%s : %s' % (job.num,job)
            print
            return True","Report summary for a given job group.

        Return True if the group had any elements.",
"def _group_flush(self,group,name):
        """"""Flush a given job group

        Return True if the group had any elements.""""""

        njobs = len(group)
        if njobs:
            plural = {1:''}.setdefault(njobs,'s')
            print 'Flushing %s %s job%s.' % (njobs,name,plural)
            group[:] = []
            return True","Flush a given job group

        Return True if the group had any elements.",
"def status(self,verbose=0):
        """"""Print a status of all jobs currently being managed.""""""

        self._update_status()
        self._group_report(self.running,'Running')
        self._group_report(self.completed,'Completed')
        self._group_report(self.dead,'Dead')
        # Also flush the report queues
        self._comp_report[:] = []
        self._dead_report[:] = []",Print a status of all jobs currently being managed.,
"def result(self,num):
        """"""result(N) -> return the result of job N.""""""
        try:
            return self.all[num].result
        except KeyError:
            error('Job #%s not found' % num)",result(N) -> return the result of job N.,
"def insert(self, idx, value):
        """"""
        Inserts a value in the ``ListVariable`` at an appropriate index.

        :param idx: The index before which to insert the new value.
        :param value: The value to insert.
        """"""

        self._value.insert(idx, value)
        self._rebuild()","Inserts a value in the ``ListVariable`` at an appropriate index.

        :param idx: The index before which to insert the new value.
        :param value: The value to insert.",
"def copy(self):
        """"""
        Retrieve a copy of the Environment.  Note that this is a shallow
        copy.
        """"""

        return self.__class__(self._data.copy(), self._sensitive.copy(),
                              self._cwd)","Retrieve a copy of the Environment.  Note that this is a shallow
        copy.",
"def cwd(self, value):
        """"""
        Change the working directory that processes should be executed in.

        :param value: The new path to change to.  If relative, will be
                      interpreted relative to the current working
                      directory.
        """"""

        self._cwd = utils.canonicalize_path(self._cwd, value)","Change the working directory that processes should be executed in.

        :param value: The new path to change to.  If relative, will be
                      interpreted relative to the current working
                      directory.",
"def move(self, state=None):
        """"""Swaps two cities in the route.

        :type state: TSPState
        """"""
        state = self.state if state is None else state
        route = state
        a = random.randint(self.locked_range, len(route) - 1)
        b = random.randint(self.locked_range, len(route) - 1)
        route[a], route[b] = route[b], route[a]","Swaps two cities in the route.

        :type state: TSPState",
"def _defaults(self, keys=None):
        """"""create an empty record""""""
        d = {}
        keys = self._keys if keys is None else keys
        for key in keys:
            d[key] = None
        return d",create an empty record,
"def _list_to_dict(self, line, keys=None):
        """"""Inverse of dict_to_list""""""
        keys = self._keys if keys is None else keys
        d = self._defaults(keys)
        for key,value in zip(keys, line):
            d[key] = value

        return d",Inverse of dict_to_list,
"def add_record(self, msg_id, rec):
        """"""Add a new Task Record, by msg_id.""""""
        d = self._defaults()
        d.update(rec)
        d['msg_id'] = msg_id
        line = self._dict_to_list(d)
        tups = '(%s)'%(','.join(['?']*len(line)))
        self._db.execute(""INSERT INTO %s VALUES %s""%(self.table, tups), line)","Add a new Task Record, by msg_id.",
"def get_record(self, msg_id):
        """"""Get a specific Task Record, by msg_id.""""""
        cursor = self._db.execute(""""""SELECT * FROM %s WHERE msg_id==?""""""%self.table, (msg_id,))
        line = cursor.fetchone()
        if line is None:
            raise KeyError(""No such msg: %r""%msg_id)
        return self._list_to_dict(line)","Get a specific Task Record, by msg_id.",
"def drop_matching_records(self, check):
        """"""Remove a record from the DB.""""""
        expr,args = self._render_expression(check)
        query = ""DELETE FROM %s WHERE %s""%(self.table, expr)
        self._db.execute(query,args)",Remove a record from the DB.,
"def get_history(self):
        """"""get all msg_ids, ordered by time submitted.""""""
        query = """"""SELECT msg_id FROM %s ORDER by submitted ASC""""""%self.table
        cursor = self._db.execute(query)
        # will be a list of length 1 tuples
        return [ tup[0] for tup in cursor.fetchall()]","get all msg_ids, ordered by time submitted.",
"def table(rows):
    '''
    Output a simple table with several columns.
    '''

    output = '<table>'

    for row in rows:
        output += '<tr>'
        for column in row:
            output += '<td>{s}</td>'.format(s=column)
        output += '</tr>'

    output += '</table>'

    return output",Output a simple table with several columns.,
"def jsfile(url):
    '''
    Output a script tag to a js file.
    '''

    if not url.startswith('http://') and not url[:1] == '/':
        #add media_url for relative paths
        url = settings.STATIC_URL + url

    return '<script type=""text/javascript"" src=""{src}""></script>'.format(
        src=url)",Output a script tag to a js file.,
"def cssfile(url):
    '''
    Output a link tag to a css stylesheet.
    '''

    if not url.startswith('http://') and not url[:1] == '/':
        #add media_url for relative paths
        url = settings.STATIC_URL + url

    return '<link href=""{src}"" rel=""stylesheet"">'.format(src=url)",Output a link tag to a css stylesheet.,
"def img(url, alt='', classes='', style=''):
    '''
    Image tag helper.
    '''

    if not url.startswith('http://') and not url[:1] == '/':
        #add media_url for relative paths
        url = settings.STATIC_URL + url

    attr = {
        'class': classes,
        'alt': alt,
        'style': style,
        'src': url
    }

    return html.tag('img', '', attr)",Image tag helper.,
"def sub(value, arg):
    """"""Subtract the arg from the value.""""""
    try:
        return valid_numeric(value) - valid_numeric(arg)
    except (ValueError, TypeError):
        try:
            return value - arg
        except Exception:
            return ''",Subtract the arg from the value.,
"def mul(value, arg):
    """"""Multiply the arg with the value.""""""
    try:
        return valid_numeric(value) * valid_numeric(arg)
    except (ValueError, TypeError):
        try:
            return value * arg
        except Exception:
            return ''",Multiply the arg with the value.,
"def div(value, arg):
    """"""Divide the arg by the value.""""""
    try:
        return valid_numeric(value) / valid_numeric(arg)
    except (ValueError, TypeError):
        try:
            return value / arg
        except Exception:
            return ''",Divide the arg by the value.,
"def mod(value, arg):
    """"""Return the modulo value.""""""
    try:
        return valid_numeric(value) % valid_numeric(arg)
    except (ValueError, TypeError):
        try:
            return value % arg
        except Exception:
            return ''",Return the modulo value.,
"def remove_builtin(self, key, orig):
        """"""Remove an added builtin and re-set the original.""""""
        if orig is BuiltinUndefined:
            del __builtin__.__dict__[key]
        else:
            __builtin__.__dict__[key] = orig",Remove an added builtin and re-set the original.,
"def activate(self):
        """"""Store ipython references in the __builtin__ namespace.""""""

        add_builtin = self.add_builtin
        for name, func in self.auto_builtins.iteritems():
            add_builtin(name, func)",Store ipython references in the __builtin__ namespace.,
"def deactivate(self):
        """"""Remove any builtins which might have been added by add_builtins, or
        restore overwritten ones to their previous values.""""""
        remove_builtin = self.remove_builtin
        for key, val in self._orig_builtins.iteritems():
            remove_builtin(key, val)
        self._orig_builtins.clear()
        self._builtins_added = False","Remove any builtins which might have been added by add_builtins, or
        restore overwritten ones to their previous values.",
"def parse_args(self, args=None, options=None):
        """"""Call optparse.parse_args, but return a triple:

        (ok, options, args)

        """"""
        try:
            options, args = \
                super(CoverageOptionParser, self).parse_args(args, options)
        except self.OptionParserError:
            return False, None, None
        return True, options, args","Call optparse.parse_args, but return a triple:

        (ok, options, args)",
"def add_action(self, dash, dashdash, action_code):
        """"""Add a specialized option that is the action to execute.""""""
        option = self.add_option(dash, dashdash, action='callback',
            callback=self._append_action
            )
        option.action_code = action_code",Add a specialized option that is the action to execute.,
"def _append_action(self, option, opt_unused, value_unused, parser):
        """"""Callback for an option that adds to the `actions` list.""""""
        parser.values.actions.append(option.action_code)",Callback for an option that adds to the `actions` list.,
"def set(self):
        """"""Set the hook.""""""
        if sys.displayhook is not self.hook:
            self.old_hook = sys.displayhook
            sys.displayhook = self.hook",Set the hook.,
"def log_errors(f, self, *args, **kwargs):
    """"""decorator to log unhandled exceptions raised in a method.
    
    For use wrapping on_recv callbacks, so that exceptions
    do not cause the stream to be closed.
    """"""
    try:
        return f(self, *args, **kwargs)
    except Exception:
        self.log.error(""Uncaught exception in %r"" % f, exc_info=True)","decorator to log unhandled exceptions raised in a method.
    
    For use wrapping on_recv callbacks, so that exceptions
    do not cause the stream to be closed.",
"def is_url(url):
    """"""boolean check for whether a string is a zmq url""""""
    if '://' not in url:
        return False
    proto, addr = url.split('://', 1)
    if proto.lower() not in ['tcp','pgm','epgm','ipc','inproc']:
        return False
    return True",boolean check for whether a string is a zmq url,
"def validate_url_container(container):
    """"""validate a potentially nested collection of urls.""""""
    if isinstance(container, basestring):
        url = container
        return validate_url(url)
    elif isinstance(container, dict):
        container = container.itervalues()
    
    for element in container:
        validate_url_container(element)",validate a potentially nested collection of urls.,
"def split_url(url):
    """"""split a zmq url (tcp://ip:port) into ('tcp','ip','port').""""""
    proto_addr = url.split('://')
    assert len(proto_addr) == 2, 'Invalid url: %r'%url
    proto, addr = proto_addr
    lis = addr.split(':')
    assert len(lis) == 2, 'Invalid url: %r'%url
    addr,s_port = lis
    return proto,addr,s_port","split a zmq url (tcp://ip:port) into ('tcp','ip','port').",
"def remote(view, block=None, **flags):
    """"""Turn a function into a remote function.

    This method can be used for map:

    In [1]: @remote(view,block=True)
       ...: def func(a):
       ...:    pass
    """"""

    def remote_function(f):
        return RemoteFunction(view, f, block=block, **flags)
    return remote_function","Turn a function into a remote function.

    This method can be used for map:

    In [1]: @remote(view,block=True)
       ...: def func(a):
       ...:    pass",
"def get_readline_tail(self, n=10):
        """"""Get the last n items in readline history.""""""
        end = self.shell.readline.get_current_history_length() + 1
        start = max(end-n, 1)
        ghi = self.shell.readline.get_history_item
        return [ghi(x) for x in range(start, end)]",Get the last n items in readline history.,
"def init_logstart(self):
        """"""Initialize logging in case it was requested at the command line.
        """"""
        if self.logappend:
            self.magic('logstart %s append' % self.logappend)
        elif self.logfile:
            self.magic('logstart %s' % self.logfile)
        elif self.logstart:
            self.magic('logstart')",Initialize logging in case it was requested at the command line.,
"def register_post_execute(self, func):
        """"""Register a function for calling after code execution.
        """"""
        if not callable(func):
            raise ValueError('argument %s must be callable' % func)
        self._post_execute[func] = True",Register a function for calling after code execution.,
"def new_main_mod(self,ns=None):
        """"""Return a new 'main' module object for user code execution.
        """"""
        main_mod = self._user_main_module
        init_fakemod_dict(main_mod,ns)
        return main_mod",Return a new 'main' module object for user code execution.,
"def _object_find(self, oname, namespaces=None):
        """"""Find an object and return a struct with info about it.""""""
        inf = Struct(self._ofind(oname, namespaces))
        return Struct(self._ofind_property(oname, inf))",Find an object and return a struct with info about it.,
"def init_history(self):
        """"""Sets up the command history, and starts regular autosaves.""""""
        self.history_manager = HistoryManager(shell=self, config=self.config)
        self.configurables.append(self.history_manager)","Sets up the command history, and starts regular autosaves.",
"def _showtraceback(self, etype, evalue, stb):
        """"""Actually show a traceback.

        Subclasses may override this method to put the traceback on a different
        place, like a side channel.
        """"""
        print >> io.stdout, self.InteractiveTB.stb2text(stb)","Actually show a traceback.

        Subclasses may override this method to put the traceback on a different
        place, like a side channel.",
"def pre_readline(self):
        """"""readline hook to be used at the start of each line.

        Currently it handles auto-indent only.""""""

        if self.rl_do_indent:
            self.readline.insert_text(self._indent_current_str())
        if self.rl_next_input is not None:
            self.readline.insert_text(self.rl_next_input)
            self.rl_next_input = None","readline hook to be used at the start of each line.

        Currently it handles auto-indent only.",
"def set_custom_completer(self, completer, pos=0):
        """"""Adds a new custom completer function.

        The position argument (defaults to 0) is the index in the completers
        list where you want the completer to be inserted.""""""

        newcomp = types.MethodType(completer,self.Completer)
        self.Completer.matchers.insert(pos,newcomp)","Adds a new custom completer function.

        The position argument (defaults to 0) is the index in the completers
        list where you want the completer to be inserted.",
"def set_completer_frame(self, frame=None):
        """"""Set the frame of the completer.""""""
        if frame:
            self.Completer.namespace = frame.f_locals
            self.Completer.global_namespace = frame.f_globals
        else:
            self.Completer.namespace = self.user_ns
            self.Completer.global_namespace = self.user_global_ns",Set the frame of the completer.,
"def find_magic(self, magic_name, magic_kind='line'):
        """"""Find and return a magic of the given type by name.

        Returns None if the magic isn't found.""""""
        return self.magics_manager.magics[magic_kind].get(magic_name)","Find and return a magic of the given type by name.

        Returns None if the magic isn't found.",
"def ex(self, cmd):
        """"""Execute a normal python statement in user namespace.""""""
        with self.builtin_trap:
            exec cmd in self.user_global_ns, self.user_ns",Execute a normal python statement in user namespace.,
"def ev(self, expr):
        """"""Evaluate python expression expr in user namespace.

        Returns the result of evaluation
        """"""
        with self.builtin_trap:
            return eval(expr, self.user_global_ns, self.user_ns)","Evaluate python expression expr in user namespace.

        Returns the result of evaluation",
"def _run_cached_cell_magic(self, magic_name, line):
        """"""Special method to call a cell magic with the data stored in self.
        """"""
        cell = self._current_cell_magic_body
        self._current_cell_magic_body = None
        return self.run_cell_magic(magic_name, line, cell)",Special method to call a cell magic with the data stored in self.,
"def broadcast(client, sender, msg_name, dest_name=None, block=None):
    """"""broadcast a message from one engine to all others.""""""
    dest_name = msg_name if dest_name is None else dest_name
    client[sender].execute('com.publish(%s)'%msg_name, block=None)
    targets = client.ids
    targets.remove(sender)
    return client[targets].execute('%s=com.consume()'%dest_name, block=None)",broadcast a message from one engine to all others.,
"def list_profiles_in(path):
    """"""list profiles in a given root directory""""""
    files = os.listdir(path)
    profiles = []
    for f in files:
        full_path = os.path.join(path, f)
        if os.path.isdir(full_path) and f.startswith('profile_'):
            profiles.append(f.split('_',1)[-1])
    return profiles",list profiles in a given root directory,
"def _bypass_ensure_directory(path, mode=0o777):
    """"""Sandbox-bypassing version of ensure_directory()""""""
    if not WRITE_SUPPORT:
        raise IOError('""os.mkdir"" not supported on this platform.')
    dirname, filename = split(path)
    if dirname and filename and not isdir(dirname):
        _bypass_ensure_directory(dirname)
        mkdir(dirname, mode)",Sandbox-bypassing version of ensure_directory(),
"def is_invalid_marker(cls, text):
        """"""
        Validate text as a PEP 426 environment marker; return an exception
        if invalid or False otherwise.
        """"""
        try:
            cls.evaluate_marker(text)
        except SyntaxError:
            return cls.normalize_exception(sys.exc_info()[1])
        return False","Validate text as a PEP 426 environment marker; return an exception
        if invalid or False otherwise.",
"def getecho (self):

        """"""This returns the terminal echo mode. This returns True if echo is
        on or False if echo is off. Child applications that are expecting you
        to enter a password often set ECHO False. See waitnoecho(). """"""

        attr = termios.tcgetattr(self.child_fd)
        if attr[3] & termios.ECHO:
            return True
        return False","This returns the terminal echo mode. This returns True if echo is
        on or False if echo is off. Child applications that are expecting you
        to enter a password often set ECHO False. See waitnoecho().",
"def next (self):    # File-like object.

        """"""This is to support iterators over a file-like object.
        """"""

        result = self.readline()
        if result == self._empty_buffer:
            raise StopIteration
        return result",This is to support iterators over a file-like object.,
"def sendintr(self):

        """"""This sends a SIGINT to the child. It does not require
        the SIGINT to be the first character on a line. """"""

        if hasattr(termios, 'VINTR'):
            char = termios.tcgetattr(self.child_fd)[6][termios.VINTR]
        else:
            # platform does not define VINTR so assume CTRL-C
            char = chr(3)
        self.send (char)","This sends a SIGINT to the child. It does not require
        the SIGINT to be the first character on a line.",
"def _prepare_regex_pattern(self, p):
        ""Recompile unicode regexes as bytes regexes. Overridden in subclass.""
        if isinstance(p.pattern, unicode):
            p = re.compile(p.pattern.encode('utf-8'), p.flags &~ re.UNICODE)
        return p",Recompile unicode regexes as bytes regexes. Overridden in subclass.,
"def getwinsize(self):

        """"""This returns the terminal window size of the child tty. The return
        value is a tuple of (rows, cols). """"""

        TIOCGWINSZ = getattr(termios, 'TIOCGWINSZ', 1074295912L)
        s = struct.pack('HHHH', 0, 0, 0, 0)
        x = fcntl.ioctl(self.fileno(), TIOCGWINSZ, s)
        return struct.unpack('HHHH', x)[0:2]","This returns the terminal window size of the child tty. The return
        value is a tuple of (rows, cols).",
"def _prepare_regex_pattern(self, p):
        ""Recompile bytes regexes as unicode regexes.""
        if isinstance(p.pattern, bytes):
            p = re.compile(p.pattern.decode(self.encoding), p.flags)
        return p",Recompile bytes regexes as unicode regexes.,
"def finish_displayhook(self):
        """"""Finish up all displayhook activities.""""""
        sys.stdout.flush()
        sys.stderr.flush()
        self.session.send(self.pub_socket, self.msg, ident=self.topic)
        self.msg = None",Finish up all displayhook activities.,
"def last_error(self):
        """"""Get the output of the last command exevuted.""""""
        if not len(self.log):
            raise RuntimeError('Nothing executed')

        try:
            errs = [l for l in self.log if l[1] != 0]

            return errs[-1][2]
        except IndexError:
            # odd case where there were no errors
            #TODO
            return 'no last error'",Get the output of the last command exevuted.,
"def check_output(self, cmd):
        """"""Wrapper for subprocess.check_output.""""""
        ret, output = self._exec(cmd)
        if not ret == 0:
            raise CommandError(self)

        return output",Wrapper for subprocess.check_output.,
"def check_call(self, cmd):
        """"""Fake the interface of subprocess.call().""""""
        ret, _ = self._exec(cmd)
        if not ret == 0:
            raise CommandError(self)

        return ret",Fake the interface of subprocess.call().,
"def arcs_executed(self):
        """"""Returns a sorted list of the arcs actually executed in the code.""""""
        executed = self.coverage.data.executed_arcs(self.filename)
        m2fl = self.parser.first_line
        executed = [(m2fl(l1), m2fl(l2)) for (l1,l2) in executed]
        return sorted(executed)",Returns a sorted list of the arcs actually executed in the code.,
"def arcs_missing(self):
        """"""Returns a sorted list of the arcs in the code not executed.""""""
        possible = self.arc_possibilities()
        executed = self.arcs_executed()
        missing = [
            p for p in possible
                if p not in executed
                    and p[0] not in self.no_branch
            ]
        return sorted(missing)",Returns a sorted list of the arcs in the code not executed.,
"def branch_lines(self):
        """"""Returns a list of line numbers that have more than one exit.""""""
        exit_counts = self.parser.exit_counts()
        return [l1 for l1,count in iitems(exit_counts) if count > 1]",Returns a list of line numbers that have more than one exit.,
"def total_branches(self):
        """"""How many total branches are there?""""""
        exit_counts = self.parser.exit_counts()
        return sum([count for count in exit_counts.values() if count > 1])",How many total branches are there?,
"def set_precision(cls, precision):
        """"""Set the number of decimal places used to report percentages.""""""
        assert 0 <= precision < 10
        cls._precision = precision
        cls._near0 = 1.0 / 10**precision
        cls._near100 = 100.0 - cls._near0",Set the number of decimal places used to report percentages.,
"def _get_pc_covered(self):
        """"""Returns a single percentage value for coverage.""""""
        if self.n_statements > 0:
            pc_cov = (100.0 * (self.n_executed + self.n_executed_branches) /
                        (self.n_statements + self.n_branches))
        else:
            pc_cov = 100.0
        return pc_cov",Returns a single percentage value for coverage.,
"def highlight(string, keywords, cls_name='highlighted'):
    """""" Given an list of words, this function highlights the matched text in the given string. """"""

    if not keywords:
        return string
    if not string:
        return ''
    include, exclude = get_text_tokenizer(keywords)
    highlighted = highlight_text(include, string, cls_name)
    return highlighted","Given an list of words, this function highlights the matched text in the given string.",
"def highlight_words(string, keywords, cls_name='highlighted'):
    """""" Given an list of words, this function highlights the matched words in the given string. """"""

    if not keywords:
        return string
    if not string:
        return ''
    include, exclude = get_text_tokenizer(keywords)
    highlighted = highlight_text(include, string, cls_name, words=True)
    return highlighted","Given an list of words, this function highlights the matched words in the given string.",
"def open(self, file, flags, mode=0777):
        """"""Called for low-level os.open()""""""
        if flags & WRITE_FLAGS and not self._ok(file):
            self._violation(""os.open"", file, flags, mode)
        return _os.open(file,flags,mode)",Called for low-level os.open(),
"def unquote_ends(istr):
    """"""Remove a single pair of quotes from the endpoints of a string.""""""

    if not istr:
        return istr
    if (istr[0]==""'"" and istr[-1]==""'"") or \
       (istr[0]=='""' and istr[-1]=='""'):
        return istr[1:-1]
    else:
        return istr",Remove a single pair of quotes from the endpoints of a string.,
"def dgrep(pat,*opts):
    """"""Return grep() on dir()+dir(__builtins__).

    A very common use of grep() when working interactively.""""""

    return grep(pat,dir(__main__)+dir(__main__.__builtins__),*opts)","Return grep() on dir()+dir(__builtins__).

    A very common use of grep() when working interactively.",
"def format_screen(strng):
    """"""Format a string for screen printing.

    This removes some latex-type format codes.""""""
    # Paragraph continue
    par_re = re.compile(r'\\$',re.MULTILINE)
    strng = par_re.sub('',strng)
    return strng","Format a string for screen printing.

    This removes some latex-type format codes.",
"def _get_or_default(mylist, i, default=None):
    """"""return list item number, or default if don't exist""""""
    if i >= len(mylist):
        return default
    else :
        return mylist[i]","return list item number, or default if don't exist",
"def build_kernel_argv(self, argv=None):
        """"""build argv to be passed to kernel subprocess""""""
        if argv is None:
            argv = sys.argv[1:]
        self.kernel_argv = swallow_argv(argv, self.frontend_aliases, self.frontend_flags)
        # kernel should inherit default config file from frontend
        self.kernel_argv.append(""--KernelApp.parent_appname='%s'""%self.name)",build argv to be passed to kernel subprocess,
"def initialize(self, argv=None):
        """"""
        Classes which mix this class in should call:
               IPythonConsoleApp.initialize(self,argv)
        """"""
        self.init_connection_file()
        default_secure(self.config)
        self.init_ssh()
        self.init_kernel_manager()","Classes which mix this class in should call:
               IPythonConsoleApp.initialize(self,argv)",
"def decode_message(self, message):
        """"""
        Decode json string to dict. Validate against node name(targets) and protocol version
        :return dict | None
        """"""
        try:
            message = json.loads(message)
            if not self._validate_message(message):
                message = None
        except ValueError:
            message = None

        return message","Decode json string to dict. Validate against node name(targets) and protocol version
        :return dict | None",
"def pretty(obj, verbose=False, max_width=79, newline='\n'):
    """"""
    Pretty print the object's representation.
    """"""
    stream = StringIO()
    printer = RepresentationPrinter(stream, verbose, max_width, newline)
    printer.pretty(obj)
    printer.flush()
    return stream.getvalue()",Pretty print the object's representation.,
"def pprint(obj, verbose=False, max_width=79, newline='\n'):
    """"""
    Like `pretty` but print to stdout.
    """"""
    printer = RepresentationPrinter(sys.stdout, verbose, max_width, newline)
    printer.pretty(obj)
    printer.flush()
    sys.stdout.write(newline)
    sys.stdout.flush()",Like `pretty` but print to stdout.,
"def _super_pprint(obj, p, cycle):
    """"""The pprint for the super type.""""""
    p.begin_group(8, '<super: ')
    p.pretty(obj.__self_class__)
    p.text(',')
    p.breakable()
    p.pretty(obj.__self__)
    p.end_group(8, '>')",The pprint for the super type.,
"def _type_pprint(obj, p, cycle):
    """"""The pprint for classes and types.""""""
    if obj.__module__ in ('__builtin__', 'exceptions'):
        name = obj.__name__
    else:
        name = obj.__module__ + '.' + obj.__name__
    p.text(name)",The pprint for classes and types.,
"def _function_pprint(obj, p, cycle):
    """"""Base pprint for all functions and builtin functions.""""""
    if obj.__module__ in ('__builtin__', 'exceptions') or not obj.__module__:
        name = obj.__name__
    else:
        name = obj.__module__ + '.' + obj.__name__
    p.text('<function %s>' % name)",Base pprint for all functions and builtin functions.,
"def for_type(typ, func):
    """"""
    Add a pretty printer for a given type.
    """"""
    oldfunc = _type_pprinters.get(typ, None)
    if func is not None:
        # To support easy restoration of old pprinters, we need to ignore Nones.
        _type_pprinters[typ] = func
    return oldfunc",Add a pretty printer for a given type.,
"def group(self, indent=0, open='', close=''):
        """"""like begin_group / end_group but for the with statement.""""""
        self.begin_group(indent, open)
        try:
            yield
        finally:
            self.end_group(indent, close)",like begin_group / end_group but for the with statement.,
"def end_group(self, dedent=0, close=''):
        """"""End a group. See `begin_group` for more details.""""""
        self.indentation -= dedent
        group = self.group_stack.pop()
        if not group.breakables:
            self.group_queue.remove(group)
        if close:
            self.text(close)",End a group. See `begin_group` for more details.,
"def flush(self):
        """"""Flush data that is left in the buffer.""""""
        for data in self.buffer:
            self.output_width += data.output(self.output, self.output_width)
        self.buffer.clear()
        self.buffer_width = 0",Flush data that is left in the buffer.,
"def patterns(prefix, *args):
    """"""As patterns() in django.""""""
    pattern_list = []
    for t in args:
        if isinstance(t, (list, tuple)):
            t = url(prefix=prefix, *t)
        elif isinstance(t, RegexURLPattern):
            t.add_prefix(prefix)
        pattern_list.append(t)
    return pattern_list",As patterns() in django.,
"def osx_clipboard_get():
    """""" Get the clipboard's text on OS X.
    """"""
    p = subprocess.Popen(['pbpaste', '-Prefer', 'ascii'],
        stdout=subprocess.PIPE)
    text, stderr = p.communicate()
    # Text comes in with old Mac \r line endings. Change them to \n.
    text = text.replace('\r', '\n')
    return text",Get the clipboard's text on OS X.,
"def squash_dates(obj):
    """"""squash datetime objects into ISO8601 strings""""""
    if isinstance(obj, dict):
        obj = dict(obj) # don't clobber
        for k,v in obj.iteritems():
            obj[k] = squash_dates(v)
    elif isinstance(obj, (list, tuple)):
        obj = [ squash_dates(o) for o in obj ]
    elif isinstance(obj, datetime):
        obj = obj.strftime(ISO8601)
    return obj",squash datetime objects into ISO8601 strings,
"def date_default(obj):
    """"""default function for packing datetime objects in JSON.""""""
    if isinstance(obj, datetime):
        return obj.strftime(ISO8601)
    else:
        raise TypeError(""%r is not JSON serializable""%obj)",default function for packing datetime objects in JSON.,
"def sleep_here(count, t):
    """"""simple function that takes args, prints a short message, sleeps for a time, and returns the same args""""""
    import time,sys
    print(""hi from engine %i"" % id)
    sys.stdout.flush()
    time.sleep(t)
    return count,t","simple function that takes args, prints a short message, sleeps for a time, and returns the same args",
"def _save_method_args(self, *args, **kwargs):
        """"""Save the args and kwargs to get/post/put/delete for future use.

        These arguments are not saved in the request or handler objects, but
        are often needed by methods such as get_stream().
        """""" 
        self._method_args = args
        self._method_kwargs = kwargs","Save the args and kwargs to get/post/put/delete for future use.

        These arguments are not saved in the request or handler objects, but
        are often needed by methods such as get_stream().",
"def _convert_pyx_sources_to_c(self):
        ""convert .pyx extensions to .c""
        def pyx_to_c(source):
            if source.endswith('.pyx'):
                source = source[:-4] + '.c'
            return source
        self.sources = map(pyx_to_c, self.sources)",convert .pyx extensions to .c,
"def _log_level_changed(self, name, old, new):
        """"""Adjust the log level when log_level is set.""""""
        if isinstance(new, basestring):
            new = getattr(logging, new)
            self.log_level = new
        self.log.setLevel(new)",Adjust the log level when log_level is set.,
"def _flags_changed(self, name, old, new):
        """"""ensure flags dict is valid""""""
        for key,value in new.iteritems():
            assert len(value) == 2, ""Bad flag: %r:%s""%(key,value)
            assert isinstance(value[0], (dict, Config)), ""Bad flag: %r:%s""%(key,value)
            assert isinstance(value[1], basestring), ""Bad flag: %r:%s""%(key,value)",ensure flags dict is valid,
"def print_flag_help(self):
        """"""Print the flag part of the help.""""""
        if not self.flags:
            return

        lines = []
        for m, (cfg,help) in self.flags.iteritems():
            prefix = '--' if len(m) > 1 else '-'
            lines.append(prefix+m)
            lines.append(indent(dedent(help.strip())))
        # lines.append('')
        print os.linesep.join(lines)",Print the flag part of the help.,
"def print_examples(self):
        """"""Print usage and examples.

        This usage string goes at the end of the command line help string
        and should contain examples of the application's usage.
        """"""
        if self.examples:
            print ""Examples""
            print ""--------""
            print
            print indent(dedent(self.examples.strip()))
            print","Print usage and examples.

        This usage string goes at the end of the command line help string
        and should contain examples of the application's usage.",
"def update_config(self, config):
        """"""Fire the traits events when the config is updated.""""""
        # Save a copy of the current config.
        newconfig = deepcopy(self.config)
        # Merge the new config into the current one.
        newconfig._merge(config)
        # Save the combined config as self.config, which triggers the traits
        # events.
        self.config = newconfig",Fire the traits events when the config is updated.,
"def generate_config_file(self):
        """"""generate default config file from Configurables""""""
        lines = [""# Configuration file for %s.""%self.name]
        lines.append('')
        lines.append('c = get_config()')
        lines.append('')
        for cls in self.classes:
            lines.append(cls.class_config_section())
        return '\n'.join(lines)",generate default config file from Configurables,
"def downsample(array, k):
    """"""Choose k random elements of array.""""""
    length = array.shape[0]
    indices = random.sample(xrange(length), k)
    return array[indices]",Choose k random elements of array.,
"def write(self, msg):
        """"""Write a line of debug output.""""""
        if self.should('pid'):
            msg = ""pid %5d: %s"" % (os.getpid(), msg)
        self.output.write(msg+""\n"")
        self.output.flush()",Write a line of debug output.,
"def _walk_mro(cls):
        """"""Walk the cls.mro() for parent classes that are also singletons

        For use in instance()
        """"""

        for subclass in cls.mro():
            if issubclass(cls, subclass) and \
                    issubclass(subclass, SingletonConfigurable) and \
                    subclass != SingletonConfigurable:
                yield subclass","Walk the cls.mro() for parent classes that are also singletons

        For use in instance()",
"def clear_instance(cls):
        """"""unset _instance for this class and singleton parents.
        """"""
        if not cls.initialized():
            return
        for subclass in cls._walk_mro():
            if isinstance(subclass._instance, cls):
                # only clear instances that are instances
                # of the calling class
                subclass._instance = None",unset _instance for this class and singleton parents.,
"def configure(self, options, conf):
        """"""Configure plugin.
        """"""
        if not self.can_configure:
            return
        self.enabled = options.detailedErrors
        self.conf = conf",Configure plugin.,
"def formatFailure(self, test, err):
        """"""Add detail from traceback inspection to error message of a failure.
        """"""
        ec, ev, tb = err
        tbinfo = inspect_traceback(tb)
        test.tbinfo = tbinfo
        return (ec, '\n'.join([str(ev), tbinfo]), tb)",Add detail from traceback inspection to error message of a failure.,
"def setvar(parser, token):
    """""" {% setvar <var_name> to <var_value> %} """"""

    try:
        setvar, var_name, to_, var_value = token.split_contents()
    except ValueError:
        raise template.TemplateSyntaxError('Invalid arguments for %r' % token.split_contents()[0])

    return SetVarNode(var_name, var_value)",{% setvar <var_name> to <var_value> %},
"def flush(self):
        """""" Reimplemented to ensure that signals are dispatched immediately.
        """"""
        super(QtSubSocketChannel, self).flush()
        QtCore.QCoreApplication.instance().processEvents()",Reimplemented to ensure that signals are dispatched immediately.,
"def call_handlers(self, msg):
        """""" Reimplemented to emit signals instead of making callbacks.
        """"""
        # Emit the generic signal.
        self.message_received.emit(msg)

        # Emit signals for specialized message types.
        msg_type = msg['header']['msg_type']
        if msg_type == 'input_request':
            self.input_requested.emit(msg)",Reimplemented to emit signals instead of making callbacks.,
"def start_kernel(self, *args, **kw):
        """""" Reimplemented for proper heartbeat management.
        """"""
        if self._shell_channel is not None:
            self._shell_channel.reset_first_reply()
        super(QtKernelManager, self).start_kernel(*args, **kw)
        self.started_kernel.emit()",Reimplemented for proper heartbeat management.,
"def start_channels(self, *args, **kw):
        """""" Reimplemented to emit signal.
        """"""
        super(QtKernelManager, self).start_channels(*args, **kw)
        self.started_channels.emit()",Reimplemented to emit signal.,
"def shell_channel(self):
        """""" Reimplemented for proper heartbeat management.
        """"""
        if self._shell_channel is None:
            self._shell_channel = super(QtKernelManager, self).shell_channel
            self._shell_channel.first_reply.connect(self._first_reply)
        return self._shell_channel",Reimplemented for proper heartbeat management.,
"def _join_lines(lines):
    """"""join lines that have been written by splitlines()
    
    Has logic to protect against `splitlines()`, which
    should have been `splitlines(True)`
    """"""
    if lines and lines[0].endswith(('\n', '\r')):
        # created by splitlines(True)
        return u''.join(lines)
    else:
        # created by splitlines()
        return u'\n'.join(lines)","join lines that have been written by splitlines()
    
    Has logic to protect against `splitlines()`, which
    should have been `splitlines(True)`",
"def read(self, fp, **kwargs):
        """"""Read a notebook from a file like object""""""
        nbs = fp.read()
        if not py3compat.PY3 and not isinstance(nbs, unicode):
            nbs = py3compat.str_to_unicode(nbs)
        return self.reads(nbs, **kwargs)",Read a notebook from a file like object,
"def write(self, nb, fp, **kwargs):
        """"""Write a notebook to a file like object""""""
        nbs = self.writes(nb,**kwargs)
        if not py3compat.PY3 and not isinstance(nbs, unicode):
            # this branch is likely only taken for JSON on Python 2
            nbs = py3compat.str_to_unicode(nbs)
        return fp.write(nbs)",Write a notebook to a file like object,
"def read_no_interrupt(p):
    """"""Read from a pipe ignoring EINTR errors.

    This is necessary because when reading from pipes with GUI event loops
    running in the background, often interrupts are raised that stop the
    command from completing.""""""
    import errno

    try:
        return p.read()
    except IOError, err:
        if err.errno != errno.EINTR:
            raise","Read from a pipe ignoring EINTR errors.

    This is necessary because when reading from pipes with GUI event loops
    running in the background, often interrupts are raised that stop the
    command from completing.",
"def default_option(self, fn, optstr):
        """"""Make an entry in the options_table for fn, with value optstr""""""

        if fn not in self.lsmagic():
            error(""%s is not a magic function"" % fn)
        self.options_table[fn] = optstr","Make an entry in the options_table for fn, with value optstr",
"def page_guiref(arg_s=None):
    """"""Show a basic reference about the GUI Console.""""""
    from IPython.core import page
    page.page(gui_reference, auto_html=True)",Show a basic reference about the GUI Console.,
"def get_member(thing_obj, member_string):
    """"""Get a member from an object by (string) name""""""
    mems = {x[0]: x[1] for x in inspect.getmembers(thing_obj)}
    if member_string in mems:
        return mems[member_string]",Get a member from an object by (string) name,
"def taskinfo_with_label(label):
    """"""Return task info dictionary from task label.  Internal function,
    pretty much only used in migrations since the model methods aren't there.""""""
    task = Task.objects.get(label=label)
    info = json.loads(task._func_info)
    return info","Return task info dictionary from task label.  Internal function,
    pretty much only used in migrations since the model methods aren't there.",
"def submit(self, timestamp):
        """"""Internal instance method to submit this task for running immediately.
        Does not handle any iteration, end-date, etc., processing.""""""
        Channel(RUN_TASK_CHANNEL).send({'id':self.pk, 'ts': timestamp.timestamp()})","Internal instance method to submit this task for running immediately.
        Does not handle any iteration, end-date, etc., processing.",
"def run_asap(self):
        """"""Instance method to run this task immediately.""""""
        now = timezone.now()
        self.last_run = now
        self.calc_next_run()
        self.save()
        self.submit(now)",Instance method to run this task immediately.,
"def run_once(cls, the_callable, userdata=None, delay_until=None):
        """"""Class method to run a one-shot task, immediately.""""""
        cls.run_iterations(the_callable, userdata=userdata, run_immediately=True, delay_until=delay_until)","Class method to run a one-shot task, immediately.",
"def pid_exists(pid):
    """"""Check whether pid exists in the current process table.""""""
    if not isinstance(pid, int):
        raise TypeError('an integer is required')
    if pid < 0:
        return False
    try:
        os.kill(pid, 0)
    except OSError:
        e = sys.exc_info()[1]
        return e.errno == errno.EPERM
    else:
        return True",Check whether pid exists in the current process table.,
"def mutex_opts(dict,ex_op):
    """"""Check for presence of mutually exclusive keys in a dict.

    Call: mutex_opts(dict,[[op1a,op1b],[op2a,op2b]...]""""""
    for op1,op2 in ex_op:
        if op1 in dict and op2 in dict:
            raise ValueError,'\n*** ERROR in Arguments *** '\
                  'Options '+op1+' and '+op2+' are mutually exclusive.'","Check for presence of mutually exclusive keys in a dict.

    Call: mutex_opts(dict,[[op1a,op1b],[op2a,op2b]...]",
"def popkey(dct,key,default=NotGiven):
    """"""Return dct[key] and delete dct[key].

    If default is given, return it if dct[key] doesn't exist, otherwise raise
    KeyError.  """"""

    try:
        val = dct[key]
    except KeyError:
        if default is NotGiven:
            raise
        else:
            return default
    else:
        del dct[key]
        return val","Return dct[key] and delete dct[key].

    If default is given, return it if dct[key] doesn't exist, otherwise raise
    KeyError.",
"def unload_extension(self, module_str):
        """"""Unload an IPython extension by its module name.

        This function looks up the extension's name in ``sys.modules`` and
        simply calls ``mod.unload_ipython_extension(self)``.
        """"""
        if module_str in sys.modules:
            mod = sys.modules[module_str]
            self._call_unload_ipython_extension(mod)","Unload an IPython extension by its module name.

        This function looks up the extension's name in ``sys.modules`` and
        simply calls ``mod.unload_ipython_extension(self)``.",
"def random_ports(port, n):
    """"""Generate a list of n random ports near the given port.

    The first 5 ports will be sequential, and the remaining n-5 will be
    randomly selected in the range [port-2*n, port+2*n].
    """"""
    for i in range(min(5, n)):
        yield port + i
    for i in range(n-5):
        yield port + random.randint(-2*n, 2*n)","Generate a list of n random ports near the given port.

    The first 5 ports will be sequential, and the remaining n-5 will be
    randomly selected in the range [port-2*n, port+2*n].",
"def cwd_filt(depth):
    """"""Return the last depth elements of the current working directory.

    $HOME is always replaced with '~'.
    If depth==0, the full path is returned.""""""

    cwd = os.getcwdu().replace(HOME,""~"")
    out = os.sep.join(cwd.split(os.sep)[-depth:])
    return out or os.sep","Return the last depth elements of the current working directory.

    $HOME is always replaced with '~'.
    If depth==0, the full path is returned.",
"def mappable(obj):
    """"""return whether an object is mappable or not.""""""
    if isinstance(obj, (tuple,list)):
        return True
    for m in arrayModules:
        if isinstance(obj,m['type']):
            return True
    return False",return whether an object is mappable or not.,
"def fetch_pi_file(filename):
    """"""This will download a segment of pi from super-computing.org
    if the file is not already present.
    """"""
    import os, urllib
    ftpdir=""ftp://pi.super-computing.org/.2/pi200m/""
    if os.path.exists(filename):
        # we already have it
        return
    else:
        # download it
        urllib.urlretrieve(ftpdir+filename,filename)","This will download a segment of pi from super-computing.org
    if the file is not already present.",
"def reduce_freqs(freqlist):
    """"""
    Add up a list of freq counts to get the total counts.
    """"""
    allfreqs = np.zeros_like(freqlist[0])
    for f in freqlist:
        allfreqs += f
    return allfreqs",Add up a list of freq counts to get the total counts.,
"def compute_n_digit_freqs(filename, n):
    """"""
    Read digits of pi from a file and compute the n digit frequencies.
    """"""
    d = txt_file_to_digits(filename)
    freqs = n_digit_freqs(d, n)
    return freqs",Read digits of pi from a file and compute the n digit frequencies.,
"def txt_file_to_digits(filename, the_type=str):
    """"""
    Yield the digits of pi read from a .txt file.
    """"""
    with open(filename, 'r') as f:
        for line in f.readlines():
            for c in line:
                if c != '\n' and c!= ' ':
                    yield the_type(c)",Yield the digits of pi read from a .txt file.,
"def one_digit_freqs(digits, normalize=False):
    """"""
    Consume digits of pi and compute 1 digit freq. counts.
    """"""
    freqs = np.zeros(10, dtype='i4')
    for d in digits:
        freqs[int(d)] += 1
    if normalize:
        freqs = freqs/freqs.sum()
    return freqs",Consume digits of pi and compute 1 digit freq. counts.,
"def two_digit_freqs(digits, normalize=False):
    """"""
    Consume digits of pi and compute 2 digits freq. counts.
    """"""
    freqs = np.zeros(100, dtype='i4')
    last = digits.next()
    this = digits.next()
    for d in digits:
        index = int(last + this)
        freqs[index] += 1
        last = this
        this = d
    if normalize:
        freqs = freqs/freqs.sum()
    return freqs",Consume digits of pi and compute 2 digits freq. counts.,
"def plot_two_digit_freqs(f2):
    """"""
    Plot two digits frequency counts using matplotlib.
    """"""
    f2_copy = f2.copy()
    f2_copy.shape = (10,10)
    ax = plt.matshow(f2_copy)
    plt.colorbar()
    for i in range(10):
        for j in range(10):
            plt.text(i-0.2, j+0.2, str(j)+str(i))
    plt.ylabel('First digit')
    plt.xlabel('Second digit')
    return ax",Plot two digits frequency counts using matplotlib.,
"def plot_one_digit_freqs(f1):
    """"""
    Plot one digit frequency counts using matplotlib.
    """"""
    ax = plt.plot(f1,'bo-')
    plt.title('Single digit counts in pi')
    plt.xlabel('Digit')
    plt.ylabel('Count')
    return ax",Plot one digit frequency counts using matplotlib.,
"def get_object_or_none(qs, *args, **kwargs):
    """"""
    Try to retrieve a model, and return None if
    it is not found.
    Useful if you do not want to bother with the try/except block.
    """"""

    try:
        return qs.get(*args, **kwargs)
    except models.ObjectDoesNotExist:
        return None","Try to retrieve a model, and return None if
    it is not found.
    Useful if you do not want to bother with the try/except block.",
"def extract_module_locals(depth=0):
    """"""Returns (module, locals) of the funciton `depth` frames away from the caller""""""
    f = sys._getframe(depth + 1)
    global_ns = f.f_globals
    module = sys.modules[global_ns['__name__']]
    return (module, f.f_locals)","Returns (module, locals) of the funciton `depth` frames away from the caller",
"def _extract_future_flags(globs):
    """"""
    Return the compiler-flags associated with the future features that
    have been imported into the given namespace (globs).
    """"""
    flags = 0
    for fname in __future__.all_feature_names:
        feature = globs.get(fname, None)
        if feature is getattr(__future__, fname):
            flags |= feature.compiler_flag
    return flags","Return the compiler-flags associated with the future features that
    have been imported into the given namespace (globs).",
"def _exception_traceback(exc_info):
    """"""
    Return a string containing a traceback message for the given
    exc_info tuple (as returned by sys.exc_info()).
    """"""
    # Get a traceback message.
    excout = StringIO()
    exc_type, exc_val, exc_tb = exc_info
    traceback.print_exception(exc_type, exc_val, exc_tb, file=excout)
    return excout.getvalue()","Return a string containing a traceback message for the given
    exc_info tuple (as returned by sys.exc_info()).",
"def debug_src(src, pm=False, globs=None):
    """"""Debug a single doctest docstring, in argument `src`'""""""
    testsrc = script_from_examples(src)
    debug_script(testsrc, pm, globs)","Debug a single doctest docstring, in argument `src`",
"def debug(module, name, pm=False):
    """"""Debug a single doctest docstring.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the docstring with tests to be debugged.
    """"""
    module = _normalize_module(module)
    testsrc = testsource(module, name)
    debug_script(testsrc, pm, module.__dict__)","Debug a single doctest docstring.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the docstring with tests to be debugged.",
"def hset(self, hashroot, key, value):
        """""" hashed set """"""
        hroot = self.root / hashroot
        if not hroot.isdir():
            hroot.makedirs()
        hfile = hroot / gethashfile(key)
        d = self.get(hfile, {})
        d.update( {key : value})
        self[hfile] = d",hashed set,
"def keys(self, globpat = None):
        """""" All keys in DB, or all keys matching a glob""""""

        if globpat is None:
            files = self.root.walkfiles()
        else:
            files = [Path(p) for p in glob.glob(self.root/globpat)]
        return [self._normalized(p) for p in files if p.isfile()]","All keys in DB, or all keys matching a glob",
"def show_items(self, cursor, items):
        """""" Shows the completion widget with 'items' at the position specified
            by 'cursor'.
        """"""
        if not items :
            return
        self.cancel_completion()
        strng = text.columnize(items)
        self._console_widget._fill_temporary_buffer(cursor, strng, html=False)","Shows the completion widget with 'items' at the position specified
            by 'cursor'.",
"def allow(self, record):
        """"""returns whether this record should be printed""""""
        if not self:
            # nothing to filter
            return True
        return self._allow(record) and not self._deny(record)",returns whether this record should be printed,
"def _any_match(matchers, record):
        """"""return the bool of whether `record` starts with
        any item in `matchers`""""""
        def record_matches_key(key):
            return record == key or record.startswith(key + '.')
        return anyp(bool, map(record_matches_key, matchers))","return the bool of whether `record` starts with
        any item in `matchers`",
"def formatError(self, test, err):
        """"""Add captured log messages to error output.
        """"""
        # logic flow copied from Capture.formatError
        test.capturedLogging = records = self.formatLogRecords()
        if not records:
            return err
        ec, ev, tb = err
        return (ec, self.addCaptureToErr(ev, records), tb)",Add captured log messages to error output.,
"def _get_all_po_filenames(locale_root, lang, po_files_path):
    """"""
    Get all po filenames from locale folder and return list of them.
    Assumes a directory structure:
    <locale_root>/<lang>/<po_files_path>/<filename>.
    """"""
    all_files = os.listdir(os.path.join(locale_root, lang, po_files_path))
    return filter(lambda s: s.endswith('.po'), all_files)","Get all po filenames from locale folder and return list of them.
    Assumes a directory structure:
    <locale_root>/<lang>/<po_files_path>/<filename>.",
"def _get_new_csv_writers(trans_title, meta_title,
                         trans_csv_path, meta_csv_path):
    """"""
    Prepare new csv writers, write title rows and return them.
    """"""
    trans_writer = UnicodeWriter(trans_csv_path)
    trans_writer.writerow(trans_title)

    meta_writer = UnicodeWriter(meta_csv_path)
    meta_writer.writerow(meta_title)

    return trans_writer, meta_writer","Prepare new csv writers, write title rows and return them.",
"def subscribe_user(self, user):
        """""" method to subscribe a user to a service
        """"""
        url = self.root_url + ""subscribe_user""
        values = {}
        values[""username""] = user
        return self._query(url, values)",method to subscribe a user to a service,
"def rsplit1(s, sep):
    """"""The same as s.rsplit(sep, 1), but works in 2.3""""""
    parts = s.split(sep)
    return sep.join(parts[:-1]), parts[-1]","The same as s.rsplit(sep, 1), but works in 2.3",
"def select_up(self):
        """"""move cursor up""""""
        r, c = self._index
        self._select_index(r-1, c)",move cursor up,
"def select_down(self):
        """"""move cursor down""""""
        r, c = self._index
        self._select_index(r+1, c)",move cursor down,
"def select_left(self):
        """"""move cursor left""""""
        r, c = self._index
        self._select_index(r, c-1)",move cursor left,
"def select_right(self):
        """"""move cursor right""""""
        r, c = self._index
        self._select_index(r, c+1)",move cursor right,
"def _complete_current(self):
        """""" Perform the completion with the currently selected item.
        """"""
        i = self._index
        item = self._items[i[0]][i[1]]
        item = item.strip()
        if item :
            self._current_text_cursor().insertText(item)
        self.cancel_completion()",Perform the completion with the currently selected item.,
"def wordfreq(text, is_filename=False):
    """"""Return a dictionary of words and word counts in a string.""""""
    if is_filename:
        with open(text) as f:
            text = f.read()
    freqs = {}
    for word in text.split():
        lword = word.lower()
        freqs[lword] = freqs.get(lword, 0) + 1
    return freqs",Return a dictionary of words and word counts in a string.,
"def print_wordfreq(freqs, n=10):
    """"""Print the n most common words and counts in the freqs dict.""""""
    
    words, counts = freqs.keys(), freqs.values()
    items = zip(counts, words)
    items.sort(reverse=True)
    for (count, word) in items[:n]:
        print(word, count)",Print the n most common words and counts in the freqs dict.,
"def tostring(self):
        """"""Return the string representation of the job description XML.""""""
        root = self.as_element()
        indent(root)
        txt = ET.tostring(root, encoding=""utf-8"")
        # Now remove the tokens used to order the attributes.
        txt = re.sub(r'_[A-Z]_','',txt)
        txt = '<?xml version=""1.0"" encoding=""utf-8""?>\n' + txt
        return txt",Return the string representation of the job description XML.,
"def write(self, filename):
        """"""Write the XML job description to a file.""""""
        txt = self.tostring()
        with open(filename, 'w') as f:
            f.write(txt)",Write the XML job description to a file.,
"def validate_pin(pin):
    """""" Validate the given pin against the schema.

    :param dict pin: The pin to validate:
    :raises pypebbleapi.schemas.DocumentError: If the pin is not valid.
    """"""
    v = _Validator(schemas.pin)
    if v.validate(pin):
        return
    else:
        raise schemas.DocumentError(errors=v.errors)","Validate the given pin against the schema.

    :param dict pin: The pin to validate:
    :raises pypebbleapi.schemas.DocumentError: If the pin is not valid.",
"def begin(self, total: int, name=None, message=None):
        """"""Call before starting work on a monitor, specifying name and amount of work""""""
        self.total = total
        message = message or name or ""Working...""
        self.name = name or ""ProgressMonitor""
        self.update(0, message)","Call before starting work on a monitor, specifying name and amount of work",
"def task(self, total: int, name=None, message=None):
        """"""Wrap code into a begin and end call on this monitor""""""
        self.begin(total, name, message)
        try:
            yield self
        finally:
            self.done()",Wrap code into a begin and end call on this monitor,
"def subtask(self, units: int):
        """"""Create a submonitor with the given units""""""
        sm = self.submonitor(units)
        try:
            yield sm
        finally:
            if sm.total is None:
                # begin was never called, so the subtask cannot be closed
                self.update(units)
            else:
                sm.done()",Create a submonitor with the given units,
"def progress(self)-> float:
        """"""What percentage (range 0-1) of work is done (including submonitors)""""""
        if self.total is None:
            return 0
        my_progress = self.worked
        my_progress += sum(s.progress * weight
                           for (s, weight) in self.sub_monitors.items())
        return min(1, my_progress / self.total)",What percentage (range 0-1) of work is done (including submonitors),
"def done(self, message: str=None):
        """"""
        Signal that this task is done.
        This is completely optional and will just call .update with the remaining work.
        """"""
        if message is None:
            message = ""{self.name} done"".format(**locals()) if self.name else ""Done""
        self.update(units=self.total - self.worked, message=message)","Signal that this task is done.
        This is completely optional and will just call .update with the remaining work.",
"def load_config(self):
        """"""Load the config from a file and return it as a Struct.""""""
        self.clear()
        try:
            self._find_file()
        except IOError as e:
            raise ConfigFileNotFound(str(e))
        self._read_file_as_dict()
        self._convert_to_config()
        return self.config",Load the config from a file and return it as a Struct.,
"def _load_flag(self, cfg):
        """"""update self.config from a flag, which can be a dict or Config""""""
        if isinstance(cfg, (dict, Config)):
            # don't clobber whole config sections, update
            # each section from config:
            for sec,c in cfg.iteritems():
                self.config[sec].update(c)
        else:
            raise TypeError(""Invalid flag: %r"" % cfg)","update self.config from a flag, which can be a dict or Config",
"def _parse_args(self, args):
        """"""self.parser->self.parsed_data""""""
        # decode sys.argv to support unicode command-line options
        enc = DEFAULT_ENCODING
        uargs = [py3compat.cast_unicode(a, enc) for a in args]
        self.parsed_data, self.extra_args = self.parser.parse_known_args(uargs)",self.parser->self.parsed_data,
"def _convert_to_config(self):
        """"""self.parsed_data->self.config""""""
        for k, v in vars(self.parsed_data).iteritems():
            exec ""self.config.%s = v""%k in locals(), globals()",self.parsed_data->self.config,
"def on_stop(self, f):
        """"""Register a callback to be called with this Launcher's stop_data
        when the process actually finishes.
        """"""
        if self.state=='after':
            return f(self.stop_data)
        else:
            self.stop_callbacks.append(f)","Register a callback to be called with this Launcher's stop_data
        when the process actually finishes.",
"def notify_start(self, data):
        """"""Call this to trigger startup actions.

        This logs the process startup and sets the state to 'running'.  It is
        a pass-through so it can be used as a callback.
        """"""

        self.log.debug('Process %r started: %r', self.args[0], data)
        self.start_data = data
        self.state = 'running'
        return data","Call this to trigger startup actions.

        This logs the process startup and sets the state to 'running'.  It is
        a pass-through so it can be used as a callback.",
"def interrupt_then_kill(self, delay=2.0):
        """"""Send INT, wait a delay and then send KILL.""""""
        try:
            self.signal(SIGINT)
        except Exception:
            self.log.debug(""interrupt failed"")
            pass
        self.killer  = ioloop.DelayedCallback(lambda : self.signal(SIGKILL), delay*1000, self.loop)
        self.killer.start()","Send INT, wait a delay and then send KILL.",
"def find_args(self):
        """"""Build self.args using all the fields.""""""
        return self.mpi_cmd + ['-n', str(self.n)] + self.mpi_args + \
               self.program + self.program_args",Build self.args using all the fields.,
"def start(self, n):
        """"""Start n instances of the program using mpiexec.""""""
        self.n = n
        return super(MPILauncher, self).start()",Start n instances of the program using mpiexec.,
"def start(self, n):
        """"""Start n engines by profile or profile_dir.""""""
        self.n = n
        return super(MPIEngineSetLauncher, self).start(n)",Start n engines by profile or profile_dir.,
"def send_files(self):
        """"""send our files (called before start)""""""
        if not self.to_send:
            return
        for local_file, remote_file in self.to_send:
            self._send_file(local_file, remote_file)",send our files (called before start),
"def fetch_files(self):
        """"""fetch remote files (called after start)""""""
        if not self.to_fetch:
            return
        for remote_file, local_file in self.to_fetch:
            self._fetch_file(remote_file, local_file)",fetch remote files (called after start),
"def _remote_profile_dir_default(self):
        """"""turns /home/you/.ipython/profile_foo into .ipython/profile_foo
        """"""
        home = get_home_dir()
        if not home.endswith('/'):
            home = home+'/'
        
        if self.profile_dir.startswith(home):
            return self.profile_dir[len(home):]
        else:
            return self.profile_dir",turns /home/you/.ipython/profile_foo into .ipython/profile_foo,
"def engine_count(self):
        """"""determine engine count from `engines` dict""""""
        count = 0
        for n in self.engines.itervalues():
            if isinstance(n, (tuple,list)):
                n,args = n
            count += n
        return count",determine engine count from `engines` dict,
"def _context_default(self):
        """"""load the default context with the default values for the basic keys

        because the _trait_changed methods only load the context if they
        are set to something other than the default value.
        """"""
        return dict(n=1, queue=u'', profile_dir=u'', cluster_id=u'')","load the default context with the default values for the basic keys

        because the _trait_changed methods only load the context if they
        are set to something other than the default value.",
"def check_filemode(filepath, mode):
    """"""Return True if 'file' matches ('permission') which should be entered in octal.
    """"""

    filemode = stat.S_IMODE(os.stat(filepath).st_mode)
    return (oct(filemode) == mode)",Return True if 'file' matches ('permission') which should be entered in octal.,
"def _append_jpg(self, jpg, before_prompt=False):
        """""" Append raw JPG data to the widget.""""""
        self._append_custom(self._insert_jpg, jpg, before_prompt)",Append raw JPG data to the widget.,
"def _append_png(self, png, before_prompt=False):
        """""" Append raw PNG data to the widget.
        """"""
        self._append_custom(self._insert_png, png, before_prompt)",Append raw PNG data to the widget.,
"def _append_svg(self, svg, before_prompt=False):
        """""" Append raw SVG data to the widget.
        """"""
        self._append_custom(self._insert_svg, svg, before_prompt)",Append raw SVG data to the widget.,
"def _copy_image(self, name):
        """""" Copies the ImageResource with 'name' to the clipboard.
        """"""
        image = self._get_image(name)
        QtGui.QApplication.clipboard().setImage(image)",Copies the ImageResource with 'name' to the clipboard.,
"def _get_image(self, name):
        """""" Returns the QImage stored as the ImageResource with 'name'.
        """"""
        document = self._control.document()
        image = document.resource(QtGui.QTextDocument.ImageResource,
                                  QtCore.QUrl(name))
        return image",Returns the QImage stored as the ImageResource with 'name'.,
"def _exit_now_changed(self, name, old, new):
        """"""stop eventloop when exit_now fires""""""
        if new:
            loop = ioloop.IOLoop.instance()
            loop.add_timeout(time.time()+0.1, loop.stop)",stop eventloop when exit_now fires,
"def ask_exit(self):
        """"""Engage the exit actions.""""""
        self.exit_now = True
        payload = dict(
            source='IPython.zmq.zmqshell.ZMQInteractiveShell.ask_exit',
            exit=True,
            keepkernel=self.keepkernel_on_exit,
            )
        self.payload_manager.write_payload(payload)",Engage the exit actions.,
"def set_next_input(self, text):
        """"""Send the specified text to the frontend to be presented at the next
        input cell.""""""
        payload = dict(
            source='IPython.zmq.zmqshell.ZMQInteractiveShell.set_next_input',
            text=text
        )
        self.payload_manager.write_payload(payload)","Send the specified text to the frontend to be presented at the next
        input cell.",
"def check_running(process_name=""apache2""):
    '''
        CHECK if process (default=apache2) is not running
    '''
    if not gurumate.base.get_pid_list(process_name):
        fail(""Apache process '%s' doesn't seem to be working"" % process_name)
        return False #unreachable
    return True",CHECK if process (default=apache2) is not running,
"def get_listening_ports(process_name=""apache2""):
    '''
        returns a list of listening ports for running process (default=apache2)
    '''
    ports = set()
    for _, address_info in gurumate.base.get_listening_ports(process_name):
        ports.add(address_info[1])
    return list(ports)",returns a list of listening ports for running process (default=apache2),
"def read(self, filename):
        """"""Read a filename as UTF-8 configuration data.""""""
        kwargs = {}
        if sys.version_info >= (3, 2):
            kwargs['encoding'] = ""utf-8""
        return configparser.RawConfigParser.read(self, filename, **kwargs)",Read a filename as UTF-8 configuration data.,
"def getlinelist(self, section, option):
        """"""Read a list of full-line strings.

        The value of `section` and `option` is treated as a newline-separated
        list of strings.  Each value is stripped of whitespace.

        Returns the list of strings.

        """"""
        value_list = self.get(section, option)
        return list(filter(None, value_list.split('\n')))","Read a list of full-line strings.

        The value of `section` and `option` is treated as a newline-separated
        list of strings.  Each value is stripped of whitespace.

        Returns the list of strings.",
"def from_args(self, **kwargs):
        """"""Read config values from `kwargs`.""""""
        for k, v in iitems(kwargs):
            if v is not None:
                if k in self.MUST_BE_LIST and isinstance(v, string_class):
                    v = [v]
                setattr(self, k, v)",Read config values from `kwargs`.,
"def set_attr_from_config_option(self, cp, attr, where, type_=''):
        """"""Set an attribute on self if it exists in the ConfigParser.""""""
        section, option = where.split("":"")
        if cp.has_option(section, option):
            method = getattr(cp, 'get'+type_)
            setattr(self, attr, method(section, option))",Set an attribute on self if it exists in the ConfigParser.,
"def delims(self, delims):
        """"""Set the delimiters for line splitting.""""""
        expr = '[' + ''.join('\\'+ c for c in delims) + ']'
        self._delim_re = re.compile(expr)
        self._delims = delims
        self._delim_expr = expr",Set the delimiters for line splitting.,
"def split_line(self, line, cursor_pos=None):
        """"""Split a line of text with a cursor at the given position.
        """"""
        l = line if cursor_pos is None else line[:cursor_pos]
        return self._delim_re.split(l)[-1]",Split a line of text with a cursor at the given position.,
"def _greedy_changed(self, name, old, new):
        """"""update the splitter and readline delims when greedy is changed""""""
        if new:
            self.splitter.delims = GREEDY_DELIMS
        else:
            self.splitter.delims = DELIMS

        if self.readline:
            self.readline.set_completer_delims(self.splitter.delims)",update the splitter and readline delims when greedy is changed,
"def _match_one(self, rec, tests):
        """"""Check if a specific record matches tests.""""""
        for key,test in tests.iteritems():
            if not test(rec.get(key, None)):
                return False
        return True",Check if a specific record matches tests.,
"def _extract_subdict(self, rec, keys):
        """"""extract subdict of keys""""""
        d = {}
        d['msg_id'] = rec['msg_id']
        for key in keys:
            d[key] = rec[key]
        return copy(d)",extract subdict of keys,
"def add_record(self, msg_id, rec):
        """"""Add a new Task Record, by msg_id.""""""
        if self._records.has_key(msg_id):
            raise KeyError(""Already have msg_id %r""%(msg_id))
        self._records[msg_id] = rec","Add a new Task Record, by msg_id.",
"def get_record(self, msg_id):
        """"""Get a specific Task Record, by msg_id.""""""
        if not msg_id in self._records:
            raise KeyError(""No such msg_id %r""%(msg_id))
        return copy(self._records[msg_id])","Get a specific Task Record, by msg_id.",
"def drop_matching_records(self, check):
        """"""Remove a record from the DB.""""""
        matches = self._match(check)
        for m in matches:
            del self._records[m['msg_id']]",Remove a record from the DB.,
"def get_history(self):
        """"""get all msg_ids, ordered by time submitted.""""""
        msg_ids = self._records.keys()
        return sorted(msg_ids, key=lambda m: self._records[m]['submitted'])","get all msg_ids, ordered by time submitted.",
"def log_output(self, format_dict):
        """"""Log the output.""""""
        if self.shell.logger.log_output:
            self.shell.logger.log_write(format_dict['text/plain'], 'output')
        self.shell.history_manager.output_hist_reprs[self.prompt_count] = \
                                                    format_dict['text/plain']",Log the output.,
"def finish_displayhook(self):
        """"""Finish up all displayhook activities.""""""
        io.stdout.write(self.shell.separate_out2)
        io.stdout.flush()",Finish up all displayhook activities.,
"def load_ipython_extension(ip):
    """"""Load the extension in IPython.""""""
    global _loaded
    if not _loaded:
        plugin = StoreMagic(shell=ip, config=ip.config)
        ip.plugin_manager.register_plugin('storemagic', plugin)
        _loaded = True",Load the extension in IPython.,
"def raise_if_freezed(self):
        '''raise `InvalidOperationException` if is freezed.'''
        if self.is_freezed:
            name = type(self).__name__
            raise InvalidOperationException('obj {name} is freezed.'.format(name=name))",raise `InvalidOperationException` if is freezed.,
"def _eventloop_changed(self, name, old, new):
        """"""schedule call to eventloop from IOLoop""""""
        loop = ioloop.IOLoop.instance()
        loop.add_timeout(time.time()+0.1, self.enter_eventloop)",schedule call to eventloop from IOLoop,
"def do_one_iteration(self):
        """"""step eventloop just once""""""
        if self.control_stream:
            self.control_stream.flush()
        for stream in self.shell_streams:
            # handle at most one request per iteration
            stream.flush(zmq.POLLIN, 1)
            stream.flush(zmq.POLLOUT)",step eventloop just once,
"def _publish_pyin(self, code, parent, execution_count):
        """"""Publish the code request on the pyin stream.""""""

        self.session.send(self.iopub_socket, u'pyin',
                            {u'code':code, u'execution_count': execution_count},
                            parent=parent, ident=self._topic('pyin')
        )",Publish the code request on the pyin stream.,
"def _publish_status(self, status, parent=None):
        """"""send status (busy/idle) on IOPub""""""
        self.session.send(self.iopub_socket,
                          u'status',
                          {u'execution_state': status},
                          parent=parent,
                          ident=self._topic('status'),
                          )",send status (busy/idle) on IOPub,
"def clear_request(self, stream, idents, parent):
        """"""Clear our namespace.""""""
        self.shell.reset(False)
        msg = self.session.send(stream, 'clear_reply', ident=idents, parent=parent,
                content = dict(status='ok'))",Clear our namespace.,
"def _topic(self, topic):
        """"""prefixed topic for IOPub messages""""""
        if self.int_id >= 0:
            base = ""engine.%i"" % self.int_id
        else:
            base = ""kernel.%s"" % self.ident
        
        return py3compat.cast_bytes(""%s.%s"" % (base, topic))",prefixed topic for IOPub messages,
"def writelines(self, lines):
        '''
        Same as `file.writelines()` but for the slice.
        
        raises:
            EOFError if the new seek position is > `self.size`.
        '''
        lines = b''.join(lines)
        self.write(lines)","Same as `file.writelines()` but for the slice.
        
        raises:
            EOFError if the new seek position is > `self.size`.",
"def configure(self, options, conf):
        """"""Configure plugin.
        """"""        
        Plugin.configure(self, options, conf)
        self._mod_stack = []",Configure plugin.,
"def beforeContext(self):
        """"""Copy sys.modules onto my mod stack
        """"""
        mods = sys.modules.copy()
        self._mod_stack.append(mods)",Copy sys.modules onto my mod stack,
"def absdir(path):
    """"""Return absolute, normalized path to directory, if it exists; None
    otherwise.
    """"""
    if not os.path.isabs(path):
        path = os.path.normpath(os.path.abspath(os.path.join(os.getcwd(),
                                                             path)))
    if path is None or not os.path.isdir(path):
        return None
    return path","Return absolute, normalized path to directory, if it exists; None
    otherwise.",
"def file_like(name):
    """"""A name is file-like if it is a path that exists, or it has a
    directory part, or it ends in .py, or it isn't a legal python
    identifier.
    """"""
    return (os.path.exists(name)
            or os.path.dirname(name)
            or name.endswith('.py')
            or not ident_re.match(os.path.splitext(name)[0]))","A name is file-like if it is a path that exists, or it has a
    directory part, or it ends in .py, or it isn't a legal python
    identifier.",
"def isclass(obj):
    """"""Is obj a class? Inspect's isclass is too liberal and returns True
    for objects that can't be subclasses of anything.
    """"""
    obj_type = type(obj)
    return obj_type in class_types or issubclass(obj_type, type)","Is obj a class? Inspect's isclass is too liberal and returns True
    for objects that can't be subclasses of anything.",
"def ln(label):
    """"""Draw a 70-char-wide divider, with label in the middle.

    >>> ln('hello there')
    '---------------------------- hello there -----------------------------'
    """"""
    label_len = len(label) + 2
    chunk = (70 - label_len) // 2
    out = '%s %s %s' % ('-' * chunk, label, '-' * chunk)
    pad = 70 - len(out)
    if pad > 0:
        out = out + ('-' * pad)
    return out","Draw a 70-char-wide divider, with label in the middle.

    >>> ln('hello there')
    '---------------------------- hello there -----------------------------'",
"def virtual_memory():
    """"""System virtual memory as a namedtuple.""""""
    total, active, inactive, wired, free = _psutil_osx.get_virtual_mem()
    avail = inactive + free
    used = active + inactive + wired
    percent = usage_percent((total - avail), total, _round=1)
    return nt_virtmem_info(total, avail, percent, used, free,
                           active, inactive, wired)",System virtual memory as a namedtuple.,
"def swap_memory():
    """"""Swap system memory as a (total, used, free, sin, sout) tuple.""""""
    total, used, free, sin, sout = _psutil_osx.get_swap_mem()
    percent = usage_percent(used, total, _round=1)
    return nt_swapmeminfo(total, used, free, percent, sin, sout)","Swap system memory as a (total, used, free, sin, sout) tuple.",
"def get_system_cpu_times():
    """"""Return system CPU times as a namedtuple.""""""
    user, nice, system, idle = _psutil_osx.get_system_cpu_times()
    return _cputimes_ntuple(user, nice, system, idle)",Return system CPU times as a namedtuple.,
"def get_system_per_cpu_times():
    """"""Return system CPU times as a named tuple""""""
    ret = []
    for cpu_t in _psutil_osx.get_system_per_cpu_times():
        user, nice, system, idle = cpu_t
        item = _cputimes_ntuple(user, nice, system, idle)
        ret.append(item)
    return ret",Return system CPU times as a named tuple,
"def get_process_cmdline(self):
        """"""Return process cmdline as a list of arguments.""""""
        if not pid_exists(self.pid):
            raise NoSuchProcess(self.pid, self._process_name)
        return _psutil_osx.get_process_cmdline(self.pid)",Return process cmdline as a list of arguments.,
"def get_memory_info(self):
        """"""Return a tuple with the process' RSS and VMS size.""""""
        rss, vms = _psutil_osx.get_process_memory_info(self.pid)[:2]
        return nt_meminfo(rss, vms)",Return a tuple with the process' RSS and VMS size.,
"def get_ext_memory_info(self):
        """"""Return a tuple with the process' RSS and VMS size.""""""
        rss, vms, pfaults, pageins = _psutil_osx.get_process_memory_info(self.pid)
        return self._nt_ext_mem(rss, vms,
                                pfaults * _PAGESIZE,
                                pageins * _PAGESIZE)",Return a tuple with the process' RSS and VMS size.,
"def get_open_files(self):
        """"""Return files opened by process.""""""
        if self.pid == 0:
            return []
        files = []
        rawlist = _psutil_osx.get_process_open_files(self.pid)
        for path, fd in rawlist:
            if isfile_strict(path):
                ntuple = nt_openfile(path, fd)
                files.append(ntuple)
        return files",Return files opened by process.,
"def user_has_group(user, group, superuser_skip=True):
    """"""
    Check if a user is in a certaing group.
    By default, the check is skipped for superusers.
    """"""

    if user.is_superuser and superuser_skip:
        return True

    return user.groups.filter(name=group).exists()","Check if a user is in a certaing group.
    By default, the check is skipped for superusers.",
"def resolve_class(class_path):
    """"""
    Load a class by a fully qualified class_path,
    eg. myapp.models.ModelName
    """"""

    modulepath, classname = class_path.rsplit('.', 1)
    module = __import__(modulepath, fromlist=[classname])
    return getattr(module, classname)","Load a class by a fully qualified class_path,
    eg. myapp.models.ModelName",
"def usage_percent(used, total, _round=None):
    """"""Calculate percentage usage of 'used' against 'total'.""""""
    try:
        ret = (used / total) * 100
    except ZeroDivisionError:
        ret = 0
    if _round is not None:
        return round(ret, _round)
    else:
        return ret",Calculate percentage usage of 'used' against 'total'.,
"def memoize(f):
    """"""A simple memoize decorator for functions.""""""
    cache= {}
    def memf(*x):
        if x not in cache:
            cache[x] = f(*x)
        return cache[x]
    return memf",A simple memoize decorator for functions.,
"def _login(self):
        """"""
        Login into Google Docs with user authentication info.
        """"""
        try:
            self.gd_client = gdata.docs.client.DocsClient()
            self.gd_client.ClientLogin(self.email, self.password, self.source)
        except RequestError as e:
            raise PODocsError(e)",Login into Google Docs with user authentication info.,
"def _get_gdocs_key(self):
        """"""
        Parse GDocs key from Spreadsheet url.
        """"""
        try:
            args = urlparse.parse_qs(urlparse.urlparse(self.url).query)
            self.key = args['key'][0]
        except KeyError as e:
            raise PODocsError(e)",Parse GDocs key from Spreadsheet url.,
"def _ensure_temp_path_exists(self):
        """"""
        Make sure temp directory exists and create one if it does not.
        """"""
        try:
            if not os.path.exists(self.temp_path):
                os.mkdir(self.temp_path)
        except OSError as e:
            raise PODocsError(e)",Make sure temp directory exists and create one if it does not.,
"def new_qt_console(self, evt=None):
        """"""start a new qtconsole connected to our kernel""""""
        return connect_qtconsole(self.ipkernel.connection_file, profile=self.ipkernel.profile)",start a new qtconsole connected to our kernel,
"def get_response_code(url, timeout=10):
    '''
    Visit the URL and return the HTTP response code in 'int'
    '''
    try:    
        req = urllib2.urlopen(url, timeout=timeout)
    except HTTPError, e:
        return e.getcode()
    except Exception, _:
        fail(""Couldn't reach the URL '%s'"" % url)
    else:
        return req.getcode()",Visit the URL and return the HTTP response code in 'int',
"def compare_content_type(url, content_type):
    '''
    Compare the content type header of url param with content_type param and returns boolean 
    @param url -> string e.g. http://127.0.0.1/index
    @param content_type -> string e.g. text/html
    '''
    try:    
        response = urllib2.urlopen(url)
    except:
        return False

    return response.headers.type == content_type","Compare the content type header of url param with content_type param and returns boolean 
    @param url -> string e.g. http://127.0.0.1/index
    @param content_type -> string e.g. text/html",
"def clear_output(self, stdout=True, stderr=True, other=True):
        """"""Clear the output of the cell receiving output.""""""
        if stdout:
            print('\033[2K\r', file=io.stdout, end='')
            io.stdout.flush()
        if stderr:
            print('\033[2K\r', file=io.stderr, end='')
            io.stderr.flush()",Clear the output of the cell receiving output.,
"def _total_seconds(td):
    """"""timedelta.total_seconds was added in 2.7""""""
    try:
        # Python >= 2.7
        return td.total_seconds()
    except AttributeError:
        # Python 2.6
        return 1e-6 * (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6)",timedelta.total_seconds was added in 2.7,
"def check_ready(f, self, *args, **kwargs):
    """"""Call spin() to sync state prior to calling the method.""""""
    self.wait(0)
    if not self._ready:
        raise error.TimeoutError(""result not ready"")
    return f(self, *args, **kwargs)",Call spin() to sync state prior to calling the method.,
"def abort(self):
        """"""abort my tasks.""""""
        assert not self.ready(), ""Can't abort, I am already done!""
        return self._client.abort(self.msg_ids, targets=self._targets, block=True)",abort my tasks.,
"def progress(self):
        """"""the number of tasks which have been completed at this point.
        
        Fractional progress would be given by 1.0 * ar.progress / len(ar)
        """"""
        self.wait(0)
        return len(self) - len(set(self.msg_ids).intersection(self._client.outstanding))","the number of tasks which have been completed at this point.
        
        Fractional progress would be given by 1.0 * ar.progress / len(ar)",
"def serial_time(self):
        """"""serial computation time of a parallel calculation
        
        Computed as the sum of (completed-started) of each task
        """"""
        t = 0
        for md in self._metadata:
            t += _total_seconds(md['completed'] - md['started'])
        return t","serial computation time of a parallel calculation
        
        Computed as the sum of (completed-started) of each task",
"def _republish_displaypub(self, content, eid):
        """"""republish individual displaypub content dicts""""""
        try:
            ip = get_ipython()
        except NameError:
            # displaypub is meaningless outside IPython
            return
        md = content['metadata'] or {}
        md['engine'] = eid
        ip.display_pub.publish(content['source'], content['data'], md)",republish individual displaypub content dicts,
"def abs_file(filename):
    """"""Return the absolute normalized form of `filename`.""""""
    path = os.path.expandvars(os.path.expanduser(filename))
    path = os.path.abspath(os.path.realpath(path))
    path = actual_path(path)
    return path",Return the absolute normalized form of `filename`.,
"def sep(s):
    """"""Find the path separator used in this string, or os.sep if none.""""""
    sep_match = re.search(r""[\\/]"", s)
    if sep_match:
        the_sep = sep_match.group(0)
    else:
        the_sep = os.sep
    return the_sep","Find the path separator used in this string, or os.sep if none.",
"def relative_filename(self, filename):
        """"""Return the relative form of `filename`.

        The filename will be relative to the current directory when the
        `FileLocator` was constructed.

        """"""
        fnorm = os.path.normcase(filename)
        if fnorm.startswith(self.relative_dir):
            filename = filename[len(self.relative_dir):]
        return filename","Return the relative form of `filename`.

        The filename will be relative to the current directory when the
        `FileLocator` was constructed.",
"def match(self, fpath):
        """"""Does `fpath` match one of our filename patterns?""""""
        for pat in self.pats:
            if fnmatch.fnmatch(fpath, pat):
                return True
        return False",Does `fpath` match one of our filename patterns?,
"def loop_gtk(kernel):
    """"""Start the kernel, coordinating with the GTK event loop""""""
    from .gui.gtkembed import GTKEmbed

    gtk_kernel = GTKEmbed(kernel)
    gtk_kernel.start()","Start the kernel, coordinating with the GTK event loop",
"def GOE(N):
    """"""Creates an NxN element of the Gaussian Orthogonal Ensemble""""""
    m = ra.standard_normal((N,N))
    m += m.T
    return m/2",Creates an NxN element of the Gaussian Orthogonal Ensemble,
"def center_eigenvalue_diff(mat):
    """"""Compute the eigvals of mat and then find the center eigval difference.""""""
    N = len(mat)
    evals = np.sort(la.eigvals(mat))
    diff = np.abs(evals[N/2] - evals[N/2-1])
    return diff",Compute the eigvals of mat and then find the center eigval difference.,
"def ensemble_diffs(num, N):
    """"""Return num eigenvalue diffs for the NxN GOE ensemble.""""""
    diffs = np.empty(num)
    for i in xrange(num):
        mat = GOE(N)
        diffs[i] = center_eigenvalue_diff(mat)
    return diffs",Return num eigenvalue diffs for the NxN GOE ensemble.,
"def init_crash_handler(self):
        """"""Create a crash handler, typically setting sys.excepthook to it.""""""
        self.crash_handler = self.crash_handler_class(self)
        sys.excepthook = self.excepthook
        def unset_crashhandler():
            sys.excepthook = sys.__excepthook__
        atexit.register(unset_crashhandler)","Create a crash handler, typically setting sys.excepthook to it.",
"def read(self):
        """"""Read coverage data from the coverage data file (if it exists).""""""
        if self.use_file:
            self.lines, self.arcs = self._read_file(self.filename)
        else:
            self.lines, self.arcs = {}, {}",Read coverage data from the coverage data file (if it exists).,
"def erase(self):
        """"""Erase the data, both in this object, and from its file storage.""""""
        if self.use_file:
            if self.filename:
                file_be_gone(self.filename)
        self.lines = {}
        self.arcs = {}","Erase the data, both in this object, and from its file storage.",
"def line_data(self):
        """"""Return the map from filenames to lists of line numbers executed.""""""
        return dict(
            [(f, sorted(lmap.keys())) for f, lmap in iitems(self.lines)]
            )",Return the map from filenames to lists of line numbers executed.,
"def arc_data(self):
        """"""Return the map from filenames to lists of line number pairs.""""""
        return dict(
            [(f, sorted(amap.keys())) for f, amap in iitems(self.arcs)]
            )",Return the map from filenames to lists of line number pairs.,
"def read_file(self, filename):
        """"""Read the coverage data from `filename`.""""""
        self.lines, self.arcs = self._read_file(filename)",Read the coverage data from `filename`.,
"def raw_data(self, filename):
        """"""Return the raw pickled data from `filename`.""""""
        if self.debug and self.debug.should('dataio'):
            self.debug.write(""Reading data from %r"" % (filename,))
        fdata = open(filename, 'rb')
        try:
            data = pickle.load(fdata)
        finally:
            fdata.close()
        return data",Return the raw pickled data from `filename`.,
"def add_line_data(self, line_data):
        """"""Add executed line data.

        `line_data` is { filename: { lineno: None, ... }, ...}

        """"""
        for filename, linenos in iitems(line_data):
            self.lines.setdefault(filename, {}).update(linenos)","Add executed line data.

        `line_data` is { filename: { lineno: None, ... }, ...}",
"def add_arc_data(self, arc_data):
        """"""Add measured arc data.

        `arc_data` is { filename: { (l1,l2): None, ... }, ...}

        """"""
        for filename, arcs in iitems(arc_data):
            self.arcs.setdefault(filename, {}).update(arcs)","Add measured arc data.

        `arc_data` is { filename: { (l1,l2): None, ... }, ...}",
"def add_to_hash(self, filename, hasher):
        """"""Contribute `filename`'s data to the Md5Hash `hasher`.""""""
        hasher.update(self.executed_lines(filename))
        hasher.update(self.executed_arcs(filename))",Contribute `filename`'s data to the Md5Hash `hasher`.,
"def exit(self):
        """"""Handle interactive exit.

        This method calls the ask_exit callback.""""""
        if self.confirm_exit:
            if self.ask_yes_no('Do you really want to exit ([y]/n)?','y'):
                self.ask_exit()
        else:
            self.ask_exit()","Handle interactive exit.

        This method calls the ask_exit callback.",
"def dispose_at_exit(exitable):
    '''
    register `exitable.__exit__()` into `atexit` module.

    return the `exitable` itself.
    '''
    @atexit.register
    def callback():
        exitable.__exit__(*sys.exc_info())
    return exitable","register `exitable.__exit__()` into `atexit` module.

    return the `exitable` itself.",
"def info(self):
        """"""return the connection info for this object's sockets.""""""
        return (self.identity, self.url, self.pub_url, self.location)",return the connection info for this object's sockets.,
"def text(self, etype, value, tb, tb_offset=None, context=5):
        """"""Return formatted traceback.

        Subclasses may override this if they add extra arguments.
        """"""
        tb_list = self.structured_traceback(etype, value, tb,
                                            tb_offset, context)
        return self.stb2text(tb_list)","Return formatted traceback.

        Subclasses may override this if they add extra arguments.",
"def add_submodule(mod, submod, fullname, subname):
    """"""mod.{subname} = submod""""""
    if mod is None:
        return #Nothing to do here.

    if submod is None:
        submod = sys.modules[fullname]

    setattr(mod, subname, submod)

    return",mod.{subname} = submod,
"def ast_parse(self, source, filename='<unknown>', symbol='exec'):
        """"""Parse code to an AST with the current compiler flags active.
        
        Arguments are exactly the same as ast.parse (in the standard library),
        and are passed to the built-in compile function.""""""
        return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)","Parse code to an AST with the current compiler flags active.
        
        Arguments are exactly the same as ast.parse (in the standard library),
        and are passed to the built-in compile function.",
"def check_cache(self, *args):
        """"""Call linecache.checkcache() safely protecting our cached values.
        """"""
        # First call the orignal checkcache as intended
        linecache._checkcache_ori(*args)
        # Then, update back the cache with our data, so that tracebacks related
        # to our compiled codes can be produced.
        linecache.cache.update(linecache._ipython_cache)",Call linecache.checkcache() safely protecting our cached values.,
"def add_line(self, line):
        """"""Add a line of source to the code.

        Don't include indentations or newlines.

        """"""
        self.code.append("" "" * self.indent_amount)
        self.code.append(line)
        self.code.append(""\n"")","Add a line of source to the code.

        Don't include indentations or newlines.",
"def add_section(self):
        """"""Add a section, a sub-CodeBuilder.""""""
        sect = CodeBuilder(self.indent_amount)
        self.code.append(sect)
        return sect","Add a section, a sub-CodeBuilder.",
"def get_function(self, fn_name):
        """"""Compile the code, and return the function `fn_name`.""""""
        assert self.indent_amount == 0
        g = {}
        code_text = str(self)
        exec(code_text, g)
        return g[fn_name]","Compile the code, and return the function `fn_name`.",
"def render(self, context=None):
        """"""Render this template by applying it to `context`.

        `context` is a dictionary of values to use in this rendering.

        """"""
        # Make the complete context we'll use.
        ctx = dict(self.context)
        if context:
            ctx.update(context)
        return self.render_function(ctx, self.do_dots)","Render this template by applying it to `context`.

        `context` is a dictionary of values to use in this rendering.",
"def do_dots(self, value, *dots):
        """"""Evaluate dotted expressions at runtime.""""""
        for dot in dots:
            try:
                value = getattr(value, dot)
            except AttributeError:
                value = value[dot]
            if hasattr(value, '__call__'):
                value = value()
        return value",Evaluate dotted expressions at runtime.,
"def user_config_files():
    """"""Return path to any existing user config files
    """"""
    return filter(os.path.exists,
                  map(os.path.expanduser, config_files))",Return path to any existing user config files,
"def flag(val):
    """"""Does the value look like an on/off flag?""""""
    if val == 1:
        return True
    elif val == 0:
        return False
    val = str(val)
    if len(val) > 5:
        return False
    return val.upper() in ('1', '0', 'F', 'T', 'TRUE', 'FALSE', 'ON', 'OFF')",Does the value look like an on/off flag?,
"def get_pager_start(pager, start):
    """"""Return the string for paging files with an offset.

    This is the '+N' argument which less and more (under Unix) accept.
    """"""

    if pager in ['less','more']:
        if start:
            start_string = '+' + str(start)
        else:
            start_string = ''
    else:
        start_string = ''
    return start_string","Return the string for paging files with an offset.

    This is the '+N' argument which less and more (under Unix) accept.",
"def timings(reps,func,*args,**kw):
    """"""timings(reps,func,*args,**kw) -> (t_total,t_per_call)

    Execute a function reps times, return a tuple with the elapsed total CPU
    time in seconds and the time per call. These are just the first two values
    in timings_out().""""""

    return timings_out(reps,func,*args,**kw)[0:2]","timings(reps,func,*args,**kw) -> (t_total,t_per_call)

    Execute a function reps times, return a tuple with the elapsed total CPU
    time in seconds and the time per call. These are just the first two values
    in timings_out().",
"def print_basic_unicode(o, p, cycle):
    """"""A function to pretty print sympy Basic objects.""""""
    if cycle:
        return p.text('Basic(...)')
    out = pretty(o, use_unicode=True)
    if '\n' in out:
        p.text(u'\n')
    p.text(out)",A function to pretty print sympy Basic objects.,
"def print_png(o):
    """"""
    A function to display sympy expression using inline style LaTeX in PNG.
    """"""
    s = latex(o, mode='inline')
    # mathtext does not understand certain latex flags, so we try to replace
    # them with suitable subs.
    s = s.replace('\\operatorname','')
    s = s.replace('\\overline', '\\bar')
    png = latex_to_png(s)
    return png",A function to display sympy expression using inline style LaTeX in PNG.,
"def print_display_png(o):
    """"""
    A function to display sympy expression using display style LaTeX in PNG.
    """"""
    s = latex(o, mode='plain')
    s = s.strip('$')
    # As matplotlib does not support display style, dvipng backend is
    # used here.
    png = latex_to_png('$$%s$$' % s, backend='dvipng')
    return png",A function to display sympy expression using display style LaTeX in PNG.,
"def print_latex(o):
    """"""A function to generate the latex representation of sympy
    expressions.""""""
    if can_print_latex(o):
        s = latex(o, mode='plain')
        s = s.replace('\\dag','\\dagger')
        s = s.strip('$')
        return '$$%s$$' % s
    # Fallback to the string printer
    return None","A function to generate the latex representation of sympy
    expressions.",
"def str2tokens(string, delimiter):
    """"""
    Usage:
    {% with 'this, is a, string'|str2tokens:',' as token_list %}do something{% endwith %}
    """"""

    token_list = [token.strip() for token in string.split(delimiter)]
    return token_list","Usage:
    {% with 'this, is a, string'|str2tokens:',' as token_list %}do something{% endwith %}",
"def str2tokenstags(string, delimiter):
    """"""
    Usage:
    {% str2tokens 'a/b/c/d' '/' as token_list %}
    """"""

    token_list = [token.strip() for token in string.split(delimiter)]
    return token_list","Usage:
    {% str2tokens 'a/b/c/d' '/' as token_list %}",
"def validate_string_list(lst):
    """"""Validate that the input is a list of strings.

    Raises ValueError if not.""""""
    if not isinstance(lst, list):
        raise ValueError('input %r must be a list' % lst)
    for x in lst:
        if not isinstance(x, basestring):
            raise ValueError('element %r in list must be a string' % x)","Validate that the input is a list of strings.

    Raises ValueError if not.",
"def validate_string_dict(dct):
    """"""Validate that the input is a dict with string keys and values.

    Raises ValueError if not.""""""
    for k,v in dct.iteritems():
        if not isinstance(k, basestring):
            raise ValueError('key %r in dict must be a string' % k)
        if not isinstance(v, basestring):
            raise ValueError('value %r in dict must be a string' % v)","Validate that the input is a dict with string keys and values.

    Raises ValueError if not.",
"def _handle_recv(self, msg):
        """"""callback for stream.on_recv
        
        unpacks message, and calls handlers with it.
        """"""
        ident,smsg = self.session.feed_identities(msg)
        self.call_handlers(self.session.unserialize(smsg))","callback for stream.on_recv
        
        unpacks message, and calls handlers with it.",
"def input(self, string):
        """"""Send a string of raw input to the kernel.""""""
        content = dict(value=string)
        msg = self.session.msg('input_reply', content)
        self._queue_send(msg)",Send a string of raw input to the kernel.,
"def is_beating(self):
        """"""Is the heartbeat running and responsive (and not paused).""""""
        if self.is_alive() and not self._pause and self._beating:
            return True
        else:
            return False",Is the heartbeat running and responsive (and not paused).,
"def channels_running(self):
        """"""Are any of the channels created and running?""""""
        return (self.shell_channel.is_alive() or self.sub_channel.is_alive() or
                self.stdin_channel.is_alive() or self.hb_channel.is_alive())",Are any of the channels created and running?,
"def signal_kernel(self, signum):
        """""" Sends a signal to the kernel. Note that since only SIGTERM is
        supported on Windows, this function is only useful on Unix systems.
        """"""
        if self.has_kernel:
            self.kernel.send_signal(signum)
        else:
            raise RuntimeError(""Cannot signal kernel. No kernel is running!"")","Sends a signal to the kernel. Note that since only SIGTERM is
        supported on Windows, this function is only useful on Unix systems.",
"def sub_channel(self):
        """"""Get the SUB socket channel object.""""""
        if self._sub_channel is None:
            self._sub_channel = self.sub_channel_class(self.context,
                                                       self.session,
                                                       (self.ip, self.iopub_port))
        return self._sub_channel",Get the SUB socket channel object.,
"def debug(self, level, message):
        """"""
        Emit a debugging message depending on the debugging level.

        :param level: The debugging level.
        :param message: The message to emit.
        """"""

        if self._debug >= level:
            print(message, file=sys.stderr)","Emit a debugging message depending on the debugging level.

        :param level: The debugging level.
        :param message: The message to emit.",
"def walk_egg(egg_dir):
    """"""Walk an unpacked egg's contents, skipping the metadata directory""""""
    walker = os.walk(egg_dir)
    base,dirs,files = walker.next()
    if 'EGG-INFO' in dirs:
        dirs.remove('EGG-INFO')
    yield base,dirs,files
    for bdf in walker:
        yield bdf","Walk an unpacked egg's contents, skipping the metadata directory",
"def _enable_autopx(self):
        """"""Enable %autopx mode by saving the original run_cell and installing
        pxrun_cell.
        """"""
        # override run_cell
        self._original_run_cell = self.shell.run_cell
        self.shell.run_cell = self.pxrun_cell

        self._autopx = True
        print ""%autopx enabled""","Enable %autopx mode by saving the original run_cell and installing
        pxrun_cell.",
"def _disable_autopx(self):
        """"""Disable %autopx by restoring the original InteractiveShell.run_cell.
        """"""
        if self._autopx:
            self.shell.run_cell = self._original_run_cell
            self._autopx = False
            print ""%autopx disabled""",Disable %autopx by restoring the original InteractiveShell.run_cell.,
"def run_heartbeat(message):
    """"""Internal ``CLOCK_CHANNEL`` consumer to process task runs""""""
    then = arrow.get(message['time'])
    now = arrow.get()

    if (now - then) > timezone.timedelta(seconds=(TICK_FREQ+1)):
        pass # discard old ticks
    else:
        Task.run_tasks()",Internal ``CLOCK_CHANNEL`` consumer to process task runs,
"def remove_task(message):
    """"""Internal ``KILL_TASK`` consumer to remove retired tasks""""""
    task = Task.objects.get(pk=message['id'])
    task.delete()",Internal ``KILL_TASK`` consumer to remove retired tasks,
"def patch_if_missing(obj, name, method):
    """"""
    Patch a method onto an object if it isn't already there.
    """"""
    setattr(obj, name, getattr(obj, name, method))",Patch a method onto an object if it isn't already there.,
"def patch_transport_abortConnection(transport, protocol):
    """"""
    Patch abortConnection() onto the transport if it doesn't already have it.
    (`Agent` assumes its transport has this.)
    """"""
    def abortConnection():
        protocol._fake_connection_aborted = True
        transport.loseConnection()
    patch_if_missing(transport, 'abortConnection', abortConnection)","Patch abortConnection() onto the transport if it doesn't already have it.
    (`Agent` assumes its transport has this.)",
"def accept_connection(self):
        """"""
        Accept a pending connection.
        """"""
        assert self.pending, ""Connection is not pending.""
        self.server_protocol = self.server.server_factory.buildProtocol(None)
        self._accept_d.callback(
            FakeServerProtocolWrapper(self, self.server_protocol))
        return self.await_connected()",Accept a pending connection.,
"def reject_connection(self, reason=None):
        """"""
        Reject a pending connection.
        """"""
        assert self.pending, ""Connection is not pending.""
        if reason is None:
            reason = ConnectionRefusedError()
        self._accept_d.errback(reason)",Reject a pending connection.,
"def get_agent(self, reactor=None, contextFactory=None):
        """"""
        Returns an IAgent that makes requests to this fake server.
        """"""
        return ProxyAgentWithContext(
            self.endpoint, reactor=reactor, contextFactory=contextFactory)",Returns an IAgent that makes requests to this fake server.,
"def delete(self, request, *args, **kwargs):
        """"""
        Calls pre and post delete hooks for DelteViews.
        """"""

        self.object = self.get_object()
        success_url = self.get_success_url()
        self.pre_delete(self.object)
        self.object.delete()
        self.post_delete(self.object)

        return HttpResponseRedirect(success_url)",Calls pre and post delete hooks for DelteViews.,
"def get_initial(self):
        """"""
        Supply user object as initial data for the specified user_field(s).
        """"""

        data = super(UserViewMixin, self).get_initial()
        for k in self.user_field:
            data[k] = self.request.user

        return data",Supply user object as initial data for the specified user_field(s).,
"def pre_save(self, instance):
        super(UserViewMixin, self).pre_save(instance)

        """"""
        Use SaveHookMixin pre_save to set the user.
        """"""
        if  self.request.user.is_authenticated():
            for field in self.user_field:
                setattr(instance, field, self.request.user)",Use SaveHookMixin pre_save to set the user.,
"def _get_compiled_ext():
    """"""Official way to get the extension of compiled files (.pyc or .pyo)""""""
    for ext, mode, typ in imp.get_suffixes():
        if typ == imp.PY_COMPILED:
            return ext",Official way to get the extension of compiled files (.pyc or .pyo),
"def add(self, func, priority=0):
        """""" Add a func to the cmd chain with given priority """"""
        self.chain.append((priority, func))
        self.chain.sort(key=lambda x: x[0])",Add a func to the cmd chain with given priority,
"def configure(self, options, conf):
        """"""Configure which kinds of exceptions trigger plugin.
        """"""
        self.conf = conf
        self.enabled = options.debugErrors or options.debugFailures
        self.enabled_for_errors = options.debugErrors
        self.enabled_for_failures = options.debugFailures",Configure which kinds of exceptions trigger plugin.,
"def spin_first(f, self, *args, **kwargs):
    """"""Call spin() to sync state prior to calling the method.""""""
    self.spin()
    return f(self, *args, **kwargs)",Call spin() to sync state prior to calling the method.,
"def _unwrap_exception(self, content):
        """"""unwrap exception, and remap engine_id to int.""""""
        e = error.unwrap_exception(content)
        # print e.traceback
        if e.engine_info:
            e_uuid = e.engine_info['engine_uuid']
            eid = self._engines[e_uuid]
            e.engine_info['engine_id'] = eid
        return e","unwrap exception, and remap engine_id to int.",
"def _register_engine(self, msg):
        """"""Register a new engine, and update our connection info.""""""
        content = msg['content']
        eid = content['id']
        d = {eid : content['queue']}
        self._update_engines(d)","Register a new engine, and update our connection info.",
"def _flush_ignored_control(self):
        """"""flush ignored control replies""""""
        while self._ignored_control_replies > 0:
            self.session.recv(self._control_socket)
            self._ignored_control_replies -= 1",flush ignored control replies,
"def _spin_every(self, interval=1):
        """"""target func for use in spin_thread""""""
        while True:
            if self._stop_spinning.is_set():
                return
            time.sleep(interval)
            self.spin()",target func for use in spin_thread,
"def stop_spin_thread(self):
        """"""stop background spin_thread, if any""""""
        if self._spin_thread is not None:
            self._stop_spinning.set()
            self._spin_thread.join()
            self._spin_thread = None","stop background spin_thread, if any",
"def _opcode_set(*names):
    """"""Return a set of opcodes by the names in `names`.""""""
    s = set()
    for name in names:
        try:
            s.add(_opcode(name))
        except KeyError:
            pass
    return s",Return a set of opcodes by the names in `names`.,
"def _get_byte_parser(self):
        """"""Create a ByteParser on demand.""""""
        if not self._byte_parser:
            self._byte_parser = \
                            ByteParser(text=self.text, filename=self.filename)
        return self._byte_parser",Create a ByteParser on demand.,
"def first_line(self, line):
        """"""Return the first line number of the statement including `line`.""""""
        rng = self.multiline.get(line)
        if rng:
            first_line = rng[0]
        else:
            first_line = line
        return first_line",Return the first line number of the statement including `line`.,
"def child_parsers(self):
        """"""Iterate over all the code objects nested within this one.

        The iteration includes `self` as its first value.

        """"""
        children = CodeObjects(self.code)
        return [ByteParser(code=c, text=self.text) for c in children]","Iterate over all the code objects nested within this one.

        The iteration includes `self` as its first value.",
"def _find_statements(self):
        """"""Find the statements in `self.code`.

        Produce a sequence of line numbers that start statements.  Recurses
        into all code objects reachable from `self.code`.

        """"""
        for bp in self.child_parsers():
            # Get all of the lineno information from this code.
            for _, l in bp._bytes_lines():
                yield l","Find the statements in `self.code`.

        Produce a sequence of line numbers that start statements.  Recurses
        into all code objects reachable from `self.code`.",
"def _block_stack_repr(self, block_stack):
        """"""Get a string version of `block_stack`, for debugging.""""""
        blocks = "", "".join(
            [""(%s, %r)"" % (dis.opname[b[0]], b[1]) for b in block_stack]
        )
        return ""["" + blocks + ""]""","Get a string version of `block_stack`, for debugging.",
"def validate_chunks(self, chunks):
        """"""Validate the rule that chunks have a single entrance.""""""
        # starts is the entrances to the chunks
        starts = set([ch.byte for ch in chunks])
        for ch in chunks:
            assert all([(ex in starts or ex < 0) for ex in ch.exits])",Validate the rule that chunks have a single entrance.,
"def _all_chunks(self):
        """"""Returns a list of `Chunk` objects for this code and its children.

        See `_split_into_chunks` for details.

        """"""
        chunks = []
        for bp in self.child_parsers():
            chunks.extend(bp._split_into_chunks())

        return chunks","Returns a list of `Chunk` objects for this code and its children.

        See `_split_into_chunks` for details.",
"def _all_arcs(self):
        """"""Get the set of all arcs in this code object and its children.

        See `_arcs` for details.

        """"""
        arcs = set()
        for bp in self.child_parsers():
            arcs.update(bp._arcs())

        return arcs","Get the set of all arcs in this code object and its children.

        See `_arcs` for details.",
"def jrepr(value):
    '''customized `repr()`.'''
    if value is None:
        return repr(value)
    t = type(value)
    if t.__repr__ is not object.__repr__:
        return repr(value)
    return 'object ' + t.__name__",customized `repr()`.,
"def get_parent(obj):
    '''
    get parent from obj.
    '''
    names = obj.__qualname__.split('.')[:-1]
    if '<locals>' in names: # locals function
        raise ValueError('cannot get parent from locals object.')
    module = sys.modules[obj.__module__]
    parent = module
    while names:
        parent = getattr(parent, names.pop(0))
    return parent",get parent from obj.,
"def root_topic(self):
        """"""this is a property, in case the handler is created
        before the engine gets registered with an id""""""
        if isinstance(getattr(self.engine, 'id', None), int):
            return ""engine.%i""%self.engine.id
        else:
            return ""engine""","this is a property, in case the handler is created
        before the engine gets registered with an id",
"def render_template(content, context):
    """""" renders context aware template """"""
    rendered = Template(content).render(Context(context))
    return rendered",renders context aware template,
"def configure(self, options, conf):
        """"""Configure plugin. Plugin is enabled by default.
        """"""
        self.conf = conf
        if not options.capture:
            self.enabled = False",Configure plugin. Plugin is enabled by default.,
"def splitBy(data, num):
    """""" Turn a list to list of list """"""
    return [data[i:i + num] for i in range(0, len(data), num)]",Turn a list to list of list,
"def _started_channels(self):
        """"""Reimplemented to make a history request and load %guiref.""""""
        super(IPythonWidget, self)._started_channels()
        self._load_guiref_magic()
        self.kernel_manager.shell_channel.history(hist_access_type='tail',
                                                  n=1000)",Reimplemented to make a history request and load %guiref.,
"def _process_execute_payload(self, item):
        """""" Reimplemented to dispatch payloads to handler methods.
        """"""
        handler = self._payload_handlers.get(item['source'])
        if handler is None:
            # We have no handler for this type of payload, simply ignore it
            return False
        else:
            handler(item)
            return True",Reimplemented to dispatch payloads to handler methods.,
"def _make_in_prompt(self, number):
        """""" Given a prompt number, returns an HTML In prompt.
        """"""
        try:
            body = self.in_prompt % number
        except TypeError:
            # allow in_prompt to leave out number, e.g. '>>> '
            body = self.in_prompt
        return '<span class=""in-prompt"">%s</span>' % body","Given a prompt number, returns an HTML In prompt.",
"def _make_continuation_prompt(self, prompt):
        """""" Given a plain text version of an In prompt, returns an HTML
            continuation prompt.
        """"""
        end_chars = '...: '
        space_count = len(prompt.lstrip('\n')) - len(end_chars)
        body = '&nbsp;' * space_count + end_chars
        return '<span class=""in-prompt"">%s</span>' % body","Given a plain text version of an In prompt, returns an HTML
            continuation prompt.",
"def _syntax_style_changed(self):
        """""" Set the style for the syntax highlighter.
        """"""
        if self._highlighter is None:
            # ignore premature calls
            return
        if self.syntax_style:
            self._highlighter.set_style(self.syntax_style)
        else:
            self._highlighter.set_style_sheet(self.style_sheet)",Set the style for the syntax highlighter.,
"def swap_memory():
    """"""System swap memory as (total, used, free, sin, sout) namedtuple.""""""
    total, used, free, sin, sout = \
        [x * _PAGESIZE for x in _psutil_bsd.get_swap_mem()]
    percent = usage_percent(used, total, _round=1)
    return nt_swapmeminfo(total, used, free, percent, sin, sout)","System swap memory as (total, used, free, sin, sout) namedtuple.",
"def get_system_cpu_times():
    """"""Return system per-CPU times as a named tuple""""""
    user, nice, system, idle, irq = _psutil_bsd.get_system_cpu_times()
    return _cputimes_ntuple(user, nice, system, idle, irq)",Return system per-CPU times as a named tuple,
"def get_system_per_cpu_times():
    """"""Return system CPU times as a named tuple""""""
    ret = []
    for cpu_t in _psutil_bsd.get_system_per_cpu_times():
        user, nice, system, idle, irq = cpu_t
        item = _cputimes_ntuple(user, nice, system, idle, irq)
        ret.append(item)
    return ret",Return system CPU times as a named tuple,
"def get_process_uids(self):
        """"""Return real, effective and saved user ids.""""""
        real, effective, saved = _psutil_bsd.get_process_uids(self.pid)
        return nt_uids(real, effective, saved)","Return real, effective and saved user ids.",
"def get_process_gids(self):
        """"""Return real, effective and saved group ids.""""""
        real, effective, saved = _psutil_bsd.get_process_gids(self.pid)
        return nt_gids(real, effective, saved)","Return real, effective and saved group ids.",
"def get_cpu_times(self):
        """"""return a tuple containing process user/kernel time.""""""
        user, system = _psutil_bsd.get_process_cpu_times(self.pid)
        return nt_cputimes(user, system)",return a tuple containing process user/kernel time.,
"def get_memory_info(self):
        """"""Return a tuple with the process' RSS and VMS size.""""""
        rss, vms = _psutil_bsd.get_process_memory_info(self.pid)[:2]
        return nt_meminfo(rss, vms)",Return a tuple with the process' RSS and VMS size.,
"def get_process_threads(self):
        """"""Return the number of threads belonging to the process.""""""
        rawlist = _psutil_bsd.get_process_threads(self.pid)
        retlist = []
        for thread_id, utime, stime in rawlist:
            ntuple = nt_thread(thread_id, utime, stime)
            retlist.append(ntuple)
        return retlist",Return the number of threads belonging to the process.,
"def _num_cpus_darwin():
    """"""Return the number of active CPUs on a Darwin system.""""""
    p = subprocess.Popen(['sysctl','-n','hw.ncpu'],stdout=subprocess.PIPE)
    return p.stdout.read()",Return the number of active CPUs on a Darwin system.,
"def handle(self, integers, **options):
        """"""
        [1, 2, 3, 4] {'accumulate': <built-in function max>}
        """"""
        print integers, options
        return super(Command, self).handle(integers, **options)","[1, 2, 3, 4] {'accumulate': <built-in function max>}",
"def fetchone(self):
        """"""Fetches a single row from the cursor.""""""
        self._check_executed()
        r = self._fetch_row(1)
        if not r:
            self._warning_check()
            return None
        self.rownumber = self.rownumber + 1
        return r[0]",Fetches a single row from the cursor.,
"def fetchmany(self, size=None):
        """"""Fetch up to size rows from the cursor. Result set may be smaller
        than size. If size is not defined, cursor.arraysize is used.""""""
        self._check_executed()
        r = self._fetch_row(size or self.arraysize)
        self.rownumber = self.rownumber + len(r)
        if not r:
            self._warning_check()
        return r","Fetch up to size rows from the cursor. Result set may be smaller
        than size. If size is not defined, cursor.arraysize is used.",
"def fetchall(self):
        """"""Fetchs all available rows from the cursor.""""""
        self._check_executed()
        r = self._fetch_row(0)
        self.rownumber = self.rownumber + len(r)
        self._warning_check()
        return r",Fetchs all available rows from the cursor.,
"def fetchmanyDict(self, size=None):
        """"""Fetch several rows as a list of dictionaries. Deprecated:
        Use fetchmany() instead. Will be removed in 1.3.""""""
        from warnings import warn
        warn(""fetchmanyDict() is non-standard and will be removed in 1.3"",
             DeprecationWarning, 2)
        return self.fetchmany(size)","Fetch several rows as a list of dictionaries. Deprecated:
        Use fetchmany() instead. Will be removed in 1.3.",
"def connect(com, peers, tree, pub_url, root_id):
    """"""this function will be called on the engines""""""
    com.connect(peers, tree, pub_url, root_id)",this function will be called on the engines,
"def parse_json(s, **kwargs):
    """"""Parse a string into a (nbformat, dict) tuple.""""""
    d = json.loads(s, **kwargs)
    nbf = d.get('nbformat', 1)
    nbm = d.get('nbformat_minor', 0)
    return nbf, nbm, d","Parse a string into a (nbformat, dict) tuple.",
"def reads_py(s, **kwargs):
    """"""Read a .py notebook from a string and return the NotebookNode object.""""""
    nbf, nbm, s = parse_py(s, **kwargs)
    if nbf == 2:
        nb = v2.to_notebook_py(s, **kwargs)
    elif nbf == 3:
        nb = v3.to_notebook_py(s, **kwargs)
    else:
        raise NBFormatError('Unsupported PY nbformat version: %i' % nbf)
    return nb",Read a .py notebook from a string and return the NotebookNode object.,
"def load_from_dict(self, src: dict, key):
        '''
        try load value from dict.
        if key is not exists, mark as state unset.
        '''
        if key in src:
            self.value = src[key]
        else:
            self.reset()","try load value from dict.
        if key is not exists, mark as state unset.",
"def _file_lines(fname):
    """"""Return the contents of a named file as a list of lines.

    This function never raises an IOError exception: if the file can't be
    read, it simply returns an empty list.""""""

    try:
        outfile = open(fname)
    except IOError:
        return []
    else:
        out = outfile.readlines()
        outfile.close()
        return out","Return the contents of a named file as a list of lines.

    This function never raises an IOError exception: if the file can't be
    read, it simply returns an empty list.",
"def list_command_pydb(self, arg):
        """"""List command to use if we have a newer pydb installed""""""
        filename, first, last = OldPdb.parse_list_cmd(self, arg)
        if filename is not None:
            self.print_list_lines(filename, first, last)",List command to use if we have a newer pydb installed,
"def do_pdef(self, arg):
        """"""The debugger interface to magic_pdef""""""
        namespaces = [('Locals', self.curframe.f_locals),
                      ('Globals', self.curframe.f_globals)]
        self.shell.find_line_magic('pdef')(arg, namespaces=namespaces)",The debugger interface to magic_pdef,
"def init_session(self):
        """"""create our session object""""""
        default_secure(self.config)
        self.session = Session(config=self.config, username=u'kernel')",create our session object,
"def init_blackhole(self):
        """"""redirects stdout/stderr to devnull if necessary""""""
        if self.no_stdout or self.no_stderr:
            blackhole = open(os.devnull, 'w')
            if self.no_stdout:
                sys.stdout = sys.__stdout__ = blackhole
            if self.no_stderr:
                sys.stderr = sys.__stderr__ = blackhole",redirects stdout/stderr to devnull if necessary,
"def html_to_text(content):
    """""" Converts html content to plain text """"""
    text = None
    h2t = html2text.HTML2Text()
    h2t.ignore_links = False
    text = h2t.handle(content)
    return text",Converts html content to plain text,
"def md_to_text(content):
    """""" Converts markdown content to text """"""
    text = None
    html = markdown.markdown(content)
    if html:
        text = html_to_text(content)
    return text",Converts markdown content to text,
"def parts_to_uri(base_uri, uri_parts):
    """"""
    Converts uri parts to valid uri.
    Example: /memebers, ['profile', 'view'] => /memembers/profile/view
    """"""
    uri = ""/"".join(map(lambda x: str(x).rstrip('/'), [base_uri] + uri_parts))
    return uri","Converts uri parts to valid uri.
    Example: /memebers, ['profile', 'view'] => /memembers/profile/view",
"def domain_to_fqdn(domain, proto=None):
    """""" returns a fully qualified app domain name """"""
    from .generic import get_site_proto
    proto = proto or get_site_proto()
    fdqn = '{proto}://{domain}'.format(proto=proto, domain=domain)
    return fdqn",returns a fully qualified app domain name,
"def wantDirectory(self, dirname):
        """"""Check if directory is eligible for test discovery""""""
        if dirname in self.exclude_dirs:
            log.debug(""excluded: %s"" % dirname)
            return False
        else:
            return None",Check if directory is eligible for test discovery,
"def call_each(funcs: list, *args, **kwargs):
    '''
    call each func from func list.

    return the last func value or None if func list is empty.
    '''
    ret = None
    for func in funcs:
        ret = func(*args, **kwargs)
    return ret","call each func from func list.

    return the last func value or None if func list is empty.",
"def call_each_reversed(funcs: list, *args, **kwargs):
    '''
    call each func from reversed func list.

    return the last func value or None if func list is empty.
    '''
    ret = None
    for func in reversed(funcs):
        ret = func(*args, **kwargs)
    return ret","call each func from reversed func list.

    return the last func value or None if func list is empty.",
"def append_func(self, func, *args, **kwargs):
        '''
        append func with given arguments and keywords.
        '''
        wraped_func = partial(func, *args, **kwargs)
        self.append(wraped_func)",append func with given arguments and keywords.,
"def insert_func(self, index, func, *args, **kwargs):
        '''
        insert func with given arguments and keywords.
        '''
        wraped_func = partial(func, *args, **kwargs)
        self.insert(index, wraped_func)",insert func with given arguments and keywords.,
"def format_usage(self, usage):
        """"""
        ensure there is only one newline between usage and the first heading
        if there is no description
        """"""
        msg = 'Usage: %s' % usage
        if self.parser.description:
            msg += '\n'
        return msg","ensure there is only one newline between usage and the first heading
        if there is no description",
"def initialize(self, argv=None):
        """"""initialize the app""""""
        super(BaseParallelApplication, self).initialize(argv)
        self.to_work_dir()
        self.reinit_logging()",initialize the app,
"def real_name(magic_func):
    """""" Find the real name of the magic.
    """"""
    magic_name = magic_func.__name__
    if magic_name.startswith('magic_'):
        magic_name = magic_name[len('magic_'):]
    return getattr(magic_func, 'argcmd_name', magic_name)",Find the real name of the magic.,
"def add_to_parser(self, parser, group):
        """""" Add this object's information to the parser.
        """"""
        if group is not None:
            parser = group
        parser.add_argument(*self.args, **self.kwds)
        return None",Add this object's information to the parser.,
"def add_to_parser(self, parser, group):
        """""" Add this object's information to the parser.
        """"""
        return parser.add_argument_group(*self.args, **self.kwds)",Add this object's information to the parser.,
"def rehighlightBlock(self, block):
        """""" Reimplemented to temporarily enable highlighting if disabled.
        """"""
        old = self.highlighting_on
        self.highlighting_on = True
        super(FrontendHighlighter, self).rehighlightBlock(block)
        self.highlighting_on = old",Reimplemented to temporarily enable highlighting if disabled.,
"def setFormat(self, start, count, format):
        """""" Reimplemented to highlight selectively.
        """"""
        start += self._current_offset
        super(FrontendHighlighter, self).setFormat(start, count, format)",Reimplemented to highlight selectively.,
"def _insert_continuation_prompt(self, cursor):
        """""" Reimplemented for auto-indentation.
        """"""
        super(FrontendWidget, self)._insert_continuation_prompt(cursor)
        cursor.insertText(' ' * self._input_splitter.indent_spaces)",Reimplemented for auto-indentation.,
"def _handle_pyout(self, msg):
        """""" Handle display hook output.
        """"""
        self.log.debug(""pyout: %s"", msg.get('content', ''))
        if not self._hidden and self._is_from_this_session(msg):
            text = msg['content']['data']
            self._append_plain_text(text + '\n', before_prompt=True)",Handle display hook output.,
"def execute_file(self, path, hidden=False):
        """""" Attempts to execute file with 'path'. If 'hidden', no output is
            shown.
        """"""
        self.execute('execfile(%r)' % path, hidden=hidden)","Attempts to execute file with 'path'. If 'hidden', no output is
            shown.",
"def _process_execute_ok(self, msg):
        """""" Process a reply for a successful execution request.
        """"""
        payload = msg['content']['payload']
        for item in payload:
            if not self._process_execute_payload(item):
                warning = 'Warning: received unknown payload of type %s'
                print(warning % repr(item['source']))",Process a reply for a successful execution request.,
"def simple(self, *arg, **kw):
        """"""Call all plugins, returning the first non-None result.
        """"""
        for p, meth in self.plugins:
            result = meth(*arg, **kw)
            if result is not None:
                return result","Call all plugins, returning the first non-None result.",
"def addPlugins(self, plugins=(), extraplugins=()):
        """"""extraplugins are maintained in a separate list and
        re-added by loadPlugins() to prevent their being overwritten
        by plugins added by a subclass of PluginManager
        """"""
        self._extraplugins = extraplugins
        for plug in iterchain(plugins, extraplugins):
            self.addPlugin(plug)","extraplugins are maintained in a separate list and
        re-added by loadPlugins() to prevent their being overwritten
        by plugins added by a subclass of PluginManager",
"def loadPlugins(self):
        """"""Load plugins in nose.plugins.builtin
        """"""
        from nose.plugins import builtin
        for plug in builtin.plugins:
            self.addPlugin(plug())
        super(BuiltinPluginManager, self).loadPlugins()",Load plugins in nose.plugins.builtin,
"def latex_to_html(s, alt='image'):
    """"""Render LaTeX to HTML with embedded PNG data using data URIs.

    Parameters
    ----------
    s : str
        The raw string containing valid inline LateX.
    alt : str
        The alt text to use for the HTML.
    """"""
    base64_data = latex_to_png(s, encode=True)
    if base64_data:
        return _data_uri_template_png  % (base64_data, alt)","Render LaTeX to HTML with embedded PNG data using data URIs.

    Parameters
    ----------
    s : str
        The raw string containing valid inline LateX.
    alt : str
        The alt text to use for the HTML.",
"def phymem_usage():
    """"""Return the amount of total, used and free physical memory
    on the system in bytes plus the percentage usage.
    Deprecated by psutil.virtual_memory().
    """"""
    mem = virtual_memory()
    return _nt_sysmeminfo(mem.total, mem.used, mem.free, mem.percent)","Return the amount of total, used and free physical memory
    on the system in bytes plus the percentage usage.
    Deprecated by psutil.virtual_memory().",
"def get_memory_percent(self):
        """"""Compare physical system memory to process resident memory and
        calculate process memory utilization as a percentage.
        """"""
        rss = self._platform_impl.get_memory_info()[0]
        try:
            return (rss / float(TOTAL_PHYMEM)) * 100
        except ZeroDivisionError:
            return 0.0","Compare physical system memory to process resident memory and
        calculate process memory utilization as a percentage.",
"def wait(self, timeout=None):
        """"""Wait for process to terminate and, if process is a children
        of the current one also return its exit code, else None.
        """"""
        if timeout is not None and not timeout >= 0:
            raise ValueError(""timeout must be a positive integer"")
        return self._platform_impl.process_wait(timeout)","Wait for process to terminate and, if process is a children
        of the current one also return its exit code, else None.",
"def nice(self):
        """"""Get or set process niceness (priority).
        Deprecated, use get_nice() instead.
        """"""
        msg = ""this property is deprecated; use Process.get_nice() method instead""
        warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
        return self.get_nice()","Get or set process niceness (priority).
        Deprecated, use get_nice() instead.",
"def init_transformers(self):
        """"""Create the default transformers.""""""
        self._transformers = []
        for transformer_cls in _default_transformers:
            transformer_cls(
                shell=self.shell, prefilter_manager=self, config=self.config
            )",Create the default transformers.,
"def register_transformer(self, transformer):
        """"""Register a transformer instance.""""""
        if transformer not in self._transformers:
            self._transformers.append(transformer)
            self.sort_transformers()",Register a transformer instance.,
"def unregister_transformer(self, transformer):
        """"""Unregister a transformer instance.""""""
        if transformer in self._transformers:
            self._transformers.remove(transformer)",Unregister a transformer instance.,
"def init_checkers(self):
        """"""Create the default checkers.""""""
        self._checkers = []
        for checker in _default_checkers:
            checker(
                shell=self.shell, prefilter_manager=self, config=self.config
            )",Create the default checkers.,
"def register_checker(self, checker):
        """"""Register a checker instance.""""""
        if checker not in self._checkers:
            self._checkers.append(checker)
            self.sort_checkers()",Register a checker instance.,
"def unregister_checker(self, checker):
        """"""Unregister a checker instance.""""""
        if checker in self._checkers:
            self._checkers.remove(checker)",Unregister a checker instance.,
"def init_handlers(self):
        """"""Create the default handlers.""""""
        self._handlers = {}
        self._esc_handlers = {}
        for handler in _default_handlers:
            handler(
                shell=self.shell, prefilter_manager=self, config=self.config
            )",Create the default handlers.,
"def register_handler(self, name, handler, esc_strings):
        """"""Register a handler instance by name with esc_strings.""""""
        self._handlers[name] = handler
        for esc_str in esc_strings:
            self._esc_handlers[esc_str] = handler",Register a handler instance by name with esc_strings.,
"def unregister_handler(self, name, handler, esc_strings):
        """"""Unregister a handler instance by name with esc_strings.""""""
        try:
            del self._handlers[name]
        except KeyError:
            pass
        for esc_str in esc_strings:
            h = self._esc_handlers.get(esc_str)
            if h is handler:
                del self._esc_handlers[esc_str]",Unregister a handler instance by name with esc_strings.,
"def prefilter_line_info(self, line_info):
        """"""Prefilter a line that has been converted to a LineInfo object.

        This implements the checker/handler part of the prefilter pipe.
        """"""
        # print ""prefilter_line_info: "", line_info
        handler = self.find_handler(line_info)
        return handler.handle(line_info)","Prefilter a line that has been converted to a LineInfo object.

        This implements the checker/handler part of the prefilter pipe.",
"def find_handler(self, line_info):
        """"""Find a handler for the line_info by trying checkers.""""""
        for checker in self.checkers:
            if checker.enabled:
                handler = checker.check(line_info)
                if handler:
                    return handler
        return self.get_handler_by_name('normal')",Find a handler for the line_info by trying checkers.,
"def transform_line(self, line, continue_prompt):
        """"""Calls the enabled transformers in order of increasing priority.""""""
        for transformer in self.transformers:
            if transformer.enabled:
                line = transformer.transform(line, continue_prompt)
        return line",Calls the enabled transformers in order of increasing priority.,
"def check(self, line_info):
        ""Instances of IPyAutocall in user_ns get autocalled immediately""
        obj = self.shell.user_ns.get(line_info.ifun, None)
        if isinstance(obj, IPyAutocall):
            obj.set_ip(self.shell)
            return self.prefilter_manager.get_handler_by_name('auto')
        else:
            return None",Instances of IPyAutocall in user_ns get autocalled immediately,
"def handle(self, line_info):
        """"""Execute magic functions.""""""
        ifun    = line_info.ifun
        the_rest = line_info.the_rest
        cmd = '%sget_ipython().magic(%r)' % (line_info.pre_whitespace,
                                                    (ifun + "" "" + the_rest))
        return cmd",Execute magic functions.,
"def enterEvent(self, event):
        """""" Reimplemented to cancel the hide timer.
        """"""
        super(CallTipWidget, self).enterEvent(event)
        self._hide_timer.stop()",Reimplemented to cancel the hide timer.,
"def paintEvent(self, event):
        """""" Reimplemented to paint the background panel.
        """"""
        painter = QtGui.QStylePainter(self)
        option = QtGui.QStyleOptionFrame()
        option.initFrom(self)
        painter.drawPrimitive(QtGui.QStyle.PE_PanelTipLabel, option)
        painter.end()

        super(CallTipWidget, self).paintEvent(event)",Reimplemented to paint the background panel.,
"def _cursor_position_changed(self):
        """""" Updates the tip based on user cursor movement.
        """"""
        cursor = self._text_edit.textCursor()
        if cursor.position() <= self._start_position:
            self.hide()
        else:
            position, commas = self._find_parenthesis(self._start_position + 1)
            if position != -1:
                self.hide()",Updates the tip based on user cursor movement.,
"def masked(self):
        """"""
        Retrieve a read-only subordinate mapping.  All values are
        stringified, and sensitive values are masked.  The subordinate
        mapping implements the context manager protocol for
        convenience.
        """"""

        if self._masked is None:
            self._masked = MaskedDict(self)

        return self._masked","Retrieve a read-only subordinate mapping.  All values are
        stringified, and sensitive values are masked.  The subordinate
        mapping implements the context manager protocol for
        convenience.",
"def read(*paths):
    """"""Build a file path from *paths* and return the contents.""""""
    with open(os.path.join(*paths), 'r') as file_handler:
        return file_handler.read()",Build a file path from *paths* and return the contents.,
"def soft_define_alias(self, name, cmd):
        """"""Define an alias, but don't raise on an AliasError.""""""
        try:
            self.define_alias(name, cmd)
        except AliasError, e:
            error(""Invalid alias: %s"" % e)","Define an alias, but don't raise on an AliasError.",
"def define_alias(self, name, cmd):
        """"""Define a new alias after validating it.

        This will raise an :exc:`AliasError` if there are validation
        problems.
        """"""
        nargs = self.validate_alias(name, cmd)
        self.alias_table[name] = (nargs, cmd)","Define a new alias after validating it.

        This will raise an :exc:`AliasError` if there are validation
        problems.",
"def call_alias(self, alias, rest=''):
        """"""Call an alias given its name and the rest of the line.""""""
        cmd = self.transform_alias(alias, rest)
        try:
            self.shell.system(cmd)
        except:
            self.shell.showtraceback()",Call an alias given its name and the rest of the line.,
"def shquote(arg):
    """"""Quote an argument for later parsing by shlex.split()""""""
    for c in '""', ""'"", ""\\"", ""#"":
        if c in arg: return repr(arg)
    if arg.split()<>[arg]:
        return repr(arg)
    return arg",Quote an argument for later parsing by shlex.split(),
"def reset_sgr(self):
        """""" Reset graphics attributs to their default values.
        """"""
        self.intensity = 0
        self.italic = False
        self.bold = False
        self.underline = False
        self.foreground_color = None
        self.background_color = None",Reset graphics attributs to their default values.,
"def generate(secret, age, **payload):
    """"""Generate a one-time jwt with an age in seconds""""""
    jti = str(uuid.uuid1()) # random id
    if not payload:
        payload = {}
    payload['exp'] = int(time.time() + age)
    payload['jti'] = jti
    return jwt.encode(payload, decode_secret(secret))",Generate a one-time jwt with an age in seconds,
"def mutex(func):
    """"""use a thread lock on current method, if self.lock is defined""""""
    def wrapper(*args, **kwargs):
        """"""Decorator Wrapper""""""
        lock = args[0].lock
        lock.acquire(True)
        try:
            return func(*args, **kwargs)
        except:
            raise
        finally:
            lock.release()

    return wrapper","use a thread lock on current method, if self.lock is defined",
"def _clean(self):
        """"""Run by housekeeper thread""""""
        now = time.time()
        for jwt in self.jwts.keys():
            if (now - self.jwts[jwt]) > (self.age * 2):
                del self.jwts[jwt]",Run by housekeeper thread,
"def already_used(self, tok):
        """"""has this jwt been used?""""""
        if tok in self.jwts:
            return True
        self.jwts[tok] = time.time()
        return False",has this jwt been used?,
"def write(self, nb, fp, **kwargs):
        """"""Write a notebook to a file like object""""""
        return fp.write(self.writes(nb,**kwargs))",Write a notebook to a file like object,
"def semaphore(count: int, bounded: bool=False):
    '''
    use `Semaphore` to keep func access thread-safety.

    example:

    ``` py
    @semaphore(3)
    def func(): pass
    ```
    '''

    lock_type = threading.BoundedSemaphore if bounded else threading.Semaphore
    lock_obj = lock_type(value=count)

    return with_it(lock_obj)","use `Semaphore` to keep func access thread-safety.

    example:

    ``` py
    @semaphore(3)
    def func(): pass
    ```",
"def can_cut(self):
        """""" Returns whether text can be cut to the clipboard.
        """"""
        cursor = self._control.textCursor()
        return (cursor.hasSelection() and
                self._in_buffer(cursor.anchor()) and
                self._in_buffer(cursor.position()))",Returns whether text can be cut to the clipboard.,
"def can_paste(self):
        """""" Returns whether text can be pasted from the clipboard.
        """"""
        if self._control.textInteractionFlags() & QtCore.Qt.TextEditable:
            return bool(QtGui.QApplication.clipboard().text())
        return False",Returns whether text can be pasted from the clipboard.,
"def cut(self):
        """""" Copy the currently selected text to the clipboard and delete it
            if it's inside the input buffer.
        """"""
        self.copy()
        if self.can_cut():
            self._control.textCursor().removeSelectedText()","Copy the currently selected text to the clipboard and delete it
            if it's inside the input buffer.",
"def print_(self, printer = None):
        """""" Print the contents of the ConsoleWidget to the specified QPrinter.
        """"""
        if (not printer):
            printer = QtGui.QPrinter()
            if(QtGui.QPrintDialog(printer).exec_() != QtGui.QDialog.Accepted):
                return
        self._control.print_(printer)",Print the contents of the ConsoleWidget to the specified QPrinter.,
"def prompt_to_top(self):
        """""" Moves the prompt to the top of the viewport.
        """"""
        if not self._executing:
            prompt_cursor = self._get_prompt_cursor()
            if self._get_cursor().blockNumber() < prompt_cursor.blockNumber():
                self._set_cursor(prompt_cursor)
            self._set_top_cursor(prompt_cursor)",Moves the prompt to the top of the viewport.,
"def change_font_size(self, delta):
        """"""Change the font size by the specified amount (in points).
        """"""
        font = self.font
        size = max(font.pointSize() + delta, 1) # minimum 1 point
        font.setPointSize(size)
        self._set_font(font)",Change the font size by the specified amount (in points).,
"def _set_tab_width(self, tab_width):
        """""" Sets the width (in terms of space characters) for tab characters.
        """"""
        font_metrics = QtGui.QFontMetrics(self.font)
        self._control.setTabStopWidth(tab_width * font_metrics.width(' '))

        self._tab_width = tab_width",Sets the width (in terms of space characters) for tab characters.,
"def _append_html(self, html, before_prompt=False):
        """""" Appends HTML at the end of the console buffer.
        """"""
        self._append_custom(self._insert_html, html, before_prompt)",Appends HTML at the end of the console buffer.,
"def _append_html_fetching_plain_text(self, html, before_prompt=False):
        """""" Appends HTML, then returns the plain text version of it.
        """"""
        return self._append_custom(self._insert_html_fetching_plain_text,
                                   html, before_prompt)","Appends HTML, then returns the plain text version of it.",
"def _append_plain_text(self, text, before_prompt=False):
        """""" Appends plain text, processing ANSI codes if enabled.
        """"""
        self._append_custom(self._insert_plain_text, text, before_prompt)","Appends plain text, processing ANSI codes if enabled.",
"def _get_block_plain_text(self, block):
        """""" Given a QTextBlock, return its unformatted text.
        """"""
        cursor = QtGui.QTextCursor(block)
        cursor.movePosition(QtGui.QTextCursor.StartOfBlock)
        cursor.movePosition(QtGui.QTextCursor.EndOfBlock,
                            QtGui.QTextCursor.KeepAnchor)
        return cursor.selection().toPlainText()","Given a QTextBlock, return its unformatted text.",
"def _get_end_cursor(self):
        """""" Convenience method that returns a cursor for the last character.
        """"""
        cursor = self._control.textCursor()
        cursor.movePosition(QtGui.QTextCursor.End)
        return cursor",Convenience method that returns a cursor for the last character.,
"def _get_prompt_cursor(self):
        """""" Convenience method that returns a cursor for the prompt position.
        """"""
        cursor = self._control.textCursor()
        cursor.setPosition(self._prompt_pos)
        return cursor",Convenience method that returns a cursor for the prompt position.,
"def _get_selection_cursor(self, start, end):
        """""" Convenience method that returns a cursor with text selected between
            the positions 'start' and 'end'.
        """"""
        cursor = self._control.textCursor()
        cursor.setPosition(start)
        cursor.setPosition(end, QtGui.QTextCursor.KeepAnchor)
        return cursor","Convenience method that returns a cursor with text selected between
            the positions 'start' and 'end'.",
"def _keep_cursor_in_buffer(self):
        """""" Ensures that the cursor is inside the editing region. Returns
            whether the cursor was moved.
        """"""
        moved = not self._in_buffer()
        if moved:
            cursor = self._control.textCursor()
            cursor.movePosition(QtGui.QTextCursor.End)
            self._control.setTextCursor(cursor)
        return moved","Ensures that the cursor is inside the editing region. Returns
            whether the cursor was moved.",
"def _keyboard_quit(self):
        """""" Cancels the current editing task ala Ctrl-G in Emacs.
        """"""
        if self._temp_buffer_filled :
            self._cancel_completion()
            self._clear_temporary_buffer()
        else:
            self.input_buffer = ''",Cancels the current editing task ala Ctrl-G in Emacs.,
"def _custom_context_menu_requested(self, pos):
        """""" Shows a context menu at the given QPoint (in widget coordinates).
        """"""
        menu = self._context_menu_make(pos)
        menu.exec_(self._control.mapToGlobal(pos))",Shows a context menu at the given QPoint (in widget coordinates).,
"def dist_in_usersite(dist):
    """"""
    Return True if given Distribution is installed in user site.
    """"""
    if user_site:
        return normalize_path(dist_location(dist)).startswith(normalize_path(user_site))
    else:
        return False",Return True if given Distribution is installed in user site.,
"def file_read(filename):
    """"""Read a file and close it.  Returns the file source.""""""
    fobj = open(filename,'r');
    source = fobj.read();
    fobj.close()
    return source",Read a file and close it.  Returns the file source.,
"def file_readlines(filename):
    """"""Read a file and close it.  Returns the file source using readlines().""""""
    fobj = open(filename,'r');
    lines = fobj.readlines();
    fobj.close()
    return lines",Read a file and close it.  Returns the file source using readlines().,
"def raw_input_ext(prompt='',  ps2='... '):
    """"""Similar to raw_input(), but accepts extended lines if input ends with \\.""""""

    line = raw_input(prompt)
    while line.endswith('\\'):
        line = line[:-1] + raw_input(ps2)
    return line","Similar to raw_input(), but accepts extended lines if input ends with \\.",
"def raw_print(*args, **kw):
    """"""Raw print to sys.__stdout__, otherwise identical interface to print().""""""

    print(*args, sep=kw.get('sep', ' '), end=kw.get('end', '\n'),
          file=sys.__stdout__)
    sys.__stdout__.flush()","Raw print to sys.__stdout__, otherwise identical interface to print().",
"def raw_print_err(*args, **kw):
    """"""Raw print to sys.__stderr__, otherwise identical interface to print().""""""

    print(*args, sep=kw.get('sep', ' '), end=kw.get('end', '\n'),
          file=sys.__stderr__)
    sys.__stderr__.flush()","Raw print to sys.__stderr__, otherwise identical interface to print().",
"def close(self):
        """"""Close the file and restore the channel.""""""
        self.flush()
        setattr(sys, self.channel, self.ostream)
        self.file.close()
        self._closed = True",Close the file and restore the channel.,
"def write(self, data):
        """"""Write data to both channels.""""""
        self.file.write(data)
        self.ostream.write(data)
        self.ostream.flush()",Write data to both channels.,
"def show(self):
        """"""write my output to sys.stdout/err as appropriate""""""
        sys.stdout.write(self.stdout)
        sys.stderr.write(self.stderr)
        sys.stdout.flush()
        sys.stderr.flush()",write my output to sys.stdout/err as appropriate,
"def add_new_heart_handler(self, handler):
        """"""add a new handler for new hearts""""""
        self.log.debug(""heartbeat::new_heart_handler: %s"", handler)
        self._new_handlers.add(handler)",add a new handler for new hearts,
"def add_heart_failure_handler(self, handler):
        """"""add a new handler for heart failure""""""
        self.log.debug(""heartbeat::new heart failure handler: %s"", handler)
        self._failure_handlers.add(handler)",add a new handler for heart failure,
"def uncache_zipdir(path):
    """"""Ensure that the importer caches dont have stale info for `path`""""""
    from zipimport import _zip_directory_cache as zdc
    _uncache(path, zdc)
    _uncache(path, sys.path_importer_cache)",Ensure that the importer caches dont have stale info for `path`,
"def is_sh(executable):
    """"""Determine if the specified executable is a .sh (contains a #! line)""""""
    try:
        fp = open(executable)
        magic = fp.read(2)
        fp.close()
    except (OSError,IOError): return executable
    return magic == '#!'",Determine if the specified executable is a .sh (contains a #! line),
"def create_home_path(self):
        """"""Create directories under ~.""""""
        if not self.user:
            return
        home = convert_path(os.path.expanduser(""~""))
        for name, path in self.config_vars.iteritems():
            if path.startswith(home) and not os.path.isdir(path):
                self.debug_print(""os.makedirs('%s', 0700)"" % path)
                os.makedirs(path, 0700)",Create directories under ~.,
"def is_archive_file(name):
    """"""Return True if `name` is a considered as an archive file.""""""
    archives = (
        '.zip', '.tar.gz', '.tar.bz2', '.tgz', '.tar', '.whl'
    )
    ext = splitext(name)[1].lower()
    if ext in archives:
        return True
    return False",Return True if `name` is a considered as an archive file.,
"def _writable_dir(path):
    """"""Whether `path` is a directory, to which the user has write access.""""""
    return os.path.isdir(path) and os.access(path, os.W_OK)","Whether `path` is a directory, to which the user has write access.",
"def unquote_filename(name, win32=(sys.platform=='win32')):
    """""" On Windows, remove leading and trailing quotes from filenames.
    """"""
    if win32:
        if name.startswith((""'"", '""')) and name.endswith((""'"", '""')):
            name = name[1:-1]
    return name","On Windows, remove leading and trailing quotes from filenames.",
"def get_ipython_package_dir():
    """"""Get the base directory where IPython itself is installed.""""""
    ipdir = os.path.dirname(IPython.__file__)
    return py3compat.cast_unicode(ipdir, fs_encoding)",Get the base directory where IPython itself is installed.,
"def filehash(path):
    """"""Make an MD5 hash of a file, ignoring any differences in line
    ending characters.""""""
    with open(path, ""rU"") as f:
        return md5(py3compat.str_to_bytes(f.read())).hexdigest()","Make an MD5 hash of a file, ignoring any differences in line
    ending characters.",
"def get_suggestions(object):
    """""" Gets a list of all suggestions for an object """"""
    content_type = ContentType.objects.get_for_model(type(object))
    return ObjectViewDictionary.objects.filter(
        current_object_id=object.id,
        current_content_type=content_type).extra(order_by=['-visits'])",Gets a list of all suggestions for an object,
"def relpath(self):
        """""" Return this path as a relative path,
        based from the current working directory.
        """"""
        cwd = self.__class__(os.getcwdu())
        return cwd.relpathto(self)","Return this path as a relative path,
        based from the current working directory.",
"def glob(self, pattern):
        """""" Return a list of path objects that match the pattern.

        pattern - a path relative to this directory, with wildcards.

        For example, path('/users').glob('*/bin/*') returns a list
        of all the files users have in their bin directories.
        """"""
        cls = self.__class__
        return [cls(s) for s in glob.glob(unicode(self / pattern))]","Return a list of path objects that match the pattern.

        pattern - a path relative to this directory, with wildcards.

        For example, path('/users').glob('*/bin/*') returns a list
        of all the files users have in their bin directories.",
"def read_md5(self):
        """""" Calculate the md5 hash for this file.

        This reads through the entire file.
        """"""
        f = self.open('rb')
        try:
            m = md5()
            while True:
                d = f.read(8192)
                if not d:
                    break
                m.update(d)
        finally:
            f.close()
        return m.digest()","Calculate the md5 hash for this file.

        This reads through the entire file.",
"def begin(self):
        """"""Create profile stats file and load profiler.
        """"""
        if not self.available():
            return
        self._create_pfile()
        self.prof = hotshot.Profile(self.pfile)",Create profile stats file and load profiler.,
"def handle(self, *args, **options):
        """"""Handle CLI command""""""
        try:
            while True:
                Channel(HEARTBEAT_CHANNEL).send({'time':time.time()})
                time.sleep(HEARTBEAT_FREQUENCY)
        except KeyboardInterrupt:
            print(""Received keyboard interrupt, exiting..."")",Handle CLI command,
"def disable_wx(self):
        """"""Disable event loop integration with wxPython.

        This merely sets PyOS_InputHook to NULL.
        """"""
        if self._apps.has_key(GUI_WX):
            self._apps[GUI_WX]._in_event_loop = False
        self.clear_inputhook()","Disable event loop integration with wxPython.

        This merely sets PyOS_InputHook to NULL.",
"def disable_qt4(self):
        """"""Disable event loop integration with PyQt4.

        This merely sets PyOS_InputHook to NULL.
        """"""
        if self._apps.has_key(GUI_QT4):
            self._apps[GUI_QT4]._in_event_loop = False
        self.clear_inputhook()","Disable event loop integration with PyQt4.

        This merely sets PyOS_InputHook to NULL.",
"def setup_partitioner(index, num_procs, gnum_cells, parts):
    """"""create a partitioner in the engine namespace""""""
    global partitioner
    p = MPIRectPartitioner2D(my_id=index, num_procs=num_procs)
    p.redim(global_num_cells=gnum_cells, num_parts=parts)
    p.prepare_communication()
    # put the partitioner into the global namespace:
    partitioner=p",create a partitioner in the engine namespace,
"def wave_saver(u, x, y, t):
    """"""save the wave log""""""
    global u_hist
    global t_hist
    t_hist.append(t)
    u_hist.append(1.0*u)",save the wave log,
"def _get_hist_file_name(self, profile=None):
        """"""Get default history file name based on the Shell's profile.
        
        The profile parameter is ignored, but must exist for compatibility with
        the parent class.""""""
        profile_dir = self.shell.profile_dir.location
        return os.path.join(profile_dir, 'history.sqlite')","Get default history file name based on the Shell's profile.
        
        The profile parameter is ignored, but must exist for compatibility with
        the parent class.",
"def new_session(self, conn=None):
        """"""Get a new session number.""""""
        if conn is None:
            conn = self.db
        
        with conn:
            cur = conn.execute(""""""INSERT INTO sessions VALUES (NULL, ?, NULL,
                            NULL, """") """""", (datetime.datetime.now(),))
            self.session_number = cur.lastrowid",Get a new session number.,
"def name_session(self, name):
        """"""Give the current session a name in the history database.""""""
        with self.db:
            self.db.execute(""UPDATE sessions SET remark=? WHERE session==?"",
                            (name, self.session_number))",Give the current session a name in the history database.,
"def stop(self):
        """"""This can be called from the main thread to safely stop this thread.

        Note that it does not attempt to write out remaining history before
        exiting. That should be done by calling the HistoryManager's
        end_session method.""""""
        self.stop_now = True
        self.history_manager.save_flag.set()
        self.join()","This can be called from the main thread to safely stop this thread.

        Note that it does not attempt to write out remaining history before
        exiting. That should be done by calling the HistoryManager's
        end_session method.",
"def _get_boot_time():
    """"""Return system boot time (epoch in seconds)""""""
    f = open('/proc/stat', 'r')
    try:
        for line in f:
            if line.startswith('btime'):
                return float(line.strip().split()[1])
        raise RuntimeError(""line not found"")
    finally:
        f.close()",Return system boot time (epoch in seconds),
"def get_system_cpu_times():
    """"""Return a named tuple representing the following CPU times:
    user, nice, system, idle, iowait, irq, softirq.
    """"""
    f = open('/proc/stat', 'r')
    try:
        values = f.readline().split()
    finally:
        f.close()

    values = values[1:8]
    values = tuple([float(x) / _CLOCK_TICKS for x in values])
    return nt_sys_cputimes(*values[:7])","Return a named tuple representing the following CPU times:
    user, nice, system, idle, iowait, irq, softirq.",
"def get_pid_list():
    """"""Returns a list of PIDs currently running on the system.""""""
    pids = [int(x) for x in os.listdir('/proc') if x.isdigit()]
    return pids",Returns a list of PIDs currently running on the system.,
"def nice_pair(pair):
    """"""Make a nice string representation of a pair of numbers.

    If the numbers are equal, just return the number, otherwise return the pair
    with a dash between them, indicating the range.

    """"""
    start, end = pair
    if start == end:
        return ""%d"" % start
    else:
        return ""%d-%d"" % (start, end)","Make a nice string representation of a pair of numbers.

    If the numbers are equal, just return the number, otherwise return the pair
    with a dash between them, indicating the range.",
"def short_stack():
    """"""Return a string summarizing the call stack.""""""
    stack = inspect.stack()[:0:-1]
    return ""\n"".join([""%30s : %s @%d"" % (t[3],t[1],t[2]) for t in stack])",Return a string summarizing the call stack.,
"def expensive(fn):
    """"""A decorator to cache the result of an expensive operation.

    Only applies to methods with no arguments.

    """"""
    attr = ""_cache_"" + fn.__name__
    def _wrapped(self):
        """"""Inner fn that checks the cache.""""""
        if not hasattr(self, attr):
            setattr(self, attr, fn(self))
        return getattr(self, attr)
    return _wrapped","A decorator to cache the result of an expensive operation.

    Only applies to methods with no arguments.",
"def join_regex(regexes):
    """"""Combine a list of regexes into one that matches any of them.""""""
    if len(regexes) > 1:
        return ""|"".join([""(%s)"" % r for r in regexes])
    elif regexes:
        return regexes[0]
    else:
        return """"",Combine a list of regexes into one that matches any of them.,
"def file_be_gone(path):
    """"""Remove a file, and don't get annoyed if it doesn't exist.""""""
    try:
        os.remove(path)
    except OSError:
        _, e, _ = sys.exc_info()
        if e.errno != errno.ENOENT:
            raise","Remove a file, and don't get annoyed if it doesn't exist.",
"def _propagate_url(self):
        """"""Ensure self.url contains full transport://interface:port""""""
        if self.url:
            iface = self.url.split('://',1)
            if len(iface) == 2:
                self.transport,iface = iface
            iface = iface.split(':')
            self.ip = iface[0]
            if iface[1]:
                self.regport = int(iface[1])",Ensure self.url contains full transport://interface:port,
"def setup_partitioner(comm, addrs, index, num_procs, gnum_cells, parts):
    """"""create a partitioner in the engine namespace""""""
    global partitioner
    p = ZMQRectPartitioner2D(comm, addrs, my_id=index, num_procs=num_procs)
    p.redim(global_num_cells=gnum_cells, num_parts=parts)
    p.prepare_communication()
    # put the partitioner into the global namespace:
    partitioner=p",create a partitioner in the engine namespace,
"def get_translations(codes):
        """""" Returns a list of (code, translation) tuples for codes  """"""
        codes = codes or self.codes
        return self._get_priority_translations(priority, codes)","Returns a list of (code, translation) tuples for codes",
"def get_translations_sorted(codes):
        """""" Returns a sorted list of (code, translation) tuples for codes  """"""
        codes = codes or self.codes
        return self._get_priority_translations(priority, codes)","Returns a sorted list of (code, translation) tuples for codes",
"def get_priority_translations(priority, codes):
        """""" Returns a list of (code, translation) tuples for priority, codes  """"""
        priority = priority or self.priority
        codes = codes or self.codes
        return self._get_priority_translations(priority, codes)","Returns a list of (code, translation) tuples for priority, codes",
"def set_trace():
    """"""Call pdb.set_trace in the calling frame, first restoring
    sys.stdout to the real output stream. Note that sys.stdout is NOT
    reset to whatever it was before the call once pdb is done!
    """"""
    import pdb
    import sys
    stdout = sys.stdout
    sys.stdout = sys.__stdout__
    pdb.Pdb().set_trace(sys._getframe().f_back)","Call pdb.set_trace in the calling frame, first restoring
    sys.stdout to the real output stream. Note that sys.stdout is NOT
    reset to whatever it was before the call once pdb is done!",
"def data(fname):
    """"""Return the contents of a data file of ours.""""""
    data_file = open(data_filename(fname))
    try:
        return data_file.read()
    finally:
        data_file.close()",Return the contents of a data file of ours.,
"def write_html(self, fname, html):
        """"""Write `html` to `fname`, properly encoded.""""""
        fout = open(fname, ""wb"")
        try:
            fout.write(html.encode('ascii', 'xmlcharrefreplace'))
        finally:
            fout.close()","Write `html` to `fname`, properly encoded.",
"def file_hash(self, source, cu):
        """"""Compute a hash that changes if the file needs to be re-reported.""""""
        m = Hasher()
        m.update(source)
        self.coverage.data.add_to_hash(cu.filename, m)
        return m.digest()",Compute a hash that changes if the file needs to be re-reported.,
"def sort_compare(lst1, lst2, inplace=1):
    """"""Sort and compare two lists.

    By default it does it in place, thus modifying the lists. Use inplace = 0
    to avoid that (at the cost of temporary copy creation).""""""
    if not inplace:
        lst1 = lst1[:]
        lst2 = lst2[:]
    lst1.sort(); lst2.sort()
    return lst1 == lst2","Sort and compare two lists.

    By default it does it in place, thus modifying the lists. Use inplace = 0
    to avoid that (at the cost of temporary copy creation).",
"def list2dict(lst):
    """"""Takes a list of (key,value) pairs and turns it into a dict.""""""

    dic = {}
    for k,v in lst: dic[k] = v
    return dic","Takes a list of (key,value) pairs and turns it into a dict.",
"def get_slice(seq, start=0, stop=None, step=1):
    """"""Get a slice of a sequence with variable step. Specify start,stop,step.""""""
    if stop == None:
        stop = len(seq)
    item = lambda i: seq[i]
    return map(item,xrange(start,stop,step))","Get a slice of a sequence with variable step. Specify start,stop,step.",
"def chop(seq, size):
    """"""Chop a sequence into chunks of the given size.""""""
    chunk = lambda i: seq[i:i+size]
    return map(chunk,xrange(0,len(seq),size))",Chop a sequence into chunks of the given size.,
"def file_matches(filename, patterns):
    """"""Does this filename match any of the patterns?""""""
    return any(fnmatch.fnmatch(filename, pat) for pat in patterns)",Does this filename match any of the patterns?,
"def shutdown_kernel(self, kernel_id):
        """"""Shutdown a kernel by its kernel uuid.

        Parameters
        ==========
        kernel_id : uuid
            The id of the kernel to shutdown.
        """"""
        self.get_kernel(kernel_id).shutdown_kernel()
        del self._kernels[kernel_id]","Shutdown a kernel by its kernel uuid.

        Parameters
        ==========
        kernel_id : uuid
            The id of the kernel to shutdown.",
"def kill_kernel(self, kernel_id):
        """"""Kill a kernel by its kernel uuid.

        Parameters
        ==========
        kernel_id : uuid
            The id of the kernel to kill.
        """"""
        self.get_kernel(kernel_id).kill_kernel()
        del self._kernels[kernel_id]","Kill a kernel by its kernel uuid.

        Parameters
        ==========
        kernel_id : uuid
            The id of the kernel to kill.",
"def get_kernel(self, kernel_id):
        """"""Get the single KernelManager object for a kernel by its uuid.

        Parameters
        ==========
        kernel_id : uuid
            The id of the kernel.
        """"""
        km = self._kernels.get(kernel_id)
        if km is not None:
            return km
        else:
            raise KeyError(""Kernel with id not found: %s"" % kernel_id)","Get the single KernelManager object for a kernel by its uuid.

        Parameters
        ==========
        kernel_id : uuid
            The id of the kernel.",
"def notebook_for_kernel(self, kernel_id):
        """"""Return the notebook_id for a kernel_id or None.""""""
        notebook_ids = [k for k, v in self._notebook_mapping.iteritems() if v == kernel_id]
        if len(notebook_ids) == 1:
            return notebook_ids[0]
        else:
            return None",Return the notebook_id for a kernel_id or None.,
"def delete_mapping_for_kernel(self, kernel_id):
        """"""Remove the kernel/notebook mapping for kernel_id.""""""
        notebook_id = self.notebook_for_kernel(kernel_id)
        if notebook_id is not None:
            del self._notebook_mapping[notebook_id]",Remove the kernel/notebook mapping for kernel_id.,
"def shutdown_kernel(self, kernel_id):
        """"""Shutdown a kernel and remove its notebook association.""""""
        self._check_kernel_id(kernel_id)
        super(MappingKernelManager, self).shutdown_kernel(kernel_id)
        self.delete_mapping_for_kernel(kernel_id)
        self.log.info(""Kernel shutdown: %s"" % kernel_id)",Shutdown a kernel and remove its notebook association.,
"def interrupt_kernel(self, kernel_id):
        """"""Interrupt a kernel.""""""
        self._check_kernel_id(kernel_id)
        super(MappingKernelManager, self).interrupt_kernel(kernel_id)
        self.log.info(""Kernel interrupted: %s"" % kernel_id)",Interrupt a kernel.,
"def create_iopub_stream(self, kernel_id):
        """"""Create a new iopub stream.""""""
        self._check_kernel_id(kernel_id)
        return super(MappingKernelManager, self).create_iopub_stream(kernel_id)",Create a new iopub stream.,
"def create_shell_stream(self, kernel_id):
        """"""Create a new shell stream.""""""
        self._check_kernel_id(kernel_id)
        return super(MappingKernelManager, self).create_shell_stream(kernel_id)",Create a new shell stream.,
"def create_hb_stream(self, kernel_id):
        """"""Create a new hb stream.""""""
        self._check_kernel_id(kernel_id)
        return super(MappingKernelManager, self).create_hb_stream(kernel_id)",Create a new hb stream.,
"def configure(self, options, conf):
        """"""Configure plugin.
        """"""
        if not self.can_configure:
            return
        self.conf = conf
        disable = getattr(options, 'noDeprecated', False)
        if disable:
            self.enabled = False",Configure plugin.,
"def iseq(start=0, stop=None, inc=1):
    """"""
    Generate integers from start to (and including!) stop,
    with increment of inc. Alternative to range/xrange.
    """"""
    if stop is None: # allow isequence(3) to be 0, 1, 2, 3
        # take 1st arg as stop, start as 0, and inc=1
        stop = start; start = 0; inc = 1
    return arange(start, stop+inc, inc)","Generate integers from start to (and including!) stop,
    with increment of inc. Alternative to range/xrange.",
"def ensure_utf8(image_tag):
    """"""wrapper for ensuring image_tag returns utf8-encoded str on Python 2""""""
    if py3compat.PY3:
        # nothing to do on Python 3
        return image_tag
    
    def utf8_image_tag(*args, **kwargs):
        s = image_tag(*args, **kwargs)
        if isinstance(s, unicode):
            s = s.encode('utf8')
        return s
    return utf8_image_tag",wrapper for ensuring image_tag returns utf8-encoded str on Python 2,
"def get_unique_or_none(klass, *args, **kwargs):
    """""" Returns a unique instance of `klass` or None """"""
    try:
        return klass.objects.get(*args, **kwargs)
    except klass.DoesNotExist:
        return None
    except klass.MultipleObjectsReturned:
        return None
    return None",Returns a unique instance of `klass` or None,
"def get_date_greater_query(days, date_field):
    """"""
    Query for if date_field is within number of ""days"" ago.
    """"""
    query = None
    days = get_integer(days)
    if days:
        past = get_days_ago(days)
        query = Q(**{""%s__gte"" % date_field: past.isoformat()})
    return query","Query for if date_field is within number of ""days"" ago.",
"def get_date_less_query(days, date_field):
    """"""
    Query for if date_field is within number of ""days"" from now.
    """"""
    query = None
    days = get_integer(days)
    if days:
        future = get_days_from_now(days)
        query = Q(**{""%s__lte"" % date_field: future.isoformat()})
    return query","Query for if date_field is within number of ""days"" from now.",
"def get_null_or_blank_query(field=None):
    """"""
    Query for null or blank field.
    """"""
    if not field:
        return field
    null_q = get_null_query(field)
    blank_q = get_blank_query(field)
    return (null_q | blank_q)",Query for null or blank field.,
"def attr(*args, **kwargs):
    """"""Decorator that adds attributes to classes or functions
    for use with the Attribute (-a) plugin.
    """"""
    def wrap_ob(ob):
        for name in args:
            setattr(ob, name, True)
        for name, value in kwargs.iteritems():
            setattr(ob, name, value)
        return ob
    return wrap_ob","Decorator that adds attributes to classes or functions
    for use with the Attribute (-a) plugin.",
"def wantMethod(self, method):
        """"""Accept the method if its attributes match.
        """"""
        try:
            cls = method.im_class
        except AttributeError:
            return False
        return self.validateAttrib(method, cls)",Accept the method if its attributes match.,
"def _really_start_hb(self):
        """"""callback for delayed heartbeat start
        
        Only start the hb loop if we haven't been closed during the wait.
        """"""
        if self._beating and not self.hb_stream.closed():
            self._hb_periodic_callback.start()","callback for delayed heartbeat start
        
        Only start the hb loop if we haven't been closed during the wait.",
"def stop_hb(self):
        """"""Stop the heartbeating and cancel all related callbacks.""""""
        if self._beating:
            self._beating = False
            self._hb_periodic_callback.stop()
            if not self.hb_stream.closed():
                self.hb_stream.on_recv(None)",Stop the heartbeating and cancel all related callbacks.,
"def seek(self,index):
        """"""Move the current seek pointer to the given block.

        You can use negative indices to seek from the end, with identical
        semantics to those of Python lists.""""""
        if index<0:
            index = self.nblocks + index
        self._validate_index(index)
        self.block_index = index
        self.finished = False","Move the current seek pointer to the given block.

        You can use negative indices to seek from the end, with identical
        semantics to those of Python lists.",
"def show(self,index=None):
        """"""Show a single block on screen""""""

        index = self._get_index(index)
        if index is None:
            return

        print >>io.stdout, self.marquee('<%s> block # %s (%s remaining)' %
                           (self.title,index,self.nblocks-index-1))
        print >>io.stdout,(self.src_blocks_colored[index])
        sys.stdout.flush()",Show a single block on screen,
"def with_it(obj):
    '''
    wrap `with obj` out of func.

    example:

    ``` py
    @with_it(Lock())
    def func(): pass
    ```
    '''

    def _wrap(func):

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            with obj:
                return func(*args, **kwargs)

        return wrapper

    return _wrap","wrap `with obj` out of func.

    example:

    ``` py
    @with_it(Lock())
    def func(): pass
    ```",
"def sync_results(f, self, *args, **kwargs):
    """"""sync relevant results from self.client to our results attribute.""""""
    ret = f(self, *args, **kwargs)
    delta = self.outstanding.difference(self.client.outstanding)
    completed = self.outstanding.intersection(delta)
    self.outstanding = self.outstanding.difference(completed)
    return ret",sync relevant results from self.client to our results attribute.,
"def spin_after(f, self, *args, **kwargs):
    """"""call spin after the method.""""""
    ret = f(self, *args, **kwargs)
    self.spin()
    return ret",call spin after the method.,
"def add_record(self, msg_id, rec):
        """"""Add a new Task Record, by msg_id.""""""
        # print rec
        rec = self._binary_buffers(rec)
        self._records.insert(rec)","Add a new Task Record, by msg_id.",
"def get_record(self, msg_id):
        """"""Get a specific Task Record, by msg_id.""""""
        r = self._records.find_one({'msg_id': msg_id})
        if not r:
            # r will be '' if nothing is found
            raise KeyError(msg_id)
        return r","Get a specific Task Record, by msg_id.",
"def update_record(self, msg_id, rec):
        """"""Update the data in an existing record.""""""
        rec = self._binary_buffers(rec)

        self._records.update({'msg_id':msg_id}, {'$set': rec})",Update the data in an existing record.,
"def get_history(self):
        """"""get all msg_ids, ordered by time submitted.""""""
        cursor = self._records.find({},{'msg_id':1}).sort('submitted')
        return [ rec['msg_id'] for rec in cursor ]","get all msg_ids, ordered by time submitted.",
"def get_msgs(self):
        """"""Get all messages that are currently ready.""""""
        msgs = []
        while True:
            try:
                msgs.append(self.get_msg(block=False))
            except Empty:
                break
        return msgs",Get all messages that are currently ready.,
"def get_msg(self, block=True, timeout=None):
        ""Gets a message if there is one that is ready.""
        return self._in_queue.get(block, timeout)",Gets a message if there is one that is ready.,
"def get_onlys(*fields):
    '''
    `get_onlys` is a sugar for multi-`property`.

    ``` py
    name, age = get_onlys('_name', '_age')

    # equals:

    @property
    def name(self):
        return getattr(self, '_name')

    @property
    def age(self):
        return getattr(self, '_age')
    ```
    '''
    return tuple(property(lambda self, f=f: getattr(self, f)) for f in fields)","`get_onlys` is a sugar for multi-`property`.

    ``` py
    name, age = get_onlys('_name', '_age')

    # equals:

    @property
    def name(self):
        return getattr(self, '_name')

    @property
    def age(self):
        return getattr(self, '_age')
    ```",
"def interact(self):
        """"""This should call display(Javascript(jscode)).""""""
        jscode = self.render()
        display(Javascript(data=jscode,lib=self.jslibs))",This should call display(Javascript(jscode)).,
"def _quoteattr(self, attr):
        """"""Escape an XML attribute. Value can be unicode.""""""
        attr = xml_safe(attr)
        if isinstance(attr, unicode) and not UNICODE_STRINGS:
            attr = attr.encode(self.encoding)
        return saxutils.quoteattr(attr)",Escape an XML attribute. Value can be unicode.,
"def twobin(loads):
    """"""Pick two at random, use the LRU of the two.

    The content of loads is ignored.

    Assumes LRU ordering of loads, with oldest first.
    """"""
    n = len(loads)
    a = randint(0,n-1)
    b = randint(0,n-1)
    return min(a,b)","Pick two at random, use the LRU of the two.

    The content of loads is ignored.

    Assumes LRU ordering of loads, with oldest first.",
"def _register_engine(self, uid):
        """"""New engine with ident `uid` became available.""""""
        # head of the line:
        self.targets.insert(0,uid)
        self.loads.insert(0,0)

        # initialize sets
        self.completed[uid] = set()
        self.failed[uid] = set()
        self.pending[uid] = {}

        # rescan the graph:
        self.update_graph(None)",New engine with ident `uid` became available.,
"def add_job(self, idx):
        """"""Called after self.targets[idx] just got the job with header.
        Override with subclasses.  The default ordering is simple LRU.
        The default loads are the number of outstanding jobs.""""""
        self.loads[idx] += 1
        for lis in (self.targets, self.loads):
            lis.append(lis.pop(idx))","Called after self.targets[idx] just got the job with header.
        Override with subclasses.  The default ordering is simple LRU.
        The default loads are the number of outstanding jobs.",
"def new_worksheet(name=None, cells=None):
    """"""Create a worksheet by name with with a list of cells.""""""
    ws = NotebookNode()
    if name is not None:
        ws.name = unicode(name)
    if cells is None:
        ws.cells = []
    else:
        ws.cells = list(cells)
    return ws",Create a worksheet by name with with a list of cells.,
"def new_notebook(metadata=None, worksheets=None):
    """"""Create a notebook by name, id and a list of worksheets.""""""
    nb = NotebookNode()
    nb.nbformat = 2
    if worksheets is None:
        nb.worksheets = []
    else:
        nb.worksheets = list(worksheets)
    if metadata is None:
        nb.metadata = new_metadata()
    else:
        nb.metadata = NotebookNode(metadata)
    return nb","Create a notebook by name, id and a list of worksheets.",
"def add_s(self, s, obj, priority= 0 ):
        """""" Adds a target 'string' for dispatching """"""

        chain = self.strs.get(s, CommandChainDispatcher())
        chain.add(obj,priority)
        self.strs[s] = chain",Adds a target 'string' for dispatching,
"def add_re(self, regex, obj, priority= 0 ):
        """""" Adds a target regexp for dispatching """"""

        chain = self.regexs.get(regex, CommandChainDispatcher())
        chain.add(obj,priority)
        self.regexs[regex] = chain",Adds a target regexp for dispatching,
"def dispatch(self, key):
        """""" Get a seq of Commandchain objects that match key """"""
        if key in self.strs:
            yield self.strs[key]

        for r, obj in self.regexs.items():
            if re.match(r, key):
                yield obj
            else:
                #print ""nomatch"",key  # dbg
                pass",Get a seq of Commandchain objects that match key,
"def flat_matches(self, key):
        """""" Yield all 'value' targets, without priority """"""
        for val in self.dispatch(key):
            for el in val:
                yield el[1] # only value, no priority
        return","Yield all 'value' targets, without priority",
"def delete_notebook_id(self, notebook_id):
        """"""Delete a notebook's id only. This doesn't delete the actual notebook.""""""
        name = self.mapping[notebook_id]
        del self.mapping[notebook_id]
        del self.rev_mapping[name]",Delete a notebook's id only. This doesn't delete the actual notebook.,
"def notebook_exists(self, notebook_id):
        """"""Does a notebook exist?""""""
        if notebook_id not in self.mapping:
            return False
        path = self.get_path_by_name(self.mapping[notebook_id])
        return os.path.isfile(path)",Does a notebook exist?,
"def find_path(self, notebook_id):
        """"""Return a full path to a notebook given its notebook_id.""""""
        try:
            name = self.mapping[notebook_id]
        except KeyError:
            raise web.HTTPError(404, u'Notebook does not exist: %s' % notebook_id)
        return self.get_path_by_name(name)",Return a full path to a notebook given its notebook_id.,
"def get_path_by_name(self, name):
        """"""Return a full path to a notebook given its name.""""""
        filename = name + self.filename_ext
        path = os.path.join(self.notebook_dir, filename)
        return path",Return a full path to a notebook given its name.,
"def delete_notebook(self, notebook_id):
        """"""Delete notebook by notebook_id.""""""
        path = self.find_path(notebook_id)
        if not os.path.isfile(path):
            raise web.HTTPError(404, u'Notebook does not exist: %s' % notebook_id)
        os.unlink(path)
        self.delete_notebook_id(notebook_id)",Delete notebook by notebook_id.,
"def new_notebook(self):
        """"""Create a new notebook and return its notebook_id.""""""
        path, name = self.increment_filename('Untitled')
        notebook_id = self.new_notebook_id(name)
        metadata = current.new_metadata(name=name)
        nb = current.new_notebook(metadata=metadata)
        with open(path,'w') as f:
            current.write(nb, f, u'json')
        return notebook_id",Create a new notebook and return its notebook_id.,
"def init_banner(self):
        """"""optionally display the banner""""""
        if self.display_banner and self.interact:
            self.shell.show_banner()
        # Make sure there is a space below the banner.
        if self.log_level <= logging.INFO: print",optionally display the banner,
"def _pylab_changed(self, name, old, new):
        """"""Replace --pylab='inline' with --pylab='auto'""""""
        if new == 'inline':
            warn.warn(""'inline' not available as pylab backend, ""
                      ""using 'auto' instead.\n"")
            self.pylab = 'auto'",Replace --pylab='inline' with --pylab='auto,
"def class_of ( object ):
    """""" Returns a string containing the class name of an object with the
    correct indefinite article ('a' or 'an') preceding it (e.g., 'an Image',
    'a PlotValue').
    """"""
    if isinstance( object, basestring ):
        return add_article( object )

    return add_article( object.__class__.__name__ )","Returns a string containing the class name of an object with the
    correct indefinite article ('a' or 'an') preceding it (e.g., 'an Image',
    'a PlotValue').",
"def repr_type(obj):
    """""" Return a string representation of a value and its type for readable
    error messages.
    """"""
    the_type = type(obj)
    if (not py3compat.PY3) and the_type is InstanceType:
        # Old-style class.
        the_type = obj.__class__
    msg = '%r %r' % (obj, the_type)
    return msg","Return a string representation of a value and its type for readable
    error messages.",
"def trait_metadata(self, traitname, key):
        """"""Get metadata values for trait by key.""""""
        try:
            trait = getattr(self.__class__, traitname)
        except AttributeError:
            raise TraitError(""Class %s does not have a trait named %s"" %
                                (self.__class__.__name__, traitname))
        else:
            return trait.get_metadata(key)",Get metadata values for trait by key.,
"def validate(self, obj, value):
        """"""Validates that the value is a valid object instance.""""""
        try:
            if issubclass(value, self.klass):
                return value
        except:
            if (value is None) and (self._allow_none):
                return value

        self.error(obj, value)",Validates that the value is a valid object instance.,
"def info(self):
        """""" Returns a description of the trait.""""""
        if isinstance(self.klass, basestring):
            klass = self.klass
        else:
            klass = self.klass.__name__
        result = 'a subclass of ' + klass
        if self._allow_none:
            return result + ' or None'
        return result",Returns a description of the trait.,
"def info(self):
        """""" Returns a description of the trait.""""""
        result = 'any of ' + repr(self.values)
        if self._allow_none:
            return result + ' or None'
        return result",Returns a description of the trait.,
"def _require(*names):
    """"""Helper for @require decorator.""""""
    from IPython.parallel.error import UnmetDependency
    user_ns = globals()
    for name in names:
        if name in user_ns:
            continue
        try:
            exec 'import %s'%name in user_ns
        except ImportError:
            raise UnmetDependency(name)
    return True",Helper for @require decorator.,
"def as_dict(self):
        """"""Represent this dependency as a dict. For json compatibility.""""""
        return dict(
            dependencies=list(self),
            all=self.all,
            success=self.success,
            failure=self.failure
        )",Represent this dependency as a dict. For json compatibility.,
"def Ainv(self):
        'Returns a Solver instance'

        if not hasattr(self, '_Ainv'):
            self._Ainv = self.Solver(self.A)
        return self._Ainv",Returns a Solver instance,
"def Ainv(self):
        'Returns a Solver instance'

        if getattr(self, '_Ainv', None) is None:
            self._Ainv = self.Solver(self.A, 13)
            self._Ainv.run_pardiso(12)
        return self._Ainv",Returns a Solver instance,
"def depth(n, tree):
    """"""get depth of an element in the tree""""""
    d = 0
    parent = tree[n]
    while parent is not None:
        d += 1
        parent = tree[parent]
    return d",get depth of an element in the tree,
"def print_bintree(tree, indent='  '):
    """"""print a binary tree""""""
    for n in sorted(tree.keys()):
        print ""%s%s"" % (indent * depth(n,tree), n)",print a binary tree,
"def disambiguate_dns_url(url, location):
    """"""accept either IP address or dns name, and return IP""""""
    if not ip_pat.match(location):
        location = socket.gethostbyname(location)
    return disambiguate_url(url, location)","accept either IP address or dns name, and return IP",
"def allreduce(self, f, value, flat=True):
        """"""parallel reduce followed by broadcast of the result""""""
        return self.reduce(f, value, flat=flat, all=True)",parallel reduce followed by broadcast of the result,
"def cd(self, newdir):
        """"""
        go to the path
        """"""
        prevdir = os.getcwd()
        os.chdir(newdir)
        try:
            yield
        finally:
            os.chdir(prevdir)",go to the path,
"def run_command_under_r_root(self, cmd, catched=True):
        """"""
        subprocess run on here
        """"""
        RPATH = self.path
        with self.cd(newdir=RPATH):
            if catched:
                process = sp.run(cmd, stdout=sp.PIPE, stderr=sp.PIPE)
            else:
                process = sp.run(cmd)
            return process",subprocess run on here,
"def execute(self):
        """"""
        Execute R script
        """"""
        rprocess = OrderedDict()
        commands = OrderedDict([
            (self.file, ['Rscript', self.file] + self.cmd),
        ])
        for cmd_name, cmd in commands.items():
            rprocess[cmd_name] = self.run_command_under_r_root(cmd)
        
        return self.decode_cmd_out(completed_cmd=rprocess[self.file])",Execute R script,
"def _dispatch(self, msg):
        """""" Calls the frontend handler associated with the message type of the
            given message.
        """"""
        msg_type = msg['header']['msg_type']
        handler = getattr(self, '_handle_' + msg_type, None)
        if handler:
            handler(msg)","Calls the frontend handler associated with the message type of the
            given message.",
"def report(self, morfs, directory=None):
        """"""Run the report.

        See `coverage.report()` for arguments.

        """"""
        self.report_files(self.annotate_file, morfs, directory)","Run the report.

        See `coverage.report()` for arguments.",
"def object_info(**kw):
    """"""Make an object info dict with all fields present.""""""
    infodict = dict(izip_longest(info_fields, [None]))
    infodict.update(kw)
    return infodict",Make an object info dict with all fields present.,
"def __head(self,h):
        """"""Return a header string with proper colors.""""""
        return '%s%s%s' % (self.color_table.active_colors.header,h,
                           self.color_table.active_colors.normal)",Return a header string with proper colors.,
"def noinfo(self, msg, oname):
        """"""Generic message when no information is found.""""""
        print 'No %s found' % msg,
        if oname:
            print 'for %s' % oname
        else:
            print",Generic message when no information is found.,
"def psource(self,obj,oname=''):
        """"""Print the source code for an object.""""""

        # Flush the source cache because inspect can return out-of-date source
        linecache.checkcache()
        try:
            src = getsource(obj)
        except:
            self.noinfo('source',oname)
        else:
            page.page(self.format(py3compat.unicode_to_str(src)))",Print the source code for an object.,
"def to_xml(self):
        """"""Encodes the stored ``data`` to XML and returns
        an ``lxml.etree`` value.
        """"""
        if self.data:
            self.document = self._update_document(self.document, self.data)

        return self.document","Encodes the stored ``data`` to XML and returns
        an ``lxml.etree`` value.",
"def start(self):
        """"""Start this Tracer.

        Return a Python function suitable for use with sys.settrace().

        """"""
        self.thread = threading.currentThread()
        sys.settrace(self._trace)
        return self._trace","Start this Tracer.

        Return a Python function suitable for use with sys.settrace().",
"def pause(self):
        """"""Pause tracing, but be prepared to `resume`.""""""
        for tracer in self.tracers:
            tracer.stop()
            stats = tracer.get_stats()
            if stats:
                print(""\nCoverage.py tracer stats:"")
                for k in sorted(stats.keys()):
                    print(""%16s: %s"" % (k, stats[k]))
        threading.settrace(None)","Pause tracing, but be prepared to `resume`.",
"def resume(self):
        """"""Resume tracing after a `pause`.""""""
        for tracer in self.tracers:
            tracer.start()
        threading.settrace(self._installation_trace)",Resume tracing after a `pause`.,
"def new_code_cell(code=None, prompt_number=None):
    """"""Create a new code cell with input and output""""""
    cell = NotebookNode()
    cell.cell_type = u'code'
    if code is not None:
        cell.code = unicode(code)
    if prompt_number is not None:
        cell.prompt_number = int(prompt_number)
    return cell",Create a new code cell with input and output,
"def new_text_cell(text=None):
    """"""Create a new text cell.""""""
    cell = NotebookNode()
    if text is not None:
        cell.text = unicode(text)
    cell.cell_type = u'text'
    return cell",Create a new text cell.,
"def new_notebook(cells=None):
    """"""Create a notebook by name, id and a list of worksheets.""""""
    nb = NotebookNode()
    if cells is not None:
        nb.cells = cells
    else:
        nb.cells = []
    return nb","Create a notebook by name, id and a list of worksheets.",
"def eq_(a, b, msg=None):
    """"""Shorthand for 'assert a == b, ""%r != %r"" % (a, b)
    """"""
    if not a == b:
        raise AssertionError(msg or ""%r != %r"" % (a, b))","Shorthand for 'assert a == b, ""%r != %r"" % (a, b)",
"def _canonical_dir(self, morf):
        """"""Return the canonical directory of the module or file `morf`.""""""
        return os.path.split(CodeUnit(morf, self.file_locator).filename)[0]",Return the canonical directory of the module or file `morf`.,
"def _source_for_file(self, filename):
        """"""Return the source file for `filename`.""""""
        if not filename.endswith("".py""):
            if filename[-4:-1] == "".py"":
                filename = filename[:-1]
            elif filename.endswith(""$py.class""): # jython
                filename = filename[:-9] + "".py""
        return filename",Return the source file for `filename`.,
"def _warn(self, msg):
        """"""Use `msg` as a warning.""""""
        self._warnings.append(msg)
        sys.stderr.write(""Coverage.py warning: %s\n"" % msg)",Use `msg` as a warning.,
"def _atexit(self):
        """"""Clean up on process shutdown.""""""
        if self._started:
            self.stop()
        if self.auto_data:
            self.save()",Clean up on process shutdown.,
"def _exclude_regex(self, which):
        """"""Return a compiled regex for the given exclusion list.""""""
        if which not in self._exclude_re:
            excl_list = getattr(self.config, which + ""_list"")
            self._exclude_re[which] = join_regex(excl_list)
        return self._exclude_re[which]",Return a compiled regex for the given exclusion list.,
"def analysis(self, morf):
        """"""Like `analysis2` but doesn't return excluded line numbers.""""""
        f, s, _, m, mf = self.analysis2(morf)
        return f, s, m, mf",Like `analysis2` but doesn't return excluded line numbers.,
"def _analyze(self, it):
        """"""Analyze a single morf or code unit.

        Returns an `Analysis` object.

        """"""
        self._harvest_data()
        if not isinstance(it, CodeUnit):
            it = code_unit_factory(it, self.file_locator)[0]

        return Analysis(self, it)","Analyze a single morf or code unit.

        Returns an `Analysis` object.",
"def _find_cmd(cmd):
    """"""Find the full path to a command using which.""""""

    path = sp.Popen(['/usr/bin/env', 'which', cmd],
                    stdout=sp.PIPE, stderr=sp.PIPE).communicate()[0]
    return py3compat.bytes_to_str(path)",Find the full path to a command using which.,
"def get_app_wx(*args, **kwargs):
    """"""Create a new wx app or return an exiting one.""""""
    import wx
    app = wx.GetApp()
    if app is None:
        if not kwargs.has_key('redirect'):
            kwargs['redirect'] = False
        app = wx.PySimpleApp(*args, **kwargs)
    return app",Create a new wx app or return an exiting one.,
"def is_event_loop_running_wx(app=None):
    """"""Is the wx event loop running.""""""
    if app is None:
        app = get_app_wx()
    if hasattr(app, '_in_event_loop'):
        return app._in_event_loop
    else:
        return app.IsMainLoopRunning()",Is the wx event loop running.,
"def start_event_loop_wx(app=None):
    """"""Start the wx event loop in a consistent manner.""""""
    if app is None:
        app = get_app_wx()
    if not is_event_loop_running_wx(app):
        app._in_event_loop = True
        app.MainLoop()
        app._in_event_loop = False
    else:
        app._in_event_loop = True",Start the wx event loop in a consistent manner.,
"def get_app_qt4(*args, **kwargs):
    """"""Create a new qt4 app or return an existing one.""""""
    from IPython.external.qt_for_kernel import QtGui
    app = QtGui.QApplication.instance()
    if app is None:
        if not args:
            args = ([''],)
        app = QtGui.QApplication(*args, **kwargs)
    return app",Create a new qt4 app or return an existing one.,
"def is_event_loop_running_qt4(app=None):
    """"""Is the qt4 event loop running.""""""
    if app is None:
        app = get_app_qt4([''])
    if hasattr(app, '_in_event_loop'):
        return app._in_event_loop
    else:
        # Does qt4 provide a other way to detect this?
        return False",Is the qt4 event loop running.,
"def start_event_loop_qt4(app=None):
    """"""Start the qt4 event loop in a consistent manner.""""""
    if app is None:
        app = get_app_qt4([''])
    if not is_event_loop_running_qt4(app):
        app._in_event_loop = True
        app.exec_()
        app._in_event_loop = False
    else:
        app._in_event_loop = True",Start the qt4 event loop in a consistent manner.,
"def blank_canvas(width, height):
        """"""Return a blank canvas to annotate.

        :param width: xdim (int)
        :param height: ydim (int)
        :returns: :class:`jicbioimage.illustrate.Canvas`
        """"""
        canvas = np.zeros((height, width, 3), dtype=np.uint8)
        return canvas.view(Canvas)","Return a blank canvas to annotate.

        :param width: xdim (int)
        :param height: ydim (int)
        :returns: :class:`jicbioimage.illustrate.Canvas`",
"def get_uuid(length=32, version=1):
    """"""
    Returns a unique ID of a given length.
    User `version=2` for cross-systems uniqueness.
    """"""
    if version == 1:
        return uuid.uuid1().hex[:length]
    else:
        return uuid.uuid4().hex[:length]","Returns a unique ID of a given length.
    User `version=2` for cross-systems uniqueness.",
"def get_dict_to_encoded_url(data):
    """"""
    Converts a dict to an encoded URL.
    Example: given  data = {'a': 1, 'b': 2}, it returns 'a=1&b=2'
    """"""
    unicode_data = dict([(k, smart_str(v)) for k, v in data.items()])
    encoded = urllib.urlencode(unicode_data)
    return encoded","Converts a dict to an encoded URL.
    Example: given  data = {'a': 1, 'b': 2}, it returns 'a=1&b=2'",
"def get_encoded_url_to_dict(string):
    """"""
    Converts an encoded URL to a dict.
    Example: given string = 'a=1&b=2' it returns {'a': 1, 'b': 2}
    """"""
    data = urllib.parse.parse_qsl(string, keep_blank_values=True)
    data = dict(data)
    return data","Converts an encoded URL to a dict.
    Example: given string = 'a=1&b=2' it returns {'a': 1, 'b': 2}",
"def get_unique_key_from_get(get_dict):
    """"""
    Build a unique key from get data
    """"""
    site = Site.objects.get_current()
    key = get_dict_to_encoded_url(get_dict)
    cache_key = '{}_{}'.format(site.domain, key)
    return hashlib.md5(cache_key).hexdigest()",Build a unique key from get data,
"def tobin(deci_num, len=32):
    """"""
    Given a decimal number, returns a string bitfield of length = len
    Example: given deci_num = 1 and len = 10, it return 0000000001
    """"""
    bitstr = """".join(map(lambda y: str((deci_num >> y) & 1), range(len - 1, -1, -1)))
    return bitstr","Given a decimal number, returns a string bitfield of length = len
    Example: given deci_num = 1 and len = 10, it return 0000000001",
"def is_valid_email(email):
    """"""
    Validates and email address.
    Note: valid emails must follow the <name>@<domain><.extension> patterns.
    """"""
    try:
        validate_email(email)
    except ValidationError:
        return False
    if simple_email_re.match(email):
        return True
    return False","Validates and email address.
    Note: valid emails must follow the <name>@<domain><.extension> patterns.",
"def get_domain(url):
    """""" Returns domain name portion of a URL """"""
    if 'http' not in url.lower():
        url = 'http://{}'.format(url)
    return urllib.parse.urlparse(url).hostname",Returns domain name portion of a URL,
"def get_url_args(url):
    """""" Returns a dictionary from a URL params """"""
    url_data = urllib.parse.urlparse(url)
    arg_dict = urllib.parse.parse_qs(url_data.query)
    return arg_dict",Returns a dictionary from a URL params,
